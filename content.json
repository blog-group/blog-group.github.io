{"posts":[{"title":"在阿里Java大牛们都是这样对Java项目代码分层的","text":"代码分层，对于任何一个Java开发来说应该都不陌生。一个好的层次划分不仅可以能使代码结构更加清楚，还可以使项目分工更加明确，可读性大大提升，更加有利于后期的维护和升级。 从另外一个角度来看，好的代码分层架构，应该是可以很好的匹配上单一职责原则的。这样就可以降低层与层之间的依赖，还能最大程度的复用各层的逻辑。本文就来介绍下Java 项目的代码到底应该如何分层。 1. 背景说起应用分层，大部分人都会认为这个不是很简单嘛 就controller，service, mapper三层。看起来简单，很多人其实并没有把他们职责划分开，在很多代码中,controller做的逻辑比service还多,service往往当成透传了，这其实是很多人开发代码都没有注意到的地方，反正功能也能用，至于放哪无所谓呗。这样往往造成后面代码无法复用，层级关系混乱，对后续代码的维护非常麻烦。 的确在这些人眼中分层只是一个形式，前辈们的代码这么写的，其他项目代码这么写的，那么我也这么跟着写。但是在真正的团队开发中每个人的习惯都不同，写出来的代码必然带着自己的标签，有的人习惯controller写大量的业务逻辑，有的人习惯在service中之间调用远程服务，这样就导致了每个人的开发代码风格完全不同，后续其他人修改的时候，一看，我靠这个人写的代码和我平常的习惯完全不同，修改的时候到底是按着自己以前的习惯改，还是跟着前辈们走，这又是个艰难的选择，选择一旦有偏差，你的后辈又维护你的代码的时候，恐怕就要骂人了。 所以一个好的应用分层需要具备以下几点: 方便后续代码进行维护扩展。 分层的效果需要让整个团队都接受 各个层职责边界清晰 2.如何进行分层2.1 阿里规范在阿里的编码规范中约束的分层如下: 开放接口层: 可直接封装 Service 方法暴露成 RPC 接口;通过 Web 封装成 http 接口;进行 网关安全控制、流量控制等。 终端显示层: 各个端的模板渲染并执行显示的层。当前主要是 velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。 Web层: 主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。 Service层 :相对具体的业务逻辑服务层。 Manager层 :通用业务处理层，它有如下特征:1. 对第三方平台封装的层，预处理返回结果及转化异常信息;2. 对Service层通用能力的下沉，如缓存方案、中间件通用处理;3. 与DAO层交互，对多个DAO的组合复用。 DAO层: 数据访问层，与底层 MySQL、Oracle、Hbase 进行数据交互。 阿里巴巴规约中的分层比较清晰简单明了，但是描述得还是过于简单了，以及service层和manager层有很多同学还是有点分不清楚之间的关系，就导致了很多项目中根本没有Manager层的存在。下面介绍一下具体业务中应该如何实现分层 2.2 优化分层从我们的业务开发中总结了一个较为的理想模型,这里要先说明一下由于我们的rpc框架选用的是thrift可能会比其他的一些rpc框架例如dubbo会多出一层,作用和controller层类似 最上层controller和TService是我们阿里分层规范里面的第一层:轻业务逻辑，参数校验，异常兜底。通常这种接口可以轻易更换接口类型,所以业务逻辑必须要轻，甚至不做具体逻辑。 Service：业务层，复用性较低，这里推荐每一个controller方法都得对应一个service,不要把业务编排放在controller中去做，为什么呢？如果我们把业务编排放在controller层去做的话，如果以后我们要接入thrift,我们这里又需要把业务编排在做一次，这样会导致我们每接入一个入口层这个代码都得重新复制一份如下图所示:这样大量的重复工作必定会导致我们开发效率下降，所以我们需要把业务编排逻辑都得放进service中去做: Mannager：可复用逻辑层。这里的Mannager可以是单个服务的，比如我们的cache,mq等等，当然也可以是复合的，当你需要调用多个Mannager的时候，这个可以合为一个Mannager，比如逻辑上的连表查询等。如果是httpMannager或rpcMannager需要在这一层做一些数据转换 DAO：数据库访问层。主要负责“操作数据库的某张表，映射到某个java对象”，dao应该只允许自己的Service访问，其他Service要访问我的数据必须通过对应的Service。 3. 分层领域模型的转换在阿里巴巴编码规约中列举了下面几个领域模型规约: DO（Data Object）：与数据库表结构一一对应，通过DAO层向上传输数据源对象。 DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。 BO（Business Object）：业务对象。由Service层输出的封装业务逻辑的对象。 AO（Application Object）：应用对象。在Web层与Service层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。 Query：数据查询对象，各层接收上层的查询请求。注意超过2个参数的查询封装，禁止使用Map类来传输。层次领域模型Controller/TServiceVO/DTOService/ManagerAO/BODAODO 每一个层基本都自己对应的领域模型，这样就导致了有些人过于追求每一层都是用自己的领域模型，这样就导致了一个对象可能会出现3次甚至4次转换在一次请求中，当返回的时候同样也会出现3-4次转换，这样有可能一次完整的请求-返回会出现很多次对象转换。如果在开发中真的按照这么来，恐怕就别写其他的了，一天就光写这个重复无用的逻辑算了吧。 所以我们得采取一个折中的方案: 1.允许Service/Manager可以操作数据领域模型，对于这个层级来说，本来自己做的工作也是做的是业务逻辑处理和数据组装。2.Controller/TService层的领域模型不允许传入DAO层，这样就不符合职责划分了。3.同理，不允许DAO层的数据传入到Controller/TService. 4. 总结总的来说业务分层对于代码规范是比较重要，决定着以后的代码是否可复用，是否职责清晰，边界清晰。 当然这种分层其实见仁见智, 团队中的所有人的分层习惯也不同，所以很难权衡出一个标准的准则，总的来说只要满足职责逻辑清晰，后续维护容易，就是好的分层。 最后，如果你的团队有更好的分层，或者上面所描述的有什么错误的地方还请留言指正一下。","link":"/alibaba-java-project-layering.html"},{"title":"资源与业务分离Aop的实现方式","text":"本章内容比较偏向系统设计方面，简单的封装就可以应用到系统中使用，从而提高我们的编码效率以及代码的可读性。统一资源在系统内是不可避免的模块，资源分类也有很多种，比较常见如：图片资源、文本资源、视频资源等，那么资源统一处理的好处是什么呢？大家有可能会有疑问，我把资源存放到业务表内岂不更好吗？这样查询起来也方便，并不需要关联资源信息表！当然设计不分好坏，只有更适合、更简单！接下来带着疑问进入本章的内容。 本章目标基于SpringBoot平台结合AOP完成统一资源的自动查询映射。 构建项目本章使用到的依赖相对来说比较多，大致：Web、MapStruct、SpringDataJpa、LomBok等，数据库方面采用MySQL来作为数据支持。 数据初始化本章用到的数据表结构以及初始化的数据之前都是放在项目的resources目录下，为了大家使用方面我在这里直接贴出来，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980---- Table structure for table `hy_common_resource`--DROP TABLE IF EXISTS `hy_common_resource`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `hy_common_resource` ( `CR_ID` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键自增', `CR_TARGET_ID` varchar(36) DEFAULT 'NULL' COMMENT '所属目标编号，关联其他信息表主键，如：用户头像关联用户编号', `CR_TYPE_ID` varchar(36) DEFAULT NULL COMMENT '资源类型编号', `CR_URL` varchar(200) DEFAULT 'NULL' COMMENT '资源路径，如：图片地址', `CR_CREATE_TIME` timestamp NOT NULL DEFAULT current_timestamp() ON UPDATE current_timestamp() COMMENT '资源添加时间', `CR_ORDER` int(11) DEFAULT 0 COMMENT '排序字段', PRIMARY KEY (`CR_ID`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COMMENT='系统资源信息表';/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `hy_common_resource`--LOCK TABLES `hy_common_resource` WRITE;/*!40000 ALTER TABLE `hy_common_resource` DISABLE KEYS */;INSERT INTO `hy_common_resource` VALUES (1,'bc4c8e38-edd6-11e7-969c-3c15c2e4a8a6','ce66916c-edd7-11e7-969c-3c15c2e4a8a6','https://upload.jianshu.io/users/upload_avatars/4461954/f09ba256-f6db-41ed-a4ac-b2d23737f0ac.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96','2017-12-31 03:08:46',0),(2,'bc4c8e38-edd6-11e7-969c-3c15c2e4a8a6','f84f12c4-edd7-11e7-969c-3c15c2e4a8a6','https://upload.jianshu.io/collections/images/358868/android.graphics.Bitmap_d88b4de.jpeg?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240','2017-12-31 03:12:38',0),(3,'bc4c8e38-edd6-11e7-969c-3c15c2e4a8a6','f84f12c4-edd7-11e7-969c-3c15c2e4a8a6','https://upload.jianshu.io/collections/images/522928/kafka_diagram.png?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240','2017-12-31 09:13:32',0);/*!40000 ALTER TABLE `hy_common_resource` ENABLE KEYS */;UNLOCK TABLES;---- Table structure for table `hy_common_resource_type`--DROP TABLE IF EXISTS `hy_common_resource_type`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `hy_common_resource_type` ( `CRT_ID` varchar(36) NOT NULL COMMENT '类型编号', `CRT_NAME` varchar(20) DEFAULT NULL COMMENT '类型名称', `CRT_FLAG` varchar(30) DEFAULT NULL COMMENT '资源标识', `CRT_CREATE_TIME` timestamp NOT NULL DEFAULT current_timestamp() COMMENT '创建时间', PRIMARY KEY (`CRT_ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='资源类型信息表';/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `hy_common_resource_type`--LOCK TABLES `hy_common_resource_type` WRITE;/*!40000 ALTER TABLE `hy_common_resource_type` DISABLE KEYS */;INSERT INTO `hy_common_resource_type` VALUES ('ce66916c-edd7-11e7-969c-3c15c2e4a8a6','用户头像','USER_HEAD_IMAGE','2017-12-31 03:07:59'),('f84f12c4-edd7-11e7-969c-3c15c2e4a8a6','用户背景图片','USER_BACK_IMAGE','2017-12-31 03:09:09');/*!40000 ALTER TABLE `hy_common_resource_type` ENABLE KEYS */;UNLOCK TABLES;---- Table structure for table `hy_user_info`--DROP TABLE IF EXISTS `hy_user_info`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `hy_user_info` ( `UI_ID` varchar(36) NOT NULL COMMENT '主键', `UI_NAME` varchar(10) DEFAULT NULL COMMENT '名称', `UI_NICK_NAME` varchar(20) DEFAULT NULL COMMENT '昵称', `UI_AGE` int(11) DEFAULT NULL COMMENT '年龄', `UI_ADDRESS` varchar(50) DEFAULT NULL COMMENT '所居地', PRIMARY KEY (`UI_ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='用户基本信息表';/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `hy_user_info`--LOCK TABLES `hy_user_info` WRITE;/*!40000 ALTER TABLE `hy_user_info` DISABLE KEYS */;INSERT INTO `hy_user_info` VALUES ('bc4c8e38-edd6-11e7-969c-3c15c2e4a8a6','hengboy','恒宇少年',23,'山东省济南市');/*!40000 ALTER TABLE `hy_user_info` ENABLE KEYS */;UNLOCK TABLES; 用到的数据库为resources，可以自行创建或者更换其他数据库使用。 搭建项目本章我们把统一资源单独拿出来作为一个项目子模块来构建，而用户服务作为另外一个单独模块构建，下面先来贴出父项目的pom.xml配置文件内容，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263....//&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;org.mapstruct.version&gt;1.2.0.Final&lt;/org.mapstruct.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--mapStruct--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.inject&lt;/groupId&gt; &lt;artifactId&gt;javax.inject&lt;/artifactId&gt; &lt;version&gt;1&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring data jpa--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--MySQL--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;....// 接下来我们开始创建common-resource子模块，将资源处理完全独立出来，在创建子模块时要注意package命名要保证可以被SpringBoot运行时扫描到！！！ common-resource我们需要先创建一个BaseEntity作为所有实体的父类存在，如下所示： 1234567891011121314/** * 所有实体的父类 * 作为类型标识存在 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：下午3:35 * 码云：http://git.oschina.net/jnyqy * ======================== */public class BaseEntity implements Serializable{} 该类仅仅实现了Serializable 接口，在创建业务实体时需要继承该类，这也是基本的设计规则，方便后期添加全局统一的字段或者配置。 资源实体 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 资源实体 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:21 * 码云：http://git.oschina.net/jnyqy * ======================== */@Data@Entity@Table(name = &quot;hy_common_resource&quot;)public class CommonResourceEntity extends BaseEntity{ /** * 资源编号 */ @Column(name = &quot;CR_ID&quot;) @Id @GeneratedValue private Integer resourceId; /** * 资源所属目标编号 */ @Column(name = &quot;CR_TARGET_ID&quot;) private String targetId; /** * 类型编号 */ @Column(name = &quot;CR_TYPE_ID&quot;) private String typeId; /** * 资源路径 */ @Column(name = &quot;CR_URL&quot;) private String resourceUrl; /** * 创建时间 */ @Column(name = &quot;CR_CREATE_TIME&quot;) private Timestamp createTime; /** * 排序 */ @Column(name = &quot;CR_ORDER&quot;) private int order;} 资源类型实体 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 资源类型实体 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:22 * 码云：http://git.oschina.net/jnyqy * ======================== */@Data@Entity@Table(name = &quot;hy_common_resource_type&quot;)public class CommonResourceTypeEntity extends BaseEntity{ /** * 类型编号 */ @Id @Column(name = &quot;CRT_ID&quot;) @GeneratedValue(generator = &quot;system-uuid&quot;) @GenericGenerator(name = &quot;system-uuid&quot;, strategy = &quot;uuid&quot;) private String id; /** * 类型名称 */ @Column(name = &quot;CRT_NAME&quot;) private String name; /** * 类型标识 */ @Column(name = &quot;CRT_FLAG&quot;) private String flag; /** * 类型添加时间 */ @Column(name = &quot;CRT_CREATE_TIME&quot;) private Timestamp createTime;} 下面我们来创建对应实体的数据接口，我们采用SpringDataJPA的方法名查询规则来查询对应的数据。 资源数据接口 12345678910111213141516171819202122/** * 资源数据接口 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:31 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface CommonResourceRepository extends JpaRepository&lt;CommonResourceEntity,Integer&gt;{ /** * 根据类型编号 &amp; 目标编号查询出资源实体 * @param typeId 类型编号 * @param targetId 目标编号 * @return */ List&lt;CommonResourceEntity&gt; findByTypeIdAndTargetId(String typeId, String targetId);} 资源类型数据接口 123456789101112131415161718192021/** * 资源类型数据接口 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:32 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface CommonResourceTypeRepository extends JpaRepository&lt;CommonResourceTypeEntity,String&gt;{ /** * 根据类别标识查询 * @param flag 资源类型标识 * @return */ CommonResourceTypeEntity findTopByFlag(String flag);} 接下来我们开始编写根据资源类型获取指定目标编号的资源列表业务逻辑方法，创建名为CommonResourceService统一资源业务逻辑实现类，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * 公共资源业务逻辑实现类 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：下午4:18 * 码云：http://git.oschina.net/jnyqy * ======================== */@Service@Transactional(rollbackFor = Exception.class)public class CommonResourceService { /** * 资源类型数据接口 */ @Autowired private CommonResourceTypeRepository resourceTypeRepository; /** * 资源数据接口 */ @Autowired private CommonResourceRepository resourceRepository; /** * 根据资源标识 &amp; 所属目标编号查询资源路径路边 * * @param resourceFlag 资源标识 * @param targetId 目标编号 * @return */ public List&lt;String&gt; selectUrlsByFlag(CommonResourceFlag resourceFlag, String targetId) throws Exception { /** * 获取资源类型 */ CommonResourceTypeEntity resourceType = selectResourceTypeByFlag(resourceFlag); /** * 查询该目标编号 &amp; 类型的资源列表 */ List&lt;CommonResourceEntity&gt; resources = resourceRepository.findByTypeIdAndTargetId(resourceType.getId(), targetId); return convertUrl(resources); } /** * 转换路径 * 通过实体集合转换成路径集合 * * @param resources 资源实体列表 * @return */ List&lt;String&gt; convertUrl(List&lt;CommonResourceEntity&gt; resources) { List&lt;String&gt; urls = null; if (!ObjectUtils.isEmpty(resources)) { urls = new ArrayList(); for (CommonResourceEntity resource : resources) { urls.add(resource.getResourceUrl()); } } return urls; } /** * 根据资源类型标识查询资源类型基本信息 * * @param resourceFlag 资源类型标识 * @return * @throws Exception */ CommonResourceTypeEntity selectResourceTypeByFlag(CommonResourceFlag resourceFlag) throws Exception { /** * 查询资源类型 */ CommonResourceTypeEntity resourceType = resourceTypeRepository.findTopByFlag(resourceFlag.getName()); if (ObjectUtils.isEmpty(resourceFlag)) { throw new Exception(&quot;未查询到资源&quot;); } return resourceType; }} 在CommonResourceService提供了对外的方法selectUrlsByFlag可以查询指定目标编号 &amp; 指定类型的多个资源地址。 统一资源映射在common-resource子模块项目内添加统一资源的相关映射内容，我们预计的目标效果是根据我们自定义的注解结合AOP来实现指定方法的结果处理映射，我们需要创建两个自定义的注解来完成我们的预想效果，注解分别为：ResourceField、ResourceMethod，下面我们来看看ResourceField注解的属性定义，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 配置统一资源字段 * 该注解配置在普通字段上，根据配置信息自动查询对应的资源地址 * Demo： * * @ResourceField(flag=CommonResourceFlagEnum.SHOP_COVER_IMG) * private String shopCoverImage; * * 其中multiple不需要配置，因为封面只有一张，使用默认值即可 * flag设置为对应的资源标识，资源类型不存在时不执行查询 * @ResourceTargetId 如果注解不存在或目标编号不存在或者为null、&quot;&quot;时不执行查询资源 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with Eclipse. * Date：2017/12/31 * Time：13:11 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)@Documentedpublic @interface ResourceField { /** * 读取资源是单条或者多条 * true：读取多条资源地址，对应设置到List&lt;String&gt;集合内 * false：读取单条资源地址，对应设置配置ResourceField注解的字段value * @return */ boolean multiple() default false; /** * 配置读取统一资源的标识类型 * @return */ CommonResourceFlag flag(); /** * 如果配置该字段则不会去找@Id配置的字段 * 该字段默认为空，则默认使用@Id标注的字段的值作为查询统一资源的target_id * @return */ String targetIdField() default &quot;&quot;;} ResourceField注解用于配置在查询结果的字段上，如：我们查询用户头像时定义的字段为userHeadImage，我们这时仅仅需要在userHeadImage字段上添加ResourceField 即可。另外一个注解ResourceMethod的作用仅仅是为了AOP根据该注解切面方法，也是只有被该注解切面的方法才会去执行AOP切面方法的返回值进行处理，代码如下所示： 123456789101112131415/** * 配置指定方法将会被AOP切面类ResourceAspect所拦截 * 拦截后会根据自定义注解进行查询资源 &amp; 设置资源等逻辑 * @author：于起宇 &lt;br/&gt; * =============================== * Created with Eclipse. * Date：2017/12/15 * Time：14:04 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Documentedpublic @interface ResourceMethod { } 我们的自定义注解已经编写完成，转过头来我们先看看@Around切面方法所需要的逻辑实现方法，创建ResourcePushService接口添加如下两个方法： 12345678910111213141516171819202122232425/** * 统一资源设置业务逻辑定义接口 * @author：于起宇 &lt;br/&gt; * =============================== * Created with Eclipse. * Date：2017/12/15 * Time：14:58 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */public interface ResourcePushService{ /** * 设置单个实例的资源信息 * @param object 需要设置资源的实例 */ void push(Object object) throws Exception; /** * 设置多个实例的资源信息 * @param objectList 需要设置资源的实例列表 */ void push(List&lt;Object&gt; objectList) throws Exception;} 分别提供了设置单个、多个资源的方法，由于实现类内容比较多这里就不贴出具体的实现代码了，详细请下载源码进行查看，源码地址：spring-boot-chapter内的Chapter44项目。 资源切面类我们一直都在说资源统一切面映射，那么我们的资源的切面该如何去配置切面切入点呢？在之前我们创建了ResourceMethod注解，我们就用它作为方法切入点完成切面的环绕实现， ResourceAspect代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 统一资源Aop切面定义 * 根据自定义注解配置自动设置配置的资源类型到指定的字段 * @author：于起宇 &lt;br/&gt; * =============================== * Created with Eclipse. * Date：2017/12/15 * Time：14:05 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Component@Aspectpublic class ResourceAspect{ /** * logback */ Logger logger = LoggerFactory.getLogger(ResourceAspect.class); /** * 资源处理业务逻辑 */ @Autowired @Qualifier(&quot;ResourcePushSupport&quot;) ResourcePushService resourcePushService; /** * 资源设置切面方法 * 拦截配置了@ResourceMethod注解的class method，cglib仅支持class 方法切面，接口切面不支持 * @param proceedingJoinPoint 切面方法实例 * @param resourceMethod 方法注解实例 * @return * @throws Throwable */ @Around(value = &quot;@annotation(resourceMethod)&quot;) public Object resourcePutAround(ProceedingJoinPoint proceedingJoinPoint, ResourceMethod resourceMethod) throws Throwable { logger.info(&quot;开始处理资源自动设置Aop切面逻辑&quot;); /** * 执行方法，获取返回值 */ Object result = proceedingJoinPoint.proceed(); if(StringUtils.isEmpty(result)) {return result;} /** * 返回值为List集合时 */ if(result instanceof List) { List&lt;Object&gt; list = (List&lt;Object&gt;) result; resourcePushService.push(list); } /** * 返回值为单值时，返回的实例类型必须继承BaseEntity */ else if(result instanceof BaseEntity) { resourcePushService.push(result); } logger.info(&quot;资源自动设置Aop切面逻辑处理完成.&quot;); return result; }} 切面环绕方法resourcePutAround 大致流程为： 执行需要切面的方法，获取方法结果 根据方法返回的结果判断是单个、多个对象进行调用不同的方法 统一资源方法自动根据@ResourceField注解配置信息以及对象类型配置@Id字段的值作为目标对象编号设置资源到返回对象内。 返回处理后的对象实例 为了方便配置我们在@ResourceField注解内添加了CommonResourceFlag枚举类型的flag属性，该属性就是配置了资源类型的标识，切面会根据该标识去查询资源的类型编号，再拿着资源类型的编号 &amp; 目标编号去查询资源列表，CommonResourceFlag枚举代码如下所示： 123456789101112131415161718192021222324252627/** * 资源标识枚举 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：下午3:40 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum CommonResourceFlag{ /** * 用户头像 */ USER_HEAD_IMAGE(&quot;USER_HEAD_IMAGE&quot;), /** * 用户背景图片 */ USER_BACK_IMAGE(&quot;USER_BACK_IMAGE&quot;); private String name; CommonResourceFlag(String name) { this.name = name; }} 以上我们简单介绍了common-resource子模块的核心内容以及基本的运行流程原理，下面我们来创建一个user-provider子模块来使用同一资源查询用户的头像、用户背景图片列表。 user-provideruser-provider子模块目内我们预计添加一个查询用户详情的方法，在方法上配置@ResourceMethod注解，这样可以让切面切到该方法，然后在查询用户详情方法返回的对象类型内字段上添加@ResourceField注解并添加对应的资源类型标识配置，这样我们就可以实现资源的自动映射。 由于该模块需要数据库的支持，在application.yml配置文件内添加对应的数据库链接配置信息，如下所示： 12345678910111213#数据源配置spring: jpa: properties: hibernate: show_sql: true format_sql: true datasource: druid: driver-class-name: com.mysql.jdbc.Driver username: root password: 123456 url: jdbc:mysql://127.0.0.1:3306/resources?characterEncoding=utf8 配置文件内使用的druid是alibaba针对SpringBoot封装的jar，提供了yml配置文件相关支持以及提示。 用户实体构建针对数据库内的用户基本信息表我们需要创建对应的Entity实体，代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 用户基本信息实体 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:18 * 码云：http://git.oschina.net/jnyqy * ======================== */@Data@Entity@Table(name = &quot;hy_user_info&quot;)public class UserInfoEntity extends BaseEntity{ /** * 用户编号 */ @Id @GeneratedValue(generator = &quot;system-uuid&quot;) @GenericGenerator(name = &quot;system-uuid&quot;, strategy = &quot;uuid&quot;) @Column(name = &quot;UI_ID&quot;) private String userId; /** * 用户名 */ @Column(name = &quot;UI_NAME&quot;) private String userName; /** * 昵称 */ @Column(name = &quot;UI_NICK_NAME&quot;) private String nickName; /** * 年龄 */ @Column(name = &quot;UI_AGE&quot;) private int age; /** * 所居地 */ @Column(name = &quot;UI_ADDRESS&quot;) private String address;} 由于我们的用户头像以及用户背景图片并没有在用户基本信息表内所以我们需要单独创建一个用户详情实体并继承用户基本信息实体，如下所示： 1234567891011121314151617181920212223242526/** * 用户详情dto映射实体 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:54 * 码云：http://git.oschina.net/jnyqy * ======================== */@Datapublic class UserDetailDTO extends UserInfoEntity{ /** * 用户头像 */ @ResourceField(flag = CommonResourceFlag.USER_HEAD_IMAGE) private String headImage; /** * 背景图片 */ @ResourceField(flag = CommonResourceFlag.USER_BACK_IMAGE,multiple = true) private List&lt;String&gt; backImage;} 在上面实体内我们仅仅是配置了字段所需的资源类型枚举。 我们一般在开发过程中，用户表内对应的实体是不允许根据业务逻辑修改的，如果你需要变动需要继承实体后添加对应的字段即可。 用户数据接口 123456789101112131415161718192021/** * 用户基本信息数据接口 * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:30 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface UserInfoRepository extends JpaRepository&lt;UserInfoEntity,String&gt;{ /** * 根据用户名称查询 * @param userName * @return */ UserInfoEntity findUserInfoEntityByUserName(String userName);} 用户业务逻辑实现 123456789101112131415161718192021222324252627282930313233343536373839/** * 用户基本信息业务逻辑实现 * * @author yuqiyu * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：上午11:53 * 码云：http://git.oschina.net/jnyqy * ======================== */@Service@Transactional(rollbackFor = Exception.class)public class UserInfoService { /** * 用户数据接口 */ @Autowired private UserInfoRepository userInfoRepository; /** * 更新用户名称查询用户详情 * @param userName 用户名 * @return */ @ResourceMethod public UserDetailDTO selectByUserName(String userName) { /** * 获取用户基本信息 */ UserInfoEntity userInfoEntity = userInfoRepository.findUserInfoEntityByUserName(userName); /** * 通过mapStruct转换detailDto */ UserDetailDTO detailDTO = UserMapStruct.INSTANCE.fromUserEntity(userInfoEntity); return detailDTO; }} 我们在方法selectByUserName 上配置了@ResourceMethod，让统一资源可以切面到该方法上，在selectByUserName 方法内我们只需要去处理根据用户名查询的业务逻辑，通过MapStruct进行UserInfoEntity与UserDetailDTO转换。在方法返回对象时就会被资源自动处理分别将查询到的资源设置到UserDetailDTO内的headImage、backImage。 用户控制器我们在控制器内添加一个根据用户名查询用户详情的方法，如下所示： 123456789101112131415161718192021222324252627282930/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：下午3:09 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestController@RequestMapping(value = &quot;/user&quot;)public class UserInfoController{ /** * 用户基本信息业务逻辑实现 */ @Autowired private UserInfoService userInfoService; /** * 根据用户名查询详情 * @param userName 用户名 * @return */ @RequestMapping(value = &quot;/{userName}&quot;,method = RequestMethod.GET) public UserDetailDTO detail(@PathVariable(&quot;userName&quot;) String userName) { return userInfoService.selectByUserName(userName); }} 下面我们来编写一个测试用例，查看是否能够达到我们预计的效果。 测试我们在src/test下创建一个名为CommonResourceTester测试类，代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 测试用例 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/12/31 * Time：下午5:04 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootTest(classes = Chapter44Application.class)@RunWith(SpringRunner.class)public class CommonResourceTester{ /** * 模拟mvc测试对象 */ private MockMvc mockMvc; /** * web项目上下文 */ @Autowired private WebApplicationContext webApplicationContext; /** * 所有测试方法执行之前执行该方法 */ @Before public void before() { //获取mockmvc对象实例 mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); } /** * 测试查询用户详情 * @throws Exception */ @Test public void selectDetail() throws Exception { /** * 发起获取请求 */ MvcResult mvcResult = mockMvc.perform(MockMvcRequestBuilders.get(&quot;/user/hengboy&quot;)) .andDo(MockMvcResultHandlers.log()) .andReturn(); int status = mvcResult.getResponse().getStatus(); mvcResult.getResponse().setCharacterEncoding(&quot;UTF-8&quot;); String responseString = mvcResult.getResponse().getContentAsString(); Assert.assertEquals(&quot;请求错误&quot;, 200, status); System.out.println(responseString); }} 接下来我们执行selectDetail测试方法，看下控制台输出对应的 JSON内容，格式化后如下所示： 123456789101112{ &quot;userId&quot;: &quot;bc4c8e38-edd6-11e7-969c-3c15c2e4a8a6&quot;, &quot;userName&quot;: &quot;hengboy&quot;, &quot;nickName&quot;: &quot;恒宇少年&quot;, &quot;age&quot;: 23, &quot;address&quot;: &quot;山东省济南市&quot;, &quot;headImage&quot;: &quot;https://upload.jianshu.io/users/upload_avatars/4461954/f09ba256-f6db-41ed-a4ac-b2d23737f0ac.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96&quot;, &quot;backImage&quot;: [ &quot;https://upload.jianshu.io/collections/images/358868/android.graphics.Bitmap_d88b4de.jpeg?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240&quot;, &quot;https://upload.jianshu.io/collections/images/522928/kafka_diagram.png?imageMogr2/auto-orient/strip|imageView2/1/w/240/h/240&quot; ]} 根据结果我们可以看到，我们已经自动的读取了配置的资源列表，也通过反射自动设置到字段内。 总结本章的代码比较多，还是建议大家根据源码比对学习，这种方式也是我们在平时开发中总结出来的，我们仅仅需要配置下@ResourceField以及@ResourceMethod就可以了完成资源的自动映射，资源与业务逻辑的耦合度得到的很好的降低。","link":"/aop-resource-load.html"},{"title":"ApiBoot开源框架各个组件的系列使用文章汇总","text":"ApiBoot是什么？ApiBoot是接口服务的落地解决方案，基于SpringBoot编写，可以认为是提供了一系列开箱即用的Starter，通过封装来简化主流第三方框架的集成，从而提高开发者开发效率、学习成本、降低入门门槛，真正的实现开箱即用。 官方文档 &amp; 源码 官方文档：https://apiboot.minbox.org GitHub：https://github.com/minbox-projects/api-boot 码云：https://gitee.com/minbox-projects/api-boot 脚手架：https://gitee.com/minbox-projects/api-boot-admin (基于 “ApiBoot” 的前后分离管理平台基础解决方案脚手架示例) 使用源码：https://gitee.com/minbox-projects/api-boot-chapter 请给我支持ApiBoot框架目前是由博客作者编写开源框架，请给我一定的支持，让我坚持去下，为开源做贡献。 请关注作者的公众号“程序员恒宇少年”，二维码在页面底部，关注后回复资料可获取恒宇少年整理的专属电子小册 请将该页面分享给更多需要它的技术学习爱好者 请给ApiBoot源码仓库点个Star，Watching后可以收到每次发版的通知。 GitHub Gitee 作者推荐我整理了极客时间学习热度比较高的课程，相关SpringCloud、SpringBoot、K8s、数据结构与算法、Jvm调优、架构师修炼等更多内容，有兴趣访问 我的推荐课程 了解详情，还能领取恒宇少年粉丝专属的 ¥199 优惠券。 任务调度组件 分布式任务调度框架ApiBoot Quartz内的两种任务存储方式 这种方式整合Quartz你见过吗？ 分布式调度框架Quartz衍生出的三种任务类型，你用过几个？ 文档组件 使用Swagger2作为文档来描述你的接口信息 Swagger2怎么整合OAuth2来在线调试接口？ 安全组件 OAuth2在内存、Redis、JDBC方式下的多客户端配置 ApiBoot实现零代码整合Spring Security &amp; OAuth2 ApiBoot零代码整合Spring Security的JDBC方式获取AccessToken 见过这么简单的方式整合Spring Security &amp; OAuth2的自定义查询用户吗？ Spring Security &amp; OAuth2实现短信验证码方式获取AccessToken 原来Spring Security整合OAuth2后开放权限拦截路径还能这么玩？ 我以为OAuth2整合JWT是很困难的事情，直到我使用了ApiBoot，一切都变了！ 来看看OAuth2怎么设置AccessToken有效期时间时长 OAuth2使用Redis来存储客户端信息以及AccessToken 分布式日志组件 《ApiBoot新特性》GlobalLog全局日志的使用详解 使用ApiBoot Logging进行统一管理请求日志 将ApiBoot Logging采集的日志上报到Admin 自定义ApiBoot Logging链路以及单元ID 修改ApiBoot Logging日志采集的前缀 ApiBoot Logging忽略路径不进行采集日志 ApiBoot Logging整合Spring Security安全上报日志 ApiBoot Logging整合SpringCloud Eureka负载均衡上报日志 ApiBoot Logging使用SpringCloud Openfeign透传链路信息 ApiBoot Logging使用RestTemplate透传链路信息 ApiBoot Logging Admin可视化界面管理日志 其他组件更多组件的使用文章正在火热连载更新… 作者公众号","link":"/apiboot-all-articles.html"},{"title":"自定义ApiBoot Logging链路以及单元ID","text":"ApiBoot Logging会为每一个请求都对应创建链路编号（TraceID）以及单元编号（SpanID），用于归类每一次请求日志，通过一个链路下日志单元的Parent SpanID可以进行上下级关系的梳理。 前文回顾 /apiboot-unified-manage-request-logs.html /apiboot-report-logs-by-logging-to-admin.html 了解链路编号的传递方式 在每一次请求中链路编号（traceId）、单元编号（spanId）都是通过HttpHeader的方式进行传递，日志的起始位置会主动生成traceId、spanId，而起始位置的Parent SpanId则是不存在的，值为null。 这样每次通过restTemplate、Openfeign的形式访问其他服务的接口时，就会携带起始位置生成的traceId、spanId到下一个服务单元。 默认编号ApiBoot Logging内部提供了默认的编号格式，默认为通用格式，没有区分性，无法从编号上进行区分日志的具体归类。 默认的链路编号ApiBoot Logging内部通过集成minbox-logging日志组件来完成日志的采集等基本功能，每一次生成采集的日志时都会通过LoggingTraceGenerator接口进行生成链路编号（TraceID），该接口源码如下所示： 12345678910111213141516171819202122/** * ApiBoot Logging Tracer * Create new traceId * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-07-10 17:01 * Blog：http://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengboy */public interface LoggingTraceGenerator { /** * create new traceId * * @return traceId * @throws MinBoxLoggingException exception */ String createTraceId() throws MinBoxLoggingException;} ApiBoot Logging默认的链路编号（TraceID）采用的是UUID随机字符串的方式生成的，内部实现是通过LoggingTraceGenerator接口的默认实现类LoggingDefaultTraceGenerator进行生成，生成类源码如下所示： 123456789101112131415161718192021222324/** * ApiBoot Logging Tracer Default Support Instance * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-07-10 17:28 * Blog：http://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengboy */public class LoggingDefaultTraceGenerator implements LoggingTraceGenerator { /** * Use UUID as the default traceId * * @return traceId * @throws MinBoxLoggingException Exception */ @Override public String createTraceId() throws MinBoxLoggingException { return UUID.randomUUID().toString(); }} 默认的单元编号单元编号是一条链路下经过的每一个业务单元的唯一标识，在SpringCloud微服务的场景下每发起一个请求内部通过Openfeign可能会经过多个服务，这样每经过的一个服务称之为单元，而当前这条链路下的单元唯一标识字符串就称为单元编号。 minbox-logging提供了生成单元编号的接口LoggingSpanGenerator，源码如下所示： 123456789101112131415161718192021/** * ApiBoot Logging Span * Create new spanId * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-07-10 17:02 * Blog：http://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengboy */public interface LoggingSpanGenerator { /** * create new spanId * * @return span id * @throws MinBoxLoggingException exception */ String createSpanId() throws MinBoxLoggingException;} spanId默认采用的跟traceId生成方式一致，都是UUID随机字符串，minbox-logging提供了LoggingSpanGenerator接口默认的实现LoggingDefaultSpanGenerator，源码如下所示： 123456789101112131415161718192021222324/** * ApiBoot Logging Default Span * Use By Create New SpanId * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-07-15 17:24 * Blog：http://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengboy */public class LoggingDefaultSpanGenerator implements LoggingSpanGenerator { /** * Create New SpanId * * @return SpanId * @throws MinBoxLoggingException Exception */ @Override public String createSpanId() throws MinBoxLoggingException { return UUID.randomUUID().toString(); }} 自定义编号我们可以根据自己的业务进行自定义traceId、spanId，可以加入一些自己业务的元素，只需要提供minbox-logging提供的生成traceId的接口LoggingTraceGenerator、生成spanId的接口LoggingSpanGenerator对应的实现类，并将实现类交给LoggingFaceBean管理即可。 自定义链路编号12345678910111213141516/** * 自定义traceId生成策略 * * @author 恒宇少年 */public class CustomTraceIdGenerator implements LoggingTraceGenerator { /** * 链路编号前缀 */ private static final String TRACE_ID_PREFIX = &quot;local&quot;; @Override public String createTraceId() throws MinBoxLoggingException { return TRACE_ID_PREFIX + UUID.randomUUID().toString().hashCode(); }} 我们创建名为CustomTraceIdGenerator的类并实现LoggingTraceGenerator接口，实现createTraceId()方法的返回值根据local-作为前缀，拼接UUID随机字符串的hashCode值作为后缀。 自定义单元编号12345678910111213141516/** * 自定义单元编号生成策略 * * @author 恒宇少年 */public class CustomSpanIdGenerator implements LoggingSpanGenerator { /** * 单元编号前缀 */ private static final String SPAN_ID_PREFIX = &quot;group&quot;; @Override public String createSpanId() throws MinBoxLoggingException { return SPAN_ID_PREFIX + UUID.randomUUID().toString().hashCode(); }} 我们创建名为CustomSpanIdGenerator的类并实现LoggingSpanGenerator接口，在createSpanId()方法的返回值根据group-作为前缀，使用UUID随机字符串的hashCode值作为后缀。 在上面我们已经创建了自定义traceId以及spanId的实现类，我们需要将实现类的实例交给LoggingFactoryBean管理，这样我们才可以实现自定义编号。 LoggingFactoryBeanCustomizerApiBoot Logging提供了一个自定义设置LoggingFactoryBean的接口LoggingFactoryBeanCustomizer，通过该接口可以修改LoggingFactoryBean内允许修改的任意值。 我们创建名为CustomCreateTraceAndSpanId类并实现LoggingFactoryBeanCustomizer接口，源码如下所示： 123456789101112131415161718192021222324252627/** * 自定义创建链路以及单元编号 * * @author 恒宇少年 * @see LoggingFactoryBeanCustomizer * @see LoggingFactoryBean * @see org.minbox.framework.logging.client.tracer.LoggingTraceGenerator * @see org.minbox.framework.logging.client.span.LoggingSpanGenerator */@Componentpublic class CustomCreateTraceAndSpanId implements LoggingFactoryBeanCustomizer { /** * {@link CustomTraceIdGenerator} 自定义链路编号生成策略 * {@link CustomSpanIdGenerator} 自定义单元编号生成策略 * * @param factoryBean {@link LoggingFactoryBean} */ @Override public void customize(LoggingFactoryBean factoryBean) { CustomTraceIdGenerator traceIdGenerator = new CustomTraceIdGenerator(); factoryBean.setTraceGenerator(traceIdGenerator); CustomSpanIdGenerator spanIdGenerator = new CustomSpanIdGenerator(); factoryBean.setSpanGenerator(spanIdGenerator); }} customize这种设计方式是在SpringBoot中比较常见的，ApiBoot也沿用了这种设计方式，customize（）方法提供了LoggingFactoryBean对象实例作为参数，我们可以直接通过setXxx方法进行修改内定义的默认配置。 通过facetory.setTraceGenerator方法可以修改默认的traceId生成策略。 通过facetory.setSpanGenerator方法可以修改默认的spanId生成策略。 测试启动项目后我们来查看控制台打印的日志内容，确认是否修改成功。 1234567891011121314151617181920212223{ &quot;endTime&quot;:1571711067664, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;accept&quot;:&quot;*/*&quot;, &quot;host&quot;:&quot;localhost:8080&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{}&quot;, &quot;requestUri&quot;:&quot;/index&quot;, &quot;responseBody&quot;:&quot;this is index.&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;apiboot-custom-logging-traceid&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;8080&quot;, &quot;spanId&quot;:&quot;group-1780993769&quot;, &quot;startTime&quot;:1571711067643, &quot;timeConsuming&quot;:21, &quot;traceId&quot;:&quot;local1111437283&quot;} traceId、spanId已经修改成我们自定义的编号生成策略方式。 敲黑板划重点本章节主要是讲到了如何自定义traceId以及spanId，我们可以通过LoggingFactoryBeanCustomizer对LoggingFactoryBean对象进行深度的自定义配置，有关ApiBoot Logging使用的正确姿势还有很多，敬请期待。 请结合文中前文回顾部分进行编写测试。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-custom-logging-traceid： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-custom-logging-traceid.html"},{"title":"使用ApiBoot来自定义OAuth2的GrantType授权方式","text":"Spring提供的原生的OAuth2依赖内置了几种比较常用的授权方式：password、authorization-code、client_credentials、refresh_token、implicit等，虽然可以满足我们日常的需求，不过针对一些特殊的需求还是捉襟见肘，有点无奈，比如：微信登录、短信登录…，针对这一点ApiBoot通过修改Spring OAuth2依赖的源码，可以根据业务进行自定义添加grantType。 ApiBoot官方文档：https://apiboot.minbox.org 创建项目我们先来使用IDEA创建本章的项目，pom.xml添加的依赖如下所示： 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-mybatis-enhance&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; ApiBoot MyBatis Enhance使用文档详见ApiBoot Mybatis Enhance官网文档。 本章的源码在ApiBoot零代码整合Spring Security的JDBC方式获取AccessToken基础上进行修改，将之前章节源码的application.yml、SystemUser、SystemUserEnhanceMppaer、UserService文件复制到本章项目对应的目录内。 验证码登录逻辑本章来讲下使用ApiBoot怎么完成自定义短信验证码登录的授权方式。 在短信验证码登录的逻辑中，大致的流程如下所示： 用户在获取验证码时，系统会将验证码保存到数据库内 当用户输入验证码后提交登录时，读取验证码并判断有效性后 最后获取手机号对应的用户信息完成登录逻辑。 返回请求令牌 根据验证码登录的流程来看我们首先需要创建一个验证码数据表，用来保存用户发送的验证码数据，在第3步中需要通过手机号获取对应的用户信息，所以我们还要修改之前章节创建的表结构，添加一列，下面我们开始进行改造。 验证码表结构在数据库内创建一个名为phone_code的数据表，并初始化一条验证码数据（模拟已经用户已经发送了验证码），SQL如下所示： 123456789CREATE TABLE `phone_code` ( `pc_id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键自增', `pc_phone` varchar(11) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '手机号', `pc_code` varchar(6) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '验证码内容', `pc_create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '验证码生成时间', PRIMARY KEY (`pc_id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='手机号验证码信息表';-- 初始化验证码数据INSERT INTO `phone_code` VALUES (1,'17111111111','123123','2019-12-04 03:01:05'); 验证码实体对应phone_code表结构编写一个数据实体，如下所示： 12345678910111213141516171819202122232425262728293031/** * 手机号验证码信息表 * * @author 恒宇少年 */@Data@Table(name = &quot;phone_code&quot;)public class PhoneCode { /** * 验证码主键 */ @Column(name = &quot;pc_id&quot;) @Id(generatorType = KeyGeneratorTypeEnum.AUTO) private Integer id; /** * 手机号 */ @Column(name = &quot;pc_phone&quot;) private String phone; /** * 验证码内容 */ @Column(name = &quot;pc_code&quot;) private String code; /** * 创建时间 */ @Column(name = &quot;pc_create_time&quot;) private Timestamp createTime;} 验证码数据接口为PhoneCode验证码数据实体添加一个查询的数据接口，实现ApiBoot MyBatis Enhance提供的EnhanceMapper&lt;Entity,ID&gt;接口，如下所示： 123456789101112131415/** * 手机号验证码数据接口 * * @author 恒宇少年 */public interface PhoneCodeEnhanceMapper extends EnhanceMapper&lt;PhoneCode, Integer&gt; { /** * 查询手机号验证码信息 * * @param phone {@link PhoneCode#getPhone()} * @param code {@link PhoneCode#getCode()} * @return {@link PhoneCode} */ PhoneCode findByPhoneAndCode(@Param(&quot;phone&quot;) String phone, @Param(&quot;code&quot;) String code);} 通过ApiBoot MyBatis Enhance提供的方法命名规则查询语法，我们可以根据指定的phone、code查询出对应的记录。 验证码业务逻辑为验证码查询提供一个业务逻辑实现类，如下所示： 123456789101112131415161718192021222324/** * 验证码业务逻辑实现 * * @author 恒宇少年 */@Servicepublic class PhoneCodeService { /** * 手机号验证码数据接口 */ @Autowired private PhoneCodeEnhanceMapper mapper; /** * 查询手机号验证码 * * @param phone {@link PhoneCode#getPhone()} * @param code {@link PhoneCode#getCode()} * @return */ public PhoneCode findPhoneCode(String phone, String code) { return mapper.findByPhoneAndCode(phone, code); }} 修改用户表结构我们在ApiBoot零代码整合Spring Security的JDBC方式获取AccessToken文章内创建的system_user用户表的基础上添加一个字段，如下所示： 12alter table system_user add su_phone varchar(11) null comment '手机号'; 字段添加后初始化表内yuqiyu这条数据的列值，我在phone_code表内添加的手机号为17111111111，所以我需要更新su_phone字段的值为17111111111。 了解ApiBootOauthTokenGranter基础的代码实现我们都已经准备好了，下面我们来介绍下本章的主角ApiBootOauthTokenGranter接口，该接口为自定义GrantType而生，由ApiBoot OAuth2提供，源码如下所示： 1234567891011121314151617181920212223242526272829/** * ApiBoot Integrates Oauth2 to Realize Custom Authorization to Acquire Token * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-05-28 09:57 * Blog：http://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengboy */public interface ApiBootOauthTokenGranter extends Serializable { /** * oauth2 grant type for ApiBoot * * @return grant type */ String grantType(); /** * load userDetails by parameter * * @param parameters parameter map * @return UserDetails * @throws ApiBootTokenException * @see UserDetails */ UserDetails loadByParameter(Map&lt;String, String&gt; parameters) throws ApiBootTokenException;} grantType()：该方法的返回值用于告知OAuth2自定义的GrantType是什么，根据自己的业务逻辑而定。 loadByParameter：该方法是自定义GrantType的业务实现，parameters参数内包含了自定义授权请求/oauth/token时所携带的全部参数，如：/oauth/token?grant_type=phone_code&amp;phone=xx&amp;code=xx，会把phone、code参数一并传递给该方法。 实现短信验证码授权方式下面我们来创建一个名为PhoneCodeGrantType的自定义授权类，实现ApiBootOauthTokenGranter接口，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 手机验证码OAuth2的认证方式实现 * * @author 恒宇少年 * @see ApiBootOauthTokenGranter */@Componentpublic class PhoneCodeGrantType implements ApiBootOauthTokenGranter { /** * 手机号验证码方式的授权方式 */ private static final String GRANT_TYPE_PHONE_CODE = &quot;phone_code&quot;; /** * 授权参数：手机号 */ private static final String PARAM_PHONE = &quot;phone&quot;; /** * 授权参数：验证码 */ private static final String PARAM_CODE = &quot;code&quot;; /** * 手机号验证码业务逻辑 */ @Autowired private PhoneCodeService phoneCodeService; /** * 系统用户业务逻辑 */ @Autowired private UserService userService; @Override public String grantType() { return GRANT_TYPE_PHONE_CODE; } /** * 根据自定义的授权参数进行查询用户信息 * * @param parameters * @return * @throws ApiBootTokenException */ @Override public UserDetails loadByParameter(Map&lt;String, String&gt; parameters) throws ApiBootTokenException { String phone = parameters.get(PARAM_PHONE); String code = parameters.get(PARAM_CODE); PhoneCode phoneCode = phoneCodeService.findPhoneCode(phone, code); if (ObjectUtils.isEmpty(phoneCode)) { throw new ApiBootTokenException(&quot;登录失败，验证码：&quot; + code + &quot;，已过期.&quot;); } UserDetails userDetails = userService.findByPhone(phone); if (ObjectUtils.isEmpty(userDetails)) { throw new ApiBootTokenException(&quot;用户：&quot; + phone + &quot;，不存在.&quot;); } return userDetails; }} 在loadByParameter方法内，我们首先获取到了本次登录的手机号（phone）、验证码（code）这两个参数，查询是否存在这条验证码的记录（PS：这里没做验证码过期时间限制，自己的业务请把这块加上），验证码验证通过后查询出手机号对应的用户信息并将用户返回交付给ApiBoot OAuth2框架来完成验证。 在验证业务逻辑方法内如果出现异常可以直接使用ApiBootTokenException异常进行抛出。 运行测试将我们的项目运行起来，下面通过CURL的方式尝试获取AccessToken，如下所示： 12➜ ~ curl -X POST hengboy:chapter@localhost:9090/oauth/token -d 'grant_type=phone_code&amp;phone=17111111111&amp;code=123123'{&quot;access_token&quot;:&quot;30e3f7d0-8c53-4dfe-b1ff-523a1db7b9eb&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;4b1f0ad5-f869-46ca-8b45-0231e69316b3&quot;,&quot;expires_in&quot;:7194,&quot;scope&quot;:&quot;api&quot;} 使用postman方式获取AccessToken，如下图所示： 敲黑板，划重点本章根据短信验证码登录的例子来给大家讲解了使用ApiBoot OAuth2怎么进行自定义授权方式来获取AccessToken，例子讲解注重点是在自定义GrantType，在生产使用时还请根据各种情况进行验证，保证数据的安全性。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-define-oauth-grant-type： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-define-oauth-grant-type.html"},{"title":"ApiBoot Logging Admin可视化界面管理日志","text":"ApiBoot Logging Admin支持界面可视化查看请求日志信息，初期版本支持查看上报日志的服务列表、最新的链路日志等功能，还可以整合Spring Security配置用户名、密码 创建Logging Admin项目我们需要创建一个SpringBoot项目，并添加ApiBoot Logging Admin相关的依赖以及配置信息。 添加依赖在项目的pom.xml配置文件内添加如下依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;!--Spring Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--MySQL--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging Admin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging-admin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Mybatis Enhance--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-mybatis-enhance&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--版本依赖--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置数据源我们需要连接到Logging Admin所需要的数据库上，具体的数据库表结构请访问【将ApiBoot Logging采集的日志上报到Admin】查看. 修改application.yml配置文件添加相关数据源信息如下所示： 1234567891011121314# 服务名称spring: application: name: logging-admin # 数据源相关配置 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/test username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource# 服务端口号server: port: 8080 配置日志输出 &amp; 美化修改application.yml配置文件添加ApiBoot Logging Admin相关配置信息，如下所示： 123456789api: boot: logging: # Logging Admin相关配置 admin: # 控制台显示采集的日志信息 show-console-report-log: true # 美化日志 format-console-log-json: true 集成Spring Security当我们集成Spring Security时，直接访问 http://localhost:8080 就可以查看ApiBoot Logging Admin提供的可视化界面，不过为了安全起见，我们添加Spring Security依赖并对应配置内存用户信息，在pom.xml文件内添加依赖如下所示： 12345&lt;!--Spring Security--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置安全用户spring-boot-starter-security依赖提供了内存方式配置用户信息，在application.yml文件配置用户如下所示： 1234567# 服务名称spring: # 整合Spring Security，配置内存用户 security: user: name: admin password: admin123 运行测试通过XxxApplication方式启动本章项目。 在浏览器内访问 http://localhost:8080 地址，效果如下所示： 因为Spring Security的安全拦截，会直接跳转到ApiBoot Logging Admin内置的登录页面，输入我们在application.yml配置的用户名、密码即可登录。 链路日志列表登录成功后会跳转到链路日志列表页面，点击每一行链路日志都可以展开查看详情，效果如下所示： 日志服务列表日志服务菜单内可以查看每一个服务的基本信息，最后上报的时间以及第一次上报日志的时间，如下图所示： 敲黑板，划重点ApiBoot Logging Admin目前支持可视化界面查看日志、服务基本信息，功能还在不断丰富，完整度有待提高。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-admin-visual-interface-management-log： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-admin-visual-interface-management-log.html"},{"title":"ApiBoot Logging整合SpringCloud Eureka负载均衡上报日志","text":"ApiBoot Logging支持整合服务注册中心（Eureka、Consul、Nacos Discovery、Zookeeper…）进行上报请求日志，Logging Client会从服务注册中心内找到指定ServiceID的Logging Admin具体可用实例，通过SpringCloud Discovery内部的负载均衡策略返回Logging Admin的部署服务器IP以及端口号，这样Logging Client就可以完成请求日志的上报流程。 搭建Eureka Server我们先来搭建一个Eureka Server，请访问【/eureka-server.html】文章内容查看具体搭建流程。 将Logging Admin注册到Eureka既然使用的是服务注册中心，我们需要将之前章节将的Logging Admin进行简单的改造，添加Eureka客户端相关的依赖，并在application.yml配置文件内添加Eureka Server的相关配置，如果对Logging Admin不了解的同学可以访问【/apiboot-report-logs-by-logging-to-admin.html】查看文章内容，文章底部有源码。 添加Eureka Client依赖我们需要将Logging Admin注册到Eureka Server，对于Eureka Server而言Logging Admin是一个客户端（Eureka Client）角色。 我们在pom.xml文件内添加如下配置： 12345&lt;!--Eureka Client--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启用Eureka Client添加依赖后我们还需要在XxxApplication入口类添加@EnableDiscoveryClient注解来启用Eureka Client的相关功能，如下所示： 1234567891011121314@SpringBootApplication@EnableLoggingAdmin@EnableDiscoveryClientpublic class LoggingAdminApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(LoggingAdminApplication.class); public static void main(String[] args) { SpringApplication.run(LoggingAdminApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;日志管理中心&quot;); }} 配置注册到Eureka Server我们在application.yml配置文件内添加连接到Eureka Server的相关配置信息，如下所示： 1234567# Eureka Configeureka: client: service-url: defaultZone: http://127.0.0.1:10000/eureka/ instance: prefer-ip-address: true 将Logging Client注册到EurekaLogging Client其实就是我们的业务服务，不要被名称误导，我们在本章源码内创建一个user-service模块来作为测试的业务服务，我们也需要将user-service作为客户端注册到Eureka Server，可参考【使用ApiBoot Logging进行统一管理请求日志】文章内容创建项目。 添加Eureka Client依赖在pom.xml配置文件内添加如下依赖： 12345&lt;!--Eureka Client--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启用Eureka Client添加依赖后同样需要启用Eureak Client，这是必不可少的步骤，在我们的入口类XxxApplication上添加如下所示： 1234567891011121314@SpringBootApplication@EnableDiscoveryClient@EnableLoggingClientpublic class UserServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(UserServiceApplication.class); public static void main(String[] args) { SpringApplication.run(UserServiceApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;用户&quot;); }} 配置注册到Eureka Server我们在application.yml配置文件内添加Eureka Server的相关配置信息，如下所示： 1234567# Eureka Configeureka: client: service-url: defaultZone: http://127.0.0.1:10000/eureka/ instance: prefer-ip-address: true 配置Logging Admin服务信息这是本章的核心内容，我们在之前都是通过api.boot.logging.admin.server-address参数进行配置Logging Admin的IP地址以及服务端口号，而本章我们就要借助服务注册中心（Eureka Server）来从实例列表中获取Logging Admin服务信息，ApiBoot Logging提供了一个配置参数api.boot.logging.discovery.service-id进行配置Logging Admin的ServiceID，也就是spring.application.name参数对应的值，如下所示： 123456789# ApiBoot Configapi: boot: logging: discovery: # Logging Admin ServiceID service-id: logging-admin show-console-log: true format-console-log-json: true 每当我们发起请求时，Logging Client就会从Eureak Server内获取ServiceID = logging-admin的服务列表，负载均衡筛选后获取一个可用的实例信息进行上报日志。 运行测试我们将本章源码内用到的三个服务eureka-server、logging-admin、user-service依次启动。 通过curl命令访问user-service提供的Controller地址，如下所示： 12➜ ~ curl http://localhost:9090/test\\?name\\=admin你好：admin 我们可以在logging-admin控制台看到user-service上报的请求日志信息，如下所示： 12345678910111213141516171819202122232425Receiving Service: 【user-service -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1572921905360, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;host&quot;:&quot;localhost:9090&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot;, &quot;accept&quot;:&quot;*/*&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{\\&quot;name\\&quot;:\\&quot;admin\\&quot;}&quot;, &quot;requestUri&quot;:&quot;/test&quot;, &quot;responseBody&quot;:&quot;你好：admin&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;user-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;9090&quot;, &quot;spanId&quot;:&quot;d97c515f-a147-4f89-9c59-398905c95a73&quot;, &quot;startTime&quot;:1572921905336, &quot;timeConsuming&quot;:24, &quot;traceId&quot;:&quot;5e6c0357-1625-4a28-af18-cacdddba146a&quot; }] 自此我们已经成功的整合Eureka与ApiBoot Logging。 敲黑板，划重点ApiBoot Logging内部提供的两种获取Logging Admin服务信息的方式，分别是：service-id、server-address，都是比较常用的，使用service-id方式可以无缝整合SpringCloud进行使用，而链路信息可以通过Openfeign、RestTemplate进行传递，这会在我们后期的知识点中讲到。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-integrates-eureka-report-logs： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-integrates-eureka-report-logs.html"},{"title":"ApiBoot Logging整合Spring Security安全上报日志","text":"ApiBoot Logging在上报日志时虽然是一般通过内网的形式部署，不过安全方面还是主要依赖于服务器的安全策略（防火墙），为了提高日志上报的安全性，ApiBoot Logging支持了整合Spring Security来使用Basic Auth的形式上传日志信息。 创建Logging Admin项目我们需要在集成ApiBoot Logging Admin项目内添加Spring Security相关依赖来完成安全配置，我们需要创建一个Logging Admin项目，可参考【/apiboot-report-logs-by-logging-to-admin.html】文章内容。 集成Spring Security在Logging Admin项目pom.xml文件内添加Spring Security依赖，如下所示： 12345&lt;!--SpringBoot Security--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 配置Spring Security认证用户我们使用SpringBoot集成Spring Security提供的配置文件的方式配置Basic User信息，这种方式使用的是内存方式，用户信息被存储在内存中，如果你需要从数据库内读取，可以查看Spring Security的UserDetails具体使用方法。 application.yml文件添加如下配置： 123456spring: # 配置内存方式Spring Security用户信息 security: user: name: admin password: admin123 创建Logging Client项目我们的业务服务需要集成ApiBoot Logging依赖（作为Logging Client进行上报请求日志），可参考【/apiboot-unified-manage-request-logs.html】文章内容创建项目。 配置安全上报如果使用过Eureka的小伙伴应该对路径配置Basic User的方式不陌生，格式为：username:password@ip:port。 application.yml修改上报的Logging Admin路径如下所示： 12345678910api: boot: logging: # 美化打印日志 format-console-log-json: true # 控制台显示打印日志 show-console-log: true # 配置Logging Admin admin: server-address: admin:admin123@127.0.0.1:8081 我们在Logging Admin配置的用户名为：admin，密码为：admin123，而@符号后面就是Logging Admin的IP地址以及端口号。 测试下面我们进行测试Spring Security是否起到了作用。 依次启动Logging Admin、Logging Client，通过以下命令访问接口： 12➜ ~ curl http://localhost:8080/test\\?name\\=admin 你好：admin 在Logging Admin控制台可以看到上报的请求日志信息时，证明我们已经安全的上报了日志，如果Logging Client控制台打印401 Exception认证错误信息，请检查Logging Client配置的路径Basic User是否正确。 敲黑板，划重点请求日志是用来检查接口的稳定性、排除一些请求异常问题的主要凭据，所以我们尽可能要保证数据的有效性、安全性，建议搭配Spring Security一块使用ApiBoot Logging。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-integrates-spring-security： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-integrates-spring-security.html"},{"title":"ApiBoot接口服务框架的又一新特性GlobalLog全局日志的使用详解","text":"全局日志是一个什么概念呢？其实理解起来比较简单，类似于我们平时一直在使用的logback、log4j这种的日志框架的其中一个功能部分，minbox-logging分布式日志框架目前独立于api-boot-plugins，已经加入了minbox-projects开源组织，之前博客有一系列的文章来讲解了ApiBoot Logging（内部是集成的minbox-logging）日志组件的使用以及极简的配置方式，可以访问ApiBoot 组件系列文章使用汇总了解日志组件的使用详情。 什么是全局日志？在之前ApiBoot Logging分布式日志组件可以实现日志采集、日志上报、日志统一存储、集成Spring Security、集成Openfeign等功能，随着ApiBoot Logging 2.2.1.RELEASE版本的发布引入了一个新的概念，那就是GlobalLog。 用过ApiBoot Logging日志组件的同学应该都有了解，它只会记录每一次发送请求相关的一些信息，如：请求参数、请求地址、请求头信息、响应内容等，并没有提供业务代码中的debug、info、error等级日志的采集方式，就不要提上报这种日志到Logging Admin了。 新版本的发布给我们带来了春天，ApiBoot Logging为了方便代码的调试，执行时业务数据的监控，支持了采集业务代码内的不同等级的日志，而且还支持采集Exception的堆栈信息，方便定位错误，及时纠正。 了解GlobalLogging接口为了支持业务全局日志，新版本中引入了GlobalLogging接口，我们先来看看这个接口的源码，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Global log collection interface * Provide debug, info, and error log collection * * @author 恒宇少年 */public interface GlobalLogging { /** * Collect Debug Level Logs * * @param msg log content */ void debug(String msg); /** * Collect Debug Level Logs * * @param format Unformatted log content * @param arguments List of parameters corresponding to log content */ void debug(String format, Object... arguments); /** * Collect Info Level Logs * * @param msg log content */ void info(String msg); /** * Collect Info Level Logs * * @param format Unformatted log content * @param arguments List of parameters corresponding to log content */ void info(String format, Object... arguments); /** * Collect Error Level Logs * * @param msg log content */ void error(String msg); /** * Collect Error Level Logs * * @param msg log content * @param throwable Exception object instance */ void error(String msg, Throwable throwable); /** * Collect Error Level Logs * * @param format Unformatted log content * @param arguments List of parameters corresponding to log content */ void error(String format, Object... arguments);} 在GlobalLogging接口内提供了三种类型的日志采集方法，分别是：debug、info、error，这个版本只是对日志的等级进行了划分，并没有添加限制或者过滤机制。 GlobalLogging当前版本有一个实现类org.minbox.framework.logging.client.global.support.GlobalLoggingMemoryStorage，该类实现了GlobalLogging内的全部方法，并将采集到的日志保存到了GlobalLoggingThreadLocal，方便统一上报到Logging Admin。 为了方便后期修改Global Log的存储方式，ApiBoot Logging提供了一个配置参数api.boot.logging.global-logging-storage-away，该配置的默认值为memory，对应GlobalLoggingMemoryStorage实现类。 GlobalLogging自动化配置ApiBoot Logging根据api.boot.logging.global-logging-storage-away配置参数，条件判断自动化配置了GlobalLogging接口的实现类，如下所示： 12345678910111213141516171819202122package org.minbox.framework.api.boot.autoconfigure.logging;import .../** * the &quot;minbox-logging&quot; global log storage configuration * * @author 恒宇少年 */@Configuration@ConditionalOnClass(GlobalLogging.class)public class ApiBootLoggingGlobalLogStorageAutoConfiguration { /** * Instance global log memory mode storage * * @return {@link GlobalLoggingMemoryStorage} */ @Bean @ConditionalOnProperty(prefix = API_BOOT_LOGGING_PREFIX, name = &quot;global-logging-storage-away&quot;, havingValue = &quot;memory&quot;, matchIfMissing = true) public GlobalLogging globalLogging() { return new GlobalLoggingMemoryStorage(); }} 根据globalLogging()方法上的条件注入注解@ConditionalOnProperty配置内容可以了解到，当我们在application.yml配置文件内添加api.boot.logging.global-logging-storage-away=memory时或者缺少该配置时，该方法会被调用并且创建一个GlobalLoggingMemoryStorage对象实例，并将该实例对象写入到IOC容器内，这样我们在使用GlobalLogging实例时，只需要注入就可以了，如下所示： 12345678/** * {@link GlobalLogging} * * @see org.minbox.framework.logging.client.global.AbstractGlobalLogging * @see org.minbox.framework.logging.client.global.support.GlobalLoggingMemoryStorage */@Autowiredprivate GlobalLogging logging; 使用GlobalLogging采集的方式很简单，我们只需要注入GlobalLogging对象，使用该接口提供的方法即可，如下所示： 1234567891011121314151617181920212223242526272829/** * 测试用户控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/user&quot;)public class UserController { /** * {@link GlobalLogging} * * @see org.minbox.framework.logging.client.global.AbstractGlobalLogging * @see org.minbox.framework.logging.client.global.support.GlobalLoggingMemoryStorage */ @Autowired private GlobalLogging logging; /** * 测试获取用户名 * * @return */ @GetMapping(value = &quot;/name&quot;) public String getUserName() { logging.debug(&quot;这是一条debug级别的日志&quot;); logging.info(&quot;这是一条info级别的日志&quot;); return &quot;用户名：恒宇少年&quot;; }} 当我们调用GlobalLogging提供的不同日志等级的方法时，会自动将日志相关信息写入到GlobalLoggingThreadLocal的集合内，等到上报请求日志时一并提交给Logging Admin，由Logging Admin进行保存。 GlobalLogging表结构GlobalLogging相关的全局日志采集到Logging Admin需要进行保存，所有对应添加了一个名为logging_global_logs信息表，结构如下所示： 1234567891011121314CREATE TABLE `logging_global_logs` ( `lgl_id` varchar(36) COLLATE utf8mb4_general_ci NOT NULL COMMENT '日志主键', `lgl_request_log_id` varchar(36) COLLATE utf8mb4_general_ci NOT NULL COMMENT '请求日志编号，关联logging_request_logs主键', `lgl_level` varchar(20) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '日志等级', `lgl_content` mediumtext COLLATE utf8mb4_general_ci COMMENT '日志内容', `lgl_caller_class` varchar(200) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '日志输出的类名', `lgl_caller_method` varchar(50) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '日志输出的方法名称', `lgl_caller_code_line_number` int(11) DEFAULT NULL COMMENT '日志输出的代码行号', `lgl_exception_stack` mediumtext COLLATE utf8mb4_general_ci COMMENT 'error等级的日志异常堆栈信息', `lgl_create_time` mediumtext COLLATE utf8mb4_general_ci COMMENT '日志发生时间', PRIMARY KEY (`lgl_id`), KEY `logging_global_logs_logging_request_logs_lrl_id_fk` (`lgl_request_log_id`), CONSTRAINT `logging_global_logs_logging_request_logs_lrl_id_fk` FOREIGN KEY (`lgl_request_log_id`) REFERENCES `logging_request_logs` (`lrl_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='全局日志信息表'; 采集Exception堆栈信息使用GlobalLogging可以采集遇到异常的详细堆栈信息，可以让我们直接定位到问题出现的位置，在第一时间解决出现的问题，具体使用如下所示： 12345try { int a = 5 / 0;} catch (Exception e) { logging.error(e.getMessage(), e);} 运行测试我们来运行本章的源码，看下日志采集的效果。 输出的采集日志12345678910111213141516171819202122232425262728293031323334353637383940414243444546{ &quot;endTime&quot;:1576561372604, &quot;globalLogs&quot;:[{ &quot;callerClass&quot;:&quot;org.minbox.chapter.user.service.UserController&quot;, &quot;callerCodeLineNumber&quot;:33, &quot;callerMethod&quot;:&quot;getUserName&quot;, &quot;content&quot;:&quot;这是一条debug级别的日志，发生时间：{}&quot;, &quot;createTime&quot;:1576561372585, &quot;level&quot;:&quot;debug&quot; },{ &quot;callerClass&quot;:&quot;org.minbox.chapter.user.service.UserController&quot;, &quot;callerCodeLineNumber&quot;:34, &quot;callerMethod&quot;:&quot;getUserName&quot;, &quot;content&quot;:&quot;这是一条info级别的日志，发生时间：1576561372586&quot;, &quot;createTime&quot;:1576561372586, &quot;level&quot;:&quot;info&quot; },{ &quot;callerClass&quot;:&quot;org.minbox.chapter.user.service.UserController&quot;, &quot;callerCodeLineNumber&quot;:43, &quot;callerMethod&quot;:&quot;aa&quot;, &quot;content&quot;:&quot;出现了异常.&quot;, &quot;createTime&quot;:1576561372586, &quot;exceptionStack&quot;:&quot;java.lang.ArithmeticException: / by zero\\n\\tat org.minbox.chapter.user.service.UserController.aa(UserController.java:41)\\n\\tat org.minbox.chapter.user.service.UserController.getUserName(UserController.java:35)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\t....&quot;, &quot;level&quot;:&quot;error&quot; }], &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;accept&quot;:&quot;*/*&quot;, &quot;host&quot;:&quot;localhost:10000&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{}&quot;, &quot;requestUri&quot;:&quot;/user/name&quot;, &quot;responseBody&quot;:&quot;用户名：恒宇少年&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;user-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;10000&quot;, &quot;spanId&quot;:&quot;41a0c852-812b-4a2e-aa4a-228b87ce52f6&quot;, &quot;startTime&quot;:1576561372577, &quot;timeConsuming&quot;:27, &quot;traceId&quot;:&quot;42ca9f5a-5977-49cf-909d-a23614a47a6b&quot;} 上面是控制台输出的一个请求日志的详细内容，其中globalLogs字段就是我们采集的全局日志列表。 存储的采集日志我们来确认下采集日志上报到Logging Admin后是否保存到了logging_global_logs日志表内，如下所示： 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from logging_global_logs order by lgl_create_time asc\\G;*************************** 1. row *************************** lgl_id: 112e36ff-e781-4f11-8f21-2196823cde38 lgl_request_log_id: f91382e2-2d79-499e-b1df-4757c1ffdbc5 lgl_level: info lgl_content: 这是一条info级别的日志，发生时间：1576561856333 lgl_caller_class: org.minbox.chapter.user.service.UserController lgl_caller_method: getUserNamelgl_caller_code_line_number: 34 lgl_exception_stack: NULL lgl_create_time: 1576561856333*************************** 2. row *************************** lgl_id: f1d172a6-5cce-4df0-bc29-fe27ac441089 lgl_request_log_id: f91382e2-2d79-499e-b1df-4757c1ffdbc5 lgl_level: debug lgl_content: 这是一条debug级别的日志，发生时间：{} lgl_caller_class: org.minbox.chapter.user.service.UserController lgl_caller_method: getUserNamelgl_caller_code_line_number: 33 lgl_exception_stack: NULL lgl_create_time: 1576561856333*************************** 3. row *************************** lgl_id: d95d850d-3bc9-4689-928a-32c6089ff7a2 lgl_request_log_id: f91382e2-2d79-499e-b1df-4757c1ffdbc5 lgl_level: error lgl_content: 出现了异常. lgl_caller_class: org.minbox.chapter.user.service.UserController lgl_caller_method: getUserNamelgl_caller_code_line_number: 38 lgl_exception_stack: java.lang.ArithmeticException: / by zero at org.minbox.chapter.user.service.UserController.getUserName(UserController.java:36) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ... lgl_create_time: 15765618563343 rows in set (0.01 sec) 这里异常的堆栈信息比较多，做出了省略。 敲黑板，划重点本章把GlobalLog全局日志的概念进行了详细的描述，建议将一些重要逻辑判断性质的GlobalLog进行采集上报，防止logging_global_logs表内的数据量过大。 详细的使用方式请参考本章的源码。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-use-global-log： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-use-global-log.html"},{"title":"ApiBoot Logging使用SpringCloud Openfeign透传链路信息","text":"ApiBoot Logging可以无缝整合SpringCloud来采集请求日志，目前支持RestTemplate、Openfeign两种方式，我们本章来讲解下在使用Openfeign完成服务之间请求相互调用的一条链路请求日志是否可以都采集到。 搭建Eureka Server我们先来搭建一个Eureka Server，请访问【/eureka-server.html】文章内容查看具体搭建流程。 搭建Logging Admin我们需要搭建一个Logging Admin用于接收Logging Client上报的请求日志，请访问【ApiBoot Logging整合SpringCloud Eureka负载均衡上报日志】查看具体的搭建流程。 我们本章来模拟提交订单的业务逻辑，涉及到两个服务，分别是：商品服务、订单服务，接下来我们需要来创建这两个服务。 本章源码采用Maven多模块的形式进行编写，请拉至文章末尾查看下载本章源码。 添加ApiBoot &amp; SpringCloud统一版本由于是采用Maven 多模块项目，存在继承关系，我们只需要在root模块添加版本依赖即可，其他子模块就可以直接使用，如下所示： 12345678910111213141516171819202122232425&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--ApiBoot版本号--&gt; &lt;api.boot.version&gt;2.1.5.RELEASE&lt;/api.boot.version&gt; &lt;!--SpringCloud版本号--&gt; &lt;spring.cloud.version&gt;Greenwich.SR3&lt;/spring.cloud.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${api.boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring.cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 创建公共Openfeign接口定义学习过Openfeign的同学应该都知道，Openfeign可以继承实现，我们只需要创建一个公共的服务接口定义，在实现该接口的服务进行业务实现，在调用该接口的地方直接注入即可。下面我们创建一个名为common-openfeign的公共依赖项目，pom.xml添加依赖如下所示： 1234567891011121314&lt;dependencies&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--Openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在提交订单时我们简单模拟需要获取商品的单价，所以在common-openfeign项目内我们要提供一个查询商品单价的服务接口，创建一个名为GoodClient的接口如下所示： 123456789101112131415161718192021222324package org.minbox.chapter.common.openfeign;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;/** * 商品服务接口定义 * * @author 恒宇少年 */@FeignClient(name = &quot;good-service&quot;)@RequestMapping(value = &quot;/good&quot;)public interface GoodClient { /** * 获取商品价格 * * @param goodId 商品编号 * @return */ @GetMapping(value = &quot;/{goodId}&quot;) Double getGoodPrice(@PathVariable(&quot;goodId&quot;) Integer goodId);} 注解解释： @FeignClient：SpringCloud Openfeign提供的接口客户端定义注解，通过value或者name来指定GoodClient访问的具体ServiceID，这里我们配置的value值为good-service项目spring.application.name配置参数（ServiceID = spring.application.name）。 这样当我们通过注入GoodClient接口调用getGoodPrice方法时，底层通过Openfeign的Http代理访问good-service的对应接口。 创建商品服务下面我们再来创建一个名为good-service的SpringBoot项目。 添加相关依赖在pom.xml项目配置文件内添加如下依赖： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;!--ApiBoot Logging Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--公共Openfeign接口定义依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.chapter&lt;/groupId&gt; &lt;artifactId&gt;common-openfeign&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 可以看到我们在good-service项目依赖内添加了我们在上面创建的common-openfeign依赖模块，因为GoodClient服务接口的实现是在good-service项目内，我们需要添加common-openfeign依赖后创建对应的XxxController并实现GoodClient接口完成对应的业务逻辑实现。 商品业务实现这里我们简单做个示例，将价格固定返回，实现GoodClient的控制器如下所示： 123456789101112131415161718192021package org.minbox.chapter.good.service;import org.minbox.chapter.common.openfeign.GoodClient;import org.springframework.web.bind.annotation.RestController;/** * 商品服务接口实现 * * @author 恒宇少年 * @see GoodClient */@RestControllerpublic class GoodController implements GoodClient { @Override public Double getGoodPrice(Integer goodId) { if (goodId == 1) { return 15.6; } return 0D; }} 注册到Eureka Server我们需要将good-service注册到Eureka Server，修改application.yml配置文件如下所示： 1234567891011121314# ServiceIDspring: application: name: good-service# 端口号server: port: 8082# Eureka Configeureka: client: service-url: defaultZone: http://127.0.0.1:10000/eureka/ instance: prefer-ip-address: true 配置上报的Logging Admin我们需要将good-service的请求日志上报到Logging Admin，采用SpringCloud ServiceID的方式配置，修改application.yml配置文件如下所示： 12345678910api: boot: logging: # 控制台打印日志 show-console-log: true # 美化打印日志 format-console-log-json: true # 配置Logging Admin 服务编号 discovery: service-id: logging-admin 启用Eureka Client &amp; Logging最后我们在XxxApplication入口类添加注解来启用Eureka Client以及Logging Client，如下所示： 12345678910111213141516171819/** * 商品服务 * * @author 恒宇少年 */@SpringBootApplication@EnableLoggingClient@EnableDiscoveryClientpublic class GoodServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(GoodServiceApplication.class); public static void main(String[] args) { SpringApplication.run(GoodServiceApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;商品&quot;); }} 至此我们的商品服务已经准备完成. 创建订单服务创建一个名为order-service的SpringBoot项目（建议参考源码，本章采用Maven多模块创建）。 添加相关依赖修改pom.xml添加相关依赖如下所示： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;!--ApiBoot Logging Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--公共Openfeign接口定义依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.chapter&lt;/groupId&gt; &lt;artifactId&gt;common-openfeign&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 订单业务实现我们来模拟一个提交订单的场景，创建一个名为OrderController的控制器，如下所示： 1234567891011121314151617181920212223/** * 订单控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/order&quot;)public class OrderController { /** * 商品接口定义注入 * {@link GoodClient} */ @Autowired private GoodClient goodClient; @PostMapping public String submit(Integer goodId, Integer buyCount) { Double goodPrice = goodClient.getGoodPrice(goodId); Double orderAmount = goodPrice * buyCount; //... return &quot;订单提交成功，订单总金额：&quot; + orderAmount; }} 注册到Eureka Server将我们创建的order-service注册到Eureka Server，修改application.yml配置文件如下所示： 123456789101112spring: application: name: order-serviceserver: port: 8081# Eureka Configeureka: client: service-url: defaultZone: http://127.0.0.1:10000/eureka/ instance: prefer-ip-address: true 配置上报的Logging Admin我们需要将order-service的请求日志上报到Logging Admin，采用SpringCloud ServiceID的方式配置，修改application.yml配置文件如下所示： 12345678910api: boot: logging: # 控制台打印日志 show-console-log: true # 美化打印日志 format-console-log-json: true # 配置Logging Admin 服务编号 discovery: service-id: logging-admin 启用Eureka Client &amp; Logging修改order-service入口类OrderServiceApplication，添加启用Eureka Client、Logging Client的注解，如下所示： 1234567891011121314151617181920/** * 订单服务 * * @author 恒宇少年 */@SpringBootApplication@EnableDiscoveryClient@EnableLoggingClient@EnableFeignClients(basePackages = &quot;org.minbox.chapter.common.openfeign&quot;)public class OrderServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(OrderServiceApplication.class); public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;&quot;); }} 注解解释： @EnableFeignClients：该注解是Openfeign提供的启用自动扫描Client的配置，我们通过basePackages（基础包名）的方式进行配置扫描包下配置@FeignClient注解的接口，并为每个接口生成对应的代理实现并添加到Spring IOC容器。 org.minbox.chapter.common.openfeign包名在common-openfeign项目内。 运行测试依次启动项目，eureka-server &gt; logging-admin &gt; good-service &gt; order-service。 通过curl命令访问order-service内的提交订单地址：/order，如下所示： 12➜ ~ curl -X POST http://localhost:8081/order\\?goodId\\=1\\&amp;buyCount\\=3订单提交成功，订单总金额：46.8 可以看到我们已经可以成功的获取订单的总金额，我们在/order请求方法内调用good-service获取商品的单价后计算得到订单总金额。 测试点：链路信息传递我们通过控制台输出的日志信息来确认下链路信息（traceId、spanId）的透传是否正确。 收到order-service上报的日志 12345678910111213141516171819202122232425Receiving Service: 【order-service -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1573009439840, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;host&quot;:&quot;localhost:8081&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot;, &quot;accept&quot;:&quot;*/*&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;POST&quot;, &quot;requestParam&quot;:&quot;{\\&quot;buyCount\\&quot;:\\&quot;3\\&quot;,\\&quot;goodId\\&quot;:\\&quot;1\\&quot;}&quot;, &quot;requestUri&quot;:&quot;/order&quot;, &quot;responseBody&quot;:&quot;订单提交成功，订单总金额：46.8&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;order-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;8081&quot;, &quot;spanId&quot;:&quot;241ef717-b0b3-4fcc-adae-b63ffd3dbbe4&quot;, &quot;startTime&quot;:1573009439301, &quot;timeConsuming&quot;:539, &quot;traceId&quot;:&quot;3e20cc72-c880-4575-90ed-d54a6b4fe555&quot; }] 收到good-service上报的日志 1234567891011121314151617181920212223242526272829Receiving Service: 【good-service -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1573009439810, &quot;httpStatus&quot;:200, &quot;parentSpanId&quot;:&quot;241ef717-b0b3-4fcc-adae-b63ffd3dbbe4&quot;, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;minbox-logging-x-parent-span-id&quot;:&quot;241ef717-b0b3-4fcc-adae-b63ffd3dbbe4&quot;, &quot;minbox-logging-x-trace-id&quot;:&quot;3e20cc72-c880-4575-90ed-d54a6b4fe555&quot;, &quot;host&quot;:&quot;10.180.98.156:8082&quot;, &quot;connection&quot;:&quot;keep-alive&quot;, &quot;accept&quot;:&quot;*/*&quot;, &quot;user-agent&quot;:&quot;Java/1.8.0_211&quot; }, &quot;requestIp&quot;:&quot;10.180.98.156&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{}&quot;, &quot;requestUri&quot;:&quot;/good/1&quot;, &quot;responseBody&quot;:&quot;15.6&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;good-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;8082&quot;, &quot;spanId&quot;:&quot;6339664e-097d-4a01-a734-935de52a7d44&quot;, &quot;startTime&quot;:1573009439787, &quot;timeConsuming&quot;:23, &quot;traceId&quot;:&quot;3e20cc72-c880-4575-90ed-d54a6b4fe555&quot; }] 结果分析： 请求日志的入口为order-service所以并不存在parentSpanId（上级单元编号），而spanId（单元编号）、traceId（链路编号）也是新生成的。 本次请求会经过good-service服务，因此parentSpanId则是order-service生成的spanId，traceId同样也是order-service生成的，透传HttpHeader方式进行传递，表示在同一条请求链路上。 敲黑板，划重点ApiBoot Logging支持使用Openfeign传递链路信息，内部通过Openfeign拦截器实现，源码详见：org.minbox.framework.logging.client.http.openfeign.LoggingOpenFeignInterceptor。 将traceId（链路编号）、parentSpanId（单元编号）通过HttpHeader的形式传递到目标访问服务，服务通过请求日志拦截器进行提取并设置链路绑定关系。 traceId传递时HttpHeader名称为：minbox-logging-x-trace-id. parentSpanId传递时HttpHeader名称为：minbox-logging-x-parent-span-id 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-using-openfeign-transparent-traceid： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-using-openfeign-transparent-traceid.html"},{"title":"ApiBoot Logging使用RestTemplate透传链路信息","text":"在上一篇文章【/apiboot-logging-using-openfeign-transparent-traceid.html】中我们详细的讲解了ApiBoot Logging整合SpringCloud通过Openfeign进行透传链路信息，包括traceId（链路编号）、parentSpanId（上级单元编号）等信息。ApiBoot Logging不仅仅可以使用Openfeign传递链路信息，还支持RestTemplate方式，本篇文章来详细的讲解下具体的使用方式。 搭建Logging Admin我们需要搭建Logging Admin服务，用于接收业务服务上报的请求日志信息，请参考【/apiboot-report-logs-by-logging-to-admin.html】文章内容. 添加ApiBoot统一版本由于本章采用是Maven 多模块的方式构建源码，所以我们只需要将ApiBoot统一版本的依赖配置在root项目的pom.xml内，如下所示： 12345678910111213141516&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--ApiBoot版本号--&gt; &lt;api.boot.version&gt;2.1.5.RELEASE&lt;/api.boot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${api.boot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 接下来我们营造本篇文章的模拟场景，查询用户基本信息时一并查询出用户的账号余额。 创建账户服务创建一个名为account-service的SpringBoot项目。 添加相关依赖在项目pom.xml配置文件内添加相关依赖，如下所示： 123456789101112&lt;dependencies&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置上报的Logging Admin在application.yml配置文件内添加请求日志上报的Logging Admin地址，如下所示： 12345678910111213141516spring: application: name: account-serviceserver: port: 9090api: boot: logging: # 控制台打印请求日志 show-console-log: true # 美化请求日志 format-console-log-json: true # Logging Admin地址 admin: server-address: 127.0.0.1:8081 注意：server-address配置参数不需要添加http://前缀 启用Logging Client添加完成依赖后我们通过@EnableLoggingClient注解来启用ApiBoot Logging，在AccountServiceApplication类上添加如下所示： 123456789101112131415161718/** * 账户服务 * * @author 恒宇少年 */@SpringBootApplication@EnableLoggingClientpublic class AccountServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(AccountServiceApplication.class); public static void main(String[] args) { SpringApplication.run(AccountServiceApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;账户&quot;); }} @EnableLoggingClient注解就实例化部分ApiBoot Logging内部所需要的类，将实例放置到Spring IOC容器内。 查询账户余额代码实现我们创建一个名为AccountController的控制器来提供查询账户的余额信息，代码实现如下所示： 12345678910111213141516171819202122232425262728/** * 账户服务实现 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/account&quot;)public class AccountController { /** * 示例，内存账户列表 */ static final HashMap&lt;Integer, Double&gt; ACCOUNTS = new HashMap() {{ put(1, 1233.22); put(2, 69269.22); }}; /** * 获取指定账户的余额 * * @param accountId * @return */ @GetMapping(value = &quot;/{accountId}&quot;) public Double getBalance(@PathVariable(&quot;accountId&quot;) Integer accountId) { return ACCOUNTS.get(accountId); }} 至此我们的账户服务已经编写完成，下面我们来编写用户服务。 创建用户服务我们来创建一个名为user-service的SpringBoot项目。 添加相关依赖在项目pom.xml配置文件内添加相关依赖，如下所示： 123456789101112&lt;dependencies&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置上报的Logging Admin本章我们使用指定Logging Admin地址的方式配置，修改application.yml配置文件如下所示： 12345678910111213141516spring: application: name: user-serviceserver: port: 9091api: boot: logging: # 控制台打印请求日志 show-console-log: true # 美化请求日志 format-console-log-json: true # Logging Admin地址 admin: server-address: 127.0.0.1:8081 启用Logging Client添加完依赖后我们需要在XxxApplication入口类上添加@EnableLoggingClient注解来启用ApiBoot Logging，如下所示： 123456789101112131415161718/** * 用户服务 * * @author 恒宇少年 */@SpringBootApplication@EnableLoggingClientpublic class UserServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(UserServiceApplication.class); public static void main(String[] args) { SpringApplication.run(UserServiceApplication.class, args); logger.info(&quot;{}服务启动成功.&quot;, &quot;用户&quot;); }} 实例化RestTemplate对象在user-service需要访问账户服务获取当前用户的余额，所以我们需要在user-service内实例化RestTemplate，这样我们才可以通过RestTemplate访问获取用户账户余额信息，我们直接在UserServiceApplication类内添加实例，如下所示： 12345678910/** * 实例化RestTemplate * * @return {@link RestTemplate} */@Bean@ConditionalOnMissingBeanpublic RestTemplate restTemplate() { return new RestTemplate();} 注解解释： @ConditionalOnMissingBean：这是SpringBoot条件注入其中的一个注解，表示当IOC容器内不存在RestTemplate类型的实例时才会去执行restTemplate()方法创建对象。 查询用户信息代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 用户基本信息控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/user&quot;)public class UserController { /** * 示例，用户列表 */ static final HashMap&lt;Integer, User&gt; USERS = new HashMap() {{ put(1, new User(1, &quot;恒宇少年&quot;)); put(2, new User(2, &quot;于起宇&quot;)); }}; /** * 注入RestTemplate */ @Autowired private RestTemplate restTemplate; /** * 获取用户基本信息 * * @param userId 用户编号 * @return */ @GetMapping(value = &quot;/{userId}&quot;) public User getUserInfo(@PathVariable(&quot;userId&quot;) Integer userId) { ResponseEntity&lt;Double&gt; responseEntity = restTemplate.getForEntity(&quot;http://localhost:9090/account/{accountId}&quot;, Double.class, userId); Double balance = responseEntity.getBody(); User user = USERS.get(userId); if (ObjectUtils.isEmpty(user)) { throw new RuntimeException(&quot;用户：&quot; + userId + &quot;，不存在.&quot;); } user.setBalance(balance); return user; } @Data public static class User { private Integer id; private String name; private Double balance; public User(Integer id, String name) { this.id = id; this.name = name; } }} 我们所需要的两个服务都已经编写完成，下面我们来测试RestTemplate是可以透传ApiBoot Logging的链路信息？ 运行测试依次启动logging-admin &gt; user-service &gt; account-service。 测试点：透传链路信息我们使用curl命令访问user-service提供的地址/user，如下所示： 12➜ ~ curl http://localhost:9091/user/1{&quot;id&quot;:1,&quot;name&quot;:&quot;恒宇少年&quot;,&quot;balance&quot;:1233.22} 下面我看来看下logging-admin控制台接收到的请求日志。 接收user-service请求日志 12345678910111213141516171819202122232425Receiving Service: 【user-service -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1573032865311, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;host&quot;:&quot;localhost:9091&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot;, &quot;accept&quot;:&quot;*/*&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{}&quot;, &quot;requestUri&quot;:&quot;/user/1&quot;, &quot;responseBody&quot;:&quot;{\\&quot;id\\&quot;:1,\\&quot;name\\&quot;:\\&quot;恒宇少年\\&quot;,\\&quot;balance\\&quot;:1233.22}&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;user-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;9091&quot;, &quot;spanId&quot;:&quot;f8cff018-42d5-481f-98df-c19b7196b3c3&quot;, &quot;startTime&quot;:1573032865130, &quot;timeConsuming&quot;:181, &quot;traceId&quot;:&quot;16ad1dd4-beaa-4110-b4b7-fc7d952d9a57&quot; }] 接收account-service请求日志 1234567891011121314151617181920212223242526272829Receiving Service: 【account-service -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1573032865309, &quot;httpStatus&quot;:200, &quot;parentSpanId&quot;:&quot;f8cff018-42d5-481f-98df-c19b7196b3c3&quot;, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;minbox-logging-x-parent-span-id&quot;:&quot;f8cff018-42d5-481f-98df-c19b7196b3c3&quot;, &quot;minbox-logging-x-trace-id&quot;:&quot;16ad1dd4-beaa-4110-b4b7-fc7d952d9a57&quot;, &quot;host&quot;:&quot;localhost:9090&quot;, &quot;connection&quot;:&quot;keep-alive&quot;, &quot;accept&quot;:&quot;application/json, application/*+json&quot;, &quot;user-agent&quot;:&quot;Java/1.8.0_211&quot; }, &quot;requestIp&quot;:&quot;127.0.0.1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{}&quot;, &quot;requestUri&quot;:&quot;/account/1&quot;, &quot;responseBody&quot;:&quot;1233.22&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;account-service&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;9090&quot;, &quot;spanId&quot;:&quot;63b18b40-5718-431c-972f-78956ce78380&quot;, &quot;startTime&quot;:1573032865307, &quot;timeConsuming&quot;:2, &quot;traceId&quot;:&quot;16ad1dd4-beaa-4110-b4b7-fc7d952d9a57&quot; }] 当我们访问user-service服务内的/user路径时，因为是第一次访问ApiBoot Logging会主动创建traceId（链路编号）、spanId（单元编号），因为没有上级单元所以parentSpanId为null. 而通过查看account-service服务上报的请求日志时，可以看到ApiBoot Logging相关的链路信息是通过HttpHeader的方式进行传递的 minbox-logging-x-trace-id -&gt; 链路编号 minbox-logging-x-parent-span-id -&gt; 上级单元编号 敲黑板，划重点ApiBoot Logging在内部自动化实现了RestTemplate的拦截器配置，所以我们只需要创建实例就可以，而不需要主动去配置拦截器信息，具体源码请访问org.minbox.framework.logging.client.http.rest.LoggingRestTemplateInterceptor查看。 不管你一次请求跨度几个服务，都可以将请求入口生成的链路信息进行依次传递，而上下级关系则是根据parentSpanId、spanId进行绑定的。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-logging-using-resttemplate-transparent-traceid： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-logging-using-resttemplate-transparent-traceid.html"},{"title":"OAuth2在内存、Redis、JDBC方式下的多客户端配置","text":"Spring所提供的OAuth2集成策略，支持多种方式存储认证信息以及客户端信息，由于在之前的文章中讲解使用时把知识点进行了拆分，有很多同学不太会组合使用，很多单独问我ApiBoot所提供的OAuth2的整合后，多个客户端该怎么配置？ 本章就来讲讲如果我们使用内存方式、Redis方式做OAuth2相关信息存储时，该如何配置多个客户端！！！ 系列文章ApiBoot针对每一个组件都提供一系列的拆分详解文章，详情请访问 ApiBoot开源框架各个组件的系列使用文章汇总 。 前言ApiBoot集成OAuth2后内存方式与Redis方式的客户端配置都位于application.yml/application.properties配置文件内，通过源码发现Spring提供了一个接口 TokenStore 来定义操作认证信息的方法列表，实现该接口后就可以定义不同的存储方式具体的逻辑，当前我们也可以进行自定义，只需要将自定义实现类的实例交付给Spring IOC进行托管就即可，OAuth2内部就会调用自定义的实现类来处理业务（在内部都是通过接口来操作，不关心实例是哪个实现类）。 当然Spring在整合OAuth2后也提供了一些内置的TokenStore实现类，如下所示： InMemoryTokenStore 将客户端信息以及生成的AccessToken存放在内存中，项目重启后之前生成的AccessToken就会丢失，而ApiBoot OAuth在项目启动时会自动加载application.yml配置文件的客户端列表，所以客户端信息不会丢失。 JdbcTokenStore 将客户端信息以及生成的AccessToken存放在数据库中，项目重启后不影响认证，表结构由OAuth2提供。 RedisTokenStore 将客户端信息以及生成的AccessToken存放在 Redis中，支持分布式部署，AccessToken默认过期时间为7200秒，过期后也会自动被删除，使用起来比较方便，ApiBoot OAuth只需要修改api.boot.oauth.away=redis就可以启用这种方式。 JwtTokenStore 主要功能是使用Jwt进行转换AccessToken，并不做数据AccessToken的存储。 客户端配置源码分析当我们使用ApiBoot OAuth2提供的内存方式、Redis方式来集成使用时，客户端列表的配置都位于application.yml，使用api.boot.oauth.clients配置参数进行指定，那这个参数所对应的源码位于 ApiBootOauthProperties 属性配置类内。 在ApiBoot最初发行版中客户端只允许配置一个，根据使用者的反馈进行了迭代更新后支持了多个客户端的配置，对应ApiBootOauthProperties属性配置类内的clientis字段，源码如下所示： 123456/** * configure multiple clients */private List&lt;Client&gt; clients = new ArrayList() {{ add(new Client());}}; clients字段默认值为一个Client的对象实例，而Client则是为ApiBootOauthProperties的一个内部类，如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * Oauth2 Client * Used to configure multiple clients */@Datapublic static class Client { /** * oauth2 client id */ private String clientId = &quot;ApiBoot&quot;; /** * oauth2 client secret */ private String clientSecret = &quot;ApiBootSecret&quot;; /** * oauth2 client grant types * default value is &quot;password,refresh_token&quot; */ private String[] grantTypes = new String[]{&quot;password&quot;, &quot;refresh_token&quot;}; /** * oauth2 client scope * default value is &quot;api&quot; */ private String[] scopes = new String[]{&quot;api&quot;}; /** * oauth2 application resource id * default value is &quot;api&quot; */ private String[] resourceId = new String[]{&quot;api&quot;}; /** * oauth2 access token validity seconds * default value is 7200 second */ private int accessTokenValiditySeconds = 7200;} 根据Client类我们也就可以明白了，为什么ApiBoot OAuth在集成时不配置客户端也可以使用ApiBoot:ApiBootSecret来进行获取AccessToken，因为在ApiBootOauthProperties属性配置类中有一个默认的Client对象实例。 注意事项：当我们配置api.boot.oauth.clients参数时默认的客户端会被覆盖掉 示例项目既然我们知道了使用api.boot.oauth.clients可以配置多个客户端，那么接下来我们创建一个测试的项目，使用IDEA创建一个SpringBoot项目，项目pom.xml文件内容如下所示： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Security OAuth--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--ApiBoot统一版本依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 配置多客户端看过ApiBoot OAuth2系列文章的同学都应该知道，默认使用内存方式进行存储生成的AccessToken，这一点我们就不做修改了，如果你项目不是使用默认，可以去参考 ApiBoot开源框架各个组件的系列使用文章汇总 内安全组件分类下的文章。 在application.yml文件内添加客户端列表配置，如下所示： 1234567891011121314api: boot: # ApiBoot OAuth 相关配置 oauth: clients: - clientId: minbox clientSecret: chapter - clientId: hengboy clientSecret: 123123 # ApiBoot Security 相关配置 security: users: - username: yuqiyu password: 123456 由于api-boot-starter-security-oauth-jwt依赖是Spring Security与OAuth2的整合，所以我们想要获取AccessToken需要配置Spring Security的用户列表，即api.boot.security.users参数，默认同样是内存方式存储，详见：ApiBoot实现零代码整合Spring Security &amp; OAuth2 运行测试通过XxxApplication方式启动本章项目，通过Curl命令测试获取AccessToken，如下所示： 12➜ ~ curl -X POST minbox:chapter@localhost:8080/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123456'{&quot;access_token&quot;:&quot;bf2d67b8-c7a4-4f5c-846e-a6f1c7e44a9d&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;522507a2-30e5-4d86-a997-c991c3cb0807&quot;,&quot;expires_in&quot;:7191,&quot;scope&quot;:&quot;api&quot;} 在上面命令行中，我们通过minbox:chapter客户端进行测试获取AccessToken，接下来我们验证是否两个客户端都已经生效，下面使用hengboy:123123客户端尝试： 12➜ ~ curl -X POST hengboy:123123@localhost:8080/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123456' {&quot;access_token&quot;:&quot;62b8da93-27cd-4963-8612-8e94036c4d78&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;4e516a7f-db52-4f40-ab92-c6b43cd62294&quot;,&quot;expires_in&quot;:7200,&quot;scope&quot;:&quot;api&quot;} 根据输出来看，是可以获取到AccessToken的，多客户端配置都已经生效。 敲黑板，划重点其实ApiBoot Security OAuth有很多配置都可以组合使用，不过跨越存储方式的配置有的是无法相互组合使用的，比如：当你使用Jdbc方式来存储认证信息时，即使我们配置了api.boot.oauth.clients参数，这时也是没有任何作用的，因为使用数据库方式来读取客户端信息时，OAuth2通过JdbcClientDetailsService类从数据库的oauth_client_details表内查询客户端列表，我们如果想要添加客户端，这时就需要向oauth_client_details表内添加一条数据。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-oauth-multiple-client-config： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-oauth-multiple-client-config.html"},{"title":"来看看OAuth2怎么设置AccessToken有效期时间时长","text":"OAuth2所生成的AccessToken以及RefreshToken都存在过期时间，当在有效期内才可以拿来作为会话身份发起请求，否者认证中心会直接拦截无效请求提示已过期，那么我们怎么修改这个过期时间来满足我们的业务场景呢？ 目前一线大厂所使用的的AccessToken的有效期一般都是7200秒，也就是2小时，而且有获取的次数限制，所以发起请求的一方必须通过一定的形式保存到本地，以方便下一次发起请求时，写入请求的header或者作为参数携带。 本章来讲解下使用ApiBoot OAuth组件该怎么去设置AccessToken的过期时间，针对memory(内存方式)、jdbc(数据库)这两种方式来讲解，更多使用请参考官方文档： ApiBoot OAuth官方文档：https://apiboot.minbox.org/zh-cn/docs/api-boot-oauth.html 默认有效时长ApiBoot OAuth在memory存储方式下为每一个客户端都提供了一个默认的AccessToken有效时长，该配置在org.minbox.framework.api.boot.autoconfigure.oauth.ApiBootOauthProperties，相关源码如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * Oauth2 Client * Used to configure multiple clients */@Datapublic static class Client { /** * oauth2 client id */ private String clientId = &quot;ApiBoot&quot;; /** * oauth2 client secret */ private String clientSecret = &quot;ApiBootSecret&quot;; /** * oauth2 client grant types * default value is &quot;password,refresh_token&quot; */ private String[] grantTypes = new String[]{&quot;password&quot;, &quot;refresh_token&quot;}; /** * oauth2 client scope * default value is &quot;api&quot; */ private String[] scopes = new String[]{&quot;api&quot;}; /** * oauth2 application resource id * default value is &quot;api&quot; */ private String[] resourceId = new String[]{&quot;api&quot;}; /** * oauth2 access token validity seconds * default value is 7200 second */ private int accessTokenValiditySeconds = 7200;} Client是ApiBootOauthProperties的一个内部类，主要是提供了OAuth2 客户端的相关配置字段，通过spring-boot-configuration-processor依赖将该类自动解析成配置元数据，这样我们在application.yml输入api.xxx时可以得到相应的提示。 在Client内部类中有一个字段accessTokenValiditySeconds，通过该字段我们来修改该客户端下所有用户生成的AccessToken默认过期时长，值得注意的是，这里的配置值时间单位是秒，7200秒 = 2小时。 内存方式在上面说到了，内存方式时ApiBoot OAuth会使用ApiBootOauthProperties#Client内部类的accessTokenValiditySeconds字段来配置过期时间，所以我们只需要在application.yml添加如下配置即可： 123456789101112api: boot: oauth: clients: - clientId: minbox clientSecret: chapter # 配置客户端Token过期时长，单位：秒 accessTokenValiditySeconds: 43200 security: users: - username: yuqiyu password: 123123 在上面配置中，我们添加了一个在内存存储的minbox客户端，设置accessTokenValiditySeconds过期时间字段为43200秒 = 12小时。 JDBC方式JDBC方式是ApiBoot OAuth无法控制的，因为OAuth2当使用JDBC方式进行存储客户端、令牌等信息时，都是通过OAuth2提供的固定的表进行操作，正因为如此我们只需要修改oauth_client_details表内每一条client信息的access_token_validity字段的值即可，时间单位同样也是秒，如下图所示： OAuth2提供的MySQL版本的建表语句请访问ApiBoot OAuth Starter查看。 运行测试下面来测试下修改后的过期时间是否已经生效，我们先来启动本章的项目示例。 通过CURL的方式获取AccessToken，如下所示： 12➜ ~ curl -X POST minbox:chapter@localhost:9090/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123123'{&quot;access_token&quot;:&quot;41127985-1b31-4413-ac9f-30d5e26f4aaf&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;0a39ca6a-8697-4f80-9bb1-ac59894a45dd&quot;,&quot;expires_in&quot;:43199,&quot;scope&quot;:&quot;api&quot;} 通过PostMan方式获取AccessToken如下图所示： 我们根据结果可以看到，由原本默认的7200修改成了我们在application.yml配置的43200（结果中的43199是因为生成token耗时差导致的）。 敲黑板，划重点ApiBoot的宗旨就是化繁为简，能使用配置简单搞定的事情，绝不拖泥带水，赶快分享下本篇文章吧，让更多人得到帮助，非常感谢~~~ ApiBoot OAuth可以一次配置多个客户端，并且为每一个客户端配置不同的过期时间。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-oauth-set-token-expire-time： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-oauth-set-token-expire-time.html"},{"title":"OAuth2使用Redis来存储客户端信息以及AccessToken","text":"使用Redis来存储OAuth2相关的客户端信息以及生成的AccessToken是一个不错的选择，Redis与生俱来的的高效率、集群部署是比较出色的功能，如果用来作为服务认证中心的数据存储，可以大大的提高响应效率。 Redis还支持超时自动删除功能，OAuth2所生成的AccessToken相关的数据在超过配置的有效时间后就会自动被清除，这样也隐形的提高了接口的安全性。 既然Redis可以做到这么好，我们该怎么实现代码逻辑呢？ ApiBoot OAuth2是支持使用Redis来存储AccessToken的，只需要修改application.yml一个配置就可以实现，相关的使用也可以通过查看文档了解。 ApiBoot OAuth 官方文档 创建项目我们使用IDEA开发工具创建一个SpringBoot项目，在项目的pom.xml添加我们需要的ApiBoot的统一版本依赖以及安全组件依赖，如下所示： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加Redis支持既然我们本章需要用到Redis，我们需要在项目内添加相关的依赖，SpringBoot已经为我们提供了封装好的依赖，在pom.xml文件内dependencies节点下添加，如下所示： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置Redis连接信息SpringBoot对Redis的连接、数据操作都做了封装，我们只需要在application.yml配置文件内添加响应的Redis连接信息即可。 spring-boot-starter-data-redis依赖所需要的配置都是由RedisProperties类提供，该类内有部分配置字段存在默认值，部分源码如下所示： 123456789101112131415161718192021222324252627282930@ConfigurationProperties(prefix = &quot;spring.redis&quot;)public class RedisProperties { /** * Database index used by the connection factory. */ private int database = 0; /** * Connection URL. Overrides host, port, and password. User is ignored. Example: * redis://user:password@example.com:6379 */ private String url; /** * Redis server host. */ private String host = &quot;localhost&quot;; /** * Login password of the redis server. */ private String password; /** * Redis server port. */ private int port = 6379; //...} 默认配置下连接Redis只需要在application.yml配置spring.redis.password，如下所示： 1234spring: # 配置Redis连接信息 redis: password: 123123 password是连接Redis所需要的密码，在redis.conf文件内配置。 相关配置解释： spring.redis.database：如果你使用的Redis DataBase并不是默认的0索引，需要修改该配置 spring.redis.host：默认为localhost，如果不是本地使用，需要修改该配置 spring.redis.url：这是一个连接字符串，如天配置了会自动覆盖database、host、port等三个配置信息 spring.redis.port：默认为Redis的端口号6379，如已修改Redis的监听端口号，需要修改该配置 启用ApiBoot OAuth RedisApiBoot OAuth提供了redis配置选项，在application.yml文件内通过api.boot.oauth.away配置参数指定，如下所示： 1234567891011121314api: boot: security: # 配置内存安全用户列表 users: - username: yuqiyu password: 123123 oauth: # 配置使用Redis存储OAuth2相关数据 away: redis # 配置客户端列表 clients: - clientId: minbox clientSecret: chapter 为了方便演示，我们使用ApiBoot Security的内存方式配置了一个用户yuqiyu，而且还修改了默认client信息，新加了minbox客户端。 如果对ApiBoot Security用户配置或者ApiBoot OAuth的客户端配置不了解，可以查看官方文档： ApiBoot Security ApiBoot OAuth 或者你可以查看我编写的ApiBoot系列的文章：ApiBoot开源框架各个组件的系列使用文章汇总 运行测试在运行测试之前我们添加一个名为ApiController的控制器用来测试，代码如下所示： 123456789101112131415161718/** * 测试Api控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/api&quot;)public class ApiController { /** * 测试请求，需携带令牌访问 * * @return */ @GetMapping(value = &quot;/index&quot;) public String index() { return &quot;this is index&quot;; }} 测试点：查看Redis存储的AccessToken预计效果是当我们发送获取AccessToken的请求时，会自动将生成的AccessToken存储到Redis。 下面我们使用CURL命令来尝试获取下AccessToken，如下所示： 12➜ ~ curl minbox:chapter@localhost:9090/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123123'{&quot;access_token&quot;:&quot;38a7ee20-2fad-43c5-a349-31e6f0ee0f29&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;f469b1e8-f63c-4be9-8564-2603f8458024&quot;,&quot;expires_in&quot;:7199,&quot;scope&quot;:&quot;api&quot;} 下面我们使用redis-cli来看下是否已经将AccessToken存储到Redis，如下所示： 1234567891011121314151617➜ ~ redis-cli 127.0.0.1:6379&gt; auth 123123OK127.0.0.1:6379&gt; keys * 1) &quot;uname_to_access:minbox:yuqiyu&quot; 2) &quot;refresh_to_access:f469b1e8-f63c-4be9-8564-2603f8458024&quot; 3) &quot;access_to_refresh:1ea8e5cd-ea63-4a73-969f-9e7767f25f30&quot; 4) &quot;auth:38a7ee20-2fad-43c5-a349-31e6f0ee0f29&quot; 5) &quot;refresh_auth:6898bef4-f4a7-4fa9-858b-a4c62a1567d8&quot; 6) &quot;refresh:6898bef4-f4a7-4fa9-858b-a4c62a1567d8&quot; 7) &quot;refresh_auth:f469b1e8-f63c-4be9-8564-2603f8458024&quot; 8) &quot;access:38a7ee20-2fad-43c5-a349-31e6f0ee0f29&quot; 9) &quot;refresh_to_access:6898bef4-f4a7-4fa9-858b-a4c62a1567d8&quot;1) &quot;auth_to_access:f02ceb5faa4577222082842b82a57067&quot;2) &quot;refresh:f469b1e8-f63c-4be9-8564-2603f8458024&quot;3) &quot;access_to_refresh:38a7ee20-2fad-43c5-a349-31e6f0ee0f29&quot;4) &quot;client_id_to_access:minbox&quot; 结果往往让人感觉惊喜，看到这里我们已经成功的把OAuth2生成的AccessToken存储到了Redis，如果AccessToken对应的数据超过了expires_in时间，就会自动被清除。 测试点：携带AccessToken访问接口我们可以拿着生成的AccessToken来访问在上面添加的测试ApiController内的接口，如下所示： 12➜ ~ curl -H 'Authorization: Bearer 38a7ee20-2fad-43c5-a349-31e6f0ee0f29' http://localhost:9090/api/indexthis is index 我们可以拿到接口的返回的接口，这也证明了一点，AccessToken的验证是没有问题的，OAuth2拿着请求携带的AccessToken去Redis验证通过。 敲黑板，划重点ApiBoot OAuth所支持的3种存储方式都已经通过文章的方式告知大家，每一种方式都做到了精简，简单的配置，添加相关的依赖，就能够实现在之前让很多人头疼的集成。 如果在生产环境中数据量较大，建议使用Redis集群来解决存储AccessToken的问题。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-oauth-use-redis-storage： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-oauth-use-redis-storage.html"},{"title":"这种方式整合Quartz你见过吗？","text":"Quartz是一款优秀的任务调度框架，支持内存、JDBC的形式来存储未执行的任务列表，支持多个任务节点同时执行任务，支持任务漂移到不同的节点执行。 前言这么优秀的任务调度框架我想应该是很多开发者的首选解决方案，因此ApiBoot对它下手了，基于SpringBoot封装了名为ApiBoot Quartz的组件，同样是通过application.yml配置文件的形式就可以简单的实现初始化集成。 如果使用默认的配置，我们可以不编写一行集成相关的代码，ApiBoot Quartz还针对日常高频率使用的方法提供了一个接口，定义的方法如：创建任务、暂停任务、恢复任务、删除任务等等。 任务存储方式Quartz自身提供了两种存储任务的方式： Memory：内存方式，将任务存储到内存中，当项目重启时就会丢失，不建议生产环境使用。 Jdbc：数据库方式，将任务存储到Quartz提供的固定结构的表内，项目重启任务不会丢失，多种数据库的建表语句请访问：Quartz Schemas 按需选择。 ApiBoot将Quartz内提供的两种存储方式进行了封装，通过api.boot.quartz.job-store-type参数进行配置，该参数默认值为memory，所以你如果使用内存方式该参数不需要修改，更多配置请访问 ApiBootQuartzProperties 查看。 任务类型任务类型是ApiBoot Quartz的新概念，其实在Quartz中任务并没有类型区分，实现org.quartz.Job接口就可以创建一个任务。 不过Spring也是爱折腾，对其进行了封装提供了QuartzJobBean，它是一个抽象类，我们继承该类后也可以创建一个定时任务。 在ApiBoot Quartz中有三种任务类型，分别是： OnceJob：仅执行一次的任务类型 CronJob：使用Cron表达式来定义任务的执行周期 LoopJob：可指定循环次数的任务，根据指定循环的次数进行重复执行 内置方法ApiBoot封装Quartz后所提供的方法都位于 ApiBootQuartzService 接口中，而该接口有一个默认的实现类 ApiBootQuartzServiceDefaultSupport ，该实现类全部实现了接口定义方法，内部通过org.quartz.Scheduler来实现任务的基本操作。 内置方法列表： 方法 描述 Scheduler getScheduler(); 获取SpringIoc容器内的Scheduler实例 String newJob(ApiBootJobWrapper jobWrapper); 通过封装的对象创建一个新的任务，这是创建所有类型任务的入口 void deleteJob(String jobKey); 删除一个任务 void deleteJobs(String… jobKeys); 删除一系列任务 void deleteJobs(Collection jobKeys); 删除集合内的所有任务 void pauseJob(String jobKey); 暂停一个任务 void pauseJobs(String… jobKeys); 暂停传递的所有任务 void pauseJobs(Collection jobKeys); 暂停集合内的所有任务 void resumeJob(String jobKey); 恢复一个任务执行 void resumeJobs(String… jobKeys); 恢复数组内的所有任务执行 void resumeJobs(Collection jobKeys); 恢复集合内的所有任务执行 void updateJobCron(String jobKey, String cron); 更新任务Cron表达式 void updateJobStartTime(String jobKey, Date jobStartTime); 更新任务开始时间 void startAllJobs(); 启动所有定时任务 void shutdownAllJobs(); 关闭所有定时任务 既然ApiBoot为我们提供了这么多内置的方法，我们接下来创建一个项目来感受一下。 示例项目使用Idea创建一个SpringBoot项目，我们把本章所需要的依赖添加在pom.xml文件内，如下所示： 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Quartz--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--ApiBoot统一版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 注意：ApiBoot的版本是根据SpringBoot的版本而定义的，详见 ApiBoot 版本分支 示例任务类我们来创建一个名为DemoJob的任务调度示例类，如下所示： 1234567891011/** * 示例任务 * * @author 恒宇少年 */public class DemoJob extends QuartzJobBean { @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { System.out.println(&quot;任务执行了..&quot;); }} QuartzJobBean是什么？QuartzJobBean是由Spring提供，实现org.quartz.Job接口，是对Quartz内置任务接口的实现并且封装。 QuartzJobBean的优势Spring所提供的QuartzJobBean具体有什么优势呢？ 自动将实现类实例加入IOC 使用QuartzJobBean来创建自定义任务时，Spring会自动扫描项目内的实现类，将每一个实现类通过反射机制创建出实例并将实例写入到IOC容器内。 可在实现类内注入实例 直接使用Quartz时，如果自定义任务类实例不加入IOC容器，我们无法在自定义任务类注入Service，这一点了解Spring基础的同学应该都明白，我们无法在非被IOC托管的类内进行注入操作，而使用QuartzJobBean则不用考虑这一点。 QuartzJobBean注册流程使用ApiBoot Quartz后为什么不需要再手动添加注入把任务实现类加入到IOC容器？ 任务类注册流程如下所示： 第一步：ApiBootQuartzAutoConfiguration#quartzScheduler() ApiBoot在集成Quartz时提供了一个自动化配置类 ApiBootQuartzAutoConfiguration ，在该类中通过quartzScheduler()方法来自动创建一个SchedulerFactoryBean实例 第二步：SchedulerFactoryBean#setJobFactory() 通过SchedulerFactoryBean内提供的setJobFactory()方法可以自定义设置具体使用JobFactory的实现类，而在spring-context-support依赖内已经提供了相关实现，名为 SpringBeanJobFactory。 第三步：SpringBeanJobFactory#createJobInstance() 在项目启动时会将扫描到的所有QuartzJobBean实现类通过JobFactory#newJob方法进行创建任务实例后将实例交付给Quartz框架进行准备后期的任务调度。 SpringBeanJobFactory类继承于AdaptableJobFactory类，而AdaptableJobFactory则是实现了JobFactory接口，这样的话如果我们将SpringBeanJobFactory设置给SchedulerFactoryBean项目启动时Quartz就会调用SpringBeanJobFactory#createJobInstance()方法来创建任务实例。 而在createJobInstance()方法内Spring则是将创建的任务实例存入了IOC容器内，这样一来我们的自定义任务内就可以进行注入其他Bean的操作了，该方法源码如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * Create the job instance, populating it with property values taken * from the scheduler context, job data map and trigger data map. */@Overrideprotected Object createJobInstance(TriggerFiredBundle bundle) throws Exception { Object job = (this.applicationContext != null ? // 通过ApplicationContext创建任务实例，并添加到IOC this.applicationContext.getAutowireCapableBeanFactory().createBean( bundle.getJobDetail().getJobClass(), AutowireCapableBeanFactory.AUTOWIRE_CONSTRUCTOR, false) : super.createJobInstance(bundle)); if (isEligibleForPropertyPopulation(job)) { BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(job); MutablePropertyValues pvs = new MutablePropertyValues(); if (this.schedulerContext != null) { pvs.addPropertyValues(this.schedulerContext); } pvs.addPropertyValues(bundle.getJobDetail().getJobDataMap()); pvs.addPropertyValues(bundle.getTrigger().getJobDataMap()); if (this.ignoredUnknownProperties != null) { for (String propName : this.ignoredUnknownProperties) { if (pvs.contains(propName) &amp;&amp; !bw.isWritableProperty(propName)) { pvs.removePropertyValue(propName); } } bw.setPropertyValues(pvs); } else { bw.setPropertyValues(pvs, true); } } return job;} 大致的QuartzJobBean实现类注册流程就是这个样子的，下面让我们来见识下是不是真的有那么简单就可以创建并执行一个任务。 运行测试为了演示方便，我们修改XxxApplication入口类，让项目启动后自动执行DemoJob任务，如下所示： 123456789101112131415161718192021@SpringBootApplicationpublic class ApibootQuartzIntegratedAwayApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication.run(ApibootQuartzIntegratedAwayApplication.class, args); } /** * ApiBoot Quartz内置方法接口 * {@link org.minbox.framework.api.boot.plugin.quartz.support.ApiBootQuartzServiceDefaultSupport} */ @Autowired private ApiBootQuartzService quartzService; @Override public void run(String... args) throws Exception { quartzService.newJob(ApiBootOnceJobWrapper.Context() .jobClass(DemoJob.class) .wrapper()); }} CommandLineRunner是由SpringBoot提供用于执行项目启动后的逻辑。 启动项目后控制台输出内容如下所示： 12......任务执行了.. 心细的同学应该看到了我们使用了ApiBootOnceJobWeapper这个封装类来创建的任务对象，我们下一章就来讲下这个封装类到底可以干什么？ 敲黑板，划重点Quartz是一个优秀的分布式任务调度框架，ApiBoot封装了它，使它插上了翅膀，让我们明白了简单的另一层定义。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-quartz-integrated-away： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-quartz-integrated-away.html"},{"title":"分布式任务调度框架ApiBoot Quartz内的两种任务存储方式","text":"前言Quartz是一款比较优秀的分布式任务调度框架，ApiBoot对其封装之前就有两种任务存储方式，分别是：memory（内存方式）、jdbc（数据库方式），不过我们需要编写一些繁琐的代码配置，ApiBoot实现了集成后，可快速应用到项目中，而且还提供了 ApiBootQuartzService 接口用于操作任务的状态、有效性、新任务创建等，提供了一些常用方法，使用时只需要注入即可，因为该类在 ApiBootQuartzAutoConfiguration 自动化配置类中已经做了实例化。 任务存储之前有提到Quartz提供了两种任务存储的方式，这两种存在什么区别呢？ 内存方式：将任务临时存储到内存中，仅支持单项目部署，项目重启后任务会失效，不支持由调度器控制任务漂移，不建议使用。 数据库方式：Quartz提供了多种数据库的所需表结构脚本，它内部通过DataSource来操作数据，支持分布式方式部署、支持任务漂移，项目重启后任务不会丢失，直到任务执行完成后才会被从数据库内清除。 默认方式ApiBoot在整合Quartz之后将内存方式（memory）作为默认的任务存储方式，默认方式下不需要一行代码的配置就可以实现集成，通过ApiBootQuartzService#newJob方法就可以实现任务的初始化运行，还可以指定Once、Loop、Cron三种方式的任意一种来运行任务，使用方式详见：分布式调度框架Quartz衍生出的三种任务类型，你用过几个？ 数据库方式Quartz针对不同数据库类型提供了代理接口DriverDelegate，不同数据库类型都会有该代理接口的实现类，而我们平时所用到的则为StdJDBCDelegate，该类内包含了Quartz操作数据库表内数据的全部方法。 数据脚本Quartz针对不同类型的数据库分别提供了 建表语句，使用时请按照脚本名称自行选择。 ApiBoot Quartz启用数据库方式启用的方式很简单，只需要在application.yml/application.properties文件内添加如下配置： 12345api: boot: quartz: # 配置使用Jdbc方式存储任务 job-store-type: jdbc 注意事项：既然启用数据库方式，那么你的项目中必须要有数据源、数据库驱动、实例化数据源（实例化DataSource的工作一般是ORM框架来担任，如：ApiBoot MyBatis Enhance）等依赖。 敲黑板，划重点本章主要介绍了ApiBoot整合Quartz后的任务存储方式配置方式以及提供的不同数据库的对应建表脚本。 如果你对ApiBoot开源框架在使用方面感觉不顺手，欢迎提出您的宝贵 意见，让开源框架走更远的路、服务更多的开发者！！！","link":"/apiboot-quartz-job-storage-away.html"},{"title":"分布式调度框架Quartz衍生出的三种任务类型，你用过几个？","text":"前言Quartz内部没有明确的任务类型的概念，在ApiBoot中对其进行封装后才确切的定义了这个概念，可以根据业务场景按需选择适合的任务类型来构建执行的任务。 系列文章ApiBoot Quartz是以系列文章的形式更新，了解更多使用方法请访问如下链接： 这种方式整合Quartz你见过吗？ ApiBoot内其他组件系列使用文章请访问：ApiBoot开源框架各个组件的系列使用文章汇总 衍生的任务类型ApiBoot对Quartz集成封装后，提供了如下三种的任务类型： OnceJob：一次性任务，仅执行一次 CronJob：使用Cron表达式定义任务周期 LoopJob：指定循环次数的任务 注意事项：任务类型是任务的执行方式类型，并不是创建任务的类型，创建任务都是通过继承QuartzJobBean来完成，同一个任务可以使用不同的类型执行。 演示项目我们使用Idea创建一个SpringBoot项目，用于我们本章的演示项目，创建项目后添加ApiBoot Quartz相关的依赖到pom.xml文件内，如下所示： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Quartz--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 示例任务我们来创建一个本章演示所需要的任务类，如下所示： 12345678910111213141516/** * 示例任务 * * @author 恒宇少年 */public class DemoJob extends QuartzJobBean { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(DemoJob.class); @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException { logger.info(&quot;这是一个示例任务，执行时间：{}&quot;, System.currentTimeMillis()); }} 当任务执行时就会在控制台输出任务执行的时间，继承自Spring提供的封装任务类QuartzJobBean，会自动扫描到DemoJob并通过反射创建实例后放入Ioc容器，具体的流程可以访问 这种方式整合Quartz你见过吗？ 了解详情。 一次性任务我们使用Once任务类型来执行上面创建的DemoJob示例任务，先上代码，如下所示： 12345678910/** * ApiBoot Quartz内置接口 * * @see org.minbox.framework.api.boot.plugin.quartz.support.ApiBootQuartzServiceDefaultSupport */@Autowiredprivate ApiBootQuartzService quartzService;// 创建Once任务quartzService.newJob(ApiBootOnceJobWrapper.Context().jobClass(DemoJob.class).wrapper()); 我们只需要一行代码就可以来定义一个新的任务，在代码中出现了一个新面孔 ApiBootOnceJobWrapper。 ApiBootOnceJobWrapper主要工作是来封装Once类型任务所需要的配置字段，内部通过Lombok提供的@Builder注解来实现，Once任务可配置的内容如下所示： 方法 默认值 描述 .jobClass(Class&lt;? extends QuartzJobBean&gt; jobClass) - 配置所执行的QuartzJobBean实现类类型 .jobKey(String jobKey) 随机UUID字符串 任务唯一key .startAtTime(Date startAtTime) 当前时间 任务开始执行时间 .param(ApiBootJobParamWrapper param) - 任务执行时的参数列表封装对象 Cron表达式任务Cron表达式来创建任务是比较灵活的，也是比较常用的方式，使用ApiBoot Quartz同样仅仅需要一行代码就可以实现，下面我们来定义每间隔一秒执行一次DemoJob内的任务逻辑，如下所示： 123456789/** * ApiBoot Quartz内置接口 * * @see org.minbox.framework.api.boot.plugin.quartz.support.ApiBootQuartzServiceDefaultSupport */@Autowiredprivate ApiBootQuartzService quartzService;// 创建Cron任务quartzService.newJob(ApiBootCronJobWrapper.Context().jobClass(DemoJob.class).cron(&quot;0/1 * * * * ?&quot;).wrapper()); ApiBootCronJobWrapper 所做的工作与ApiBootOnceJobWrapper其实是一样的，都是用来采集Cron类型的任务所需要的配置字段，内部同样是通过Lombok提供的@Builder注解实现，Cron类型任务可配置的内容如下所示： 方法 默认值 描述 .jobClass(Class&lt;? extends QuartzJobBean&gt; jobClass) - 配置所执行的QuartzJobBean实现类类型 .jobKey(String jobKey) 随机UUID字符串 任务唯一key .cron(String cron) - 任务执行时间的Cron表达式 .param(ApiBootJobParamWrapper param) - 任务执行时的参数列表封装对象 Loop循环任务Loop类型的任务在开发中也是比较常用的，根据指定的循环次数以及每一次执行的间隔时间运行定时任务逻辑，当获取到期望的结果后还可以将任务自身进行删除，先来看看一个简单例子： 123456789/** * ApiBoot Quartz内置接口 * * @see org.minbox.framework.api.boot.plugin.quartz.support.ApiBootQuartzServiceDefaultSupport */@Autowiredprivate ApiBootQuartzService quartzService;// 创建Loop任务quartzService.newJob(ApiBootLoopJobWrapper.Context().jobClass(DemoJob.class).loopIntervalTime(2000).repeatTimes(5).wrapper()); 上面的定时任务会先执行1次后每间隔2000毫秒再执行5次，一共是执行6次，大家注意配置。 可以看到Loop类型的任务也提供了一个 ApiBootLoopJobWrapper 来封装任务执行所需要的配置字段，可配置的字段方法如下所示： 方法 默认值 描述 .jobClass(Class&lt;? extends QuartzJobBean&gt; jobClass) - 配置所执行的QuartzJobBean实现类类型 .jobKey(String jobKey) 随机UUID字符串 任务唯一key .loopIntervalTime(int intervalTime) 1000 循环执行的间隔时间，单位：毫秒 .repeatTimes(int times) 0 循环执行次数 .startAtTime(Date startAtTime) 当前时间 任务开始执行时间 .param(ApiBootJobParamWrapper param) - 任务执行时的参数列表封装对象 如果不设置repeatTimes仅执行一次，效果与Once一样。 运行测试在运行项目之前先来修改项目的XxxApplication入口类，我们期望在项目启动完成后就执行任务，那么我们直接实现CommandLineRunner接口来完成这一需求，如下所示： 123456789101112131415161718192021222324252627282930/** * ApiBoot Quartz 三种任务类型示例 */@SpringBootApplicationpublic class ApibootQuartzJobTypesApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication.run(ApibootQuartzJobTypesApplication.class, args); } /** * ApiBoot Quartz内置接口 * * @see org.minbox.framework.api.boot.plugin.quartz.support.ApiBootQuartzServiceDefaultSupport */ @Autowired private ApiBootQuartzService quartzService; @Override public void run(String... args) throws Exception { // 一次性任务 quartzService.newJob(ApiBootOnceJobWrapper.Context().jobClass(DemoJob.class).wrapper()); // 循环执行任务，每隔2000毫秒执行一次，循环5次，一共执行6次 quartzService.newJob(ApiBootLoopJobWrapper.Context().jobClass(DemoJob.class).loopIntervalTime(2000).repeatTimes(5).wrapper()); // Cron表达式任务，间隔1秒执行一次 quartzService.newJob(ApiBootCronJobWrapper.Context().jobClass(DemoJob.class).cron(&quot;0/1 * * * * ?&quot;).wrapper()); }} 启动项目后我们可以在控制台看到有任务执行时间输出，如下所示： 123456782019-12-24 14:56:05.046 INFO 3113 --- [eduler_Worker-1] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705650462019-12-24 14:56:05.046 INFO 3113 --- [eduler_Worker-2] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705650462019-12-24 14:56:05.047 INFO 3113 --- [eduler_Worker-3] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705650472019-12-24 14:56:06.005 INFO 3113 --- [eduler_Worker-4] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705660052019-12-24 14:56:07.002 INFO 3113 --- [eduler_Worker-5] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705670022019-12-24 14:56:07.042 INFO 3113 --- [eduler_Worker-6] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：15771705670422019-12-24 14:56:08.003 INFO 3113 --- [eduler_Worker-7] o.minbox.chapter.apiboot.quartz.DemoJob : 这是一个示例任务，执行时间：1577170568003... 虽然任务已经执行了，但是由于是多种执行方式同时执行同一个任务，我们不好做出区分，针对这个问题可以使用ApiBoot Quartz提供的参数来解决。 敲黑板，划重点ApiBoot Quartz所提供的功能已经可以满足日常开发所需要，而且比较灵活，可以通过ApiBoot Quartz提供的Wrapper封装类的方法进行自定义配置，任务的执行是子线程异步操作，不需要考虑会影响访问响应的效率问题。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-quartz-job-types： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-quartz-job-types.html"},{"title":"将ApiBoot Logging采集的日志上报到Admin","text":"通过ApiBoot Logging可以将每一条请求的详细信息获取到，在分布式部署方式中，一个请求可能会经过多个服务，如果是每个服务都独立保存请求日志信息，我们没有办法做到统一的控制，而且还会存在日志数据库与业务数据库不一致的情况出现（可能会用到多数据源配置），正因为这个问题ApiBoot Logging提供了一个Admin的概念，将客户端采集到的的每一条日志都进行上报到Admin，由Admin进行分析、保存等操作。 创建Logging Admin项目ApiBoot Logging Admin既然可以汇总每一个业务服务（ApiBoot Logging）的请求日志，因此我们需要将每一个业务服务采集单的日志进行上报到Admin，所以应该使用独立的方式进行部署，我们单独创建一个服务来专门采集请求日志然后进行保存。 初始化Logging Admin项目依赖使用idea创建一个SpringBoot项目，pom.xml配置文件内的依赖如下所示： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging Admin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging-admin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--MySQL--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot MyBatis Enhance--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-mybatis-enhance&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们需要将采集到的请求日志进行保存到数据库，所以在项目内需要添加数据库驱动、数据库连接池相关的依赖，ApiBoot Logging Admin内部通过DataSource进行操作数据，通过ApiBoot MyBatis Enhance的依赖可以自动化创建DataSource，摆脱手动创建并加入Spring IOC容器。 添加ApiBoot统一版本依赖123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--ApiBoot统一版本依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 最新版的ApiBoot，请访问：https://search.maven.org/search?q=a:api-boot-dependencies进行查询。 启用Logging Admin添加ApiBoot Logging Admin依赖后还不能完全使用Admin的功能，我们需要通过@EnableLoggingAdmin注解来启用，该注解会自动将Logging Admin内所需要的部分类自动注册到Spring IOC，在入口类添加注解如下所示： 123456789101112/** * ApiBoot Logging Admin入口类 */@SpringBootApplication@EnableLoggingAdminpublic class ApibootReportLogsByLoggingToAdminApplication { public static void main(String[] args) { SpringApplication.run(ApibootReportLogsByLoggingToAdminApplication.class, args); }} 配置日志数据源application.yml配置文件内数据源配置如下所示： 1234567891011121314# 服务名称spring: application: name: apiboot-report-logs-by-logging-to-admin # 数据源相关配置 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/test username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource# 服务端口号server: port: 8081 控制台打印上报日志ApiBoot Logging Admin可以通过配置文件的方式进行控制是否在控制台打印采集到的请求日志信息，在application.yml配置文件内添加如下内容： 1234567api: boot: logging: # Logging Admin相关配置 admin: # 控制台显示采集的日志信息 show-console-report-log: true 注意：这里不要跟ApiBoot Logging所提供的api.boot.logging.show-console-log配置混淆。 美化控制台打印的上报日志1234567api: boot: logging: # Logging Admin相关配置 admin: # 控制台输出时美化采集到的日志 format-console-log-json: true 注意：这里不要跟api.boot.logging.format-console-log-json配置混淆。 初始化日志表结构ApiBoot Logging Admin内部通过固定的表结构来进行存储请求日志、服务信息，建表语句如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344SET NAMES utf8mb4 ;---- Table structure for table `logging_request_logs`--CREATE TABLE `logging_request_logs` ( `lrl_id` varchar(36) COLLATE utf8mb4_general_ci NOT NULL COMMENT '主键，UUID', `lrl_service_detail_id` varchar(36) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '服务详情编号，关联logging_service_details主键', `lrl_trace_id` varchar(36) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '链路ID', `lrl_parent_span_id` varchar(36) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '上级跨度ID', `lrl_span_id` varchar(36) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '跨度ID', `lrl_start_time` mediumtext COLLATE utf8mb4_general_ci COMMENT '请求开始时间', `lrl_end_time` mediumtext COLLATE utf8mb4_general_ci COMMENT '请求结束时间', `lrl_http_status` int(11) DEFAULT NULL COMMENT '请求响应状态码', `lrl_request_body` longtext COLLATE utf8mb4_general_ci COMMENT '请求主体内容', `lrl_request_headers` text COLLATE utf8mb4_general_ci COMMENT '请求头信息', `lrl_request_ip` varchar(30) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '发起请求客户端的IP地址', `lrl_request_method` varchar(10) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '请求方式', `lrl_request_uri` varchar(200) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '请求路径', `lrl_response_body` longtext COLLATE utf8mb4_general_ci COMMENT '响应内容', `lrl_response_headers` text COLLATE utf8mb4_general_ci COMMENT '响应头信息', `lrl_time_consuming` int(11) DEFAULT NULL COMMENT '请求耗时', `lrl_create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '日志保存时间', `lrl_request_params` text COLLATE utf8mb4_general_ci, `lrl_exception_stack` text COLLATE utf8mb4_general_ci, PRIMARY KEY (`lrl_id`), KEY `logging_request_logs_LRL_SERVICE_DETAIL_ID_index` (`lrl_service_detail_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='请求日志信息表';---- Table structure for table `logging_service_details`--CREATE TABLE `logging_service_details` ( `lsd_id` varchar(36) COLLATE utf8mb4_general_ci NOT NULL, `lsd_service_id` varchar(200) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '上报服务的ID，对应spring.application.name配置值', `lsd_service_ip` varchar(50) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '上报服务的IP地址', `lsd_service_port` int(11) DEFAULT NULL COMMENT '上报服务的端口号', `lsd_last_report_time` timestamp NULL DEFAULT NULL COMMENT '最后一次上报时间，每次上报更新', `lsd_create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '首次上报时创建时间', PRIMARY KEY (`lsd_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='上报日志的客户端服务详情'; ApiBoot Logging Admin目前为止已经准备完毕，接下来我们需要修改业务服务将请求日志上报到Logging Admin。 上报日志到指定Logging Admin我们将修改/apiboot-unified-manage-request-logs.html文章源码，在application.yml添加Logging Admin的地址，如下所示： 1234567api: boot: # ApiBoot Logging 日志组件配置 logging: # 配置Logging Admin地址 admin: server-address: 127.0.0.1:8081 api.boot.logging.admin-service-address的配置格式为：Ip:Port，我们只需要修改这一个地方即可，其他的工作都交付给ApiBoot Logging内部完成。 测试我们将ApiBoot Logging Admin以及业务服务通过Application的形式进行启动。 使用curl访问测试地址如下所示： 12~ curl http://localhost:8080/test\\?name\\=admin你好：admin 我们查看ApiBoot Logging Admin控制台日志如下所示： 1234567891011121314151617181920212223242526Receiving Service: 【apiboot-unified-manage-request-logs -&gt; 127.0.0.1】, Request Log Report，Logging Content：[ { &quot;endTime&quot;:1571641723779, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;server-region&quot;:&quot;JiNan&quot;, &quot;host&quot;:&quot;localhost:8080&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot;, &quot;accept&quot;:&quot;*/*&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{\\&quot;name\\&quot;:\\&quot;admin\\&quot;}&quot;, &quot;requestUri&quot;:&quot;/test&quot;, &quot;responseBody&quot;:&quot;你好：admin&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;apiboot-unified-manage-request-logs&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;8080&quot;, &quot;spanId&quot;:&quot;95a73ca0-831b-45df-aa43-2b5887e8d98d&quot;, &quot;startTime&quot;:1571641723776, &quot;timeConsuming&quot;:3, &quot;traceId&quot;:&quot;25a7de96-b3dd-48e5-9854-1a8069a4a681&quot; }] 我们已经看到了Logging Admin控制台打印的上报请求日志，而这条请求的日志是否已经被保存到数据库了还不确定，下面我使用命令行来查看数据库的日志信息。 查看logging_service_details表内数据 12345678mysql&gt; select * from logging_service_details\\G;*************************** 1. row *************************** lsd_id: b069366a-25dc-41ec-8f09-242d81755cd0 lsd_service_id: apiboot-unified-manage-request-logs lsd_service_ip: 10.180.98.112 lsd_service_port: 8080lsd_last_report_time: 2019-10-21 02:14:26 lsd_create_time: 2019-10-21 15:14:26 logging_service_details存放了每一个上报请求日志的业务服务基本信息，每一个服务基本信息会在Logging Admin内存中缓存一份，方便获取service_id进行存储日志，根据ip+port+service_id进行确定唯一性，同一个服务只进行保存一次。 查看logging_request_logs表内数据 123456789101112131415161718192021mysql&gt; select * from logging_request_logs\\G;*************************** 1. row *************************** lrl_id: c42761f6-b072-4744-8a17-d8e6097b85delrl_service_detail_id: b069366a-25dc-41ec-8f09-242d81755cd0 lrl_trace_id: 055329a0-cfc1-4606-baf0-4fb0cc905ba2 lrl_parent_span_id: NULL lrl_span_id: aab83092-7749-4f88-8cb6-a949cc060197 lrl_start_time: 1571642065262 lrl_end_time: 1571642065286 lrl_http_status: 200 lrl_request_body: lrl_request_headers: {&quot;server-region&quot;:&quot;JiNan&quot;,&quot;host&quot;:&quot;localhost:8080&quot;,&quot;user-agent&quot;:&quot;curl/7.64.1&quot;,&quot;accept&quot;:&quot;*/*&quot;} lrl_request_ip: 0:0:0:0:0:0:0:1 lrl_request_method: GET lrl_request_uri: /test lrl_response_body: 你好：admin lrl_response_headers: {} lrl_time_consuming: 24 lrl_create_time: 2019-10-21 15:14:26 lrl_request_params: {&quot;name&quot;:&quot;admin&quot;} lrl_exception_stack: NULL 敲黑板画重点本章我们进行集成了ApiBoot Logging Admin，将业务服务的每一次请求日志都进行上报到Logging Admin，通过数据库的方式进行保存请求日志，然后也可以通过其他的方式，而且可以通过spanId以及traceId查看每一条请求链路的日志上下级关系以及每一个请求内耗时最多的span，可以精准的进行优化服务性能。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-report-logs-by-logging-to-admin： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-report-logs-by-logging-to-admin.html"},{"title":"ApiBoot零代码整合Spring Security的JDBC方式获取AccessToken","text":"ApiBoot Security内部提供了两种方式进行读取需要认证的用户信息，在之前的文章中讲到过ApiBoot Security使用内存方式（memory）不写一行代码就可以实现用户的认证并获取AccessToken，那我们使用JDBC方式是不是也是这么的简单呢？ 如果你还对ApiBoot不了解，可以通过以下的途径来获取帮助。 官方文档：https://apiboot.minbox.org 源码：https://gitee.com/minbox-projects/api-boot ApiBoot Security的认证方式有一些同学可能对ApiBoot Security的两种认证方式还不太了解，下面介绍下这两种认证方式的区别。 内存方式内存方式（memory）是将用户信息（用户名、密码、角色列表）在application.yml文件内配置，可配置多个用户，项目启动后将用户信息加载到内存中，用于获取AccessToken时的认证。 数据库方式数据库方式（jdbc）是将用户信息保存到数据库内，ApiBoot Security定义了一个默认表结构的用户信息数据表，我们可以从官网找到建表语句直接在自己的数据库内创建即可，当然如果不使用默认的表结构可以进行自定义读取用户信息。 注意：在数据库内存放用户的密码必须是通过BCryptPasswordEncoder加密后的密文字符串。 创建项目对ApiBoot Security的两种认证方式概念明白后，我们开始说下怎么才能使用JDBC方式进行用户认证，我们先来使用IDEA开发工具创建一个SpringBoot项目。 添加ApiBoot统一版本在使用ApiBoot内提供的组件依赖时，首先我们需要在pom.xml文件内添加ApiBoot统一版本，如下所示： 1234567891011121314151617&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--ApiBoot版本号--&gt; &lt;apiboot.version&gt;2.1.5.RELEASE&lt;/apiboot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--ApiBoot版本依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${apiboot.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加ApiBoot Security依赖在项目pom.xml文件添加ApiBoot Security依赖，如下所示： 12345&lt;!--ApiBoot Security OAuth--&gt;&lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt;&lt;/dependency&gt; 添加JDBC相关依赖我们本章使用MySQL数据库做演示，我们需要添加相关的数据库依赖以及数据库连接池依赖，由于ApiBoot Security读取内置的默认用户表结构使用的是DataSource，所以我们还需要添加一个可以实例化DataSource的依赖，可以选择api-boot-starter-mybatis-enhance或者spring-boot-starter-jdbc，在pom.xml添加依赖如下所示： 123456789101112131415161718192021&lt;!--SpringBoot Web--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--MySQL--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--Hikari--&gt;&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--SpringBoot JDBC--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 注意：spring-boot-starter-web这个依赖不可少，在ApiBoot AutoConfiguration内需要一些Web的依赖类。 创建默认用户表结构本章使用ApiBoot Security提供的默认用户表结构，访问官方文档查看3.3 使用内置表结构的用户，将建表语句在自己数据库内执行创建表信息，创建后添加一条用户信息，如下所示： 1INSERT INTO `api_boot_user_info` VALUES (1,'admin','昵称','$2a$10$RbJGpi.v3PwkjrYENzOzTuMxazuanX3Qa2hwI/f55cYsZhFT/nX3.',NULL,NULL,NULL,'N','Y','O','2019-11-29 06:14:44'); 配置数据源依赖添加完成后我们在application.yml配置文件内进行配置数据源，如下所示： 123456789101112spring: application: name: apiboot-security-customize-select-user # 数据源配置 datasource: type: com.zaxxer.hikari.HikariDataSource url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driverserver: port: 9090 配置ApiBootSecurity JDBC方式由于ApiBoot Security默认使用memory用户认证读取方式，我们需要在application.yml文件内进行修改，如下所示： 123456# ApiBoot相关配置api: boot: # 启用ApiBoot Security 的JDBC方式 security: away: jdbc 运行测试项目配置完成，下面我们通过XxxApplication方式启动项目。 在获取AccessToken之前我们要知道的一点，ApiBoot Security内部默认集成了OAuth2，而且还默认配置了clientId、clientSecret客户端基本信息，默认值分别是ApiBoot、ApiBootSecret。 12clientId = ApiBootclientSecret = ApiBootSecret 如果你对ApiBoot OAuth其他功能有兴趣可以查看ApiBoot OAuth文档了解详情。 获取AccessToken由于学习者的本机环境不同，下面采用两种方式进行获取AccessToken。 CURL方式执行如下命令获取AccessToken： 12➜ ~ curl -X POST ApiBoot:ApiBootSecret@localhost:9090/oauth/token\\?grant_type\\=password\\&amp;username\\=admin\\&amp;password\\=123456{&quot;access_token&quot;:&quot;d9cb97ee-d1bf-42e1-a7a0-c1002df48c52&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;db9e9d52-cbe3-4379-a5f2-ffaa34681c01&quot;,&quot;expires_in&quot;:2884,&quot;scope&quot;:&quot;api&quot;} PostMan方式 注意：获取AccessToken的请求方式为POST. 敲黑板，划重点ApiBoot Security不仅内存方式可以实现零代码的方式进行集成Spring Security、OAuth2，JDBC方式同样也可以，不过要根据ApiBoot的约定创建用户表。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-security-customize-select-user： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-security-customize-select-user.html"},{"title":"见过这么简单的方式整合SpringSecurity &amp; OAuth2的自定义查询用户吗？","text":"SpringSecurity整合OAuth2是开发者公认的资源保护、服务认证的最佳搭配伙伴，这对好基友一直在默默的守护着应用服务的安全，根据访问者的不同角色可以颗粒度控制到具体的接口，从而实现权限的细微划分。 而SpringSecurity框架在安全框架的队伍中算是入门比较高的，虽然Spring通过SpringBoot进行了封装，但是使用起来还是有很多容易遗漏的配置，因为配置比较多，让初学者理解起来也比较困难，针对这个问题ApiBoot对SpringSecurity以及OAuth2进行了封装，在基础上极大的简化了配置（只做简化、增强，SpringSecurity的基础语法、配置还可以正常使用） ApiBoot Security 系列文章 ApiBoot实现零代码整合Spring Security &amp; OAuth2 ApiBoot零代码整合Spring Security的JDBC方式获取AccessToken 创建项目使用IDEA开发工具创建一个SpringBoot项目。 ApiBoot的底层是SpringBoot，而且ApiBoot为了支持SpringBoot的2.2.x分支，也对应的创建了2.2.x分支版本。 添加ApiBoot统一依赖创建完项目后我们需要在pom.xml添加ApiBoot的统一版本依赖，如下所示： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加相关依赖本章我们需要查询数据库内的用户信息进行认证，所以需要在pom.xml添加数据库相关的依赖，如下所示： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-mybatis-enhance&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在本章使用到了ApiBoot Mybatis Enhance，具体的使用请访问官方文档ApiBoot MyBatis Enhance使用文档 配置数据源添加数据库相关的依赖后，在application.yml文件内添加如下配置信息： 123456789101112spring: application: name: apiboot-security-oauth-custom-certification-user # 数据源配置 datasource: type: com.zaxxer.hikari.HikariDataSource url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8&amp;serverTimezone=Asia/Shanghai username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driverserver: port: 9090 配置ApiBoot SecurityApiBoot Security默认采用的是内存方式（memory）读取用户信息，我们本章需要修改为JDBC方式，并且禁用默认读取用户信息（ApiBoot Security内部提供了默认的表结构，建表后添加数据即可直接使用用户信息进行认证，详见：ApiBoot Security使用文档）。 在application.yml配置文件中添加如下配置： 12345678# ApiBoot配置api: boot: security: # ApiBoot Security 使用JDBC方式读取用户 away: jdbc # 禁用默认的读取用户方式 enable-default-store-delegate: false api.boot.security.enable-default-store-delegate配置参数默认值为true，也就是会自动读取数据源对应数据库内的api_boot_user_info用户信息表，当我们设置为false后需要通过实现ApiBootStoreDelegate接口来进行自定义查询的用户信息。 配置ApiBoot OAuthapi-boot-starter-security-oauth-jwt这个依赖内部也默认集成了OAuth2，而且默认的数据存储方式与Spring Security一致也是内存方式（memory），我们本章的主要目的是查询认证用户信息，而不是客户端信息，所以我们还是采用默认的内存方式，不过修改下客户端的默认配置信息，在application.yml文件内添加配置如下所示： 123456789# ApiBoot配置api: boot: oauth: # ApiBoot OAuth2的客户端列表 clients: - clientId: hengboy clientSecret: chapter grantTypes: password,refresh_token 在ApiBoot中OAuth2默认的客户端配置信息，可以通过查看org.minbox.framework.api.boot.autoconfigure.oauth.ApiBootOauthProperties.Client源码了解详情。 用户认证配置已经完成，下面我们来编写查询用户信息，将用户信息交给ApiBoot Security框架进行认证、生成AccessToken等操作。 本章使用的持久化框架是ApiBoot MyBatis Enhance，具体的使用方法请查看官方文档。 创建用户表我们在数据库内创建一张名为system_user的系统用户信息表，表结构如下所示： 123456789CREATE TABLE `system_user` ( `su_id` varchar(36) COLLATE utf8mb4_general_ci NOT NULL COMMENT '用户编号', `su_login_name` varchar(30) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '登录名', `su_nick_name` varchar(30) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '昵称', `su_password` varchar(200) COLLATE utf8mb4_general_ci DEFAULT NULL COMMENT '用户密码', `su_create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `su_status` int(11) DEFAULT '1' COMMENT '用户状态，1：正常，0：冻结，-1：已删除', PRIMARY KEY (`su_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci COMMENT='系统用户信息表'; system_user用户表创建完成后，我们往这张表内添加一条用户数据，如下所示： 1INSERT INTO `system_user` VALUES ('9b69fd26-14db-11ea-b743-dcd28627348e','yuqiyu','恒宇少年 - 于起宇','$2a$10$RbJGpi.v3PwkjrYENzOzTuMxazuanX3Qa2hwI/f55cYsZhFT/nX3.','2019-12-02 08:13:22',1); 我们在登录时用户名对应su_login_name字段，而密码则是对应su_password字段，yuqiyu这个用户的密码初始化为123456，密码的格式必须为BCryptPasswordEncoder加密后的密文。 创建用户实体针对system_user表我们需要来创建一个ApiBoot MyBatis Enhance使用的实体，创建一个名为SystemUser的实体如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * 系统用户基本信息 * * @author 恒宇少年 */@Data@Table(name = &quot;system_user&quot;)public class SystemUser implements UserDetails { /** * 用户编号 */ @Id(generatorType = KeyGeneratorTypeEnum.UUID) @Column(name = &quot;su_id&quot;) private String userId; /** * 登录名 */ @Column(name = &quot;su_login_name&quot;) private String loginName; /** * 昵称 */ @Column(name = &quot;su_nick_name&quot;) private String nickName; /** * 密码 */ @Column(name = &quot;su_password&quot;) private String password; /** * 创建时间 */ @Column(name = &quot;su_create_time&quot;) private String createTime; /** * 用户状态 * 1：正常，0：已冻结，-1：已删除 */ @Column(name = &quot;su_status&quot;) private Integer status; @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return Collections.EMPTY_LIST; } @Override public String getUsername() { return this.loginName; } @Override public String getPassword() { return this.password; } /** * UserDetails提供的方法，用户是否未过期 * 可根据自己用户数据表内的字段进行扩展，这里为了演示配置为true * * @return */ @Override public boolean isAccountNonExpired() { return true; } /** * UserDetails提供的方法，用户是否未锁定 * 可根据自己用户数据表内的字段进行扩展，这里为了演示配置为true * * @return */ @Override public boolean isAccountNonLocked() { return true; } /** * UserDetails提供的方法，凭证是否未过期 * 可根据自己用户数据表内的字段进行扩展，这里为了演示配置为true * * @return */ @Override public boolean isCredentialsNonExpired() { return true; } /** * UserDetails提供的方法，是否启用 * * @return */ @Override public boolean isEnabled() { return this.status == 1; }} 具体的注解使用详见ApiBoot MyBatis Enhance文档，这里还一点需要注意的是，SystemUser实现了UserDetails接口，如果使用过Spring Security的同学应该都知道这是Spring Security提供的用户详情接口定义，我们如果自定义查询用户就应该让我们自定义的用户实体（注：这是的自定义用户实体也就是SystemUser实体）实现这个接口并全部实现UserDetails接口内提供的方法。 创建用户数据接口用户的实体已经创建完成，我们本章需要一个根据用户的登录名来查询用户基本的数据接口，创建一个名为SystemUserEnhanceMapper的接口如下所示： 12345678910111213141516/** * ApiBoot Enhance提供的增强Mapper * 自动被扫描并且注册到IOC * * @author 恒宇少年 * @see org.minbox.framework.api.boot.autoconfigure.enhance.ApiBootMyBatisEnhanceAutoConfiguration */public interface SystemUserEnhanceMapper extends EnhanceMapper&lt;SystemUser, Integer&gt; { /** * 根据用户登录名查询用户信息 * * @param loginName {@link SystemUser#getLoginName()} * @return {@link SystemUser} */ SystemUser findByLoginName(@Param(&quot;loginName&quot;) String loginName);} 该接口继承了EnhanceMapper&lt;Entity,ID&gt;接口，可以自动被扫描到创建代理的实例后并且加入IOC，这样我们在项目其他的地方可以直接注入使用。 注意：findByXxx方法是ApiBoot MyBatis Enhance提供的方法命名规则查询，多个查询条件可以使用And或者Or追加，会自动根据方法的规则生成对应的SQL。 实现ApiBootStoreDelegate接口ApiBoot Security提供了一个接口ApiBootStoreDelegate，这个接口主要是用来查询登录用户的具体信息的作用，当我们通过grant_type=password&amp;username=xxx的方式进行获取AccessToken时，ApiBoot Security会直接把username的参数值传递给ApiBootStoreDelegate#loadUserByUsername的方法内，这样我们就可以根据username进行查询用户并返回给ApiBoot Security做后续的认证操作。 我们来创建一个名为UserService的类并实现ApiBootStoreDelegate接口，如下所示： 12345678910111213141516171819202122232425262728/** * 自定义读取用户信息 * * @author 恒宇少年 */@Servicepublic class UserService implements ApiBootStoreDelegate { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(UserService.class); /** * 用户数据接口 */ @Autowired private SystemUserEnhanceMapper mapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { UserDetails userDetails = mapper.findByLoginName(username); if (ObjectUtils.isEmpty(userDetails)) { throw new UsernameNotFoundException(&quot;用户：&quot; + username + &quot;，不存在.&quot;); } logger.info(&quot;登录用户的信息：{}&quot;, JSON.toJSONString(userDetails)); return userDetails; }} loadUserByUsername方法的返回值是UserDetails接口类型，在之前我们已经将SystemUser实现了该接口，所以我们可以直接将SystemUser实例作为返回值。 运行测试代码一切就绪，通过XxxxApplication的方式来启动项目。 测试点：获取AccessToken在获取AccessToken之前，我们需要确认application.yml文件内配置的api.boot.oauth.clients的客户端的clientId、clientSecret配置内容，下面是通过CURL的方式： 12➜ ~ curl hengboy:chapter@localhost:9090/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123456'{&quot;access_token&quot;:&quot;3beb1bee-9ca6-45e1-9fb8-5fc181670f63&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;d2243e18-8ab3-4842-a98f-ebd79da94e2e&quot;,&quot;expires_in&quot;:7199,&quot;scope&quot;:&quot;api&quot;} 测试点：刷新AccessToken复制上面获取到的refresh_token的值进行刷新，下面是刷新AccessToken的CURL方式： 12➜ ~ curl hengboy:chapter@localhost:9090/oauth/token -d 'grant_type=refresh_token&amp;refresh_token=d2243e18-8ab3-4842-a98f-ebd79da94e2e'{&quot;access_token&quot;:&quot;e842c2ee-5672-49db-a530-329186f36492&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;d2243e18-8ab3-4842-a98f-ebd79da94e2e&quot;,&quot;expires_in&quot;:7199,&quot;scope&quot;:&quot;api&quot;} hengboy这个OAuth2客户端在application.yml中通过配置grantTypes授权了两种grant_type，分别是password、refresh_token，如果需要别的方式可以在配置文件内对应添加。 敲黑板，划重点ApiBoot整合Spring Security以及OAuth2后读取自定义用户信息，我们只需要关注具体怎么读取用户信息，之前那些懵懵懂懂的代码配置都可以通过配置文件的方式代替，本章的主要内容是ApiBootStoreDelegate这个接口，ApiBoot所提供的功能还不止这些，会陆续分享给大家。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-security-oauth-custom-certification-user： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-security-oauth-custom-certification-user.html"},{"title":"还不会使用JWT格式化OAuth2令牌吗？","text":"OAuth2默认的AccessToken是由DefaultAccessTokenConverter生成，是具有唯一性的UUID随机字符串，我们如果想要使用JWT来格式化AccessToken就需要使用JwtAccessTokenConverter来进行格式化，当然如果你有自己独特的业务可以自己实现AccessTokenConverter接口，并将实现类交付给IOC托管即可。 ApiBoot内部集成了DefaultAccessTokenConverter（默认）、JwtAccessTokenConverter，只需要一个配置就可以实现相互转换。 相关文档 ApiBoot OAuth2官方文档：https://apiboot.minbox.org/zh-cn/docs/api-boot-oauth.html ApiBoot 开源源码：minbox-projects/api-boot JWT加密秘钥对JWT了解的同学应该知道，它内部不可逆的部分采用的是RSA加密，在加密过程中需要一个秘钥，在JwtAccessTokenConverter实现类中采用了6位随机字符串作为秘钥，相关源码如下： 1234567891011121314151617181920/** * Helper that translates between JWT encoded token values and OAuth authentication * information (in both directions). Also acts as a {@link TokenEnhancer} when tokens are * granted. * * @see TokenEnhancer * @see AccessTokenConverter * * @author Dave Syer * @author Luke Taylor */public class JwtAccessTokenConverter implements TokenEnhancer, AccessTokenConverter, InitializingBean { ..... private String verifierKey = new RandomValueStringGenerator().generate(); private Signer signer = new MacSigner(verifierKey); private String signingKey = verifierKey;} 这种形式虽然在某一些层面上是唯一的，实在感觉不太严谨，所以ApiBoot添加一个配置，可以自定义这个加密秘钥signingKey字段。 创建示例项目为了本章的演示效果，我们使用IDEA来创建一个SpringBoot项目，pom.xml文件内相关的依赖如下所示： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 依赖添加完成后下面我们配置下测试的用户以及客户端信息。 配置内存用户我们在获取AccessToken时使用的password授权类型，所以我们需要在application.yml文件内配置登录用户所使用的用户名、密码，如下所示： 123456api: boot: security: users: - username: yuqiyu password: 123456 本章为了演示JWT格式化AccessToken，验证的用户采用内存方式配置，了解详情。 开启JWT转换ApiBoot OAuth2默认使用DefaultAccessTokenConverter实现类来格式化AccessToken，如果我们想要切换到JwtAccessTokenConverter，需要在application.yml添加一个配置，如下所示： 123456api: boot: oauth: # 启用JWT，用于格式化AccessToken jwt: enable: true 配置加密秘钥在本文开头说到了JwtAccessTokenConverter实现类内采用的是6位随机字符串的方式来作为RSA加密的秘钥，ApiBoot OAuth2提供了参数配置可以进行自定义，如下所示： 123456api: boot: oauth: jwt: # 加密秘钥 sign-key: 恒宇少年 秘钥格式不限，如：特殊字符串、汉字、数字、字母…. 运行测试见证奇迹的时刻到了，我们通过IDEA的XxxApplication方式来启动本章项目，尝试使用CURL方式获取AccessToken如下所示： 123456789➜ ~ curl ApiBoot:ApiBootSecret@localhost:9090/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123456'{ &quot;access_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiYXBpIl0sInVzZXJfbmFtZSI6Inl1cWl5dSIsInNjb3BlIjpbImFwaSJdLCJleHAiOjE1NzU5NTMwNDgsImF1dGhvcml0aWVzIjpbIlJPTEVfYXBpIl0sImp0aSI6ImQxMDNmNDYwLTk3YzMtNGNiZS05OWM4LWYzZjU2MmRhMDZhOCIsImNsaWVudF9pZCI6IkFwaUJvb3QifQ.HMHRBCIGPZNlkJPCnXaktMWxXEW-5roo7tdQR1JpCyY&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsiYXBpIl0sInVzZXJfbmFtZSI6Inl1cWl5dSIsInNjb3BlIjpbImFwaSJdLCJhdGkiOiJkMTAzZjQ2MC05N2MzLTRjYmUtOTljOC1mM2Y1NjJkYTA2YTgiLCJleHAiOjE1Nzg1Mzc4NDgsImF1dGhvcml0aWVzIjpbIlJPTEVfYXBpIl0sImp0aSI6ImY1NDMxZTMzLWE1YzMtNGVmNC1hZDM0LTk1MGQ3ODliYTRiZCIsImNsaWVudF9pZCI6IkFwaUJvb3QifQ.TfJ5vThvaibV2kVo2obHqnYzmYm-GsdtRLoB3RJbkrg&quot;, &quot;expires_in&quot;: 6925, &quot;scope&quot;: &quot;api&quot;, &quot;jti&quot;: &quot;d103f460-97c3-4cbe-99c8-f3f562da06a8&quot;} ApiBoot OAuth有默认的客户端配置信息为ApiBoot、ApiBootSecret，为了方便演示，这里没做修改，如需修改请查看ApiBoot OAuth文档，如果你感觉控制台打印的json不美观，阅读性太差，可以使用在线格式化JSON工具. 敲黑板，划重点使用ApiBoot来格式化OAuth2的AccessToken是不是特别简单？省去了我们自己去创建JwtAccessTokenConverter实例，然后还需要将实例放入IOC繁琐的步骤，更多使用详解敬请期待~~ 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-security-oauth-use-jwt： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-security-oauth-use-jwt.html"},{"title":"ApiBoot实现零代码整合Spring Security &amp; OAuth2","text":"接口服务的安全性一直是程序员比较注重的一个问题，成熟的安全框架也比较多，其中一个组合就是Spring Security与OAuth2的整合，在ApiBoot内通过代码的封装、自动化配置实现了自动化整合这两大安全框架。 ApiBoot Security OAuth简介ApiBoot Security OAuth是ApiBoot开源项目内的一个组件，内部通过SpringBoot AutoConfiguration整合了Spring Security、OAuth2，而且支持多种存储方式，如：内存（memory）、数据库（jdbc）、Redis等，使用配置文件的方式来代替代码侵入式集成方式，提高开发效率、减少非业务的繁琐代码，而且还有这比较高的可扩展性。 ApiBoot 源码（源码详见：api-boot-plugins、api-boot-autoconfigure目录）：https://gitee.com/minbox-projects/api-boot ApiBoot Security使用文档：https://apiboot.minbox.org/zh-cn/docs/api-boot-security.html ApiBoot OAuth使用文档：https://apiboot.minbox.org/zh-cn/docs/api-boot-oauth.html 创建项目通过Idea开发工具创建一个名为apiboot-security-oauth-zero-code-integration的SpringBoot项目。 添加ApiBoot统一版本依赖在添加依赖之前我们需要将ApiBoot的统一版本依赖加入到我们项目的pom.xml文件内，如下所示： 123456789101112&lt;!--ApiBoot统一版本依赖--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 添加ApiBoot Security OAuth依赖添加完成版本依赖后，我们继续在pom.xml文件内添加ApiBoot Security OAuth依赖，如下所示： 12345678910111213&lt;dependencies&gt; &lt;!--SpringBoot Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Security Oauth--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置ApiBoot Security用户列表ApiBoot Security默认支持内存方式（memory）配置用户列表，用于整合OAuth2的密码授权方式（grant_type=password），我们需要在application.yml配置文件内添加相关配置，如下所示： 12345678910111213141516spring: application: name: apiboot-security-oauth-first-applicationserver: port: 9090# ApiBoot 相关配置api: boot: # ApiBoot Security配置 security: # 配置内存用户列表 users: - username: hengboy password: 123456 - username: yuqiyu password: 123123 通过api.boot.security.users参数可以配置多个用户信息，每个用户可配置username、password、roles，可以通过查看org.minbox.framework.api.boot.autoconfigure.security.ApiBootSecurityProperties源码类了解详情。 username：配置Spring Security用户的用户名。 password：配置Spring Security用户的密码。 roles：配置Spring Security用户对应授权的角色列表，多个可以使用英文半角,隔开，或者使用-方式配置。 运行测试我们通过XxxApplication方式启动本章项目。 测试点：获取AccessToken项目运行成功后我们先来测试下是否可以获取到AccessToken。 Curl方式获取： 12➜ ~ curl -X POST ApiBoot:ApiBootSecret@localhost:9090/oauth/token -d &quot;grant_type=password&amp;username=hengboy&amp;password=123456&quot;{&quot;access_token&quot;:&quot;f16202f7-ab8c-41ae-86be-e314aebe82ff&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;93c74812-ec5b-4676-8378-b68e4c1751ae&quot;,&quot;expires_in&quot;:3297,&quot;scope&quot;:&quot;api&quot;} PostMan方式获取： 如果对Spring Security与OAuth2整合有一定经验的同学应该明白grant_type是OAuth2内提供的其中一种授权方式，而参数username、password则是整合后对应的Spring Security的用户名以及密码，也就是我们在application.yml配置文件api.boot.security.users配置用户列表的其中一个用户信息。 在上面分别通过Curl、PostMan两种方式进行测试获取AccessToken，都是可以直接获取到的。 测试点：获取当前用户信息ApiBoot Security OAuth获取当前用户信息的方式与Spring Security一样，通过注入java.security.Principal接口来完成，下面我们创建一个名为UserController的控制器来测试下效果： 12345678910111213141516171819202122232425262728293031package org.minbox.chapter.apiboot.security.oauth.first.application;import org.springframework.security.access.prepost.PreAuthorize;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.security.Principal;/** * 登录用户信息 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/api/user&quot;)public class UserController { /** * 获取当前登录的用户信息 * 通过Spring Security提供的注解{@link PreAuthorize}进行验证角色 * * @param principal {@link Principal} * @return {@link Principal#getName()} */ @GetMapping @PreAuthorize(&quot;hasRole('api')&quot;) public String info(Principal principal) { return principal.getName(); }} 注意：ApiBoot Security OAuth默认权限拦截的路径时/api/**，所以我们在测试控制器上配置了/api/user作为路径前缀，如果想对ApiBoot Security OAuth详细了解，请访问ApiBoot官网文档ApiBoot Security使用文档 我们通过Curl方式访问http://localhost:9090/api/user接口效果如下： 12➜ ~ curl http://localhost:9090/api/user -H 'Authorization: Bearer d73e86a8-892f-42c1-bc95-04aedfe97828'hengboy 访问/api/user路径的AccessToken是通过用户hengboy用户生成的，所以该接口返回了hengboy用户名。 敲黑板，划重点ApiBoot Security OAuth极其简单的完成了Spring Security与OAuth2的整合，使用内存方式时不需要配置一行代码就可以完成自动化的整合。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-security-oauth-first-application： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-security-oauth-zero-code-integration.html"},{"title":"原来SpringSecurity整合OAuth2后开放权限拦截路径还能这么玩？","text":"当我们整合了Spring Security以及OAuth2后发现，有一些业务请求是需要开放的，因为种种原因这时访问者还没有身份标识（比如：用户刚来，还没有注册，需要进行新用户注册，这时注册业务相关的接口都应该是开放的），下面我们来看看ApiBoot是怎么排除路径不进行权限拦截的。 官方相关文档相关ApiBoot Security官方使用文档，请访问 ApiBoot Security。 在文档的第4. 默认排除路径部分，我们了解到了ApiBoot Security为了与其他的第三方框架进行集成，在内部已经添加了一些默认的拦截路径，当我们在添加开放路径时会在默认的基础上增量添加，不会覆盖。 创建项目我们使用IDEA开发工具创建一个SpringBoot项目，在pom.xml内添加相关的依赖，如下所示： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Security OAuth安全组件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--ApiBoot统一版本依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 排除路径配置ApiBoot Security OAuth安全组件默认拦截配置为/api/**，也就是/api下的全部路径以及子路径都需要认证后才可以访问。 我们可以通过api.boot.security.auth-prefix参数配置修改保护的路径列表，ApiBoot还提供了另外的一个参数配置api.boot.security.ignoring-urls，用于配置开放的路径列表（开放路径可直接访问，不走权限拦截），支持使用Ant风格，application.yml配置内容如下所示： 123456789101112131415spring: application: name: apiboot-security-open-paths-without-interceptserver: port: 9090api: boot: # ApiBoot Security安全配置 security: # 权限拦截的路径前缀 auth-prefix: /** # 排除不拦截的路径 ignoring-urls: - /index/** 我们在application.yml文件内配置api.boot.security.ignoring-urls的值为/index/**，这时我们在访问/index、/index/xxx路径时都不会经过权限的拦截，直接可以访问到。 示例请求我们来创建一个名为IndexController的示例控制器，来验证我们开放的路径是否已经生效了，如下所示： 12345678910111213141516171819202122232425262728293031/** * 示例：控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/index&quot;)public class IndexController { /** * 示例：首页地址 * /index * * @return */ @GetMapping public String index() { return &quot;this is index page.&quot;; } /** * 示例：首页地址子页面 * /index/sub * * @return */ @GetMapping(value = &quot;/sub&quot;) public String indexSub() { return &quot;this is sub index page.&quot;; }} 在application.yml我们配置的开放地址为/index/**，所以IndexController控制器内的两个地址/index、/index/sub都会被开放，不走权限拦截，直接放行。 运行测试我们使用IDEA通过XxxApplication入口类的方式来启动本章项目源码，下面是我们要验证的测试点。 测试点：开放路径我们先来访问下http://localhost:9090/index，效果如下所示： 12➜ ~ curl http://localhost:9090/index this is index page. 直接访问/index是可以直接获取接口返回的内容，这也证明了一点，这个地址被开放了，不再被权限拦截。 在之前说到ApiBoot Security OAuth开放地址支持Ant风格，我们配置的开放地址为/index/**，所以/index/sub这个请求地址也应该已经被开放了，效果如下所示： 12➜ ~ curl http://localhost:9090/index/subthis is sub index page. 如果我们修改api.boot.security.ignoring-urls配置为/index，我们在访问/index/sub这个地址时是没有权限的，需要携带有效的AccessToken才可以访问到。 测试点：未开放路径的拦截下面我们来完成一个比较特殊的测试点，访问一个并没有在后台定义的路径，如下所示： 12➜ ~ curl http://localhost:9090/index/11{&quot;error&quot;:&quot;unauthorized&quot;,&quot;error_description&quot;:&quot;Full authentication is required to access this resource&quot;} 我们并没有添加/index/xx这个请求地址的实现，当访问时同样也会被拦截，这证明了我们发起的请求并没有到达解析请求就已经被权限拦截了。 敲黑板，划重点除了被开放的路径都需要提供有效的AccessToken才可以访问，无论这个地址是否存在，本章为了示例讲解方便我这里配置的权限拦截根地址为/**，api.boot.security.auth-paths参数源码是一个数组（详见：org.minbox.framework.api.boot.autoconfigure.security.ApiBootSecurityProperties），可以配置多个地址，比如：/user/**、/order/**，api.boot.security.ignoring-urls同样支持数组形式配置多个。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-security-open-paths-without-intercept： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-security-open-paths-without-intercept.html"},{"title":"使用Swagger2作为文档来描述你的接口信息","text":"接口文档在前后分离的项目中是必不可少的一部分，文档的编写一直以来都是一件头疼的事情，写程序不写注释、不写文档这几乎是程序员的通病，Swagger2的产生给广大的程序员们带来了曙光，只需要在接口类或者接口的方法上添加注解配置，就可以实现文档效果，除了可以应用到单体应用，在微服务架构中也是可以使用的，只需要整合zuul就可以实现各个服务的文档整合。 本文所需ApiBoot相关链接： ApiBoot官网 ApiBoot全组件系列文章 ApiBoot Gitee源码仓库（欢迎Contributor） ApiBoot GitHub源码仓库（欢迎Contributor） 前言ApiBoot Swagger内部封装了Swagger2，只需要一个注解@EnableApiBootSwagger就可以实现集成，使用起来非常简单。 ApiBoot Swagger提供了一系列的默认配置，比如：文档标题、文档描述、文档版本号等，如果需要修改文档的默认配置，只需要在application.yml文件内对应配置参数即可实现自定义，告别了繁琐的代码配置，ApiBoot通过自动化配置的方式来实现这一点，可以查看 ApiBootSwaggerAutoConfiguration 配置类源码了解详情。 ApiBoot Swagger支持在线调试集成OAuth2的接口，只需要在文档界面通过 &quot;Authorize&quot;按钮设置有效的AccessToken即可。 可配置参数一览ApiBoot Swagger之所以可以只需要一个注解就可以实现Swagger2的集成，其中难免有很多的配置参数在做支持，了解每一个配置参数的作用，我们才能进行心应手的自定义调整。 参数名 默认值 描述 api.boot.swagger.enable true 是否启用文档 api.boot.swagger.title ApiBoot快速集成Swagger文档 文档标题 api.boot.swagger.description - 文档描述 api.boot.swagger.base-package SpringBoot默认package，详见AutoConfigurationPackages 生成文档的基础package api.boot.swagger.version ApiBoot的版本号 文档版本号 api.boot.swagger.authorization.name 授权名称 api.boot.swagger.authorization.key-name Authorization 整合Oauth2后AccessToken在Header内的Name 上面是常用的参数，更多配置参数详见官方文档：https://apiboot.minbox.org/zh-cn/docs/api-boot-swagger.html 创建示例项目我们先来创建一个SpringBoot应用程序，在项目的pom.xml文件内添加ApiBoot的相关依赖，如下所示： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-swagger&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 启用ApiBoot Swagger通过@EnableApiBootSwagger注解来启用ApiBoot Swagger，该注解可以配置在XxxApplication入口类上，也可以配置在被@Configuration注解修饰的配置类上。 123456789@SpringBootApplication@EnableApiBootSwaggerpublic class ApibootSwaggerDescribeTheInterfaceApplication { public static void main(String[] args) { SpringApplication.run(ApibootSwaggerDescribeTheInterfaceApplication.class, args); }} 修改默认配置ApiBoot Swagger所提供的配置参数都可以在application.yml文件内进行设置或修改默认值，下面是修改了版本号、标题的配置： 12345678# ApiBoot相关配置api: boot: swagger: # 配置文档标题 title: 接口文档 # 配置文档版本 version: v1.0 测试控制器为了方便演示Swagger文档的强大之处，我们来创建一个测试的控制器，使用Swagger提供的注解来描述测试接口，如下所示： 123456789101112131415161718192021222324252627282930313233343536/** * 示例控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/user&quot;)@Api(tags = &quot;用户控制器&quot;)public class UserController { /** * 示例： * 根据用户名查询用户基本信息 * * @param name {@link UserResponse#getName()} * @return {@link UserResponse} */ @GetMapping(value = &quot;/{name}&quot;) @ApiOperation(value = &quot;查询用户信息&quot;, response = UserResponse.class) @ApiResponse(code = 200, message = &quot;success&quot;, response = UserResponse.class) public UserResponse getUser(@PathVariable(&quot;name&quot;) String name) { return new UserResponse(name, 25); } /** * 响应实体示例 */ @ApiModel @Data @AllArgsConstructor @NoArgsConstructor public static class UserResponse { @ApiModelProperty(value = &quot;用户名&quot;) private String name; @ApiModelProperty(value = &quot;年龄&quot;) private Integer age; }} 注意：ApiBoot Swagger只是针对Swagger进行了封装，实现了快速集成，对内部的注解以及配置不做修改。 运行测试启动本章项目源码，访问：http://localhost:8080/swagger-ui.html 查看运行效果，如下图所示： 当我们点击 “用户控制器” 时可以展开该Controller内定义的接口列表，每一个接口都提供了 “Try it out”（在线调试）功能。 本章并没有集成OAuth2，在执行在线调试时并不需要配置AccessToken。 敲黑板，划重点ApiBoot Swagger的实现主要归功于SpringBoot自定义Starter，根据配置参数进行条件配置控制对象的实例化，通过@Import来导入Swagger所需要的配置类。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-swagger-describe-the-interface： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-swagger-describe-the-interface.html"},{"title":"Swagger2怎么整合OAuth2来在线调试接口？","text":"前言Swagger2作为侵入式文档中比较出色的一员，支持接口认证的在线调试肯定是不在话下的，当我们在调用OAuth2所保护的接口时，需要将有效的AccessToken作为请求Header内Authorization的值时，我们才拥有了访问权限，那么我们在使用Swagger在线调试时该设置AccessToken的值呢？ 本文所需ApiBoot相关链接： ApiBoot官网 ApiBoot全组件系列文章 ApiBoot Gitee源码仓库（欢迎Contributor） ApiBoot GitHub源码仓库（欢迎Contributor） 创建示例项目在之前文章「使用Swagger2作为文档来描述你的接口信息」我们已经讲到了使用Swagger2来简单的描述接口，提供可视化在线的接口文档，我们本章的主要目的是来集成使用OAuth2实现在线调试接口，我们把之前章节测试的接口UserController复制到本篇文章中以便于测试，本章项目pom.xml依赖如下所示： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-swagger&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-security-oauth-jwt&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 如果你看过ApiBoot Security、ApiBoot OAuth你应该知道，通过application.yml文件简单的几行配置就可以集成Spring Security整合OAuth2，本章来使用内存方式配置用户列表以及客户端列表。 ApiBoot Security &amp; ApiBoot OAuth组件使用系列文章：https://blog.minbox.org/apiboot-all-articles.html 如果你想深入的了解这个神奇的ApiBoot安全组件，可以通过依赖文章汇总链接学习。 启用ApiBoot Swagger通过@EnableApiBootSwagger注解来启用ApiBoot Swagger相关功能，在XxxApplication入口类配置如下所示： 123456789@SpringBootApplication@EnableApiBootSwaggerpublic class ApibootSwaggerIntegratedOauthApplication { public static void main(String[] args) { SpringApplication.run(ApibootSwaggerIntegratedOauthApplication.class, args); }} 配置ApiBoot Security使用grant_type=password获取AccessToken时，需要我们传递用户的username、password，使用默认的内存方式配置我们只需要在application.yml文件内添加如下配置： 123456789api: boot: security: # 配置安全用户列表 users: - username: yuqiyu password: 123123 # 资源保护路径前缀，默认为/api/** auth-prefix: /** 配置ApiBoot OAuth我们来添加OAuth2所需要的客户端列表配置信息，使用默认的内存方式配置客户端的client-id、client-secret，只需要修改application.yml文件内容如下所示： 1234567api: boot: oauth: # 配置OAuth客户端列表 clients: - clientId: minbox clientSecret: chapter 了解资源文件排除拦截Swagger2可视化界面有很多静态资源组成，比如：js/css/images等，而集成Spring Security后这些资源需要排除权限拦截才可以访问到，如果是使用传统的方式整合Spring Security，需要使用WebSecurity来进行忽略路径才可以，而通过ApiBoot Security则是不用考虑这一点，在内部已经对Swagger的静态资源文件做出了排除。 运行测试通过Application方式启动本章项目，Swagger可视化界面访问：http://localhost:8080/swagger-ui.html 获取AccessToken通过CURL方式获取用户：yuqiyu的请求令牌，如下所示： 12➜ ~ curl -X POST minbox:chapter@localhost:8080/oauth/token -d 'grant_type=password&amp;username=yuqiyu&amp;password=123123'{&quot;access_token&quot;:&quot;304676a4-b9a6-4c4d-af40-e439b934aba8&quot;,&quot;token_type&quot;:&quot;bearer&quot;,&quot;refresh_token&quot;:&quot;ee2b5744-6947-4677-862e-fcf9517afca5&quot;,&quot;expires_in&quot;:7199,&quot;scope&quot;:&quot;api&quot;} Swagger在线调试我们把获取的AccessToken与类型进行组合成：Bearer 304676a4-b9a6-4c4d-af40-e439b934aba8，将该令牌字符串配置到Swagger界面上，如下图所示： 输入后点击Authorize按钮即可。 敲黑板，划重点Swagger的在线调试其实内部是模拟发送请求，将界面上输入的参数进行组合装配，发送到需要测试的接口路径，而上图设置AccessToken，也是一个临时保存，刷新页面就会丢失，发送请求时会自动追加到Request Header列表内。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-swagger-integrated-oauth： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-swagger-integrated-oauth.html"},{"title":"使用ApiBoot Logging进行统一管理请求日志","text":"ApiBoot Logging通过集成minbox-logging来进行管理每一次请求的日志信息，包含头信息、参数、主体内容、路径、发生的服务器相关信息等，根据接口的响应状态还可以记录响应的头信息、响应的内容以及发生异常时的堆栈信息。 minbox-projects开源组织“org.minbox.framework” 致力于向广大开发者提供一系列的 “开箱即用” 的框架落地实现解决方案。 自从ApiBoot框架的落地，内部集成的第三方插件（plugin）日渐增多也同样导致了ApiBoot的源码太过于冗肿，针对这个问题minbox-projects开源组织就诞生了，ApiBoot第一个加入了该组织，并且会将ApiBoot内集成的第三方插件进行陆续分离，将每一个插件作为独立的开源项目加入minbox-projects开源组织，方便各个项目的单独维护以及更新发版。 组织首页：https://gitee.com/minbox-projects minbox-logging日志组件minbox-logging日志组件是minbox-projects开源组织内的一员，是一款分布式零侵入式、链路式请求日志分析框架。 提供Admin端点进行采集日志、分析日志、日志告警通知、服务性能分析等。通过Admin Ui可查看实时链路日志信息、在线业务服务列表，致力解决request -&gt; response整个业务请求的日志分析以及记录。 minbox-logging日志组件源码：https://gitee.com/minbox-projects/minbox-logging 创建示例项目通过idea开发工具创建一个SpringBoot项目。 pom.xml依赖 12345678910111213141516171819202122232425262728293031&lt;!--配置参数--&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;api.boot.version&gt;2.1.4.RELEASE&lt;/api.boot.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;!--ApiBoot统一版本依赖--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;version&gt;${api.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 测试控制器 添加一个用于测试的LoggingSampleController控制器，源码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738/** * 请求日志示例 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/test&quot;)public class LoggingSampleController { /** * 验证请求参数以及相应内容 * * @param name * @return */ @GetMapping public String hello(@RequestParam(&quot;name&quot;) String name) { return &quot;你好：&quot; + name; } /** * 验证主体请求内容以及相应内容 * * @param user * @return */ @PostMapping public String bodyHello(@RequestBody User user) { return &quot;你好：&quot; + user.getName(); } /** * RequestBody 示例类 */ @Data public static class User { private String name; }} application.yml 12345spring: application: name: apiboot-unified-manage-request-logsserver: port: 8080 由于ApiBoot Logging需要记录日志产生的服务器相关信息，所以spring.application.name以及server.port这两个参数必须配置，要不然启动项目时会抛出错误信息。 @EnableLoggingClient注解 123456789@SpringBootApplication@EnableLoggingClientpublic class ApibootUnifiedManageRequestLogsApplication { public static void main(String[] args) { SpringApplication.run(ApibootUnifiedManageRequestLogsApplication.class, args); }} 使用@EnableLoggingClient注解来开启日志的客户端，将该注解配置在入口类上，内部通过ImportBeanDefinitionRegistrar进行注册minbox-logging-client所需要的Bean。 ApiBoot的版本统一依赖我们在使用SpringBoot时发现我们添加的依赖并不需要指定具体的版本号，这就是版本统一依赖起到的作用，主要还是Maven继承关系缘故。 在ApiBoot内也存在这么一个统一维护依赖版本的模块api-boot-dependencies，这个模块源码仅一个pom.xml文件，主要用来配置每一个第三方依赖或者内置的依赖的具体版本。 我们通过在项目中的pom.xml配置文件内添加如下版本管理依赖： 123456789101112&lt;dependencyManagement&gt; &lt;!--ApiBoot统一版本依赖--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;version&gt;${api.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 就可以不指定版本号使用ApiBoot所提供的全部依赖。 最新版的ApiBoot，请访问：https://search.maven.org/search?q=a:api-boot-dependencies进行查询。 测试请求项目准备完成，我们先来把项目通过SpringBoot Application方式进行启动，通过如下curl命令访问我们的测试接口： 1curl http://localhost:8080/test\\?name\\=hengboy 访问完成后，请求成功，但是控制台并没有打印任何请求日志信息，倒是有一个警告的日志： 1Not set 【LoggingAdminDiscovery】in LoggingFactoryBean，don't invoke report request logs. 这个警告告知的很清楚，我们并未配置logging-admin，所以无法执行日志的上报，我们本章节是独立使用ApiBoot Logging日志组件，所以这个警告信息可以忽略。 控制台打印请求日志ApiBoot Logging提供了一个配置api.boot.logging.show-console-log，该配置默认值为false，通过该配置可以实现在控制台打印请求日志。 在application.yml配置文件内添加配置如下所示： 12345api: boot: # ApiBoot Logging 日志组件配置 logging: show-console-log: true 添加完成后，重启项目，再次访问测试接口，控制台打印如下所示： 122019-10-16 10:20:18.489 INFO 3930 --- [ task-1] o.m.f.l.c.n.support.LoggingLocalNotice : Request Uri：/test， Logging：{&quot;endTime&quot;:1571192418416,&quot;httpStatus&quot;:200,&quot;requestBody&quot;:&quot;&quot;,&quot;requestHeaders&quot;:{&quot;host&quot;:&quot;localhost:8080&quot;,&quot;user-agent&quot;:&quot;curl/7.64.1&quot;,&quot;accept&quot;:&quot;*/*&quot;},&quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;,&quot;requestMethod&quot;:&quot;GET&quot;,&quot;requestParam&quot;:&quot;{\\&quot;name\\&quot;:\\&quot;hengboy\\&quot;}&quot;,&quot;requestUri&quot;:&quot;/test&quot;,&quot;responseBody&quot;:&quot;你好：hengboy&quot;,&quot;responseHeaders&quot;:{},&quot;serviceId&quot;:&quot;apiboot-unified-manage-request-logs&quot;,&quot;serviceIp&quot;:&quot;127.0.0.1&quot;,&quot;servicePort&quot;:&quot;8080&quot;,&quot;spanId&quot;:&quot;35a22772-5015-438a-a441-ba407926b789&quot;,&quot;startTime&quot;:1571192418391,&quot;timeConsuming&quot;:25,&quot;traceId&quot;:&quot;ec53d162-314e-4516-8c24-5d5e03181543&quot;} 这时我们就可以看到打印的请求日志信息了，不过打印的日志内容并未进行美化，不要着急，ApiBoot Logging同样提供了一个配置来进行美化输出内容。 控制台美化请求日志ApiBoot Logging提供了配置api.boot.logging.format-console-log-json，该参数默认为false，我们通过修改该配置的值可以实现美化打印请求日志。 在application.yml配置文件内添加配置如下所示： 123456api: boot: # ApiBoot Logging 日志组件配置 logging: show-console-log: true format-console-log-json: true 添加完成后我们再次来重启项目后，访问测试接口，控制台打印如下所示： 1234567891011121314151617181920212223242019-10-16 10:24:05.480 INFO 4051 --- [ task-1] o.m.f.l.c.n.support.LoggingLocalNotice : Request Uri：/test， Logging：{ &quot;endTime&quot;:1571192645404, &quot;httpStatus&quot;:200, &quot;requestBody&quot;:&quot;&quot;, &quot;requestHeaders&quot;:{ &quot;accept&quot;:&quot;*/*&quot;, &quot;host&quot;:&quot;localhost:8080&quot;, &quot;user-agent&quot;:&quot;curl/7.64.1&quot; }, &quot;requestIp&quot;:&quot;0:0:0:0:0:0:0:1&quot;, &quot;requestMethod&quot;:&quot;GET&quot;, &quot;requestParam&quot;:&quot;{\\&quot;name\\&quot;:\\&quot;hengboy\\&quot;}&quot;, &quot;requestUri&quot;:&quot;/test&quot;, &quot;responseBody&quot;:&quot;你好：hengboy&quot;, &quot;responseHeaders&quot;:{}, &quot;serviceId&quot;:&quot;apiboot-unified-manage-request-logs&quot;, &quot;serviceIp&quot;:&quot;127.0.0.1&quot;, &quot;servicePort&quot;:&quot;8080&quot;, &quot;spanId&quot;:&quot;277c0973-8042-4740-a8e7-2dbb0c7bb42c&quot;, &quot;startTime&quot;:1571192645381, &quot;timeConsuming&quot;:23, &quot;traceId&quot;:&quot;7a742942-f3cc-4d72-9493-d828b090f1cc&quot;} 这样是不是很直接明了的看到了请求的详细信息了？不过建议根据自己项目的实际情况来配置，美化后的日志会占用更多的控制台行。 LoggingNotice日志通知ApiBoot Logging提供了日志通知的接口，我们只需要实现该接口就可以获取到每一次请求的日志对象，还可以自定义每一个日志通知实现类的执行顺序。 在ApiBoot Logging内部提供的实现类如下图所示： LoggingLocalNotice 该类就是用于在控制台打印请求日志以及美化请求日志的实现，优先级为：Ordered#HIGHEST_PRECEDENCE（最高优先级）。 LoggingAdminNotice 该类用于将请求日志上报到Logging Admin，优先级为：Ordered#HIGHEST_PRECEDENCE +1，仅低于LoggingLocalNotice。 使用LoggingNotice添加Header在上面我们已经知道了两个内置的LoggingNotice实现类，优先级我们也已经清楚了，那么我们如果添加自定义的LoggingNotice实现类来向本次请求日志的RequestHeader内添加一个我们自定义的头信息该怎么做呢？ AddHeaderLoggingNotice通知类源码如下所示： 123456789101112131415161718192021222324252627/** * 通过{@link LoggingNotice}向日志的请求header内添加区域信息 * * @author 恒宇少年 */@Componentpublic class AddHeaderLoggingNotice implements LoggingNotice { /** * 区域头信息key */ private static final String SERVER_REGION = &quot;server-region&quot;; @Override public void notice(MinBoxLog minBoxLog) { minBoxLog.getRequestHeaders().put(SERVER_REGION, &quot;JiNan&quot;); } /** * 最大优先级 * * @return */ @Override public int getOrder() { return HIGHEST_PRECEDENCE; }} 由于minbox-logging在设计初期就已经考虑到了这一点，所以添加起来比较简单，我们只需要调整我们自定义日志通知的优先级，然后通过#notice方法修改本次请求日志对象的值即可。 敲黑板划重点本章节我们介绍了ApiBoot Logging的集成使用，可用于采集请求日志，能力确不仅仅如此，使用得当它会很强大，日志通知设计可以使我们很好的控制一个请求的日志，对日志进行添加标识、归类等，可以通过配置来控制日志打印以及美化。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为apiboot-unified-manage-request-logs： Gitee：https://gitee.com/minbox-projects/api-boot-chapter","link":"/apiboot-unified-manage-request-logs.html"},{"title":"初识BFF架构设计","text":"BFF是（Backends For Frontends）单词的缩写，主要是用于服务前端的后台应用程序，来解决多访问终端业务耦合问题。 最近在公司的微服务架构中遇到了一些多终端访问接口的问题，不同的终端拥有不同的接口服务，有不同的操作数据的能力，针对这种业务场景做出了调研，我们是否可以在不同的访问层进行业务逻辑处理，获取不同的数据内容呢？ 早在微服务出现的初期就已经存在类似的业务需求出现，而且衍生出了一套成熟的解决方案，那就是BFF，可以针对不用业务场景来提供对应的服务接口，每一种业务场景之间完全独立。 演进过程 在传统的应用程序中，我们一般只将接口提供给一种类型的终端使用。 单端调用基础服务 传统的应用程序内提供的接口是有业务针对性的，这种类型的接口如果独立出来再提供给别的系统再次使用是一件比较麻烦的事情，设计初期的高耦合就决定了这一点。 多端直接调用基础服务 如果我们的接口同时提供给web、移动端使用，移动端仅用来采集数据以及数据的展示，而web端大多数场景是用来管理数据，因为不同端点的业务有所不同每一个端的接口复用度不会太高。 多端共用一个BFF 针对多端共用服务接口的场景，我们将基础的数据服务与BFF进行了分离，数据服务仅提供数据的增删改查，并不过多涉及业务的判断处理，所有业务判断处理都交给BFF来把控，遇到的一些业务逻辑异常也同样由BFF格式化处理后展示给访问端点。 这种设计方式同样存在一定的问题，虽然基础服务与BFF进行了分离，我们只需要在BFF层面进行业务判断处理，但是多个端共用一个BFF，也会导致代码编写复杂度增高、代码可阅读性降低、多端业务耦合。 每个端提供一个BFF 如果我们为每一个端点都提供一个BFF，每个端点的BFF处理自身的业务逻辑，需要数据时从基础服务内获取，然后在接口返回之前进行组装数据用于实例化返回对象。 这样基础服务如果有新功能添加，BFF几乎不会受到影响，而我们如果后期把App端点进行拆分成Android、IOS时我们只需要将app-bff进行拆分为android-bff、ios-bff，基础服务同样也不会受到影响 这样每当新增一个访问端点时，我们需要修改的地方也只有网关的转发以及添加一个BFF即可，基础服务内提供的服务接口我们完全可以复用，因为基础服务提供的接口都是没有业务针对性的！！！ 总结在微服务架构设计中，BFF起到了一个业务聚合的关键作用，可以 通过openfeign、restTemplate调用基础服务来获取数据，将获取到的数据进行组装返回结果对象，BFF解决了业务场景问题，也同样带来了一些问题，如下所示： 响应时间延迟（服务如果是内网之间访问，延迟时间较低） 编写起来较为浪费时间（因为在基础服务上添加的一层转发，所以会多写一部分代码） 业务异常处理（统一格式化业务异常的返回内容） 分布式事务（微服务的通病）","link":"/bff-first-meet.html"},{"title":"聊聊缓存淘汰算法-LRU 实现原理","text":"我们常用缓存提升数据查询速度，由于缓存容量有限，当缓存容量到达上限，就需要删除部分数据挪出空间，这样新数据才可以添加进来。缓存数据不能随机删除，一般情况下我们需要根据某种算法删除缓存数据。常用淘汰算法有 LRU,LFU,FIFO,这篇文章我们聊聊 LRU 算法。 LRU 简介LRU 是 Least Recently Used 的缩写，这种算法认为最近使用的数据是热门数据，下一次很大概率将会再次被使用。而最近很少被使用的数据，很大概率下一次不再用到。当缓存容量的满时候，优先淘汰最近很少使用的数据。假设现在缓存内部数据如图所示： 这里我们将列表第一个节点称为头结点，最后一个节点为尾结点。 当调用缓存获取 key=1 的数据，LRU 算法需要将 1 这个节点移动到头结点，其余节点不变，如图所示。 然后我们插入一个 key=8 节点，此时缓存容量到达上限，所以加入之前需要先删除数据。由于每次查询都会将数据移动到头结点，未被查询的数据就将会下沉到尾部节点，尾部的数据就可以认为是最少被访问的数据，所以删除尾结点的数据。 然后我们直接将数据添加到头结点。 这里总结一下 LRU 算法具体步骤： 新数据直接插入到列表头部 缓存数据被命中，将数据移动到列表头部 缓存已满的时候，移除列表尾部数据。 LRU 算法实现上面例子中可以看到，LRU 算法需要添加头节点，删除尾结点。而链表添加节点/删除节点时间复杂度 O(1)，非常适合当做存储缓存数据容器。但是不能使用普通的单向链表，单向链表有几点劣势: 每次获取任意节点数据，都需要从头结点遍历下去，这就导致获取节点复杂度为 O(N)。 移动中间节点到头结点，我们需要知道中间节点前一个节点的信息，单向链表就不得不再次遍历获取信息。 针对以上问题，可以结合其他数据结构解决。 使用散列表存储节点，获取节点的复杂度将会降低为 O(1)。节点移动问题可以在节点中再增加前驱指针，记录上一个节点信息，这样链表就从单向链表变成了双向链表。 综上使用双向链表加散列表结合体，数据结构如图所示: 在双向链表中特意增加两个『哨兵』节点，不用来存储任何数据。使用哨兵节点，增加/删除节点的时候就可以不用考虑边界节点不存在情况，简化编程难度，降低代码复杂度。 LRU 算法实现代码如下，为了简化 key ，val 都认为 int 类型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121public class LRUCache { Entry head, tail; int capacity; int size; Map&lt;Integer, Entry&gt; cache; public LRUCache(int capacity) { this.capacity = capacity; // 初始化链表 initLinkedList(); size = 0; cache = new HashMap&lt;&gt;(capacity + 2); } /** * 如果节点不存在，返回 -1.如果存在，将节点移动到头结点，并返回节点的数据。 * * @param key * @return */ public int get(int key) { Entry node = cache.get(key); if (node == null) { return -1; } // 存在移动节点 moveToHead(node); return node.value; } /** * 将节点加入到头结点，如果容量已满，将会删除尾结点 * * @param key * @param value */ public void put(int key, int value) { Entry node = cache.get(key); if (node != null) { node.value = value; moveToHead(node); return; } // 不存在。先加进去，再移除尾结点 // 此时容量已满 删除尾结点 if (size == capacity) { Entry lastNode = tail.pre; deleteNode(lastNode); cache.remove(lastNode.key); size--; } // 加入头结点 Entry newNode = new Entry(); newNode.key = key; newNode.value = value; addNode(newNode); cache.put(key, newNode); size++; } private void moveToHead(Entry node) { // 首先删除原来节点的关系 deleteNode(node); addNode(node); } private void addNode(Entry node) { head.next.pre = node; node.next = head.next; node.pre = head; head.next = node; } private void deleteNode(Entry node) { node.pre.next = node.next; node.next.pre = node.pre; } public static class Entry { public Entry pre; public Entry next; public int key; public int value; public Entry(int key, int value) { this.key = key; this.value = value; } public Entry() { } } private void initLinkedList() { head = new Entry(); tail = new Entry(); head.next = tail; tail.pre = head; } public static void main(String[] args) { LRUCache cache = new LRUCache(2); cache.put(1, 1); cache.put(2, 2); System.out.println(cache.get(1)); cache.put(3, 3); System.out.println(cache.get(2)); }} LRU 算法分析缓存命中率是缓存系统的非常重要指标，如果缓存系统的缓存命中率过低，将会导致查询回流到数据库，导致数据库的压力升高。结合以上分析 LRU 算法优缺点。LRU 算法优势在于算法实现难度不大，对于对于热点数据， LRU 效率会很好。LRU 算法劣势在于对于偶发的批量操作，比如说批量查询历史数据，就有可能使缓存中热门数据被这些历史数据替换，造成缓存污染，导致缓存命中率下降，减慢了正常数据查询。 LRU 算法改进方案 以下方案来源与 MySQL InnoDB LRU 改进算法 将链表拆分成两部分，分为热数据区，与冷数据区，如图所示。改进之后算法流程将会变成下面一样: 访问数据如果位于热数据区，与之前 LRU 算法一样，移动到热数据区的头结点。 插入数据时，若缓存已满，淘汰尾结点的数据。然后将数据插入冷数据区的头结点。 处于冷数据区的数据每次被访问需要做如下判断： 若该数据已在缓存中超过指定时间，比如说 1 s，则移动到热数据区的头结点。 若该数据存在在时间小于指定的时间，则位置保持不变。 对于偶发的批量查询，数据仅仅只会落入冷数据区，然后很快就会被淘汰出去。热门数据区的数据将不会受到影响，这样就解决了 LRU 算法缓存命中率下降的问题。 其他改进方法还有 LRU-K，2Q,LIRS 算法，感兴趣同学可以自行查阅。","link":"/cache-lru-principle-of-impl.html"},{"title":"GitHub标星超1万的Chrome插件，助你轻松查看文件Git历史","text":"前言之前给大家介绍过一款好用的GitHub代码层级阅读浏览器插件Octotree，该插件直接可以读取GitHub源码仓库的全部文件并生成树形层级关系，省去了连续不断地点击进入目录的操作。 GitHistory Chrome Plugin有些时候我们需要查看源码仓库中某一个文件的修改历史记录，方便我们做一些变动的追溯，在GitHub上还真有一款大神级别的浏览器插件，该插件可以界面图形化查看某一个文件的全部修改历史记录，很是方便，今天推荐给大家。 该插件在Chrome商店内可以找到，名为：Git History Browser Extension，由Luis Reinoso提供。 它是一款开源的浏览器插件，仓库地址：https://github.com/pomber/git-history，目前Star已经超过11k。 怎么使用？通过Chrome商店安装完成后，这时我们打开GitHub的任意仓库（这里以ApiBoot仓库为例），找到某一个文件点击后，效果如下： 可以看到在工具栏多出了一个名为Open in Git History的按钮，我们点击该按钮会跳转到 https://github.githistory.xyz/ ，效果如下图所示： 在地址栏中除了域名以外，后面的地址与访问GitHub时是一样的。 该页面分了两部分： 顶部横向滚动条 初次访问该页面时默认是最新的提交的历史文件内容，在顶部会列出该文件的全部的提交记录，当我们点击任意一个记录时，在下面都会显示属于这个文件这次提交的内容。 底部文件历史内容 对应顶部的提交信息当前文件的变动内容。 不能访问Chome商店？由于网络访问受限，我们无法直接访问Chrome商店，我在之前文章中推荐了一款科学上网的神器，GHelper也是一款浏览器插件（该插件可直接通过源码方式安装）。 关注 “程序员恒宇少年”微信公众号，回复”Google”获取GHelper源码方式安装包。","link":"/chrome-plugin-git-history.html"},{"title":"自定义你自己的Eureka管理界面","text":"Eureka服务端的界面是可以自定义的，而且方式比较简单，下面我们来看下修改方式。 在某一些公司内部，服务注册中心界面可能需要完全自定义，需要携带一些公司的特性以及元素，如果是这样那么本章节的内容可以帮到你，效果可以查看我公开的Open Eureka Server服务。 创建Eureka Server项目使用IDEA开发工具创建一个SpringBoot项目，在pom.xml内添加依赖如下所示： 1234567891011121314151617181920212223&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Hoxton.RC2&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 启用Eureka Server我们在启动类XxxApplication使用@EnableEurekaServer注解来启用Eureka管理端的功能，如下所示： 1234567891011121314/** * 自定义Eureka Server管理界面 * * @author 恒宇少年 */@SpringBootApplication@EnableEurekaServerpublic class CustomizeEurekaManagePageApplication { public static void main(String[] args) { SpringApplication.run(CustomizeEurekaManagePageApplication.class, args); }} 配置服务接下来我们在application.yml配置文件内添加Eureka相关配置信息，如下所示： 12345678910111213spring: application: name: customize-eureka-manage-page# Eureka配置eureka: client: service-url: defaultZone: http://127.0.0.1:${server.port}/eureka/ fetch-registry: false register-with-eureka: falseserver: port: 10000 自定义页面在spring-cloud-netflix-eureka-server-xx.xx.xx.jar依赖文件内我们可以找到tempaltes.eureka目录，结构如下图所示： templates.eureka目录下存放了Erueka Server管理页面的模板文件，我们可以将模板文件复制出来到当前项目的resources/templates/eureka目录下，然后进行自定义界面内容。 header.ftlh：顶部菜单导航模板页面 lastn.ftlh：服务注册记录模板页面 navbar.ftlh：首页导航栏信息模板页面 status.ftlh：服务所在服务器的基本状态模板页面 我们找到navbar.ftlh文件，这个文件内是Eureka Server在首页显示系统信息、服务注册列表、服务服务器基本信息的展示页面，我们简单在System Status分类下的第一个table内添加一行信息，如下所示： 1234&lt;tr&gt; &lt;td&gt;程序员恒宇少年&lt;/td&gt; &lt;td&gt;&lt;img src=&quot;https://blog.minbox.org/images/profile2.png&quot; width=&quot;400px&quot;/&gt;&lt;/td&gt;&lt;/tr&gt; 查看效果我们来启动或重启下本项目，访问http://127.0.0.1:10000，查看效果如下图所示： 总结通过修改templates.eureka目录下的文件我们就可以完成Eureka Server界面的自定义的操作，完全可以将页面的内容都进行定制化，心随所动，赶紧行动起来吧~ 代码示例本篇文章示例源码可以通过以下途径获取，目录为customize-eureka-manage-page： Gitee：https://gitee.com/hengboy/spring-cloud-chapter","link":"/customize-eureka-manage-page.html"},{"title":"SpringCloud下使用Eureka高可用集群部署","text":"我们在之前的章节/eureka-server.html学习到了单个服务注册中心的创建，不过单模式的部署方式在实战中确实不太提倡，因为有很多种原因可能会导致服务注册中心宕机，如果宕机就会有一些灾难性的问题出现，所以保证服务注册中心处于活着运行状态显得尤为重要！！！ 本章目标高可用集群部署Eureka服务注册中心。 构建项目使用idea开发工具创建一个SpringBoot项目，添加Eureka Server依赖即可，pom.xml配置文件如下所示： 1234567891011121314151617181920&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--Eureka Server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们本章主要是完成Eureka Server的集群配置，所以只需要添加spring-cloud-starter-netflix-eureka-server依赖即可。 启用Eureka Server在入口类XxxApplication上添加@EnableEurekaServer注解来启用Eureka Server服务以及实例化一些依赖，修改如下所示： 12345@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEurekaHighApplication { //....} Eureka服务配置依赖已经添加完成，接下来我们就需要在application.yml内编写相关配置信息，因为测试环境都在我们本机，有两种方式可以模拟测试同时运行： 创建两个不同的项目 使用一个项目进行根据spring.profiles.active设置运行不同环境 为了方便演示，我们使用的第二种方式，主要是感觉再去创建一个项目没有必要，那我们的profiles环境该怎么配置呢？请继续往下看。 Profile多环境配置我们在src/main/resources目录下创建名为application-node1.yml的配置文件，在该配置文件内添加如下配置： 12345678910111213141516# Eureka 客户端配置eureka: client: service-url: defaultZone: http://node2:10002/eureka/ instance: # 配置通过主机名方式注册 hostname: node1 # 配置实例编号 instance-id: ${eureka.instance.hostname}:${server.port}:@project.version@ # 集群节点之间读取超时时间。单位：毫秒 server: peer-node-read-timeout-ms: 1000# 服务端口号server: port: 10001 继续在src/main/resources下创建一个名为application-node2.yml的配置文件，内容如下所示： 123456789101112131415# Eureka 客户端配置eureka: client: service-url: defaultZone: http://node1:10001/eureka/ instance: # 配置通过主机名方式注册 hostname: node2 # 配置实例编号 instance-id: ${eureka.instance.hostname}:${server.port}:@project.version@ # 集群节点之间读取超时时间。单位：毫秒 server: peer-node-read-timeout-ms: 1000server: port: 10002 下面我们先来说下node1、node2主机名的配置方式，然后再说下为什么实现了集群的效果？ 主机名设置 Mac或者Linux配置方式如果你使用的是osx系统。可以找到/etc/hosts文件并添加如下内容：12127.0.0.1 node1127.0.0.1 node2 一般情况下配置完成后就会生效，如果你的配置并没有生效，你可以尝试重启。 Windows配置方式如果你使用的是windows系统，你可以修改C:\\Windows\\System32\\drivers\\etc\\hosts文件，添加内容与Mac方式一致。 Eureka Sever相互注册 application-node1.yml eureka.client.service-url.defaultZone这个配置参数的值，配置的是http://node2:10002/eureka/，那这里的node2是什么呢？其实一看应该可以明白，这是们在hosts文件内配置的hostname，而端口号我们配置的则是10002，根据hostname以及port我们可以看出，环境node1注册到了node2上。 application-node2.yml 在node2环境内配置eureka.client.service-url.defaultZone是指向的http://node1:10001/eureka/，同样node2注册到了node1上。 通过这种相互注册的方式牢靠的把两个服务注册中心绑定在了一块。 运行测试我们先来运行测试下Eureka Server的集群是否可行？下一章节我们再来讲解把服务提供者注册到Eureka集群，测试步骤如下： clean &amp;&amp; package 本项目（diea工具自带maven常用操作命令快捷方式，右侧导航栏Maven Projects -&gt; Lifecycle） 打开终端cd项目target目录 通过如下命令启动node1环境： 1java -jar hengboy-spring-cloud-eureka-high-0.0.1-SNAPSHOT.jar --spring.profiles.active=node1 再打开一个终端，同样是cd项目的target目录下，通过如下命令启动node2环境： 1java -jar hengboy-spring-cloud-eureka-high-0.0.1-SNAPSHOT.jar --spring.profiles.active=node2 访问http://node1:10001查看node1环境的Eureka管理中心 访问http://node2:10002查看node2环境的Eureka管理中心 效果如下图所示： 总结本章讲解了集群环境下怎么构建让Eureka Server更健壮，在下一章我们来看看怎么把服务提供者注册到Eureka Server集群内。 建议：在实战环境中建议把Eureka Server节点放在不同的服务器下，并且通过主机名或者内网方式进行相互注册。","link":"/eureka-cluster-high.html"},{"title":"SpringCloud下使用Eureka的服务发现与消费","text":"在之前的章节我们已经把服务注册到Eureka Server，那么我们该怎么调用已经注册后的服务呢？我们本章来简单的介绍我们具体该怎么调用服务节点请求内容。 本章目标消费Eureka注册的服务节点的请求信息。 构建项目我们只需要创建一个服务节点项目即可，因为服务提供者也是消费者，然后将本项目注册到之前编写的服务注册中心，下载文章/eureka-server.html源码运行即可。我们使用idea开发工具创建一个SpringBoot项目，对应的选择spring-boot-starter-web、spring-cloud-starter-netflix-ribbon、spring-cloud-starter-netflix-eureka-client三个依赖，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--Web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ribbon--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加完依赖后我们需要对本项目进行配置，让本项目注册到服务中心，在之前的章节/eureka-register-service.html有讲过，这里就不做过多的赘述。 配置Eureka客户端打开XxxApplication入口类，添加@EnableDiscoveryClient注解，如下所示： 12345@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudEurekaConsumerApplication { //...} 修改application.yml配置文件下面我们修改application.yml配置文件，添加Eureka Client对应的配置信息，如下所示： 123456789101112131415# 服务名称spring: application: name: hengboy-spring-cloud-eureka-consumer# 启动端口号server: port: 20002# Eureka 服务注册中心配置eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 配置优先使用IP地址注册服务 instance: prefer-ip-address: true 获取服务实例信息如果你只是将服务注册到服务注册中心也就是Eureka Server上，到现在已经完全没有问题了，但是我们想要通过服务名(spring.application.name)来获取服务实例列表该怎么操作呢？ 本章内容涉及一点有关Ribbon的知识点，我们通过添加依赖spring-cloud-starter-netflix-ribbon就可以直接使用RestTemplate类进行发送http请求，而且RestTemnplate可以直接使用服务名进行发送请求！！！ 实例化RestTemplatespring-cloud-starter-netflix-ribbon依赖并没有为我们实例化RestTemplate，我们需要手动进行实例化，我采用@Bean方式进行实例化，在XxxApplication类内添加如下代码： 12345678910/** * 实例化RestTemplate对象实例 * * @return */@Bean@LoadBalancedpublic RestTemplate restTemplate() { return new RestTemplate();} 在这里有个@LoadBalanced注解，我们后续章节会对它详细的讲解，博客搜索关键字LoadBalanced查询文章信息，不过如果你不添加并使用这个注解，你是没有办法通过服务名直接发送请求的，会出现错误信息。 了解DiscoveryClient我们需要创建一个发送请求以及请求消费的Controller，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 消费者控制器 * * @author：于起宇 &lt;p&gt; * ================================ * Created with IDEA. * Date：2018/9/29 * Time：5:55 PM * 简书：http://www.jianshu.com/u/092df3f77bca * 码云：https://gitee.com/hengboy * GitHub：https://github.com/hengyuboy * ================================ * &lt;/p&gt; */@RestController@RequestMapping(value = &quot;/consumer&quot;)public class ConsumerController { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(ConsumerController.class); /** * 注入服务客户端实例 */ @Autowired private DiscoveryClient discoveryClient; /** * 注入restTemplate模板 */ @Autowired private RestTemplate restTemplate; /** * 服务消费者业务逻辑方法 * 该方法使用restTemplate访问获取返回数据 * * @return */ @RequestMapping(value = &quot;/logic&quot;) public String home() { return &quot;this is home page&quot;; } /** * 请求地址 * 输出服务的基本信息 */ @RequestMapping(value = &quot;/index&quot;) public void index() { discoveryClient.getInstances(&quot;hengboy-spring-cloud-eureka-consumer&quot;) .stream() .forEach( instance -&gt; { logger.info(&quot;服务地址：{}，服务端口号：{}，服务实例编号：{}，服务地址：{}&quot;, instance.getHost(), instance.getPort(), instance.getServiceId(), instance.getUri()); String response = restTemplate.getForEntity(&quot;http://&quot; + instance.getServiceId() + &quot;/consumer/logic&quot;, String.class).getBody(); logger.info(&quot;响应内容：{}&quot;, response); } ); }} 在上面代码中我们注入了DiscoveryClient，这是一个接口类，具体该接口的实现类是什么要取决你使用的是什么服务注册中心，我们本章采用的Eureka理所当然使用的是Eureka实现类，源码可以查看org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient，在EurekaDiscoveryClient内可以看到具体是怎么通过服务名获取实例的列表，部分源码如下所示： 12345678910@Overridepublic List&lt;ServiceInstance&gt; getInstances(String serviceId) { List&lt;InstanceInfo&gt; infos = this.eurekaClient.getInstancesByVipAddress(serviceId, false); List&lt;ServiceInstance&gt; instances = new ArrayList&lt;&gt;(); for (InstanceInfo info : infos) { instances.add(new EurekaServiceInstance(info)); } return instances;} 你如果对具体的源码执行流程感兴趣，可以使用断点来一步一步的观察。在获取ServiceInstance服务实例后，可以得到实例的一些基本信息如： serviceId：服务名称、服务的实例编号，也就是spring.application.name配置信息 host：注册该实例的hostName port：注册该实例的端口号，对应server.port配置信息 uri：服务地址 metadata：服务自定义的元数据map集合 请求转发流程 执行流程：我们在访问/consumer/index请求地址时，会通过RestTemplate转发请求访问http://hengboy-spring-cloud-eureka-consumer/consumer/logic地址并返回信息this is home page。 运行测试我们的测试流程如下： 启动服务注册中心 启动本章项目 访问http://localhost:20002/consumer/index 查看控制台输出内容是否有this is home page 访问有多种形式，你可以浏览器直接访问地址，我通过curl命令来访问地址，打开terminal输入以下命令： 1curl http://localhost:20002/consumer/index 请求正常，查看控制台输出内容如下所示： 1232018-10-04 15:23:36.333 INFO 29075 --- [io-20002-exec-5] c.y.c.h.s.e.consumer.ConsumerController : 服务地址：192.168.1.75，服务端口号：20002，服务实例编号：HENGBOY-SPRING-CLOUD-EUREKA-CONSUMER，服务地址：http://192.168.1.75:20002......2018-10-04 15:23:36.748 INFO 29075 --- [io-20002-exec-5] c.y.c.h.s.e.consumer.ConsumerController : 响应内容：this is home page 总结本章通过Ribbon简单的实现了服务节点的消费，通过RestTemplate发送请求来获取响应内容，需要注意的是我们并不是通过IP:Port的形式，而是通过服务名的形式发送请求，这都归功于@LoadBalanced这个注解，这个注解在讲解Ribbon时会详细的说明。","link":"/eureka-service-consumer.html"},{"title":"Eureka服务注册中心的失效剔除与自我保护机制","text":"Eureka作为一个成熟的服务注册中心当然也有合理的内部维护服务节点的机制，比如我们本章将要讲解到的服务下线、失效剔除、自我保护，也正是因为内部有这种维护机制才让Eureka更健壮、更稳定。 本章目标了解Eureka是怎么保证服务相对较短时长内的有效性。 服务下线迭代更新、终止访问某一个或者多个服务节点时，我们在正常关闭服务节点的情况下，Eureka Client会通过PUT请求方式调用Eureka Server的REST访问节点/eureka/apps/{appID}/{instanceID}/status?value=DOWN请求地址，告知Eureka Server我要下线了，Eureka Server收到请求后会将该服务实例的运行状态由UP修改为DOWN，这样我们在管理平台服务列表内看到的就是DOWN状态的服务实例。 有关Eureka Server内部的REST节点地址，请访问/eureka-rest.html来了解详情。 失效剔除Eureka Server在启动完成后会创建一个定时器每隔60秒检查一次服务健康状况，如果其中一个服务节点超过90秒未检查到心跳，那么Eureka Server会自动从服务实例列表内将该服务剔除。 由于非正常关闭不会执行主动下线动作，所以才会出现失效剔除机制，该机制主要是应对非正常关闭服务的情况，如：内存溢出、杀死进程、服务器宕机等非正常流程关闭服务节点时。 自我保护Eureka Server的自我保护机制会检查最近15分钟内所有Eureka Client正常心跳的占比，如果低于85%就会被触发。我们如果在Eureka Server的管理界面发现如下的红色内容，就说明已经触发了自我保护机制。 1EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 当触发自我保护机制后Eureka Server就会锁定服务列表，不让服务列表内的服务过期，不过这样我们在访问服务时，得到的服务很有可能是已经失效的实例，如果是这样我们就会无法访问到期望的资源，会导致服务调用失败，所以这时我们就需要有对应的容错机制、熔断机制，我们在接下来的文章内会详细讲解这块知识点。 我们的服务如果是采用的公网IP地址，出现自我保护机制的几率就会大大增加，所以这时更要我们部署多个相同InstanId的服务或者建立一套完整的熔断机制解决方案。 自我保护开关如果在本地测试环境，建议关掉自我保护机制，这样方便我们进行测试，也更准备的保证了服务实例的有效性！！！ 关闭自我保护只需要修改application.yml配置文件内参数eureka.server.enable-self-preservation将值设置为false即可。 总结我们通过本章的讲解，了解到了Eureka Server对服务的治理，其中包含服务下线、失效剔除、自我保护等，对自我保护机制一定要谨慎的处理，防止出现服务失效问题。","link":"/eureka-preservation.html"},{"title":"Eureka服务注册方式流程源码分析","text":"/eureka-register-away.html文章中我们讲到了`服务注册`的几种`注册方式`，那么这几种`注册方式`的源码是怎么实现的呢？我们带着这一个疑问来阅读本章内容能够让你更深入了解这块的知识点！！！ 本章目标分析每一种服务注册方式源码执行流程。 构建项目本章以分析源码为主，所以不去新创建项目来讲解相关内容，我们使用/eureka-register-away.html源码作为注册服务，/eureka-server.html源码作为服务注册中心，还是按照之前的运行流程： 启动服务注册中心 启动本章服务项目 查看服务列表，服务注册方式 配置信息获取执行流程在开始讲解本章注册方式之前，我们需要了解整体的配置信息获取的流程信息，这样才可以分析指定的注册方式执行流程。 第一步：实例化EurekaInstanceConfigBean配置实体在项目启动时由于依赖spring-cloud-starter-netflix-eureka-client内通过配置spring.factories文件来让项目启动时自动加载并实例化org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration配置类，EurekaClientAutoConfiguration内会自动实例化EurekaInstanceConfigBean并且自动绑定eureka.instance开头的配置信息（具体为什么会自动映射可以去了解下@ConfigurationProperties注解作用），部分源码如下所示： 123456789101112public class EurekaClientAutoConfiguration { //省略部分源码 @Bean @ConditionalOnMissingBean(value = EurekaInstanceConfig.class, search = SearchStrategy.CURRENT) public EurekaInstanceConfigBean eurekaInstanceConfigBean(InetUtils inetUtils, ManagementMetadataProvider managementMetadataProvider) { //省略部分源码 // 传递 EurekaInstanceConfigBean instance = new EurekaInstanceConfigBean(inetUtils); // 省略部分源码 } //省略部分源码} EurekaClientAutoConfiguration#eurekaInstanceConfigBean方法只有满足@ConditionalOnMissingBean(value = EurekaInstanceConfig.class, search = SearchStrategy.CURRENT)表达式后才会去实例化，并且把实例化对象放入到IOC容器内容，BeanId为eurekaInstanceConfigBean，也就是方法的名称。在EurekaClientAutoConfiguration#eurekaInstanceConfigBean方法中有这么一行代码我们可以进行下一步的分析 12// 通过有参构造函数实例化EurekaInstanceConfigBean配置实体EurekaInstanceConfigBean instance = new EurekaInstanceConfigBean(inetUtils); 通过调用EurekaInstanceConfigBean(InetUtils inetUtils)构造函数来进行实例化EurekaInstanceConfigBean对象，在这个构造函数内也有一些实例化的工作，源码如下： 123456public EurekaInstanceConfigBean(InetUtils inetUtils) { this.inetUtils = inetUtils; this.hostInfo = this.inetUtils.findFirstNonLoopbackHostInfo(); this.ipAddress = this.hostInfo.getIpAddress(); this.hostname = this.hostInfo.getHostname();} 第二步：InetUtils#findFirstNonLoopbackHostInfo获取主机基本信息在构造函数EurekaInstanceConfigBean(InetUtils inetUtils)源码实现内hostInfo主机信息通过了InetUtils#findFirstNonLoopbackHostInfo方法来进行实例化，我们来看看这个方法的具体实现逻辑，它会自动读取系统网卡列表然再进行循环遍历查询正在UP状态的网卡信息，如果没有查询到网卡信息，则使用默认的HostName、IpAddress配置信息，源码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public HostInfo findFirstNonLoopbackHostInfo() { InetAddress address = findFirstNonLoopbackAddress(); if (address != null) { return convertAddress(address); } HostInfo hostInfo = new HostInfo(); hostInfo.setHostname(this.properties.getDefaultHostname()); hostInfo.setIpAddress(this.properties.getDefaultIpAddress()); return hostInfo;}public InetAddress findFirstNonLoopbackAddress() { InetAddress result = null; try { int lowest = Integer.MAX_VALUE; for (Enumeration&lt;NetworkInterface&gt; nics = NetworkInterface .getNetworkInterfaces(); nics.hasMoreElements();) { NetworkInterface ifc = nics.nextElement(); if (ifc.isUp()) { log.trace(&quot;Testing interface: &quot; + ifc.getDisplayName()); if (ifc.getIndex() &lt; lowest || result == null) { lowest = ifc.getIndex(); } else if (result != null) { continue; } // @formatter:off if (!ignoreInterface(ifc.getDisplayName())) { for (Enumeration&lt;InetAddress&gt; addrs = ifc .getInetAddresses(); addrs.hasMoreElements();) { InetAddress address = addrs.nextElement(); if (address instanceof Inet4Address &amp;&amp; !address.isLoopbackAddress() &amp;&amp; isPreferredAddress(address)) { log.trace(&quot;Found non-loopback interface: &quot; + ifc.getDisplayName()); result = address; } } } // @formatter:on } } } catch (IOException ex) { log.error(&quot;Cannot get first non-loopback address&quot;, ex); } if (result != null) { return result; } try { return InetAddress.getLocalHost(); } catch (UnknownHostException e) { log.warn(&quot;Unable to retrieve localhost&quot;); } return null;} 默认的HostName、IpAddress属性配置信息在InetUtilsProperties配置实体类内，如果不进行设置则直接使用默认值，如果你想更换默认值，那么你可以在application.yml配置文件内通过设置spring.cloud.inetutils.defaultHostname、spring.cloud.inetutils.defaultIpAddress进行修改默认值，源码如下所示： 12345678910111213public class InetUtilsProperties { public static final String PREFIX = &quot;spring.cloud.inetutils&quot;; /** * The default hostname. Used in case of errors. */ private String defaultHostname = &quot;localhost&quot;; /** * The default ipaddress. Used in case of errors. */ private String defaultIpAddress = &quot;127.0.0.1&quot;;} 第三步：EurekaInstanceConfigBean#getHostName方法实现getHostName是一个Override的方法，继承于com.netflix.appinfo.EurekaInstanceConfig接口，该方法有个boolean类型的参数refresh来判断是否需要刷新重新获取主机网络基本信息，当传递refresh=false并且在application.yml配置文件内并没有进行手动设置eureka.instance.hostname以及eureka.instance.ip-address参数则会根据eureka.instance.prefer-ip-address设置的值进行返回信息，源码如下所示： 12345678@Overridepublic String getHostName(boolean refresh) { if (refresh &amp;&amp; !this.hostInfo.override) { this.ipAddress = this.hostInfo.getIpAddress(); this.hostname = this.hostInfo.getHostname(); } return this.preferIpAddress ? this.ipAddress : this.hostname;} 默认注册方式源码分析由于在实例化EurekaInstanceConfigBean配置实体类时，构造函数进行了获取第一个非回环主机信息，默认的hostName以及ipAddress参数则是会直接使用InetUtils#findFirstNonLoopbackHostInfo方法返回的相对应的值。 IP优先注册方式源码分析EurekaInstanceConfigBean#getHostName方法直接调用本类重载方法getHostName(boolean refresh)并且传递参数为false，根据第三步源码我们就可以看到： 1return this.preferIpAddress ? this.ipAddress : this.hostname; 如果eureka.instance.prefer-ip-address参数设置了true就会返回eureka.instance.ip-address的值，这样我们就可以从中明白为什么主动设置eureka.instance.ip-address参数后需要同时设置eureka.instance.prefer-ip-address参数才可以生效。 指定IP、HostName源码分析我们通过application.yml配置文件进行设置eureka.instance.hostname以及eureka.instance.ip-address后会直接替换原默认值，在EurekaInstanceConfigBean#getHostName中也是返回的this.hostname、this.ipAddress所以在这里设置后会直接生效作为返回的配置值。 总结我们通过源码进行分析服务注册方式执行流程，这样在以后进行配置eureka.instance.hostname、eureka.instance.prefer.ip-address、eureka.instance.ip-address三个配置信息时就可以根据优先级顺序达到预期的效果，避免没有必要的错误出现。","link":"/eureka-register-away-code.html"},{"title":"Eureka服务注册是采用主机名还是IP地址？","text":"我们一直在使用Eureka进行注册服务，然而你有可能很少关心服务在注册到Eureka Server时是采用的主机名的方式？还是IP地址的方式？ 构建项目我们把之前章节将服务注册到Eureka的源码复制一份修改项目名称为hengboy-spring-cloud-eureka-register-away，并简单的对application.yml配置文件进行修改,如下所示： 1234567891011121314151617# 服务名称spring: application: name: hengboy-spring-cloud-eureka-register-away# 服务提供者端口号server: port: 20001# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 自定义实例编号 instance: instance-id: ${spring.application.name}:${server.port}:@project.version@ 在上面配置中，并没有对注册方式进行任何修改，如果现在启动当然就是采用的默认方式进行注册，接下来我们来看看默认的方式是采用的哪种？ 查看默认方式我们仍然使用/eureka-server.html源码作为服务注册中心(Eureka Server)来完成本章的测试工作。 测试步骤： 启动服务注册中心 启动本章项目 访问http://localhost:10000打开服务注册中心管理界面 点击服务列表服务，查看地址栏地址 当我们点击hengboy-spring-cloud-eureka-register-away:20001:v1.0服务名称后会跳转到服务的监控信息界面，不过我们并没有添加监控相关的依赖或者配置，所以这里跳转后是404访问不到页面，即使是这样我们还是可以看到跳转的网址是http://192.168.1.75:20001/actuator/info，这也证实了一点Eureka Client向Eureka Server进行注册的时候默认采用的是IP Address方式。 那么如果你想采用主机名的方式进行注册服务，该怎么配置呢？请继续阅读。 配置使用主机名我们如果采用主机名的方式进行注册服务，只需要修改application.yml配置文件内的eureka.instance.hostname配置信息即可，如下所示： 12345678910# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 自定义实例编号 instance: instance-id: ${spring.application.name}:${server.port}:@project.version@ # 配置使用主机名注册服务 hostname: node1 node1是我本机配置的其中一个主机名 OS X/Linux系统下修改主机名 我是采用的MAC OS X系统作为运行环境，所以修改/etc/hosts文件对应的添加主机名、IP地址的映射即可，如下所示： 1234567891011### Host Database## localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.##127.0.0.1 localhost255.255.255.255 broadcasthost::1 localhost127.0.0.1 node1127.0.0.1 node2 Windows系统下修改主机名 如果你是采用的Windows系统作为运行环境，你可以修改C:\\Windows\\System32\\drivers\\etc\\hosts文件内容并添加映射关系。 修改完成主机名后，一定不要忘记是需要让主机名生效的，修改完成后最有效的办法是重启你的计算机可以生效主机名。 接下来我们需要按照下面的步骤进行测试主机名方式注册是否已经生效？ 重启本章项目 刷新Eureka Server管理平台界面 点击服务名称查看跳转地址 我们可以发现跳转的路径由原本默认的http://192.168.1.75:20001/actuator/info方式修改成了http://node1:20001/actuator/info，可以看到已经是使用了主机名的方式进行的注册服务！！！ 配置优先使用IP如果你在部署的时候某种原因导致的无法使用主机名方式进行部署，当然你可以选择不配置eureka.instance.hostname参数，如果你配置后仍然想使用IP Address方式进行服务注册，这时我们可以通过eureka.instance.prefer-ip-address参数来进行设置，如果该参数设置为true，则优先使用IP Address进行服务注册。配置如下所示： 123456789101112# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 自定义实例编号 instance: instance-id: ${spring.application.name}:${server.port}:@project.version@ # 配置使用主机名注册服务 hostname: node1 # 优先使用IP地址方式进行注册服务 prefer-ip-address: true 具体的测试过程与上述配置使用主机名一致，可以进行尝试运行测试。既然我们可以优先使用IP进行注册服务，我们想根据指定的IP地址进行注册该怎么配置呢？ 配置使用指定IP配置使用指定IP也比较简单，我们可以进行设置eureka.instance.ip-address参数的值来进行修改注册的IP 地址。我们基于上面步骤的配置文件进行修改内容如下所示： 1234567891011121314# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 自定义实例编号 instance: instance-id: ${spring.application.name}:${server.port}:@project.version@ # 配置使用主机名注册服务 hostname: node1 # 优先使用IP地址方式进行注册服务 prefer-ip-address: true # 配置使用指定IP ip-address: 127.0.0.1 配置文件修改完成后，进行如下步骤进行测试是否失效： 重启本章项目 刷新Eureka Server管理平台界面 点击服务名称，查看跳转地址信息 我们发现跳转地址栏的地址已经使用了我们配置的ip-address参数，地址为：http://127.0.0.1:20001/actuator/info。 注意：如果配置ip-address参数后并没有开启prefer-ip-address: true，那么仍然使用主机名或者默认的注册方式。 总结我们通过几种不同的服务注册方式来全面讲解了Eureka Client在注册到服务注册中心时使用的主机信息，这几种注册方式也是存在一定的优先级顺序的，这一知识点我们在下一章结合Eureka源码进行分别全面剖析这几种注册方式以及优先级顺序。","link":"/eureka-register-away.html"},{"title":"将服务注册到Eureka","text":"Eureka提供了Server当然也提供了Client，如果你对Eureka Server不了解，通过阅读文章查看具体的编码实现。 本章构建的项目其实是一个Eureka Client，因为是向Eureka Server注册的服务，相对于Eureka Server来说相当于一个客户端的形式存在。 我们使用spring-cloud-starter-netflix-eureka-client可以快速的构建Eureka Client项目，简单的配置就可以完成Client与Server之间的通信以及绑定，下面我们来看下具体是怎么向Eureka Server注册服务。 构建项目同样的是采用idea开发工具创建一个SpringBoot项目，在依赖选择界面对应的添加Web以及Eureka Discovery依赖，直接完成创建项目。项目的pom.xml内容如下所示： 123456789101112131415161718192021222324252627282930313233343536373839&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--Web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;....//省略部分配置 跟Eureka Server项目不同依赖的选择的地方是Client项目需要添加spring-cloud-starter-netflix-eureka-client，通过该依赖可以完成服务的注册以及服务之间的通信等。 添加spring-boot-starter-web依赖的目的是为了简单创建一个Controller请求示例，在后面章节我们需要用到该依赖。 Eureka Client的配置Eureka Client的配置步骤与Eureka Server几乎是一致的，不过采用的注解不同以及配置信息有出入，同样是两步完成配置： 第一步入口类添加注解@EnableDiscoveryClient我们在配置Client时通常会采用通用的客户端注解配置，也就是@EnableDiscoveryClient注解，当然如果服务注册中心确定采用的是Eureka也可以使用@EnableEurekaClient注解来完成配置，至于这两个的区别后续章节细讲。12345678910111213@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudEurekaProviderApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(SpringCloudEurekaProviderApplication.class); public static void main(String[] args) { SpringApplication.run(SpringCloudEurekaProviderApplication.class, args); logger.info(&quot;「「「「「Eureka服务提供者启动完成.」」」」」&quot;); }} 第二步application.yml配置文件添加配置信息我比较喜欢ymal这种配置风格，所以删除了创建项目时创建的application.properties配置文件，自行创建了application.yml，因为层级的原因可以更清晰明了的看清配置，配置内容如下所示：1234567891011121314# 服务名称spring: application: name: hengboy-spring-cloud-eureka-provider# 服务提供者端口号server: port: 20000# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ spring.application.name：配置服务的名称 server.port：服务端口号 eureka.client.service-url：配置Eureka Server服务注册中心地址 运行测试我们已经完成了Eureka Client的相关配置信息，接下来我们按照下面的步骤进行执行测试。 启动服务注册中心Eureka Server 启动本章项目 查看控制台日志输出信息 查看服务注册中心管理界面服务列表 运行过程中本章项目控制台输出内容如下所示： 1234......DiscoveryClient_HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER/192.168.1.75:hengboy-spring-cloud-eureka-provider:20000: registering service...DiscoveryClient_HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER/192.168.1.75:hengboy-spring-cloud-eureka-provider:20000 - registration status: 204...... 可以看到控制台打印了向我们配置的服务注册中心进行registering service，既然控制台并没有给我抛出相关的异常信息，那么我们猜想是不是Eureka Server服务注册中心的服务列表已经存在了该条记录了呢？ 查看Eureka Server 服务列表我们带着这个疑问打开Eureka Server管理界面地址：http://localhost:10000。 在管理界面我们可以看到本章的服务已经注册到了Eureka Server服务注册中心，而且是UP状态也就是正常运行状态。 在服务注册的过程中，SpringCloud Eureka为每一个服务节点都提供默认且唯一的实例编号(InstanceId) 实例编号默认值：${spring.cloud.client.ipAddress}:${spring.application.name}:${spring.application.instance_id:${server.port}} 本章服务注册时的实例编号：192.168.1.75:hengboy-spring-cloud-eureka-provider:20000 如果你想要随心所欲的自定义这个实例编号，那么好可以满足你，不过要注意自定义时要保证唯一性！！！ 自定义InstanceId我们可以来考虑考虑根据什么格式来自定义这个实例编号可以更好的帮助我们定位问题？ 一般来说我们在线上运行着的服务来说，我要知道服务的名称这是肯定的，还有就是端口号，因为如果你同一台服务器部署多个相同的服务肯定端口号要有所变动，当然如果你还想要知道当前运行代码的版本号，那要更有利于你分析并定位解决运行中遇到的问题，那既然这样，我们就可以采用这种方式进行自定义。application.yml配置文件内修改实例编号后内容如下所示: 12345678# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/ # 自定义实例编号 instance: instance-id: ${spring.application.name}:${server.port}:@project.version@ @project.version@源码的版本号我们是采用了获取pom.xml配置文件内设置的version来设置的值，通过@xxx@的方式就可以得到maven的一些相关配置信息来直接使用。既然修改了那么我们来看下效果，重启我们本章的项目，启动完成后再次打开Eureka Server的管理界面，查看服务列表，如下图所示： 可以看到正在UP状态服务的实例编号是hengboy-spring-cloud-eureka-provider:20000:v1.0，也就是我们自定义eureka.instance.instance-id的值，至于DOWN状态的服务时间久了就会被Eureka Server所剔除，不会影响我们服务的正常使用。 总结本章通过一个SpringBoot项目来讲解了怎么将自定义的服务注册到Eureka Server(服务注册中心)，简单的两个步骤就可以完成这个注册、绑定、生效的过程，在这个过程中我们还了解到了怎么去自定义服务注册时的实例编号。","link":"/eureka-register-service.html"},{"title":"Eureka服务注册中心内置的REST节点列表","text":"你有没有考虑过Eureka Client与Eureka Server是通过什么方式进行通讯的？为什么Client启动成功后Server就会被注册到Server的服务列表内？为什么我们在正常关闭Client后Server会有所感知？ 既然这么多问题，带着这些问题来进行本章的学习吧。 本章目标熟悉Eureka Server内部提供的REST服务维护请求节点。 构建项目我们本章知识点不需要涉及到代码的编写，所以我们只需要运行之前章节/eureka-server.html的源码即可。 REST节点一览Eureka Server内部通过JAX-RS(Java API for RESTful Web Services)规范提供了一系列的管理服务节点的请求节点，这样也保证了在非JVM环境运行的程序可以通过HTTP REST方式进行管理维护指定服务节点，所以只要遵循Eureka协议的服务节点都可以进行注册到Eureka Server。 Eureka提供的REST请求可以支持XML以及JSON形式通信，默认采用XML方式，REST列表如表所示： 请求名称 请求方式 HTTP地址 请求描述 注册新服务 POST /eureka/apps/{appID} 传递JSON或者XML格式参数内容，HTTP code为204时表示成功 取消注册服务 DELETE /eureka/apps/{appID}/{instanceID} HTTP code为200时表示成功 发送服务心跳 PUT /eureka/apps/{appID}/{instanceID} HTTP code为200时表示成功 查询所有服务 GET /eureka/apps HTTP code为200时表示成功，返回XML/JSON数据内容 查询指定appID的服务列表 GET /eureka/apps/{appID} HTTP code为200时表示成功，返回XML/JSON数据内容 查询指定appID&amp;instanceID GET /eureka/apps/{appID}/{instanceID} 获取指定appID以及InstanceId的服务信息，HTTP code为200时表示成功，返回XML/JSON数据内容 查询指定instanceID服务列表 GET /eureka/apps/instances/{instanceID} 获取指定instanceID的服务列表，HTTP code为200时表示成功，返回XML/JSON数据内容 变更服务状态 PUT /eureka/apps/{appID}/{instanceID}/status?value=DOWN 服务上线、服务下线等状态变动，HTTP code为200时表示成功 变更元数据 PUT /eureka/apps/{appID}/{instanceID}/metadata?key=value HTTP code为200时表示成功 查询指定IP下的服务列表 GET /eureka/vips/{vipAddress} HTTP code为200时表示成功 查询指定安全IP下的服务列表 GET /eureka/svips/{svipAddress} HTTP code为200时表示成功 在上面列表中参数解释 {appID}：服务名称，对应spring.application.name参数值 {instanceID}：实例名称，如果已经自定义instanceId则对应eureka.instance.instance-id参数值 服务注册在Eureka Client启动成功后会发送POST方式的请求到/eureka/apps/{appID}，发送注册请求时的主体内容在官网也有介绍，如果我们根据指定的主体内容发送请求到Eureka Server时也是可以将服务注册成功的，主体内容要以XML/JSON格式的XSD传递： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;xsd:schema xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; elementFormDefault=&quot;qualified&quot; attributeFormDefault=&quot;unqualified&quot;&gt; &lt;xsd:element name=&quot;instance&quot;&gt; &lt;xsd:complexType&gt; &lt;xsd:all&gt; &lt;!-- hostName in ec2 should be the public dns name, within ec2 public dns name will always resolve to its private IP --&gt; &lt;xsd:element name=&quot;hostName&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;app&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;ipAddr&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;vipAddress&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;secureVipAddress&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;status&quot; type=&quot;statusType&quot; /&gt; &lt;xsd:element name=&quot;port&quot; type=&quot;xsd:positiveInteger&quot; minOccurs=&quot;0&quot; /&gt; &lt;xsd:element name=&quot;securePort&quot; type=&quot;xsd:positiveInteger&quot; /&gt; &lt;xsd:element name=&quot;homePageUrl&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;statusPageUrl&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;healthCheckUrl&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element ref=&quot;dataCenterInfo&quot; minOccurs=&quot;1&quot; maxOccurs=&quot;1&quot; /&gt; &lt;!-- optional --&gt; &lt;xsd:element ref=&quot;leaseInfo&quot; minOccurs=&quot;0&quot;/&gt; &lt;!-- optional app specific metadata --&gt; &lt;xsd:element name=&quot;metadata&quot; type=&quot;appMetadataType&quot; minOccurs=&quot;0&quot; /&gt; &lt;/xsd:all&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=&quot;dataCenterInfo&quot;&gt; &lt;xsd:complexType&gt; &lt;xsd:all&gt; &lt;xsd:element name=&quot;name&quot; type=&quot;dcNameType&quot; /&gt; &lt;!-- metadata is only required if name is Amazon --&gt; &lt;xsd:element name=&quot;metadata&quot; type=&quot;amazonMetdataType&quot; minOccurs=&quot;0&quot;/&gt; &lt;/xsd:all&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:element name=&quot;leaseInfo&quot;&gt; &lt;xsd:complexType&gt; &lt;xsd:all&gt; &lt;!-- (optional) if you want to change the length of lease - default if 90 secs --&gt; &lt;xsd:element name=&quot;evictionDurationInSecs&quot; minOccurs=&quot;0&quot; type=&quot;xsd:positiveInteger&quot;/&gt; &lt;/xsd:all&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;xsd:simpleType name=&quot;dcNameType&quot;&gt; &lt;!-- Restricting the values to a set of value using 'enumeration' --&gt; &lt;xsd:restriction base = &quot;xsd:string&quot;&gt; &lt;xsd:enumeration value = &quot;MyOwn&quot;/&gt; &lt;xsd:enumeration value = &quot;Amazon&quot;/&gt; &lt;/xsd:restriction&gt; &lt;/xsd:simpleType&gt; &lt;xsd:simpleType name=&quot;statusType&quot;&gt; &lt;!-- Restricting the values to a set of value using 'enumeration' --&gt; &lt;xsd:restriction base = &quot;xsd:string&quot;&gt; &lt;xsd:enumeration value = &quot;UP&quot;/&gt; &lt;xsd:enumeration value = &quot;DOWN&quot;/&gt; &lt;xsd:enumeration value = &quot;STARTING&quot;/&gt; &lt;xsd:enumeration value = &quot;OUT_OF_SERVICE&quot;/&gt; &lt;xsd:enumeration value = &quot;UNKNOWN&quot;/&gt; &lt;/xsd:restriction&gt; &lt;/xsd:simpleType&gt; &lt;xsd:complexType name=&quot;amazonMetdataType&quot;&gt; &lt;!-- From &lt;a class=&quot;jive-link-external-small&quot; href=&quot;http://docs.amazonwebservices.com/AWSEC2/latest/DeveloperGuide/index.html?AESDG-chapter-instancedata.html&quot; target=&quot;_blank&quot;&gt;http://docs.amazonwebservices.com/AWSEC2/latest/DeveloperGuide/index.html?AESDG-chapter-instancedata.html&lt;/a&gt; --&gt; &lt;xsd:all&gt; &lt;xsd:element name=&quot;ami-launch-index&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;local-hostname&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;availability-zone&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;instance-id&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;public-ipv4&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;public-hostname&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;ami-manifest-path&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;local-ipv4&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;hostname&quot; type=&quot;xsd:string&quot;/&gt; &lt;xsd:element name=&quot;ami-id&quot; type=&quot;xsd:string&quot; /&gt; &lt;xsd:element name=&quot;instance-type&quot; type=&quot;xsd:string&quot; /&gt; &lt;/xsd:all&gt; &lt;/xsd:complexType&gt; &lt;xsd:complexType name=&quot;appMetadataType&quot;&gt; &lt;xsd:sequence&gt; &lt;!-- this is optional application specific name, value metadata --&gt; &lt;xsd:any minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot; processContents=&quot;skip&quot;/&gt; &lt;/xsd:sequence&gt; &lt;/xsd:complexType&gt;&lt;/xsd:schema&gt; 我们本章先来使用之前章节/eureka-register-service.html源码进行自动注册服务，在之后的章节内我们再来细讲具体怎么通过符合以上XSD主体内容的XML/JSON手动注册。 在下面我们来看下通过REST来维护服务实例，在这之前我们需要通过以下步骤进行启动服务，为后续REST请求维护服务实例提供环境： 启动Eureka Server，源码查看/eureka-server.html 启动Eureka Client，源码查看/eureka-register-service.html 服务状态变更我们可以直接修改服务实例的运行状态，比如服务关闭，会从UP转换为DOWN，我们通过curl命令来测试服务的状态变更，如下所示： 1curl -v -X PUT http://localhost:10000/eureka/apps/HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER/hengboy-spring-cloud-eureka-provider:20000:v1.0/status\\?value\\=DOWN 其中参数HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER为appID，hengboy-spring-cloud-eureka-provider:20000:v1.0为instanceID。执行完成后可以打开Eureka Server管理平台查看服务实例列表查看服务状态，如下图所示：服务的状态已经由原本的UP改为了DOWN。 服务基本信息获取Eureka提供获取指定appID以及instanceID的详细信息，可以详细的返回服务实例的配置内容，获取信息的命令如下： 1curl http://localhost:10000/eureka/apps/HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER/hengboy-spring-cloud-eureka-provider:20000:v1.0 执行命令返回值的格式化如下所示： 1234567891011121314151617181920212223242526272829303132333435&lt;instance&gt; &lt;instanceId&gt;hengboy-spring-cloud-eureka-provider:20000:v1.0&lt;/instanceId&gt; &lt;hostName&gt;192.168.1.75&lt;/hostName&gt; &lt;app&gt;HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER&lt;/app&gt; &lt;ipAddr&gt;192.168.1.75&lt;/ipAddr&gt; &lt;status&gt;UP&lt;/status&gt; &lt;overriddenstatus&gt;UNKNOWN&lt;/overriddenstatus&gt; &lt;port enabled=&quot;true&quot;&gt;20000&lt;/port&gt; &lt;securePort enabled=&quot;false&quot;&gt;443&lt;/securePort&gt; &lt;countryId&gt;1&lt;/countryId&gt; &lt;dataCenterInfo class=&quot;com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo&quot;&gt; &lt;name&gt;MyOwn&lt;/name&gt; &lt;/dataCenterInfo&gt; &lt;leaseInfo&gt; &lt;renewalIntervalInSecs&gt;30&lt;/renewalIntervalInSecs&gt; &lt;durationInSecs&gt;90&lt;/durationInSecs&gt; &lt;registrationTimestamp&gt;1539223540390&lt;/registrationTimestamp&gt; &lt;lastRenewalTimestamp&gt;1539229835439&lt;/lastRenewalTimestamp&gt; &lt;evictionTimestamp&gt;0&lt;/evictionTimestamp&gt; &lt;serviceUpTimestamp&gt;1539223539774&lt;/serviceUpTimestamp&gt; &lt;/leaseInfo&gt; &lt;metadata&gt; &lt;management.port&gt;20000&lt;/management.port&gt; &lt;jmx.port&gt;54581&lt;/jmx.port&gt; &lt;/metadata&gt; &lt;homePageUrl&gt;http://192.168.1.75:20000/&lt;/homePageUrl&gt; &lt;statusPageUrl&gt;http://192.168.1.75:20000/actuator/info&lt;/statusPageUrl&gt; &lt;healthCheckUrl&gt;http://192.168.1.75:20000/actuator/health&lt;/healthCheckUrl&gt; &lt;vipAddress&gt;hengboy-spring-cloud-eureka-provider&lt;/vipAddress&gt; &lt;secureVipAddress&gt;hengboy-spring-cloud-eureka-provider&lt;/secureVipAddress&gt; &lt;isCoordinatingDiscoveryServer&gt;false&lt;/isCoordinatingDiscoveryServer&gt; &lt;lastUpdatedTimestamp&gt;1539223540390&lt;/lastUpdatedTimestamp&gt; &lt;lastDirtyTimestamp&gt;1539223539732&lt;/lastDirtyTimestamp&gt; &lt;actionType&gt;ADDED&lt;/actionType&gt;&lt;/instance&gt; 返回值的比较详细，如需选择使用。 服务剔除当然我们同样可以主动将服务从Eureka剔除，剔除后会直接从服务实例列表中删除，可执行如下命令： 1curl -v -X DELETE localhost:10000/eureka/apps/HENGBOY-SPRING-CLOUD-EUREKA-PROVIDER/hengboy-spring-cloud-eureka-provider:20000:v1.0 注意：由于Eureka Client一直在运行，删除后也会自动通过注册服务的REST注册实例。 总结本章讲解了怎么通过主动以及自动同步的方式将Eureka Client注册到服务注册中心集群环境中，为了保证完整性，还是建议手动进行配置，自动同步也有不成功的情况存在。","link":"/eureka-rest.html"},{"title":"你的Eureka服务注册中心安全吗？","text":"在之前的章节我们讲到了/eureka-server.html，已经可以让我们自定义的微服务节点进行注册到该Eureka Server上，不过在注册过程中存在一个风险的问题，如果我们的Eureka Server的地址无意暴露在外，那岂不是通过Eureka协议创建的任意服务都可以进行注册到该Eureka Server吗？（当然如果你配置了服务器的安全组并且使用内网的IP地址或者主机名方式对外提供服务注册地址几乎不存在这个问题。） 本章目标为Eureka Server穿上安全的外套，我的注册中心更安全。 构建项目依然使用idea开发工具创建一个SpringBoot项目，在依赖的选择界面我们添加Eureka Server、Security相关依赖，pom.xml配置文件如下所示： 1234567891011121314151617181920//...省略部分内容&lt;dependencies&gt; &lt;!--Eureka服务端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--添加安全认证--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;//...省略部分内容 因为我们是用的是Spring Security作为安全组件，所以在这里需要添加spring-boot-starter-security依赖来完成安全相关组件的自动化配置以及实例化。 既然依赖已经添加好了，那么我们怎么配置安全用户呢？ 开启注册中心安全配置在添加安全配置之前，我们需要把Eureka Server的配置也一并添加上，如果你对Eureka Server配置不太了解，你可以查看/eureka-server.html阅读学习 配置文件的安全配置修改application.yml配置文件内容，添加安全配置信息，如下所示： 12345678910111213141516171819202122# 服务名称spring: application: name: hengboy-spring-cloud-eureka-security # 安全参数配置 security: user: name: api password: node roles: SERVICE_NODE# eureka配置eureka: client: service-url: defaultZone: http://localhost:${server.port}/eureka/ fetch-registry: false register-with-eureka: false# 端口号server: port: 10000 安全相关的内容我们通过spring.security.user开头的参数进行配置，对应自动绑定spring-boot-starter-security依赖内的org.springframework.boot.autoconfigure.security.SecurityProperties属性实体类。在SecurityProperties的内部类SecurityProperties.User内我们可以看到已经给我们生成了一个默认的name以及password spring.security.user.name用户名，默认值为user，配置Spring Security内置使用内存方式存储的用户名。 spring.security.user.password用户对应的密码，默认值为UUID随机字符串，配置Spring Security默认对应user用户的密码，该密码在系统启动时会在控制台打印，如果使用默认值可以运行查看控制台的输出内容。 开启Http Basic 安全认证旧版本的Spring Security的依赖是可以在配置文件内容直接通security.basic.enabled参数进行开启basic认证，不过目前版本已经被废除，既然这种方式不可行，那我们就使用另外一种方式进行配置，通过继承WebSecurityConfigurerAdapter安全配置类来完成开启认证权限，配置类如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * 开启Eureka Server安全认证配置 * * @author：于起宇 &lt;p&gt; * ================================ * Created with IDEA. * Date：2018/9/28 * Time：5:42 PM * 简书：http://www.jianshu.com/u/092df3f77bca * 码云：https://gitee.com/hengboy * GitHub：https://github.com/hengyuboy * ================================ * &lt;/p&gt; */@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter { /** * 配置安全信息 * - 禁用csrf攻击功能 * - 开启所有请求需要验证并且使用http basic进行认证 * * @param http * @throws Exception */ @Override protected void configure(HttpSecurity http) throws Exception { http.csrf() .disable() .authorizeRequests() .anyRequest().authenticated() .and() .httpBasic(); }} 如果你了解Spring Security那肯定对我们自定义的安全配置类SecurityConfiguration的内容不陌生，在SecurityConfiguration#configure方法内，我们禁用了csrf功能并且开启所有请求都需要通过basic方式进行验证。 到目前为止我们的Eureka 注册中心的安全相关配置已经添加完成，那么我们的服务在进行注册时是不是也需要同步修改呢？ 答案：肯定以及必须的 不过服务注册时仅仅是微调，影响不太大，那么我们下面来看下该怎么调整。 注册服务时的安全配置如果你对怎么把服务注册到Eureka Server不太了解，你可以阅读/eureka-register-service.html来进行学习，我们只需要修改eureka.client.service-url.defaultZone配置的连接字符串内容即可，下面是修改前后的对比： 12345678910111213// 修改前# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://localhost:10000/eureka/// 修改后# 配置Eureka Server 信息eureka: client: service-url: defaultZone: http://api:node@localhost:10000/eureka/ 修改后的api:node@这块的内容，前面是spring.security.user.name配置的值，而后面则是spring.security.user.password配置的值，@符号后面才是原本之前的Eureka Server的连接字符串信息。对于上面的修改是不是很简单？ 这也归功于Eureka的设计，安全方面也是netflix他们在研发过程中考虑到的一点，所以才会可以这么简单的集成Spring Security安全认证。 运行测试 本章的测试流程如下： 启动Eureka Server（本章项目） 启动Eureka Client（可以自行创建一个服务节点，也可以直接使用/eureka-register-service.html源码进行测试。） 访问Eureka Server管理平台 http://localhost:10000 输入用户名api以及密码node进行登录 查看服务注册列表 总结我们本章为Eureka Server穿上了安全的外套，让它可以更安全，在文章开始的时候我说到了如果使用内网IP或者主机名方式进行服务注册时是几乎不存在安全问题的，如果你想你的服务注册中心更新安全，大可不必考虑你的服务注册方式都可以添加安全认证。","link":"/eureka-security.html"},{"title":"搭建Eureka服务注册中心","text":"Eureka服务注册中心是netflix开源组织提供的一个服务高可用的解决方案，在前端时间一直在疯传的2.0开源流产的问题，其实并不影响我们的使用，netflix只不过是不再维护2.0分支的开源代码，所以做出了免责声明，不过对于我们使用者来说确实比较担心这一点，还有不少人更换服务注册中心，比如：zookeeper、consul。 当然对于Eureka 2.0 流产这件事情就当做一场闹剧来对待吧，因为SpringCloud.Finchley.SR1版本依赖的Eureka是1.9.3，根本不需要考虑到这一点了。我们还是来关心我们的分布式微服务架构系统该怎么去设计。 构建项目跟我们之前构建项目一样， 使用idea工具直接创建一个新的SpringBoot项目，在选择依赖的界面勾选Cloud Discovert -&gt; Eureka Server依赖，创建完成后的pom.xml配置文件内容如下： 1234567891011121314151617181920212223242526272829&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--SpringCloud最新稳定版本--&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--Netflix Eureka依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--SpringCloud依赖版本管理--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 我们在创建新的项目时，如果选择了相关SpringCloud的依赖，则会自动在pom.xml配置文件内添加SpringCloud最新稳定版本依赖配置。spring-cloud-dependencies这个依赖是SpringCloud内所需要依赖的版本维护，在maven项目内如果被&lt;dependencyManagement&gt;内修饰的&lt;dependency&gt;，子项目或者本项目在使用时可以不用设置版本号，默认使用&lt;dependencyManagement&gt;下&lt;dependency&gt;内设置的版本信息。正因如此，这也是为什么我们添加了spring-cloud-dependencies依赖后，在使用相关SpringCloud插件时可以不用添加version标签设置导入指定版本的依赖。 Eureka Server的配置添加spring-cloud-starter-netflix-eureka-server依赖后，我们就来看看怎么开启Eureka Server服务。开启Eureka的注册中心服务端比较简单，只需要修改注意两个地方。 第一个地方是在入口类上添加启用Eureka Server的注解@EnableEurekaServer，如下所示：12345@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEurekaApplication { // main method} 第二个地方是application.yml/application.properties文件内添加配置基本信息,如下所示：123456789101112131415161718# 服务名称spring: application: name: hengboy-spring-cloud-eureka# 服务端口号server: port: 10000#Eureka 相关配置eureka: client: service-url: defaultZone: http://localhost:${server.port}/eureka/ # 是否从其他的服务中心同步服务列表 fetch-registry: false # 是否把自己作为服务注册到其他服务注册中心 register-with-eureka: false spring.application.name：服务名称 server.port：服务端口号 eureka.client.service-url.defaultZone：Eureka默认的服务地址空间信息配置 eureka.client.fetch-registry：是否从其他Eureka注册中心同步服务列表（单节点无需配置启用）. eureka.client.register-with-eureka：是否将自己作为服务注册到其他Eureka服务注册中心（单节点无需配置启用）. 运行测试上面的步骤我们已经把Eureka服务端所需要的依赖以及配置进行了集成，接下来我们来运行测试看下效果，Eureka给我们提供了一个漂亮的管理界面，这样我们就可以通过管理界面来查看注册的服务列表以及服务状态等信息。 测试步骤： 通过Application方式进行启动Eureka Server 在本地浏览器访问http://localhost:10000，10000端口号是我们在application.yml配置文件内设置的server.port的值。 成功访问到Eureka Server管理界面 界面如下所示： 对于界面我们可以看到一些Eureka Server的健康数据以及基本信息，比如： server-uptime：已经启动的耗时 current-memory-usage：当前占用的内存总量 Instances currently registered with Eureka：注册到该中心的服务列表 ipAddr：当前Eureka Server的IP地址，如果没有配置eureka.instance.ip-address那么这里使用默认的IP地址。… 总结本章介绍了Eureka作为Server的配置，配置的步骤比较简单，没有那么多繁琐的地方，当然这只是Eureka单个服务节点的配置方式，更多高级的使用方式请查看后续文章。","link":"/eureka-server.html"},{"title":"MacOS系统fish终端快速切换JDK版本","text":"倘若装有多个版本，特别是从 8 跨到 9 这个分界线，如果是基于 IDE，那么一般使用 IDE 提供的 JDK 设置来指定就可以了。但如果是直接命令执行，那就需要来个方便切换版本的方法。 对于 MacOS，只需要设定 JAVA_HOME 这个环境变量就可以了，甚至不必要把这个路径添加到 PATH 中。 同时，在 MacOS 中，JAVA 相关有个好用的内置工具：/usr/libexec/java_home 123456789101112yuqiyu@hengyu ~&gt; /usr/libexec/java_home -hUsage: java_home [options...] Returns the path to a Java home directory from the current user's settings.Options: [-v/--version &lt;version&gt;] Filter versions (as if JAVA_VERSION had been set in the environment). [-a/--arch &lt;architecture&gt;] Filter architecture (as if JAVA_ARCH had been set in the environment). [-F/--failfast] Fail when filters return no JVMs, do not continue with default. [ --exec &lt;command&gt; ...] Execute the $JAVA_HOME/bin/&lt;command&gt; with the remaining arguments. [-X/--xml] Print full JVM list and additional data as XML plist. [-V/--verbose] Print full JVM list with architectures. [-h/--help] This usage information. 所以，通过 /usr/libexec/java_home -v 1.8 这样的形式即可把 JDK 切到指定版本。 这里是 8，当然，需要先安装对应的版本 查看可以切换的JDK列表1234567yuqiyu@hengyu ~&gt; /usr/libexec/java_home -VMatching Java Virtual Machines (4): 17.0.1 (x86_64) &quot;Oracle Corporation&quot; - &quot;OpenJDK 17.0.1&quot; /Users/yuqiyu/Library/Java/JavaVirtualMachines/openjdk-17.0.1/Contents/Home 11.0.8 (x86_64) &quot;Oracle Corporation&quot; - &quot;Java SE 11.0.8&quot; /Library/Java/JavaVirtualMachines/jdk-11.0.8.jdk/Contents/Home 1.8.0_312 (x86_64) &quot;Amazon&quot; - &quot;Amazon Corretto 8&quot; /Users/yuqiyu/Library/Java/JavaVirtualMachines/corretto-1.8.0_312/Contents/Home 1.8.0_231 (x86_64) &quot;Oracle Corporation&quot; - &quot;Java SE 8&quot; /Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/Users/yuqiyu/Library/Java/JavaVirtualMachines/openjdk-17.0.1/Contents/Home 创建切换JDK的fish函数1234function setjdk set -g -x JAVA_HOME (/usr/libexec/java_home -v $argv) echo (java -version)end 在 ~/.config/fish/functions/ 下添加一个 setjdk.fish，填写以下内容，那么就可以在终端中使用 setjdk 1.8 / setjdk 9 的形式来切换到 JDK8 和 JDK9 了。 切换效果： 1234567891011121314yuqiyu@hengyu ~&gt; java -versionopenjdk version &quot;17.0.1&quot; 2021-10-19OpenJDK Runtime Environment (build 17.0.1+12-39)OpenJDK 64-Bit Server VM (build 17.0.1+12-39, mixed mode, sharing)yuqiyu@hengyu ~&gt; setjdk 1.8openjdk version &quot;1.8.0_312&quot;OpenJDK Runtime Environment Corretto-8.312.07.1 (build 1.8.0_312-b07)OpenJDK 64-Bit Server VM Corretto-8.312.07.1 (build 25.312-b07, mixed mode)yuqiyu@hengyu ~&gt; setjdk 11java version &quot;11.0.8&quot; 2020-07-14 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.8+10-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.8+10-LTS, mixed mode)","link":"/fish-fast-switch-jdk.html"},{"title":"Git分支管理规范构思","text":"最近对于公司项目源码分支管理有一些规范构思，对于同一个项目而言，不同环境的源码管理、自动化部署方式、以及接口数据隔离等我们是否可以满足现状？ 对于基础项目源码分支而言，一般有develop、master两个，develop来研发功能并测试没有问题后合并到master再发布到生产环境。 分支示意图 特性分支（feature）如果项目比较大，协同人员比较多，每个研发人员的分工比较明确，针对这种情况我们如果还是简单的使用develop/master两个分支就不太能满足需求了，针对这个情况我们如何去规范化管理呢？ 特性分支一般是基于develop开发分支衍生创建的，而且是本地分支（Local Branches），不太建议一个特性任务多个人同时使用，如果必须是多人协同的任务，那么该特性分支则会变成远程分支（Remote Branches），特性分支的任务完成后需要合并到develop分支并后续提交给测试人员进行测试。 任务分配到具体研发人员后，研发人员可以在本地创建特性分支，如果分支较多为了区分方便，我们可以定义一个分支名称的前缀，如：feature-，如果给我分配了用户管理的任务，那么我就可以在本地创建feature-user特性分支来研发。 紧急缺陷修复分支（bugfix）如果代码已经发布，在运行过程中遇到了一个紧急的缺陷，针对这个缺陷我们需要怎么去修复呢？ 首先我们需要基于master分支来衍生创建缺陷修复分支，该分支也应该是本地分支（Local Branches）不应该被推送到远程目标仓库，我们可以以bugfix-作为缺陷修复分支的前缀，如：bugfix-register-error。 缺陷一旦修复完成后需要将bugfix-xxx分支的代码变动合并到master以及develop： 为什么合并到develop？ 遇到的缺陷不仅是master分支存在，因为master分支的代码是从develop合并而来的，所以我们需要同步合并到develop防止后续发版再次出现相同的问题。 为什么合并到master？ 因为该缺陷是生产环境发现的，虽然我们合并到了develop分支，但是不保证距下次发版生产环境不再出现紧急的缺陷所以我们需要将代码合并到master。 下一个版本分支（next-version）如果项目是有规划根据迭代版本循序渐进的，那么建议使用next-version分支，那么为什么这么做呢？ 顾名思义，next-version是下一个版本，当前版本源码一般存放于develop分支，而且当前版本是跟任务规划来的，不会涉及next-version分支的源码，这样就做到了版本之间的源码隔离，当前版本准备发布时防止发布下个版本未完成的功能。 next-version是基于develop分支衍生创建的，develop是当前版本，那么next-version就是下一个当前版本，develop一旦合并到master发布后就需要将next-version的代码合并到develop作为当前版本继续做后续研发。 支持自动化部署的分支自动化部署可以极大的提高CI/CD效率，研发人员只需要关心业务功能怎么去实现，无需考虑代码怎么去部署，代码一旦被提交就可以触发自动化部署的程序，实现流水线的自动化部署业务。 开发环境自动化部署可以考虑使用Drone来配置，它很轻量级，在根目录下创建一个名为.drone.yml的文件即可搞定配置流程，它还可以结合支持私有部署的Git源码仓库：Gitea 实现钩子回调，部署也很简单使用docker部署一个管理端、一个运行节点即可。 参与自动化部署的分支一般为：develop、next-version。 master分支则是建议手动触发的方式来部署，可以使用Jenkins。 常见问题 功能还未研发完成，临时接到紧急任务，我怎么把未完成的工作保存并切换分支？ 可以使用git stash暂存工作空间的文件变动，暂存后就可以切换到其他分支做相关工作了，处理完成后返回未完成的分支执行git stash pop恢复暂存即可，git stash还有很多用法，可以参考官网文档：git-stash","link":"/git-branches-management-normative-idea.html"},{"title":"Git托管项目的.git目录下都有什么？","text":"我们在使用git托管项目代码时，如果是新建项目需要通过git init命令在项目根目录下初始化.git目录来实现后续的代码托管管理，如果直接从代码仓库拉取代码则会自动创建.git目录与远程仓库进行绑定。 .git目录结构首先我们先来看看.git这个目录的结构是什么样子的，如下所示： 12345678910111213141516171819⋊&gt; ~/s/g/.git on master ⨯ pwd 10:24:08/Users/yuqiyu/study/git-chapter/.git⋊&gt; ~/s/g/.git on master ⨯ ll 10:24:09total 64-rw-r--r-- 1 yuqiyu staff 16B May 26 13:51 COMMIT_EDITMSG-rw-r--r-- 1 yuqiyu staff 91B May 27 11:20 FETCH_HEAD-rw-r--r-- 1 yuqiyu staff 23B May 26 13:33 HEAD-rw-r--r-- 1 yuqiyu staff 41B May 26 13:50 ORIG_HEADdrwxr-xr-x 2 yuqiyu staff 64B May 19 09:07 branches/-rw-r--r-- 1 yuqiyu staff 361B May 29 09:31 config-rw-r--r-- 1 yuqiyu staff 73B May 19 09:07 descriptiondrwxr-xr-x 13 yuqiyu staff 416B May 19 09:07 hooks/-rw-r--r-- 1 yuqiyu staff 751B May 26 13:51 indexdrwxr-xr-x 3 yuqiyu staff 96B May 19 09:07 info/drwxr-xr-x 4 yuqiyu staff 128B May 19 09:08 logs/drwxr-xr-x 127 yuqiyu staff 4.0K May 27 11:20 objects/drwxr-xr-x 6 yuqiyu staff 192B May 25 16:17 refs/-rw-r--r--@ 1 yuqiyu staff 174B May 27 11:20 sourcetreeconfig⋊&gt; ~/s/g/.git on master ⨯ HEAD文件HEAD是当前活动分支的游标指向，我们可以查看下该文件的内容： 12⋊&gt; ~/s/g/.git on master ⨯ cat HEAD 11:17:22ref: refs/heads/master 可以看到HEAD文件目前指向master分支，而master分支则位于refs/heads目录下，我们接下来可以去refs目录下看看都有哪些内容。 refs目录refs目录存储了一些引用指向，我们在使用branch、tag时大多数都是引用到该目录下，然后再指向具体的objects。 refs目录结构如下所示： 12345678⋊&gt; ~/s/g/.g/refs on master ⨯ pwd 11:26:27/Users/yuqiyu/study/git-chapter/.git/refs⋊&gt; ~/s/g/.g/refs on master ⨯ ll 11:26:28total 8drwxr-xr-x 3 yuqiyu staff 96B May 26 13:51 heads/drwxr-xr-x 3 yuqiyu staff 96B May 25 16:17 remotes/-rw-r--r-- 1 yuqiyu staff 41B May 19 10:12 stashdrwxr-xr-x 3 yuqiyu staff 96B May 29 09:36 tags/ refs内全部目录的文件都是存储的objects引用，我们下面以heads目录为例 heads该目录下存放该项目在本地全部的分支，每个分支文件存储了commit id，如下所示： 12345⋊&gt; ~/s/g/.g/refs on master ⨯ cd heads/ 09:01:37⋊&gt; ~/s/g/.g/r/heads on master ⨯ ls 09:03:13master⋊&gt; ~/s/g/.g/r/heads on master ⨯ cat master 09:03:1333248b733e36a495ea3691f2d1291c5e77633229 通过cat master命令我们可以查看该文件的内容，发现该文件的内容是一长串的字符编号，如果想要知道这个一长串字符编号是什么我们可以通过git cat-file命令来查看类型以及详细内容，如下所示： 123456789101112# -t 参数查看文件的类型⋊&gt; ~/s/g/.g/r/heads on master ⨯ git cat-file -t 33248b733e36a495ea3691f2d1291c5e77633229 09:32:11commit# -p 参数查看该文件的详细内容⋊&gt; ~/s/g/.g/r/heads on master ⨯ git cat-file -p 33248b733e36a495ea3691f2d1291c5e77633229 09:59:48tree 026567e8fe35ef942c1ea7f833799f26027d964fparent d78e592e663b2a34da826810303bd75f671a84afauthor 恒宇少年 &lt;39233436+hengboy@users.noreply.github.com&gt; 1653544281 +0800committer 恒宇少年 &lt;39233436+hengboy@users.noreply.github.com&gt; 1653544281 +0800添加默认值 通过git cat-file -t命令我们发现33248b733e36a495ea3691f2d1291c5e77633229文件是一个commit类型的objects，通过git cat-file -p命令就可以查看该文件的详细内容了。 我们从文件内容来看可以猜测出该文件应该是对应的master分支的最后一次提交的commit，我们可以通过git branch -av命令来查看每个分支的情况，如下所示： 123⋊&gt; ~/s/g/.g/r/heads on master ⨯ git branch -av 09:07:59* master 33248b7 添加默认值 remotes/origin/master 33248b7 添加默认值 发现本地master分支指向了33248b7，也就是我们刚才cat master内容33248b733e36a495ea3691f2d1291c5e77633229的缩写，这样我们就明白了，master文件内存储了最新提交的指向。 tags该目录下存储了全部的tag文件，每个tag文件也是存储了objects指向，一般tag是基于commit来打的所以指向跟commit一致。 我们项目中有个temp的tag，我们可以查看下该文件的类型以及内容： 1234567⋊&gt; ~/s/g/.g/refs on master ⨯ cd tags/ 10:13:42⋊&gt; ~/s/g/.g/r/tags on master ⨯ ls 10:13:43temp⋊&gt; ~/s/g/.g/r/tags on master ⨯ cat temp 10:13:4433248b733e36a495ea3691f2d1291c5e77633229⋊&gt; ~/s/g/.g/r/tags on master ⨯ git cat-file -t 33248b733e36a495ea3691f2d1291c5e77633229 10:13:46commit 我们发现temp分支文件内存储的指向也是33248b733e36a495ea3691f2d1291c5e77633229，temp标签是基于master分支最新commit打的，所以tag的objects指向与master分支的指向是一致的。 config文件在.git目录下有个config文件，存放了该仓库的配置信息，内容如下： 12345678910111213[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true[remote &quot;origin&quot;] url = git@gitee.com:hengboy/git-chapter.git fetch = +refs/heads/*:refs/remotes/origin/*[branch &quot;master&quot;] remote = origin merge = refs/heads/master 该文件内定义了一些核心参数配置、远程分支信息、本地分支列表等，我们通过git config --local 也可以为该仓库配置参数，如下所示： 12git config --local user.name '恒宇少年'git config --local user.email 'jnyuqy@gmail.com' 通过上面命令配置后再.git/config文件内就会添加对应的配置内容： 123[user] name = 恒宇少年 email = jnyuqy@gmail.com 总结git远比我们想的强大，本文章是一个入门篇，应对工作中遇到的各种问题后续针对git还回详谈，熟练的运用git让我们在协同开发过程中不再有冲突恐惧症。","link":"/git-chapter-core-directory.html"},{"title":"在Ubuntu下为Gitolite添加客户端","text":"在之前的章节完成了服务端、管理客户端的配置，基础的配置已经完成，下面就可以开始把团队的开发人员添加到服务端了，客户端的配置要比管理客户端更简单一些，只需要把客户端生成的公钥上传到服务端即可。 相关文章： /git-gitolite-server.html /git-gitolite-manage.html 本章目标完成客户端的gitolite配置。 前置条件客户端需要安装Git客户端，可以去Git官网进行下载对应系统的安装文件，点击下载https://git-scm.com/downloads 客户端的SSH KEY在上传公钥之前，客户端需要先生成公钥文件才可以，同样是使用ssh-keygen命令来完成RSA方式的公钥秘钥生成。 Windows系统生成如果你的客户端是使用Windows系统进行开发，安装完成Git客户端后在鼠标右键的功能菜单会出现一个Git Bash Here选项，点击该选项会弹出Git命令终端，在终端内执行如下命令： 1ssh-keygen -t rsa 一路回车过后，文件会出现在当前用户文件下，自动创建隐藏.ssh文件夹存放。如：C:\\Users\\hengboy\\.ssh Linux/Mac系统生成在Linux/Mac系统上相对来说更简单一些，直接在终端输入上面的命令即可（前提：需要安装open-ssh相关依赖），一路回车后文件默认会被保存到~/.ssh目录下。 上传客户端公钥将.ssh目录下的id_rsa.pub文件进行重命名，尽量使用开发人员的姓名全拼来命名，这样方便管理。 将新客户端的公钥上传到gitolite-admin/keydir的方式有很多种，可以通过fileZiller工具上传，也可以通过scp命令上传。 提交管理仓库公钥上传到管理客户端的gitolite-admin/keydir仓库目录后，需要把变动进行Push到Git服务端才能生效，在管理端执行命令进入gitolite-admin仓库目录下后，执行如下命令： 123456// addyuqiyu@code-server:~/gitolite-admin$ git add .// commityuqiyu@code-server:~/gitolite-admin$ git commit -m 'add developer users'// pushyuqiyu@code-server:~/gitolite-admin$ git push origin master 上传完成后，这时gitolite-admin/keydir目录新添加的客户端就已经生效，可以进行操作配置的对应仓库。 总结本章完成了gitolite的客户端添加，让git管理团队的代码更简单，简简单单的通过公钥、秘钥方式进行操作仓库。","link":"/git-gitolite-client.html"},{"title":"在Ubuntu下为Gitolite添加管理端","text":"在之前章节已经完成了服务端的配置，可以访问/git-gitolite-server.html查看配置步骤，因为gitolite的管理是通过一个名为gitolite-admin的仓库进行的，我们本章来主要讲解下这个仓库。 本章目标了解gitolite-admin仓库组成。 注意事项 注意：本章（除设置管理用户）操作用户并不是git（git用户是我们为服务端专属创建的用户），如果你是连续阅读/git-gitolite-server.html进行配置，请执行exit退出git用户。 生成SSH KEYGitolite的管理端可以跟Server是一个系统也可以是分开的系统，本章我们使用相同的系统来进行配置，后期我们创建的客户端用户也可以授权管理权限。 我们通过ssh-keygen命令来生成管理端的公私对秘钥，采用RSA加密方式进行生成，执行如下命令： 1yuqiyu@code-server:~$ ssh-keygen -t rsa 这一步我们不用输入任何内容，敲回车跳过步骤直到生成结束，生成文件默认会到当前用户根目录下的.ssh目录内，查看命令如下： 123yuqiyu@code-server:~$ cd ~/.ssh/yuqiyu@code-server:~/.ssh$ lsid_rsa id_rsa.pub 我们通过执行ssh-keygen命令已经生成了公钥、秘钥文件，接下来我们需要将公钥文件上传到服务端来完成管理端的配置。 上传公钥到服务端在上传公钥之前，为了后期方便区分，我们来给id_rsa.pub文件修改下名称，命令如下所示： 1yuqiyu@code-server:~/.ssh$ mv id_rsa.pub yuqiyu.pub 如果你的客户端与服务端在同一台服务器上，你可以直接把文件从.ssh复制到服务端，那如果不在同一台服务器上，只能通过scp命令进行远程复制，我们这里直接使用远程复制，同样适用于同一台服务器的场景，命令如下所示： 1yuqiyu@code-server:~$ scp ~/.ssh/yuqiyu.pub yuqiyu@192.168.1.75:/tmp 上面的scp命令分解解释： ~/.ssh/yuqiyu.pub：需要复制的文件 yuqiyu：ssh复制时登录服务端的用户名 192.168.1.75：服务端IP地址 /tmp：文件复制目标目录 命令执行完成后，文件会自动复制到服务端的/tmp目录。 设置管理用户公钥文件上传到服务端后我们需要把持有该公钥文件的用户设置为管理用户，首先我们需要登录git用户，如下所示： 1yuqiyu@code-server:~$ sudo su git 然后执行设置管理用户的命令如下所示： 1git@code-server:~$ ${HOME}/bin/gitolite setup -pk /tmp/yuqiyu.pub 执行完成后在终端会输出初始化管理仓库的消息，如下所示： 123456Initialized empty Git repository in /home/git/repositories/gitolite-admin.Initialized empty Git repository in /home/git/repositories/testing.git/ WARNING: /home/git/.ssh missing; creating a new one (this is normal on a brand new install) WARNING: /home/git/.ssh/authorized_keys missing; creating a new one (this is normal on a brand new install) 这样我们的管理用户已经设置完成了，也就是把我们的yuqiyu用户设置成为了服务端的管理用户，只有yuqiyu用户才可以操作gitolite-admin仓库内容。 克隆管理仓库我们再次将用户切换到yuqiyu，由于我们目前在git用户下，需要执行exit命令退出git用户，到yuqiyu的根目录下执行clone管理仓库gitolite-admin，如下所示： 1234567891011yuqiyu@code-server:/home$ cd ~yuqiyu@code-server:~$ git clone git@192.168.1.75:gitolite-admin.gitCloning into 'gitolite-admin'... remote: Counting objects: 6, done. remote: Compressing objects: 100% (4/4), done. Receiving objects: 100% (6/6), 719 bytes | 0 bytes/s, done. remote: Total 6 (delta 0), reused 0 (delta 0) Checking connectivity... done.yuqiyu@code-server:~$ cd gitolite-admin/yuqiyu@code-server:~/gitolite-admin$ lsconf keydir 192.168.1.75：服务端的IP地址 gitolite-admin.git：管理仓库的名称，位置在/home/git/repositories/ conf：gitolite-admin配置文件存放目录 keydir：gitolite-admin公钥存放目录，我们之前配置的yuqiyu.pub也就是我们管理用户yuqiyu的公钥也会自动复制到该目录下。 Gitolite Admin简介gitolite-admin用于gitolite为了管理用户秘钥、仓库信息、用户授权等操作的仓库，通过简单的git push origin master命令就可以完成信息的修改，下面我们来简单看下配置文件的内容。 配置文件clone后，在conf目录下有一个名为gitolite.conf的配置文件，在该文件配置仓库的信息以及授权信息，如下所示： 1234repo gitolite-admin RW+ = yuqiyurepo testing RW+ = @all repo：声明一个仓库，上面示例中仓库名为gitolite-admin、testing RW+：有读写的权限且可以强制推送 @all：表示所有人、任何人 在仓库tesing的权限配置为所有人都有读写的权限，而gitolite-admin则是仅仅yuqiyu这个客户端有读写权限。 gitolite内权限的基本定义有如下几种： C：创建权限 R：只读权限 RW+：读写权限，可以强制推送 RWC或RW+C：读写 + 创建 RWD或RW+D：读写 + 删除 RWCD或RW+CD：读写 + 创建删除 公钥目录在gitolite-admin内有一个名为keydir的目录，该目录存放了所有客户端的公钥，当然管理端其实也是一个客户端，管理端的公钥也存放在该目录，如果你想添加用户可以把公钥存放到该目录然后配置该用户对应的权限，创建客户端详见/git-gitolite-client.html 总结通过本章我们完成了对gitolite添加管理客户端，可以通过管理客户端来维护仓库信息、仓库授权等。","link":"/git-gitolite-manage.html"},{"title":"在Ubuntu下部署Gitolite服务端","text":"代码版本控制服务最常用的有两种，分别是：SVN、Git，如果你在为你团队的Git代码服务部署搭建而犯愁可以通过本章的内容进行完成搭建部署，快速的进行添加开发者以及仓库信息维护、权限控制等。 本章目标在Linux / Ubuntu18.04系统搭建Git服务端。 安装Git在搭建Git服务端的前提当然就是需要安装Git，当然本章虽然是基于Ubuntu18.04进行搭建的环境，如果你是Ubuntu其他版本也是可以的，不过安装之前建议更新下apt-get仓库源信息。 更新系统软件仓库源1sudo apt-get update 执行安装Git如果你系统之前没有安装open-ssh相关依赖环境需要一并进行安装，命令如下所示： 1sudo apt-get install git openssh-server openssh-client 在上述安装过程中使用默认的配置即可，下面我们需要添加一个管理Git Server的系统用户，需要通过该用户进行配置一些服务端信息。 添加Git管理用户执行如下命令添加git系统用户： 1sudo adduser --system --shell /bin/bash --gecos 'Git Server User' --group --disabled-password --home /home/git git 创建一个名为git的系统用户，并且创建将git用户的根目录指定到/home/git，设置禁用密码方式登录，自动创建与用户同名的git用户组，将该用户加入到该用户组。 系统用户创建完成后我们需要切换到该用户进行安装Gitolite以及对Gitolite进行初始化，命令如下所示： 1sudo su git 安装Gitolite用户我们已经创建完成，接下来我们就需要进行安装gitolite了，如果你对gitolite不了解，可以去https://github.com/sitaramc/gitolite查看官方文档。目前我们已经登录了git用户，我们进入git用户的home目录，执行下载gitolite安装源码文件，如下所示： 1234// 进入git用户根目录cd $HOME// git clone gitolite源码git clone https://github.com/sitaramc/gitolite clone完成后，我们创建一个存放gitolite执行文件的目录，该目录用于后期的初始化以及设置，执行如下命令创建目录： 1mkdir -p ${HOME}/bin 接下来我们需要将gitolite的执行命令都安装到${HOME}/bin目录下，如下所示： 1${HOME}/gitolite/install -to ${HOME}/bin 执行完成后我们可以查看%{HOME}/bin目录下的内容，执行文件gitolite已经给我初始化好了： 12git@code-server:~/bin$ lscommands gitolite gitolite-shell lib syntactic-sugar triggers VERSION VREF 到目前这一步我们差不多已经完成了Gitolite Server的配置，不过我们需要设置一个管理员权限的客户端，详见/git-gitolite-manage.html。 总结本章简单完成了Gitolite的安装，在接下来的章节会对仓库创建、权限控制等进行更新。","link":"/git-gitolite-server.html"},{"title":"GitHub Actions使用入门","text":"简介GitHub Actions 是由GitHub在2018年推出的一款持续集成的服务方案，对于GitHub上托管的开源项目来说比较友好，集成使用简单，个人感觉比 Travis-CI 玩法要更多，而且还是可以自己去编写Actions在构建的过程中使用。 推荐阅读 SpringBoot2.x 教程汇总 基本概念GitHub Actions内有一些概念性的定义，如下所示： workflow：顾名思义这是工作流程，在GitHub Actions中每执行一次就是一个工作流程。 job：工作流程中的一个任务，一个工作流程可以配置多个任务 step：工作任务中的步骤，根据配置的先后顺序执行，一个任务内可以配置多个步骤 action：每个步骤所使用的构建动作，可以使用GitHub官方提供的动作实现，也可以自动编写。 使用GitHub Actions 当我们打开项目的主页时可以看到Actions功能标签页，这就是该仓库的GitHub Actions，如果你的仓库没有添加过workflow文件，看到的效果如下所示： 配置Workflow YML每一个工作流都是由一个YML文件进行配置的，在该文件内我们可以配置仓库的GitHub Actions所相关的全部内容，GitHub针对文件所处的目录进行了约定，必须在仓库根下的.github/workflows目录内。 方式一：直接在GitHub页面上添加在上面的截图中，我们点击set up a workflow yourself -&gt;回跳转添加workflow文件的页面，在该页面中我们可以修改文件名，也可以修改workflow文件的配置内容，如下所示： 方式二：项目源码中添加后推送我们也可以在项目源码中添加后进行推送，首先在项目的根目录下创建.github/workflows目录，然后在新创建的目录下添加一个名为deploy.yml的工作流配置文件，将修改提交后push到GitHub仓库即可。 GitHub提供的ActionsGitHub官方所提供的Actions都是开源的，而且都位于 https://github.com/actions 开源组织下，比较常用到的Actions： checkout：用于checkout一个仓库源码到构建环境中 setup-java：用于安装Maven、JDK等构建项目的依赖到构建环境中 setup-node：用于安装nodeJs到构建环境中 …","link":"/github-action-getting-started.html"},{"title":"使用GitHub Actions编译项目并将Jar发布到Maven Central仓库","text":"在上一篇 GitHub Actions使用入门 文章中，我们了解到了该怎么去启用GitHub Actions功能，本篇文章来介绍下使用GitHub Actions怎么将我们的开源项目自动化构建后发布到Maven Central仓库中。 推荐阅读 SpringBoot2.x 教程汇总 新建workflow文件本篇文章以我的开源框架 ApiBoot 为例，大家有兴趣的也可以去了解下这个开源框架，详情请访问：ApiBoot是什么？ 在上一篇文章中我们提到过，GitHub Actions所需要的工作流文件要在.github/workflows文件夹内创建，那么接下来我们创建一个名为deploy.yml的工作流配置文件，配置name为该工作流的名称，如下所示： 123# This is a basic workflow to help you get started with Actionsname: Publish package to the Maven Central Repository 配置触发的分支我们还需要配置当前工作流在什么情况进行触发自动构建的事件，在deploy.yml配置文件内添加触发事件，如下所示： 1234567891011# Controls when the action will run. Triggers the workflow on push or pull request# events but only for the master branchon: push: branches: - master - 2.3.x pull_request: branches: - master - 2.3.x 在上面我们配置了两种触发工作流程的事件，分别是：push、pull_request，也就是仓库收到推送更新以及pull_request时就会触发该工作流程，实现自动化构建。 GitHub Actions其实为我们提供了多种触发工作流程的事件，访问 触发工作流程的事件 了解详情。 配置工作任务触发事件配置完成后我们就需要来配置当前工作流程所需要的系统环境以及每一个步骤所需要做的事情了。 构建系统GitHub Actions支持针对工作流程中的每一个任务（Job）进行配置独立的构建系统版本，我们选择最新版本的Ubuntu来作为本次任务的运行系统环境，配置内容如下所示： 123456# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: # This workflow contains a single job called &quot;build&quot; build: # The type of runner that the job will run on runs-on: ubuntu-latest 我们今天文章的主题是Jar发布到Maven Central仓库，根据分析我们大约需要三个步骤来完成这一工作。 Step1：检出代码首先我们需要将项目的源码检出到构建环境中，这时我们就可以借助GitHub Actions官方提供的actions/checkout来完成这一步骤，Action源码：https://github.com/actions/checkout Step2：安装环境ApiBoot 是一个Java项目（JDK1.8+），而且采用Maven进行构建项目，所以我们需要在构建的环境中安装相关的环境支持，GitHub Actions官方同样提供了相关的Action，名为：actions/setup-java，Action源码：https://github.com/actions/setup-java Step3：执行发布最后一步我们就需要通过mvn deploy命令来完成发布Jar，由于项目发布到Release仓库时需要GPG秘钥的支持，而我们期望的只是自动发布快照版本，所以可以通过-Dgpg.skip来排除GPG插件的介入。 全部步骤的配置内容如下所示： 123456789101112131415161718# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checkout source code - uses: actions/checkout@v2 # Install Java 1.8 - uses: actions/setup-java@v1 with: server-id: hengyu java-version: 1.8 server-username: MAVEN_USERNAME server-password: MAVEN_PASSWORD # Publish to Apache Maven Central - run: mvn -B deploy -Dgpg.skip env: MAVEN_USERNAME: ${{ secrets.MAVEN_CENTER_USER_NAME }} MAVEN_PASSWORD: ${{ secrets.MAVEN_CENTER_PASSWORD }} 注意事项：使用Action时，需要指定版本号，通过@v?的这种方式，其实这个版本号是仓库源码的标签。 配置GitHub Secretsactions/setup-java@v1在执行时会创建Maven所需要的settings.xml文件，而在该文件内我们可以通过配置server-username、server-password来指定发布的目标仓库的用户名、密码。 由于该工作流配置文件是公开的，我们肯定不会明文进行配置，GitHub针对这一点，提供了Secrets配置的方式，我们需要将存在安全性的变量进行配置，使用时注意变量名称的对应即可。 Secrets在使用时需要根据约定的格式配置： 1${{ secrets.MAVEN_CENTER_USER_NAME }} secrets为前缀，而后面的变量名必须与GitHub内的配置一致，如果你的相关Secrets配置需要用于多个项目，可以在组织下进行配置。 推送更新到目前为止，我们的项目已经完成了GitHub Actions的配置，接下来需要将该工作流程配置文件推送()push)到目标仓库，推送后我们查看项目的Actions标签页的内容，如下所示： 每当我们推送代码时都会自动触发构建工作流程的事件，一个工作流程的任务都会有完整的日志记录，如下所示： 当一个任务的全部步骤都执行成功后，当前任务也算是真正的执行成功，如果一个工作流程文件内配置了多个任务，则是需要多个任务都构建成功后才算成功。 槽点目前针对GPG的支持确实有点问题，GitHub官方所提供的Action也是会有一些问题，导致无法完成通过GPG的方式完成构建项目，如果这一点可以解决，就可以实现在GitHub仓库创建发布版本时触发工作事件，实现自动上传Jar到Release仓库，省去了在本地发布的工作。 示例本文的workflow配置文件内容可以访问：https://github.com/minbox-projects/api-boot/blob/2.3.x/.github/workflows/deploy.yml 。","link":"/github-action-publish-jar-to-maven-central.html"},{"title":"官宣，GitHub正式发布了移动端v1.0版本","text":"GitHub在2019年开发者大会上已经表明正在研发手机客户端，而就在昨天（2020-3-18）提供了正式版本的下载链接，苹果端也已经上架到了AppStore。 安装在 GitHub移动端 官网上仅提供了两种安装方式，如下图所示： 如果你手机上可以访问Google那么你就可以通过Google Play直接安装，当然手机上访问Google还是需要一点灰色手段的，不过不用怕， 我已经将Apk下载了，放到了阿里云的对象存储内，可以直接访问下载。 IOS安装 https://apps.apple.com/cn/app/github/id1477376905 复制上面的地址到Safari浏览器中打开。 Android 安装 https://hengboy-image.oss-cn-beijing.aliyuncs.com/GitHub.v1.0.0.apk 复制上面的地址在浏览器直接访问即可。 当我们安装完成就可以看到在你的手机上多了一个 “黑猫” 应用。 开箱打开GitHub App 然后登录我们的账号。 首页 首页中间的内容分为了三个部分，分别是：My Work（我的工作台）、Favorites（收藏夹）、Recent（最近动态）。 Issues 点进去可以查看由我创建的、分配给我的、提到我的Issues列表，支持搜索功能。 Pull Requests 点进去可以查看由我创建、分配给我、提到我的、已合并的Pull Requests列表，支持搜索功能。 Repositories 点进去可以查看账号下的全部仓库（加入组织创建的、由我创建的、Fork的） Organizations 点进去可以看到我所加入的组织，可以查看组织的详情、组织内的仓库列表。 消息通知 搜索 输入关键字可以搜索GitHub内匹配关键字的仓库列表。 个人首页 点击左上角的头像可以进去我的主页，主页的顶部是个人的详细信息，中间为自定义固定的展示仓库（最多6个），底部则是创建的仓库、点赞的仓库、加入的组织。 设置 自定义皮肤 皮肤默认根据手机系统的设定而来，我手机设置为深色系，而GitHub App也是黑色，可以自行修改为亮色。 自定义Icon图标![](/images/post/github-app-release/IMG_1675 2.PNG) 手机App的图标也支持自定义，内部提供了多种样式供你选择。 浏览代码 浏览代码比较麻烦，需要一层一层进入Package，不过返回的时候比较简单，点击文件名称后面的箭头，可以选择返回任意一层，当然也可以直接返回Root目录，查看代码的质感还是很不错的。 项目主页 查看项目主页详情的功能基本跟网页版的差不多，点击Browse code就可以查看该项目的全部代码，点击右上角的“+”号可以直接创建Issues。 优缺点 使用起来不太稳定，需要开代理 由于App安装文件较小，使用起来流畅度很不错 基本的功能很完整，该有的都有了 只能分享一个链接地址","link":"/github-app-release.html"},{"title":"ApiBoot Logging忽略路径不进行采集日志","text":"ApiBoot Logging支持排除指定路径不参与日志的采集，当我们的服务集成actuator时，会不断的重复调用内置的路径导致大量采集到一些无关业务的日志信息，当然这只是一个例子，集成其他的第三方组件时也可能出现定时重复调用接口的场景。 创建示例项目本章所使用的示例项目请访问【/modify-apiboot-logging-collection-prefix.html】文章底部访问源码下载后导入idea工具。 配置排除路径ApiBoot Logging提供了配置参数api.boot.logging.ignore-paths，该配置参数的数据类型为java.lang.String[]，可以使用,逗号隔开配置多个忽略采集日志的路径。 修改application.yml配置文件内容如下所示： 123456789101112api: boot: # ApiBoot Logging 相关配置 logging: # 修改采集日志的前缀 logging-path-prefix: /user/**,/order/** # 控制台打印日志 show-console-log: true # 美化控制台打印的日志 format-console-log-json: true # 排除/user/info路径不进行采集日志 ignore-paths: /user/info 在上面配置中排除了/user/info路径采集日志。 运行测试导入idea的源码并没有添加/user/info路径请求方法，下面我们修改UserController类如下所示： 12345678910/** * 用户信息 * /user/info * * @return */@GetMapping(value = &quot;/info&quot;)public String info() { return &quot;this is user info&quot;;} 使用Application方式启动本章源码，通过curl方式访问/user/info路径，如下所示： 12➜ ~ curl http://localhost:8080/user/infothis is user info 访问成功后，查看控制台并未发现有请求日志输出，证明了/user/info路径被排除了。 敲黑板，划重点api.boot.logging.ignore-paths配置参数与api.boot.logging.logging-path-prefix可以组合使用，可以进行重叠，排除的路径是在org.minbox.framework.logging.client.interceptor.web.LoggingWebInterceptor#checkIgnore方法内进行判断，支持Ant风格路径过滤。 本章源码本篇文章示例源码可以通过以下途径获取，目录为SpringBoot2.x/modify-apiboot-logging-collection-prefix： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/ignore-apiboot-logging-collection-path.html"},{"title":"将OpenStreetMap导出的OSM数据导入MySQL数据库","text":"OpenStreetMap是一个所有人都可以编辑并自由使用的世界地图。 其中的大部分内容由志愿者从无到有地构建起来，并以开放授权发布， OpenStreetMap版权协议允许所有人自由且免费使用我们的地图图像与地图数据，而且本项目鼓励把数据用于有趣崭新的用途。 OpenStreetMap： https://www.openstreetmap.org 导出osm数据我们访问上面OpenStreetMap主页，我们可以看到跟其他提供地图服务的网站一样，也提供了位置导航的功能，也会直接定位到当前浏览的位置，那我们怎么才可以导出地图数据呢？ 我们访问页面的左上角有个导出的按钮，我们点击后可以看到如下图的界面： 我们点击红框内的导出按钮可以导出上面默认区域（两个经纬度组成的区域）内的全部地图数据（街道、建筑等），导出数据文件的后缀格式为.osm，默认导出文件的名称为map.osm。 如果我们需要自定义导出的区域可以点击 “手动选择不同的区域”，通过拖拽的方式来定位区域的位置以及大小，如下图所示： 点击 导出 按钮就可以获得我们选中区域内的地图数据。 注意事项：这种区域导出方式有个弊端，不能导出数据量超过50000个经纬度点的数据。 安装osmosis我们已经导出了地图数据（map.osm），我们可以通过osmosis来实现数据导入数据库，osx系统可以通过brew进行安装，如下所示： 1yuqiyu@hengyu ~&gt; brew install osmosis 初始化数据库表通过osmosis导入到数据库时，需要提前创建数据库以及数据表，点击 下载MySQL建表语句。 导入数据库1yuqiyu@hengyu ~&gt; osmosis --read-xml file=&quot;/Users/yuqiyu/Downloads/map.osm&quot; --write-apidb-0.6 host=&quot;127.0.0.1&quot; dbType=&quot;mysql&quot; database=&quot;api06_test&quot; user=&quot;root&quot; password=&quot;123456&quot; validateSchemaVersion=no 敲黑板，划重点基于OpenStreetMap提供的开源道路数据我们可以做的事情有很多，拿到道路上的经纬度（longitude、latitude）地理位置后做一些独特的业务处理，比如：我可以清楚的知道某一条道路上有哪些业务车辆经过、建立自有业务的地图数据、规划工作路线等。","link":"/import-osm-data-into-mysql.html"},{"title":"面试攻略","text":"又到了一年一度的跳槽旺季，面试官要问的问题你真的准备好了吗？ 恒宇少年最近在公众号陆续整理面试题、面试攻略，从面试官的心理来分析回答问题。 公众号的二维码在右侧，有需要实时获取微信公众号推送的同学可以扫码关注下。 Java基础 如何决定使用 HashMap 还是 TreeMap？ 你知道为什么HashMap是线程不安全的吗？ 消息队列 消息队列中，如何保证消息的顺序性？ 高并发 分库分表之后，ID主键如何处理？ Redis中是如何实现分布式锁的？ 谈谈Redis的过期策略 持续更新，敬请期待…","link":"/interview-strategy.html"},{"title":"微服务中使用 OpenJ9 JVM 内存占用降60%(相对HotSpot)","text":"随着微服务的普及，许多企业踏上微服务之旅。 微服务化后，应用数量可能高一个数量级。一般企业，以前三五个应用能支撑业务，微服务化之后应用数量可能多达几十个。每个微服务往往独立部署，内存的消耗自然也高居不下，以前两台8核16G机器指不定就能跑起来，现两台16核64G还不一定够用，同时由于多套环境的存在加上容器编排工具(如K8s)所需的资源，硬件资源的投入自然是成倍增加。 在 Web 应用开发中，为了降低内存消耗，你是否尝试过： 去除不必要的组件，减少代码体积 更换 Web 容器，如将 Tomcat 更换为Undertow 优化Docker基础镜像，减少镜像体积 这些效果往往不是很理想。本篇介绍 OpenJ9 JVM，通过将 HotSpot 更换为 OpenJ9，内存占用能降低至少 60%，而启动时间也能快 40% 以上，效果立竿见影。 OpenJ9 简介OpenJ9 的前身是IBM的 J9 Java 虚拟机，主要服务于IBM企业级软件产品，是一款高性能的JVM。 2017年9月，IBM 将 J9 JVM 捐献给 Eclipse 基金会，并更名 Eclipse OpenJ9，开启开源之旅。 OpenJ9 擅长于内存管理，同时针对容器化做了很多工作，按官方说法是： more container-aware 。 下面摘自 OpenJ9 的 Release History，选择了部分内容，可快速一览： 2017.11 支持使用 OpenJDK8 构建 OpenJ9 2018.3 发布 0.8.0：OpenJ9 开始支持各平台(Mac、Linux、Windows等) 的 OpenJDK 8，宣布在JDK8中，比HotSpot 42% faster startup and a footprint at least 60% smaller 2018.8 发布 0.9.0：支持 OpenJDK 10；对Docker容器支持更友好；在运行一些Eclipse性能测试时，比HotSpot JVM快 43%，少用42%的内存. 2018.10 发布 0.10.0：支持 OpenJDK 11，开始适配 HotSpot JVM的一些参数配置 2018.10 发布 0.11.0：改善AOT性能、针对运行在容器中的应用内存优化、 “pause-less” GC mode for response-time sensitive, large heap applications 2019.2 发布 0.12.1 ：提示RSA算法加密性能；性能进一步提升 2019.3 发布 0.13.0：支持OpenJDK 12; 支持jps命令；支持将Java dump 文件写入STDOUT/STDERR 官方性能报告下面是 OpenJ9官方的基准测试结果(完整报告)，包含启动时间、响应时间、吞吐量等指标。 66% smaller footprint after startup 由于减少内存占用的重要性，OpenJ9 对云负载(cloud wordloads)做了深度优化，在应用启动后，占用内存比HotSpot 约少 66%。 66% smaller footprint after startup 由于减少内存占用的重要性，OpenJ9 对云负载(cloud wordloads)做了深度优化，在应用启动后，占用内存比HotSpot 约少 66%。 63% smaller footprint during ramp up 应用负载增加时，内存都会骤增。但状态稳定后，使用 OpenJ9 的OpenJDK 8 比使用 HotSpot 的 OpenJDK 8 减少了约 63% 的物理内存。 42% faster startup time Shared classes 和 Ahead-of-Time(AOT) 技术的应用显著减少了应用启动时间。通过使用 -Xquickstart 参数(启用AOT)，**启动时间可以减少高达42%**。 Comparable throughput 在做吞吐量对比时，二者峰值吞吐量差不多，但使用OpenJ9 的 OpenJDK 8 大约快1分钟达到峰值。 Faster ramp-up time in the cloud 在云环境下，虚拟化技术被广泛使用，一台大的机器经常被切割成若干小的虚拟机，这些虚拟机往往做了资源限制。OpenJ9 在单核CPU上用了8.5分钟达到峰值吞吐量，而 HotSpot用了30分钟。对于在资源受限的环境下(如云环境)跑 short-lived VMs，能够更快的完成更多工作就显得更为重要。 资源受限的一大副作用就是 **Java应用花费更长的启动时间(受JIT影响)**。 笔者注：内存限制时，应用甚至会无法启动，导致不断重启。 性能测试创建一个 Spring Boot Web 应用并打成jar包，分别使用 HotSpot、OpenJ9 虚拟机的 Open JDK8 结合Docker来做测试。 基于OpenJ9的Dockerfile 123FROM adoptopenjdk/openjdk8-openj9:alpine-slimCOPY target/app.jar /app.jarENTRYPOINT java $JAVA_OPTS -Xshareclasses -Xquickstart -jar /app.jar 基于HotSpot的Dockerfile 123FROM openjdk:8u181-jre-slim-stretchCOPY target/app.jar /app.jarENTRYPOINT java $JAVA_OPTS -jar /app.jar 启动容器后，docker stats openj9 hotspot 查看容器资源使用情况如下： OpenJ9 是 50.89M；HotSpot 是235.7M，差异非常大。 下面是我们测试环境中的一个普通应用(使用Docker运行)的测试结果。 基于 Open JDK8 (HotSpot) 时内存消耗稳定在 1G左右。 基于 OpenJDK8(OpenJ9)时内存消耗稳定在 300M左右。 该怎么切换到 OpenJ9 ？如果使用Docker，直接更换基础镜像即可，容器场景下更能发挥 OpenJ9 的作用。 如果JDK直接安装在服务器上，可以直接在 AdoptOpenJDK 上下载相应的介质。 对于 JVM Options，可以参考做一些调整。 对开发人员的影响有哪些？大家一般接触的都是HotSpot VM，且对于其理论、JVM参数、命令行工具甚至性能调优等相对比较熟悉，这块资料也比较丰富。 OpenJ9 以前更多的是支持IBM企业级的商业产品，大家了解相对较少，连日用命令行工具暂时都只提供了jps、jstack，不过可以使用像阿里 arthas 这类Java应用诊断工具，效果也是一样的。 对于小企业来说，JVM一般不是瓶颈，而更换JVM所带来的IT成本投入减少确是实实在在的，尤其是对于初创团队，自然是能省则省。","link":"/know-openj9-jvm.html"},{"title":"秒懂 QPS、TPS、PV、UV、GMV、IP、RPS！","text":"QPS、TPS、PV、UV、GMV、IP、RPS等各种名词，外行看起来很牛X，实际上对程序员来说都是必懂知识点。下面我来一一解释一下。 QPS Queries Per Second，每秒查询数。每秒能够响应的查询次数。QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。每秒的响应请求数，也即是最大吞吐能力。 TPS Transactions Per Second 的缩写，每秒处理的事务数目。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。 TPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端。例如，访问一个 Index 页面会请求服务器 3 次，包括一次 html，一次 css，一次 js，那么访问这一个页面就会产生一个“T”，产生三个“Q”。 PV（page view）即页面浏览量，通常是衡量一个网络新闻频道或网站甚至一条网络新闻的主要指标。PV 即 page view，页面浏览量。用户每一次对网站中的每个页面访问均被记录 1 次。用户对同一页面的多次刷新，访问量累计。 根据这个特性，刷网站的 PV 就很好刷了。 与 PV 相关的还有 RV，即重复访问者数量（repeat visitors）。 UV 访问数（Unique Visitor）指独立访客访问数，统计1天内访问某站点的用户数(以 cookie 为依据)，一台电脑终端为一个访客。 IP（Internet Protocol）独立 IP 数，是指 1 天内多少个独立的 IP 浏览了页面，即统计不同的 IP 浏览用户数量。同一 IP 不管访问了几个页面，独立 IP 数均为 1；不同的 IP 浏览页面，计数会加 1。IP 是基于用户广域网 IP 地址来区分不同的访问者的，所以，多个用户（多个局域网 IP）在同一个路由器（同一个广域网 IP）内上网，可能被记录为一个独立 IP 访问者。如果用户不断更换 IP，则有可能被多次统计。 GMV，是 Gross Merchandise Volume 的简称。只要是订单，不管消费者是否付款、卖家是否发货、是否退货，都可放进 GMV 。 RPS 代表吞吐率，即 Requests Per Second 的缩写。吞吐率是服务器并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大的请求数，称之为最大吞吐率。 有人把 RPS 说等效于 QPS。其实可以看作同一个统计方式，只是叫法不同而已。RPS/QPS，可以使用 apche ab 工具进行测量。","link":"/know-qps-tps-uv-pv.html"},{"title":"作为高级Java，你应该了解的Linux知识","text":"作为一个javaer，我以前写过很多关于Linux的文章。但经过多年的观察，发现其实对于大部分人，有些东西压根就用不着。用的最多的，就是到线上排查个问题而已，这让人很是苦恼。那么，我们就将范围再缩小一下。 Linux命令好像还真不少，根本原因就是软件多，也有像ag这样的命令想替代grep,但大多数命令古老而坚挺。不是因为这些软件设计的有多好，原因是一些软件最开始入驻了系统，时间久了，就变成了一种约定，这种习惯改变代价太大，就像把所有键盘的L和F换一下一样。 这片文章假定你已经了解大多数Linux命令，并了解操作系统的基本元素。如果你现在了解的命令还不足10个，下面的内容就不用看了。除了最基本的东西，本文列出一些对你的面试最常见的最能加分的地方，有些组合可能是你没见过的技巧。但本文仅仅是给出一个大致的轮廓和印象，为以后的专题性考察点作一个序。 本文中出现的所有命令，应该熟记并熟练使用。 几种比较典型的Linux系统首先对目前的Linux版本有个大体的印象，大体分Desktop版和Server版，已经是百花齐放。 Ubuntu 最常见的Linux个人发行版，一位有情怀的南非富豪，有了钱你也可以这么做 CentOS 最常用Linux服务器发新版，RHEL的开放版本，因版权而生的轮子 Arch 滚动升级，海量二进制包，社区活跃，个人最爱 Gentoo 安装软件需要从源码开始编译，稳定，但用起来会很痛 LFS 从零构建Linux，跟着做一遍，Linux每根毛都看的清清楚楚 Kali 专做渗透用的，代表了发行版的一个发展路径，就是领域 首先要了解的概念 KISS Keep it Simple and Stupid，据说是哲学 一切皆文件 通常是文件的东西叫文件，进程、磁盘等也被抽象成了文件，比较离谱的管道、设备、socket等，也是文件。这是Linux最重要的组织方式。 管道 | 分隔，前面命令的输出作为后面命令的输入，可以串联多个 重定向&lt; 将文件做为命令的输入&gt; 将命令的输出输出到文件&gt;&gt; 将命令的输出追加到文件 SHELL 首先确认你的shell，一般最常用的是bash，也有不少用csh，zsh等的，通过echo $SHELL可以看到当前用户的shell，对应的配置文件也要相应改变。比如.zshrc,.bashrc 四大元素进入linux，我们首先关注的是四个元素：内存，cpu，存储，网络。Linux提供了足够的命令，让你窥探它的每个角落。接下来的命令都是些最常用的，不管精通不精通，想不起来要打屁股。 CPU 使用top查看cpu的load，使用shift+p按照cpu排序。需要了解wa，us等都是什么意思 使用uptime查看系统启动时间和load，load是什么意思呢？什么算是系统过载？这是个高频问题，别怪我没告诉你 ps命令勃大茎深，除了查进程号外，你还需要知道R、S、D、T、Z、&lt;、N状态位的含义 top和ps很多功能是相通的，比如watch &quot;ps -mo %cpu,%mem,pid,ppid,command ax&quot; 相当于top的进程列表；top -n 1 -bc 和ps -ef的结果相似。 有生就有死，可以用kill杀死进程。对java来说，需要关注kill -9、kill -15、kill -3的含义，kill的信号太多了，可以用kill -l查看，搞懂大多数信号大有裨益。 如果暂时不想死，可以通过&amp;符号在后台执行，比如tail -f a.log &amp;。jobs命令可以查看当前后台的列表，想恢复的话，使用fg回到幕前。这都是终端作业，当你把term关了你的后台命令也会跟着消失，所以想让你的程序继续执行的话，需要nohup命令，此命令需要牢记 mpstat 显示了系统中 CPU 的各种统计信 了解cpu亲和性 内存 free -m 命令，了解free、used、cached、swap各项的含义 cat /proc/meminfo 查看更详细的内存信息细心的同学可能注意到，CPU和内存的信息，通过top等不同的命令显示的数值是一样的。 slabtop 用来显示内核缓存占用情况，比如遍历大量文件造成缓存目录项。曾在生产环境中遇到因执行find /造成dentry_cache耗尽服务器内存。 vmstat 命令是我最喜欢也最常用的命令之一，可以以最快的速度了解系统的运行状况。每个参数的意义都要搞懂。 swapon、swapoff 开启，关闭交换空间 sar 又一统计类轮子，一般用作采样工具 存储 使用df -h查看系统磁盘使用概况 lsblk 列出块设备信息 du 查看目录或者文件大小 网络 rsync 强大的同步工具，可以增量哦 netstat 查看Linux中网络系统状态信息，各种 ss 它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 curl、wget 模拟请求工具、下载工具。如wget -r http://site 将下载整个站点 ab Apache服务器的性能测试工具 ifstat 统计网络接口流量状态 nslookup 查询域名DNS信息的工具，在内网根据ip查询域名是爽爆了 nc 网络工具中的瑞士军刀，不会用真是太可惜了 arp 可以显示和修改IP到MAC转换表 traceroute 显示数据包到主机间的路径，俗称几跳，跳的越少越快 tcpdump 不多说了，去下载wireshark了 wall 向当前所有打开的终端上输出信息。使用who命令发现女神正在终端上，可以求爱 网络方面推荐安装体验一下kaliLinux，上面的工具会让你high到极点。 如何组织起来linux的命令很有意思，除了各种stat来监控状态，也有各种trace来进行深入的跟踪，也有各种top来统计资源消耗者，也有各种ls来查看系统硬件如lsblk、lsusb、lscpi。基本上跟着你的感觉走，就能找到相应的工具，因为约定是系统中最强大的导向。 Linux有个比较另类的目录/proc，承载了每个命令的蹂躏。像sysctl命令，就是修改的/proc/sys目录下的映射项。不信看看find /proc/sys -type f | wc -l和sysctl -a| wc -l的结果是不是很像？ /proc文件系统是一个伪文件系统，它只存在内存当中，而不占用外存空间。只不过以文件系统的方式为访问系统内核数据的操作提供接口。系统的所有状态都逃不过它的火眼金睛。例如: cat /proc/vmstat 看一下，是不是和vmstat命令的输出很像? cat /proc/meminfo 是不是最全的内存信息 cat /proc/slabinfo 这不就是slabtop的信息么 cat /proc/devices 已经加载对设备们 cat /proc/loadavg load avg原来就躺在这里啊 cat /proc/stat 所有的CPU活动信息 ls /proc/$pid/fd 静静地躺着lsof的结果 一般排除问题的方法一般排查问题也是围绕着内存cpu等几个元素去排查。下图是一张大体的排查故障或者性能问题的过程，看图，不多说。 应用场景举例下面举例从具体应用场景来说明各种命令的组合应用，此类场景数不胜数，需要个人积累。但强烈建议将sed和awk练的熟练一些。 怎么查看某个Java进程里面占用CPU最高的一个线程具体信息？ 获取进程中占用CPU最高的线程，计为n。 使用top top -H -p pid，肉眼观察之 使用ps ps -mo spid,lwp,stime,time,%cpu -p pid 将线程号转化成十六进制printf 0x%x n 使用jstack找到相应进程，打印线程后的100行信息 jstack -l pid| grep spid -A 100 统计每种网络状态的数量netstat -ant | awk '{print $6}' | sort | uniq -c | sort -n -k 1 -r首先使用netstat查看列表，使用’awk’截取第六列，使用uniq进行统计，并对统计结果排序。当然，也可以这样。netstat -ant | awk '{arr[$6]++}END{for(i in arr){print arr[i]&quot; &quot;i }}' | sort -n -k 1 -r这和“分析apache日志，给出当日访问ip的降序列表”是一样的问题。 怎么查看哪个进程在用swap首先要了解/proc/$pid/smaps里有我们所需要的各种信息，其中Swap字段即是我们所需要的。只要循环遍历一下即可。 1for i in `cd /proc;ls |grep &quot;^[0-9]&quot;|awk ' $0 &gt;100'` ;do awk '/Swap:/{a=a+$2}END{print '&quot;$i&quot;',a/1024&quot;M&quot;}' /proc/$i/smaps ;done |sort -k2nr 最后，附上http://www.brendangregg.com/ 的大图一张 End软件领域有两种人才，一种是工程型的，一种是研究型的。在Linux领域里，相对于搞内核研究的来说，搞命令行的就属于工程型。工程型也有他自己的苦衷，比如，背诵命令就挺痛苦的，一般来说不太推荐背诵，第一覆盖的面不广，第二记的快忘的也快，浪费脑细胞。牛逼的记法就是用，用时间来冲淡烟云，见微知著，并体验其中的喜悦。","link":"/linux-knowledge-you-should-know.html"},{"title":"Linux上，最常用的一批命令解析（10年精选）","text":"Linux这么多命令，通常会让初学者望而生畏。下面是我结合日常工作，以及在公司的内部培训中，针对对Linux不是很熟悉的同学，精选的一批必须要搞懂的命令集合。 任何一个命令其实都是可以深入的，比如tail -f和tail -F的区别。我们不去关心，只使用最常见的示例来说明。本文不会教你具体的用法，那是抢man命令的饭碗。这只是个引导篇，力求简洁。 学习方式：多敲多打，用条件反射替代大脑记忆–如果你将来或者现在要用它来吃饭的话。 其中，也有一些难啃的骨头，关注小姐姐味道微信公众号，我们一起用锋利的牙齿，来把它嚼碎。内容：✔ 目录操作✔ 文本处理✔ 压缩✔ 日常运维✔ 系统状态概览✔ 工作常用 目录操作工作中，最常打交道的就是对目录和文件的操作。linux提供了相应的命令去操作他，并将这些命令抽象、缩写。 基本操作可能是这些命令太常用了，多打一个字符都是罪过。所以它们都很短，不用阿拉伯数字，一个剪刀手就能数过来。看命令。mkdir 创建目录 make dir cp 拷贝文件 copy mv 移动文件 move rm 删除文件 remove例子： 123456789101112# 创建目录和父目录a,b,c,dmkdir -p a/b/c/d# 拷贝文件夹a到/tmp目录cp -rvf a/ /tmp/# 移动文件a到/tmp目录，并重命名为bmv -vf a /tmp/b# 删除tmp目录的所有文件rm -rvf /tmp/ 漫游linux上是黑漆漆的命令行，依然要面临人生三问：我是谁？我在哪？我要去何方？ls 命令能够看到当前目录的所有内容。ls -l能够看到更多信息，判断你是谁。pwd 命令能够看到当前终端所在的目录。告诉你你在哪。cd 假如你去错了地方，cd命令能够切换到对的目录。find find命令通过筛选一些条件，能够找到已经被遗忘的文件。至于要去何方，可能就是主宰者的意志了。 文本处理这是是非常非常加分的技能。get到之后，也能节省更多时间来研究面向对象。 查看文件cat最常用的就是cat命令了，注意，如果文件很大的话，cat命令的输出结果会疯狂在终端上输出，可以多次按ctrl+c终止。 123456# 查看文件大小du -h file# 查看文件内容cat file less既然cat有这个问题，针对比较大的文件，我们就可以使用less命令打开某个文件。 类似vim，less可以在输入/后进入查找模式，然后按n(N)向下(上)查找。有许多操作，都和vim类似，你可以类比看下。 tail大多数做服务端开发的同学，都了解这么命令。比如，查看nginx的滚动日志。 1tail -f access.log tail命令可以静态的查看某个文件的最后n行，与之对应的，head命令查看文件头n行。但head没有滚动功能，就像尾巴是往外长的，不会反着往里长。 12tail -n100 access.loghead -n100 access.log 统计sort和uniq经常配对使用。 sort可以使用-t指定分隔符，使用-k指定要排序的列。 下面这个命令输出nginx日志的ip和每个ip的pv，pv最高的前10 123# 2019-06-26T10:01:57+08:00|nginx001.server.ops.pro.dc|100.116.222.80|10.31.150.232:41021|0.014|0.011|0.000|200|200|273|-|/visit|sign=91CD1988CE8B313B8A0454A4BBE930DF|-|-|http|POST|112.4.238.213awk -F&quot;|&quot; '{print $3}' access.log | sort | uniq -c | sort -nk1 -r | head -n10 其他grepgrep用来对内容进行过滤，带上–color参数，可以在支持的终端可以打印彩色，参数n则输出具体的行数，用来快速定位。比如：查看nginx日志中的POST请求。 1grep -rn --color POST access.log 推荐每次都使用这样的参数。 如果我想要看某个异常前后相关的内容，就可以使用ABC参数。它们是几个单词的缩写，经常被使用。 A after 内容后n行 B before 内容前n行 C count? 内容前后n行就像是这样： 1grep -rn --color Exception -A10 -B2 error.log diffdiff命令用来比较两个文件是否的差异。当然，在ide中都提供了这个功能，diff只是命令行下的原始折衷。对了，diff和patch还是一些平台源码的打补丁方式，你要是不用，就pass吧。 压缩为了减小传输文件的大小，一般都开启压缩。linux下常见的压缩文件有tar、bzip2、zip、rar等，7z这种用的相对较少。.tar 使用tar命令压缩或解压.bz2 使用bzip2命令操作.gz 使用gzip命令操作.zip 使用unzip命令解压.rar 使用unrar命令解压最常用的就是.tar.gz文件格式了。其实是经过了tar打包后，再使用gzip压缩。创建压缩文件 1tar cvfz archive.tar.gz dir/ 解压 1tar xvfz. archive.tar.gz 快去弄清楚它们的关系吧。 日常运维开机是按一下启动按钮，关机总不至于是长按启动按钮吧。对了，是shutdown命令，不过一般也没权限-.-!。passwd命令可以用来修改密码，这个权限还是可以有的。mountmount命令可以挂在一些外接设备，比如u盘，比如iso，比如刚申请的ssd。可以放心的看小电影了。 1mount /dev/sdb1 /xiaodianying chownchown 用来改变文件的所属用户和所属组。chmod 用来改变文件的访问权限。 这两个命令，都和linux的文件权限777有关。示例： 12345678# 毁灭性的命令chmod 000 -R /# 修改a目录的用户和组为 xjjchown -R xjj:xjj a# 给a.sh文件增加执行权限（这个太常用了)chmod a+x a.sh yum假定你用的是centos，则包管理工具就是yum。如果你的系统没有wget命令，就可以使用如下命令进行安装。 1yum install wget -y systemctl当然，centos管理后台服务也有一些套路。service命令就是。systemctl兼容了service命令，我们看一下怎么重启mysql服务。 推荐用下面这个。 12service mysql restartsystemctl restart mysqld 对于普通的进程，就要使用kill命令进行更加详细的控制了。kill命令有很多信号，如果你在用kill -9，你一定想要了解kill -15以及kill -3的区别和用途。 susu用来切换用户。比如你现在是root，想要用xjj用户做一些勾当，就可以使用su切换。 12su xjjsu - xjj -可以让你干净纯洁的降临另一个账号，不出意外，推荐。 系统状态概览登陆一台linux机器，有些命令能够帮助你快速找到问题。这些命令涵盖内存、cpu、网络、io、磁盘等。unameuname命令可以输出当前的内核信息，让你了解到用的是什么机器。 1uname -a psps命令能够看到进程/线程状态。和top有些内容重叠，常用。 12# 找到java进程ps -ef | grep java top系统状态一览，主要查看。cpu load负载、cpu占用率。使用内存或者cpu最高的一些进程。下面这个命令可以查看某个进程中的线程状态。 1top -H -p pid freetop也能看内存，但不友好，free是专门用来查看内存的。包括物理内存和虚拟内存swap。 dfdf命令用来查看系统中磁盘的使用量，用来查看磁盘是否已经到达上限。参数h可以以友好的方式进行展示。 1df -h ifconfig查看ip地址，不啰嗦，替代品是ip addr命令。 ping至于网络通不通，可以使用ping来探测。（不包括那些禁ping的网站） netstat虽然ss命令可以替代netstat了，但现实中netstat仍然用的更广泛一些。比如，查看当前的所有tcp连接。 1netstat -ant 此命令，在找一些本地起了什么端口之类的问题上，作用很大。 工作日常还有一些在工作中经常会用到的命令，它们的出现频率是非常高的 ，都是些熟面孔。 export很多安装了jdk的同学找不到java命令，export就可以帮你办到它。export用来设定一些环境变量，env命令能看到当前系统中所有的环境变量。比如，下面设置的就是jdk的。 1export PATH=$PATH:/home/xjj/jdk/bin 有时候，你想要知道所执行命令的具体路径。那么就可以使用whereis命令，我是假定了你装了多个版本的jdk。 crontab这就是linux本地的job工具。不是分布式的，你要不是运维，就不要用了。比如，每10分钟提醒喝茶上厕所。 1*/10 * * * * /home/xjj/wc10min datedate命令用来输出当前的系统时间，可以使用-s参数指定输出格式。但设置时间涉及到设置硬件，所以有另外一个命令叫做hwclock。 xargsxargs读取输入源，然后逐行处理。这个命令非常有用。举个栗子，删除目录中的所有class文件。 1234find . | grep .class$ | xargs rm -rvf#把所有的rmvb文件拷贝到目录ls *.rmvb | xargs -n1 -i cp {} /mount/xiaodianying 网络linux是一个多作业的网络操作系统，所以网络命令有很多很多。工作中，最常和这些打交道。ssh这个，就不啰嗦了。你一定希望了解ssh隧道是什么。你要是想要详细的输出过程，记得加参数-v。scpscp用来进行文件传输。也可以用来传输目录。也有更高级的sftp命令。 12scp a.txt 192.168.0.12:/tmp/a.txtscp -r a_dir 192.168.0.12:/tmp/ wget你想要在服务器上安装jdk，不会先在本地下载下来，然后使用scp传到服务器上吧（有时候不得不这样）。wget命令可以让你直接使用命令行下载文件，并支持断点续传。 1wget -c http://oracle.fuck/jdk2019.bin mysqlmysql应用广泛，并不是每个人都有条件用上navicat的。你需要了解mysql的连接方式和基本的操作，在异常情况下才能游刃有余。 1mysql -u root -p -h 192.168.1.2 End不要觉得复杂，命令是有限的，但激情无限；都会也不要骄傲，一个vim就够折腾一辈子。捷径就是总结，深入只有探索。白马过隙，终会行云流水，手到擒来。物是人非，年华易老。唯有时光，不会辜负。","link":"/linux-most-commonly-used-commands.html"},{"title":"Mac&#x2F;Linux下配置远程Linux服务器免密登录","text":"你还在为你每次打开测试环境、生产环境需要登录而犯愁吗？登录是必须的，但密码是可或缺的！！！ 因为前两章讲到了Gitolite服务端的配置，配置客户端时是采用的SSH方式授权登录的Git Server，如果你看过我的文章应该对open-ssh有一定的了解，我们本章的内容同样也是需要open-ssh的支持。 本章目标访问Linux/Ubuntu免密码SSH方式登录。 安装openssh-server如果你的服务器并没有安装openssh-server需要执行下面的命令进行安装： 1ubuntu@yuqiyu:~$ sudo apt-get install openssh-server 安装openssh-clientMac系统自带openssh，所以不需要再次安装。如果你是Linux系统作为client，执行如下命令安装： 1client@other:~$ sudo apt-get install openssh-client Mac下生成SSH KEY打开Mac系统自带的终端，通过ssh-keygen命令来进行生成ssh key信息，命令如下所示： 1ssh-keygen -t rsa 不需要自定义配置信息，所有的询问通过回车跳过即可。生成的文件去了哪里？之前也讲过位置，在这里再简单的说下，默认的位置在当前用户根目录下的.ssh隐藏目录内： 1234// 执行查看命令ls ~/.ssh// 文件列表id_rsa id_rsa.pub 远程Linux服务器授权公钥先通过用户名密码的方式登录远程Linux服务器，把我们上一步生成的id_rsa.pub文件的内容复制到authorized_keys文件内，如下所示： 1ubuntu@yuqiyu:~$ echo &quot;公钥内容&quot; &gt;&gt; ~/.ssh/authorized_keys 公钥内容：在上面命令中公钥内容就是生成的id_rsa.pub文件内容 测试免密登录在本地终端输入如下命令测试是否可以直接连接到远程服务器： 1ssh ubuntu@192.168.1.75 ubuntu：访问远程服务器的用户名 192.168.1.75：你的远程服务器的IP地址，根据实际情况而定 如果配置没有问题是直接可以访问到远程服务器的，这样是不是很简单？ SSH Config 那如果你感觉通过ssh user@ip的方式比较麻烦（因为平时服务器较多的情况下会出现记错的情况而导致无法登录），我们还有更简单的方式。 通过修改本机的.ssh/config文件可以进行配置访问远程服务器的基本信息，下面是我的配置： 1234Host ownerHostName 192.168.1.75User ubuntuIdentitiesOnly yes 配置文件保存退出，我们再次在终端输入如下命令进行测试免密登录： 1ssh owner 发现同样可以免密进行登录，在这里的owner就是我们在~/.ssh/config配置文件的Host值，我们通过执行ssh owner，ssh就会去找配置该owner的Host信息，然后再次访问远程服务器。","link":"/linux-without-password.html"},{"title":"修改ApiBoot Logging日志采集的前缀","text":"ApiBoot Logging支持指定单个或者多个路径的前缀进行采集，也就是我们可以指定/user/**或者/order/**下的单个或者同时指定多个路径进行采集请求日志，其他不符合Ant表达式的路径就会被忽略掉。 创建示例项目使用idea创建SpringBoot项目。 添加ApiBoot Logging依赖创建项目后在pom.xml配置文件内添加依赖如下所示： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--ApiBoot Logging--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--ApiBoot版本依赖--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 默认拦截路径ApiBoot Logging默认的拦截路径是/**，可以访问org.minbox.framework.api.boot.autoconfigure.logging.ApiBootLoggingProperties属性配置类查看源码。 配置采集拦截器前缀ApiBoot Logging提供了在application.yml配置文件内修改的配置参数api.boot.logging.logging-path-prefix，该配置参数接收的类型为java.lang.String[]，所以我们可以使用,逗号隔开配置多个路径，如下所示： 12345678910111213141516spring: application: name: modify-apiboot-logging-collection-prefixserver: port: 8080api: boot: # ApiBoot Logging 相关配置 logging: # 修改采集日志的前缀 logging-path-prefix: /user/**,/order/** # 控制台打印日志 show-console-log: true # 美化控制台打印的日志 format-console-log-json: true 启用ApiBoot Logging Client配置已经完成，下面我们在入口类（XxxApplication）或者配置类（XxxConfiguration）上添加@EnableLoggingClient注解来启用ApiBoot Logging的功能，如下所示： 1234567891011121314/** * 入口类 * * @author 恒宇少年 */@SpringBootApplication@EnableLoggingClientpublic class ModifyApibootLoggingCollectionPrefixApplication { public static void main(String[] args) { SpringApplication.run(ModifyApibootLoggingCollectionPrefixApplication.class, args); }} 运行测试使用idea的Application或者java -jar xxx.jar的形式来运行本章源码，本章源码的端口号配置为8080，我们需要从下面几个点进行测试。 测试点：匹配/user/**路径添加测试控制器类UserController如下所示： 1234567891011121314@RestController@RequestMapping(value = &quot;/user&quot;)public class UserController { /** * 测试日志拦截路径接口 * * @param name * @return */ @GetMapping public String welcome(@RequestParam(&quot;name&quot;) String name) { return &quot;hello, &quot; + name; }} 通过如下命令访问测试接口： 12➜ ~ curl http://localhost:8080/user\\?name\\=hengboyhello, hengboy /user路径匹配/user/**表达式，所以我们在控制台可以看到请求日志的打印。 测试点：匹配/order/**路径添加测试控制器类OrderController如下所示： 123456789@RestController@RequestMapping(value = &quot;/order&quot;)public class OrderController { @PostMapping public String submit() { return &quot;订单：&quot; + UUID.randomUUID().toString() + &quot;，提交成功.&quot;; }} 通过如下命令访问测试接口： 12➜ ~ curl -X POST http://localhost:8080/order 订单：24a24d24-539e-4da9-9272-e68fd592313c，提交成功. /order路径匹配/order/**表达式，所以我们在控制台也可以看到请求日志的打印。 测试点：其他路径添加测试控制器类OtherController如下所示： 12345678@RestControllerpublic class OtherController { @GetMapping(value = &quot;/other&quot;) public String other() { return &quot;this is other path&quot;; }} 通过如下命令访问测试接口： 12➜ ~ curl http://localhost:8080/other this is other path 由于/other路径并不匹配/user/**或者/order/**表达式，所以我们在控制台并没有看到日志的打印。 敲黑板，划重点ApiBoot Logging支持单个或者多个路径配置来进行过滤指定路径前缀来采集日志，让日志采集不再不可控，更精准的定位到业务请求的日志采集。 本章源码本篇文章示例源码可以通过以下途径获取，目录为SpringBoot2.x/modify-apiboot-logging-collection-prefix： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/modify-apiboot-logging-collection-prefix.html"},{"title":"SpringBoot2.x使用MongoDB的Rest端点访问数据","text":"在之前项目中我们想要读取MongoDB内的内容需要使用MongoDBTemplate来完成数据的CRUD，那如果我们想要通过RestController的形式获取MongoDB内的数据就更麻烦了，还需要自行去创建对应的控制器，然后使用MongoDBTemplate从MongoDB内读取出数据后返回给前端。 在上一章节第五十一章：基于SpringBoot2 &amp; MongoDB完成自动化集成我们讲到了SpringBoot2与MongoDB集成后怎么简单的操作数据，当然Spring Data Xxx家族方式的设计与Spring Data JPA一样，Sring Data MongoDB提供了一个MongoRepository&lt;T,PK&gt;接口来为继承该接口的子接口自动提供代理类完成数据操作实现。 本章目标使用Spring Data Rest自动映射读取MongoDB内的数据，省去一系列繁琐的操作步骤。 构建项目使用Idea开发工具创建一个SpringBoot的项目，添加相应的依赖，pom.xml配置文件依赖内容如下所示： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;!--mongodb依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--data rest依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-rest&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们本章节的依赖比上一章多了一个spring-boot-starter-data-rest，通过这个依赖我们可以自动完成RestController的依赖配置，不需要再手动去创建控制器，因为我们通过一些简单的注解配置以及固定格式名称规则的方法就可以完成控制器的实现。 因为本章的内容需要在上一章的基础上编写，所以我们直接把之前章节的相关的配置以及类都复制到本项目内，复制的内容有：application.yml、Customer、CustomerRepository。(源码位置：第五十一章源码) 改造CustomerRepositoryspring-boot-starter-data-rest会自动扫描添加@RepositoryRestResource注解的接口，自动将该接口映射为一系列可通过rest访问的请求路径，这里说到一系列，我们在测试的时候会讲到为什么说是一系列！！！。既然需要添加注解，那么我们就打开CustomerRepository接口，对应为它添加上如下注解内容： 1234@RepositoryRestResource(collectionResourceRel = &quot;customer&quot;, path = &quot;customer&quot;)public interface CustomerRepository extends MongoRepository&lt;Customer, String&gt; {//....省略} 注解内需要提供两个参数，collectionResourceRel ：该参数配置映射MongoDB内的Collection名称。path ：该参数配置映射完成rest后访问的路径前缀。 运行测试我们先来简单的运行测试下是否可以通过我们配置的path路径实现访问内容，启动项目时我们可以看到控制台的输出内容： 12345Mapped &quot;{[/{repository}/search],methods=[GET]Mapped &quot;{[/{repository}/search/{search}],methods=[GET]Mapped &quot;{[/{repository}/{id}/{property}],methods=[GET]Mapped &quot;{[/{repository}],methods=[GET].... 我们配置一个@RepositoryRestResource注解的接口就会根据rest内置的一系列的条件生成对应的请求，这也是我们在之前说到的一系列请求路径的地方，我们先来访问下映射/{repository}的路径。 测试 /{repository} 映射路径 你如果使用Windows系统直接打开浏览器输出地址就可以看到返回的内容，如果你使用Linux或者OS X系统可以在Terminal使用curl命令查看返回内容。 我们访问：http://localhost:8080/customer，路径查看返回的内容： 1234567891011121314151617181920212223242526272829303132➜ ~ curl http://localhost:8080/customer{ &quot;_embedded&quot; : { &quot;customer&quot; : [ { &quot;firstName&quot; : &quot;恒宇&quot;, &quot;lastName&quot; : &quot;少年&quot;, &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; }, &quot;customer&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; } } } ] }, &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer{?page,size,sort}&quot;, &quot;templated&quot; : true }, &quot;profile&quot; : { &quot;href&quot; : &quot;http://localhost:8080/profile/customer&quot; } }, &quot;page&quot; : { &quot;size&quot; : 20, &quot;totalElements&quot; : 1, &quot;totalPages&quot; : 1, &quot;number&quot; : 0 }} 通过这个地址我们可以读取出@RepositoryRestResource注解配置的collectionResourceRel对应的 MongoDB.collection集合内的数据，我们发现不仅读取出来了数据而且还为我们提供了分页的信息，这可是很贴心的地方啊，默认读取第1页，每页20条数据。 测试 /{repository}/{id} 映射路径我们访问http://localhost:8080/customer/5adbec9ceb89f105acd90cec（注意：这里的id是你本地生成的，这个id是我本地生成，直接访问会出现404）如下所示： 12345678910111213➜ ~ curl http://localhost:8080/customer/5adbec9ceb89f105acd90cec{ &quot;firstName&quot; : &quot;恒宇&quot;, &quot;lastName&quot; : &quot;少年&quot;, &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; }, &quot;customer&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; } }} 根据返回的内容看到是能够访问根据id查询的数据内容的。 测试 /{repository}/search/{search} 映射路径这个映射的配置是专门为我们自定义方法准备的，自定义方法的规则与SpringDataJPA的方法名称规则一样，当我们在接口创建findByXxx方法时Idea会自动为我们提示相应的内容，下面我们就创建两个不同的查询方法，如下所示： 123456789101112131415/** * 更加名字查询数据 * * @param firstName 名字 * @return */List&lt;Customer&gt; findByFirstName(@Param(&quot;firstName&quot;) String firstName);/** * 根据姓氏查询出最靠前的一条数据 * * @param lastName 姓氏 * @return */Customer findTopByLastName(@Param(&quot;lastName&quot;) String lastName); 下面我们重启下项目访问路径http://localhost:8080/customer/search/findByFirstName?firstName=恒宇可以看到返回内容： 12345678910111213141516171819202122➜ ~ curl http://localhost:8080/customer/search/findByFirstName\\?firstName\\=%E6%81%92%E5%AE%87{ &quot;_embedded&quot; : { &quot;customer&quot; : [ { &quot;firstName&quot; : &quot;恒宇&quot;, &quot;lastName&quot; : &quot;少年&quot;, &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; }, &quot;customer&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/5adbec9ceb89f105acd90cec&quot; } } } ] }, &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/search/findByFirstName?firstName=%E6%81%92%E5%AE%87&quot; } }} 自动的根据我们的配置的方法查询出了对应的数据，自动过滤了对应的数据，不过这个是没有分页的。同样另外一个自定义方法的请求http://localhost:8080/customer/search/findTopByLastName?lastName=少年，也是一样的可以对应的获取过滤后的数据。 注意：@Param注解内的参数名称要与Customer内的属性对应。 如果你想查看配置的全部自定义的方法，访问：http://localhost:8080/customer/search，如下所示： 12345678910111213141516➜ ~ curl http://localhost:8080/customer/search { &quot;_links&quot; : { &quot;findByFirstName&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/search/findByFirstName{?firstName}&quot;, &quot;templated&quot; : true }, &quot;findTopByLastName&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/search/findTopByLastName{?lastName}&quot;, &quot;templated&quot; : true }, &quot;self&quot; : { &quot;href&quot; : &quot;http://localhost:8080/customer/search&quot; } }} 总结本章内容主要是围绕着spring-boot-starter-data-rest这个依赖进行的，这个依赖帮助我们完成了日常编码中一些重复的工作，而且很智能的提供了一些映射，更方便我们进行查询数据。","link":"/mongodb-springboot2-rest.html"},{"title":"SpringBoot2.x使用MongoDB存储数据","text":"MongoDB在企业级项目中一般用于存储文档信息、图片资源等，MongoDB的内容完全是以 JSON字符串的形式进行存储的，所以我们在获取数据时通过简单的 反序列化就可以完成与项目内的实体类转换，不过这个过程是自动的，不需要我们手动进行反序列化处理。 本章目标完成简单的SpringBoot与MongoDB的自动化整合，让我们像是使用spring-data-jpa的形式来完成MongoDB的数据操作。 准备MongDB我们使用MongoDB官方提供的安装方式进行安装，下面是对应系统的官方安装文档： Linux下安装MongoDB Windows下安装MongoDB OSX下安装MongoDB 创建用户我们需要创建一个用户，用于本章的使用，如果你是OSX系统，只需要打开终端输入mongo命令就可以进入MongoDB的管理界面。 123456789101. 创建数据库使用 use test; 命令可以创建一个名为`test`的数据库2. 创建数据库所有者角色的用户db.createUser( { user: &quot;test&quot;, pwd: &quot;123456&quot;, roles: [ { role: &quot;dbOwner&quot;, db: &quot;test&quot; } ] }); 用户创建完成后就可以进行本章的编码了，环境有了之后我们接下来需要进行环境的连接进行操作数据。 构建项目我们使用IDEA创建一个新的SpringBoot项目，在pom.xml配置文件内添加我们本章所需要的依赖，如下所示： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;!--mongodb依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--fastjson依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt; &lt;/dependency&gt; &lt;!--测试依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 根据mongodb的依赖我们可以看到Spring家族式的设计，把所有操作数据的依赖都进行归类到spring-boot-starter-data-xxx下，我们比较常用到的如：spring-boot-starter-data-jpa、spring-boot-starter-data-redis等。 MongoRepositoryspring-boot-starter-data-mongodb确实采用了跟spring-boot-starter-data-jpa同样的方式来完成接口代理类的生成，并且提供了一些常用的单个对象操作的公共方法，MongoRepository接口作用与JPARepository一致，继承了该接口的业务数据接口就可以提供一个被Spring IOC托管的代理实现类，这样我们在注入业务数据接口时就会完成代理实现类的注入。废话不多说了，下面我们直接来创建一个名为CustomerRepository的数据接口，该接口继承MongoRepository&lt;T,PK&gt;，如下所示： 1234567891011121314/** * 客户数据接口 * 继承自MongoRepository接口 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/28 * Time：下午7:41 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */public interface CustomerRepository extends MongoRepository&lt;Customer, String&gt; {} MongoRepository &lt;T,PK&gt;同样也是采用了两个泛型参数，T：实体类类型。PK：T实体类内的主键类型，如：String。 自定义实体类我们在CustomerRepository 接口内使用了Customer实体类作为泛型参数，下面我们简单创建Customer实体类，内容如下所示： 123456789101112131415161718192021@Datapublic class Customer implements Serializable { /** * 客户编号 */ @Id public String id; /** * 客户名称 */ public String firstName; /** * 客户姓氏 */ public String lastName; public Customer(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; }} 同样我们需要通过@Id注解进行设置主键，不过这个主键的值是MongoDB自动生成的，生成的主键值是具有唯一性的。 添加配置代码已经准备好了，我们只需要添加MongoDB的一些配置信息就大功告成了，下面我们需要在application.yml配置文件内添加如下配置： 12345678spring: application: name: spring-boot-mongodb data: mongodb: uri: mongodb://localhost/test username: test password: 123456 在上面配置的uri内的test即为数据库的名称，username配置我们自定义的用户名称，password配置为自定义用户设置的密码。 上面我们的代码已经全部编写完成，接下来我们需要进行测试，来查看我们的CustomerRepository是否已经生效. 测试我们使用CommandLineRunner接口进行简单的项目运行后就执行Customer文档内的数据操作，修改Chapter51Application入口类，添加CommandLineRunner接口的实现，如下所示： 12345678910111213141516171819202122232425262728293031/** * 程序入口类 * @author yuqiyu */@SpringBootApplicationpublic class Chapter51Application implements CommandLineRunner { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(Chapter51Application.class); /** * 客户数据接口注入 */ @Autowired private CustomerRepository repository; public static void main(String[] args) { SpringApplication.run(Chapter51Application.class, args); logger.info(&quot;【【【【【SpringBoot整合Mongodb启动完成.】】】】】&quot;); } @Override public void run(String... args) { // 删除全部 repository.deleteAll(); // 添加一条数据 repository.save(new Customer(&quot;于&quot;, &quot;起宇&quot;)); // 查询全部 logger.info(JSON.toJSONString(repository.findAll())); }} 在run方法内 删除了Customer文档内的全部内容 执行了保存数据的操作 查询出本次保存的数据内容 下面我们来运行下程序查看控制台的效果，如下所示： 12[{&quot;firstName&quot;:&quot;于&quot;,&quot;id&quot;:&quot;5ad4be1cab73ac0bdc23bd9a&quot;,&quot;lastName&quot;:&quot;起宇&quot;}]【【【【【SpringBoot整合Mongodb启动完成.】】】】】 已经可以正常的输出了MongoDB我们添加到文档内的数据，在上面说到了id这个字段的特殊性，这是个分布式唯一性的字段值，是一个短板的md5格式的字符串。 修改默认扫描路径如果你不打算使用SpringBoot默认的扫描路径（SpringBoot默认扫描XxxApplication类的同级以及所有子级的package）可以通过@EnableMongoRepositories注解配置basePackages属性完成自定义的MongoDB的MongoRepository实现类的扫描，如下所示： 123@SpringBootApplication@EnableMongoRepositories(basePackages = &quot;com.hengyu.chapter51&quot;)public class Chapter51Application implements CommandLineRunner { } 总结本章简单的讲解了SpringBoot集成MongoDB，它与JPA有着同样的数据操作方式，数据接口通过继承MongoRepository就可以让我们可以使用与JPA相同的方法进行操作MongoDB文档内的数据，从而减少了学习的成本。","link":"/mongodb-springboot2-starter.html"},{"title":"无意间发现一个好用的视频转换gif图片的开源框架","text":"简介Gifify是一款工具类的开源框架，可以将任何视频文件转换为优化的动画GIF。 GitHub：https://github.com/vvo/gifify 有些时候我们需要将视频转换为动画GIF图，可以更生动形象的描述我们想要说明的事物以及框架的使用方式，它对于程序员来说是一个不可或缺的工具之一。 环境支持在安装Gifify之前首先我们需要先安装它所需要的运行环境： Node.js（brew install node） FFmpeg（brew install ffmpeg） ImageMagick（brew install imagemagick） giflossy（brew install giflossy） 安装可以通过npm直接安装Gifify，如下所示： 1npm install -g gifify 命令行参数下面是Gifify所支持的命令行参数列表。 123456789101112131415161718➜ ~ gifify -hUsage: gifify [options] [file]Options: -V, --version output the version number --colors &lt;n&gt; Number of colors, up to 255, defaults to 80 (default: 80) --compress &lt;n&gt; Compression (quality) level, from 0 (no compression) to 100, defaults to 40 (default: 40) --from &lt;position&gt; Start position, hh:mm:ss or seconds, defaults to 0 --fps &lt;n&gt; Frames Per Second, defaults to 10 (default: 10) -o, --output &lt;file&gt; Output file, defaults to stdout --resize &lt;W:H&gt; Resize output, use -1 when specifying only width or height. `350:100`, `400:-1`, `-1:200` --reverse Reverses movie --speed &lt;n&gt; Movie speed, defaults to 1 (default: 1) --subtitles &lt;filepath&gt; Subtitle filepath to burn to the GIF --text &lt;string&gt; Add some text at the bottom of the movie --to &lt;position&gt; End position, hh:mm:ss or seconds, defaults to end of movie --no-loop Will show every frame once without looping -h, --help output usage information 视频转换为GIF我使用Mac自带的屏幕录制软件QuickTime Player录制了一个测试视频，根据上面的命令行参数来看如果我们不做一些其他的自定义，只添加-o、--output输出的gif文件名即可，如下所示： 12➜ gifify 屏幕录制2020-08-05\\ 上午8.58.01.mov --output example.gifGenerating GIF, please wait... 当我们看到提示信息Generating GIF, please wait...时，说明已经开始转换了，因为视频文件的大小有差异，所以转换所需要的时间也所有不同。 自动创建的example.gif文件与转换的视频文件在同一目录下。 GIF截取如果你只需要转换视频中的一个时间段，我们可以通过指定--from、--to参数来配置，如下所示： 1➜ gifify 屏幕录制2020-08-05\\ 上午8.58.01.mov --output example.gif --from 00:00:10 --to 00:00:15 GIF压缩Gifify默认压缩比例为40%，压缩后的Gif图可能会比较模糊，我们可以通过--compress参数来修改压缩比例，0表示无压缩，取值范围为0~100，如下所示： 1➜ gifify 屏幕录制2020-08-05\\ 上午8.58.01.mov --output example.gif --from 00:00:10 --to 00:00:12 --compress 0 总结Gifify还有很多隐藏的功能，比如在GIF图片上添加文字描述，缩放视频比例，反转视频等功能，赶快去发掘它的隐藏功能吧。","link":"/mp4-convert-to-gif.html"},{"title":"Nacos 作为配置中心 &amp; 读取Properties配置信息","text":"SpringCloud Alibaba是阿里巴巴致力于对微服务的管理、配置、注册等一整套的解决方案，内部主要是Nacos相关的依赖进行实现，本系列文章主要来讲解下Nacos Config在SpringCloud环境下的运用。 简介Nacos 提供用于存储配置和其他元数据的 K-V 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Nacos Config支持多种方式的配置格式，比如：TEXT、JSON、XML、YAML、HTML、PROPERTIES等。我们本章先来看下是怎么读取外部Properties类型的配置。 前提本地需要安装Nacos Server，具体安装步骤访问Nacos官网文档，Nacos Server 安装 创建项目使用idea工具创建一个SpringCloud项目。 添加依赖添加依赖在pom.xml配置文件如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//...&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--alibaba nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--SpringCloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringCloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;//... bootstrap引导配置Nacos Config相关的配置必须在bootstrap.yml或者bootstrap.properties文件内添加。配置内容如下所示： 123456789spring: application: name: alibaba-nacos-config-client # nacos config cloud: nacos: config: server-addr: 127.0.0.1:8848 spring.application.namespring-cloud-starter-alibaba-nacos-config依赖默认会使用该值的内容作为DATA-ID来匹配读取Nacos Config,读取规则下面介绍。 spring.cloud.nacos.config.server-addr配置nacos server的地址信息，nacos server本地安装访问Nacos Server 安装 读取Nacos配置在启动类内添加读取Nacos Config部分代码，为了跟下一步做铺垫来测试自动更新，我们间隔1秒后再次读取配置内容，编码如下所示： 1234567891011121314151617181920212223242526272829/** * Nacos Config Properties方式 * * @author：恒宇少年 - 于起宇 * &lt;p&gt; * DateTime：2019-03-01 11:20 * Blog：https://blog.minbox.org * WebSite：http://www.jianshu.com/u/092df3f77bca * Gitee：https://gitee.com/hengboy * GitHub：https://github.com/hengyuboy */@SpringBootApplicationpublic class SpringCloudAlibabaNacosConfigPropertiesApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(SpringCloudAlibabaNacosConfigPropertiesApplication.class); public static void main(String[] args) throws Exception { ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringCloudAlibabaNacosConfigPropertiesApplication.class, args); while (true) { //当动态配置刷新时，会更新到 Enviroment中，因此这里每隔一秒中从Enviroment中获取配置 String userName = applicationContext.getEnvironment().getProperty(&quot;hengboy.name&quot;); String userAge = applicationContext.getEnvironment().getProperty(&quot;hengboy.age&quot;); logger.info(&quot;配置信息，名称：{}，年龄：{}&quot;, userName, userAge); TimeUnit.SECONDS.sleep(1); } }} 测试接下来我们来测试是否可以从Nacos Config内读取相关的配置信息，我们需要访问Nacos Console控制台来添加配置信息。访问：Nacos Console，默认用户名/密码为：nacos/nacos。 添加 Nacos Config通过配置列表内添加配置信息，添加时DATA-ID的组成部分为：{spring.application.name}.{file-extension}。file-extension文件后缀名默认为properties，如果需要修改，在bootstrap文件内进行修改配置spring.cloud.nacos.config.file-extension的值。添加的配置信息如下所示： 12345DATA ID : alibaba-nacos-config-client.propertiesGroup : DEFAULT_GROUP配置内容 : hengboy.name=admin-propertieshengboy.age=11 输出 Nacos Config一切就绪，我们通过Application方式启动项目，查看控制台打印内容如下所示： 123Loading nacos data, dataId: 'alibaba-nacos-config-client.properties', group: 'DEFAULT_GROUP'Located property source: CompositePropertySource {name='NACOS', propertySources=[NacosPropertySource {name='alibaba-nacos-config-client.properties'}]}配置信息，名称：admin-properties，年龄：11 自动更新配置在上面的步骤中我们已经可以从Nacos Config内读取到对应的properties配置文件内容信息。那我们如果通过Nacos Console进行修改了配置内容后，我们的应用程序是不是可以立马获取到修改后的值呢？ 我们带着这个疑问，去Nacos Console找到DATA-ID = alibaba-nacos-config-client.properties的配置信息，修改hengboy.age的值为25，重新发布配置信息后查看我们的应用程序的控制台输出内容如下所示： 1234Loading nacos data, dataId: 'alibaba-nacos-config-client.properties', group: 'DEFAULT_GROUP'Located property source: CompositePropertySource {name='NACOS', propertySources=[NacosPropertySource {name='alibaba-nacos-config-client.properties'}]}Refresh keys changed: [hengboy.age]配置信息，名称：admin-properties，年龄：25 可以看到输出的内容，我们修改完外部的配置信息后，Nacos Client会自动刷新所修改的配置文件内容，始终让配置内容保持与Nacos Config内配置一致。我们通过Nacos Console修改的当前DATA-ID下的任何参数都会在控制台Refresh keys changed: [xxx,xxx]打印。 总结本章简单的讲解了SpringCloud Alibaba的配置中心读取配置信息方式以及自动更新配置信息实现，在开头我们说了Nacos Config所支持的配置文件的格式不仅仅是properties这一种，不过这是默认的一种方式，在下一章我们来讲解下YAML方式的配置信息读取。","link":"/nacos-config-properties.html"},{"title":"Nacos 作为配置中心 &amp; 读取Yaml配置信息","text":"通过本系列的前篇文章： /nacos-config-properties.html 在之前文章中我们学习到了SpringCloud Alibaba读取Nacos Config内定义的properties类型的配置文件信息，并且使用Nacos Console进行修改配置信息后可以在应用程序内实时更新。 本章目标Nacos Config所支持的配置文件类型既然有多种，那我们该怎么配置才能读取不同的配置类型的内容呢？ 快速入门我们还是先来通过Nacos Console来添加本章所使用的配置信息，要注意配置的后缀名改为yaml。 Nacos Server需要在本地安装Nacos Server才能完成本章的内容讲解，具体的安装步骤访问Nacos 官方文档 创建配置配置信息如下所示： 创建应用我们在Nacos Console已经添加了本章所使用的Yaml类型的配置信息，下面通过Idea开发工具创建一个SpringBoot项目，并添加SpringCloud Alibaba、SpringCloud版本的依赖，pom.xml配置文件内容如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940//...&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--alibaba nacos config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--SpringCloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringCloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;//... 配置文件扩展名在之前讲到过默认的配置文件扩展名为properties，既然我们本章是读取的yaml类型的文件，那肯定需要修改这个配置参数，application.yml配置文件如下所示： 12345678910spring: application: name: hengboy-spring-cloud # nacos config cloud: nacos: config: server-addr: 127.0.0.1:8848 # 配置文件后缀名为yaml file-extension: yaml 通过spring.cloud.nacos.config.file-extension参数进行修改默认的Nacos Config所匹配的默认文件扩展名。 在上面的配置文件内要注意的时，hengboy-spring-cloud要与Nacos Console内添加的配置data-id前部分匹配，也就是匹配：hengboy-spring-cloud.yaml。 读取配置下面我们通过简单的几个步骤来读取我们配置的yaml配置内容。 第一步：创建一个配置读取的Controller 创建一个名为ConfigController的配置查询控制器，并且类上配置@RequestMapping(&quot;/config&quot;)。 第二步：通过@Value注解读取配置信息 我们在之前章节通过applicationContext#getEnvironment#getProperty方法可以直接获取对应的Nacos Config的配置信息，当然SpringCloud Alibaba也同样支持通过@Value注解来获取配置信息，如下所示： 1234567891011121314151617181920212223242526@RestController@RequestMapping(value = &quot;/config&quot;)@RefreshScopepublic class ConfigController { /** * 读取hengboy.name配置信息 */ @Value(value = &quot;${hengboy.name:}&quot;) private String userName; /** * 读取hengboy.age配置信息 */ @Value(value = &quot;${hengboy.age:}&quot;) private String userAge; /** * 获取配置内容 * * @return */ @RequestMapping(value = &quot;/get&quot;) public String getConfig() { return userName + &quot;:&quot; + userAge; }} 解释：${hengboy.name:}表示需要从全局的配置内容中读取hengboy.name的配置信息，如果没有找到则使用 冒号（:） 后的内容，当然这里我们没有添加任何的默认值，如果没有配置则为空字符串。 第三步：通过@RefreshScope注解实时刷新配置信息我们在ConfigController控制器上添加了注解@RefreshScope主要目的是来实时同步通过Nacos Console修改的配置内容。 @RefreshScope注解是SpringCloud内部提供，用于配置热加载。 第四步：运行测试 启动应用程序，我们通过curl http://localhost:8080/config/get可以获取我们在Nacos Console添加的配置内容：admin:25 第五步：实时更新测试 通过Nacos Console我们修改下两个参数的内容并且重新发布配置信息： 12hengboy.name : admin -&gt; admin-change-afterhegnboy.age : 25 -&gt; 30 再次通过curl http://localhost:8080/config/get命令访问，我们已经可以得到更新后的配置内容：admin-change-after:30","link":"/nacos-config-yaml.html"},{"title":"Spring OAuth2 实现始终获取新的令牌","text":"Spring基于OAuth2协议编写的spring-oauth2实现，是行业级的接口资源安全解决方案，我们可以基于该依赖配置不同客户端的不同权限来访问接口数据。 默认令牌生成方式每当我们获取请求令牌（access_token）时，默认情况返回第一次生成的令牌，使用同一个用户多次获取令牌时，只有过期时间在缩短，其它的内容不变。 这种方式有利有弊，如果同一个账户只能有一个人登录，这样是没有任何问题的，但是如果同一个账号可以让多个人同时登录，那么就会存在一定的问题。 比如我们现在有一个名为hengboy的账户：第一个人登录时令牌有效期为我们配置的最长有效期（假设为7200秒），这时又有第二个人登录的同一个用户，第二个人获取的令牌并不会重置有效期（可能还剩下3000秒），对于这种结果并不是我们期望的。 原因分析目前spring-oauth2依赖内集成了三种存储令牌的方式，分别是：InMemoryTokenStore（内存方式）、RedisTokenStore（Redis方式）、JdbcTokenStore（数据库方式）。 从阅读源码中可以发现无论我们配置使用什么方式来进行存储令牌，同一个账户的有效令牌只会存在一个，结合上面的场景来思考所以第二个人获取的令牌与第一个人是同一个。 DefaultTokenServicesDefaultTokenServices令牌服务是AuthorizationServerTokenServices接口的默认实现，位于org.springframework.security.oauth2.provider.token包内，提供了默认的操作令牌的方法，常用的有： createAccessToken：根据客户端信息、登录用户信息来创建请求令牌（access_token）以及刷新令牌（refresh_token） refreshAccessToken：根据刷新令牌（refresh_token）来获取一个全新的请求令牌（access_token） revokeToken：撤销令牌，删除用户生成的请求令牌（access_token）、刷新令牌（refresh_token） 源码解析：生成令牌DefaultTokenServices#createAccessToken： 123456789101112131415161718192021222324252627282930313233343536@Transactional public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException { OAuth2AccessToken existingAccessToken = this.tokenStore.getAccessToken(authentication); OAuth2RefreshToken refreshToken = null; if (existingAccessToken != null) { if (!existingAccessToken.isExpired()) { this.tokenStore.storeAccessToken(existingAccessToken, authentication); return existingAccessToken; } if (existingAccessToken.getRefreshToken() != null) { refreshToken = existingAccessToken.getRefreshToken(); this.tokenStore.removeRefreshToken(refreshToken); } this.tokenStore.removeAccessToken(existingAccessToken); } if (refreshToken == null) { refreshToken = this.createRefreshToken(authentication); } else if (refreshToken instanceof ExpiringOAuth2RefreshToken) { ExpiringOAuth2RefreshToken expiring = (ExpiringOAuth2RefreshToken)refreshToken; if (System.currentTimeMillis() &gt; expiring.getExpiration().getTime()) { refreshToken = this.createRefreshToken(authentication); } } OAuth2AccessToken accessToken = this.createAccessToken(authentication, refreshToken); this.tokenStore.storeAccessToken(accessToken, authentication); refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) { this.tokenStore.storeRefreshToken(refreshToken, authentication); } return accessToken; } 在创建令牌的源码方法中，首先根据认证信息去读取存储介质（TokenStore实现类）内该账户的令牌，如果令牌已经存储并且并未过期，则直接返回（这也就是同一个账户不同人登录时返回同一个令牌的逻辑），如果令牌已经过期，则删除刷新令牌（refresh_token）、请求令牌（access_token）后重新生成。 源码解析：刷新令牌DefaultTokenServices#refreshAccessToken： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Transactional( noRollbackFor = {InvalidTokenException.class, InvalidGrantException.class} ) public OAuth2AccessToken refreshAccessToken(String refreshTokenValue, TokenRequest tokenRequest) throws AuthenticationException { if (!this.supportRefreshToken) { throw new InvalidGrantException(&quot;Invalid refresh token: &quot; + refreshTokenValue); } else { OAuth2RefreshToken refreshToken = this.tokenStore.readRefreshToken(refreshTokenValue); if (refreshToken == null) { throw new InvalidGrantException(&quot;Invalid refresh token: &quot; + refreshTokenValue); } else { OAuth2Authentication authentication = this.tokenStore.readAuthenticationForRefreshToken(refreshToken); if (this.authenticationManager != null &amp;&amp; !authentication.isClientOnly()) { Authentication userAuthentication = authentication.getUserAuthentication(); PreAuthenticatedAuthenticationToken preAuthenticatedToken = new PreAuthenticatedAuthenticationToken(userAuthentication, &quot;&quot;, authentication.getAuthorities()); if (userAuthentication.getDetails() != null) { preAuthenticatedToken.setDetails(userAuthentication.getDetails()); } Authentication user = this.authenticationManager.authenticate(preAuthenticatedToken); Object details = authentication.getDetails(); authentication = new OAuth2Authentication(authentication.getOAuth2Request(), user); authentication.setDetails(details); } String clientId = authentication.getOAuth2Request().getClientId(); if (clientId != null &amp;&amp; clientId.equals(tokenRequest.getClientId())) { this.tokenStore.removeAccessTokenUsingRefreshToken(refreshToken); if (this.isExpired(refreshToken)) { this.tokenStore.removeRefreshToken(refreshToken); throw new InvalidTokenException(&quot;Invalid refresh token (expired): &quot; + refreshToken); } else { authentication = this.createRefreshedAuthentication(authentication, tokenRequest); if (!this.reuseRefreshToken) { this.tokenStore.removeRefreshToken(refreshToken); refreshToken = this.createRefreshToken(authentication); } OAuth2AccessToken accessToken = this.createAccessToken(authentication, refreshToken); this.tokenStore.storeAccessToken(accessToken, authentication); if (!this.reuseRefreshToken) { this.tokenStore.storeRefreshToken(accessToken.getRefreshToken(), authentication); } return accessToken; } } else { throw new InvalidGrantException(&quot;Wrong client for this refresh token: &quot; + refreshTokenValue); } } } } 在刷新令牌的源码方法中，首先需要读取刷新令牌（refresh_token）的具体内容，如果不存在则直接抛出刷新令牌无效的异常InvalidGrantException。 执行令牌刷新之前，需要根据刷新令牌删除请求令牌removeAccessTokenUsingRefreshToken，删除后再次判定刷新令牌是否失效，如果失效抛出InvalidTokenException异常。 刷新令牌的重复使用是根据全局变量reuseRefreshToken来判定的，默认情况下该变量的值为true，也就是刷新令牌可以重复使用，但是经过createAccessToken &gt; TokenEnhancer#enhance处理后刷新令牌会被重新创建并替换（这个地方貌似是一个Bug）。 重写TokenServices期望效果假设请求令牌（access_token）的有效期为7200秒，也就是2个小时，刷新令牌（refresh_token）的有效期为43200秒，也就是12个小时。 在第一次通过createAccessToken获取令牌后，每次请求令牌（access_token）过期后通过刷新的方式（/oauth/token?grant_type=refresh_token）重新获取一次新的（有效期为2个小时）请求令牌，当刷新令牌（refresh_token）失效后，再次通过createAccessToken方法来获取令牌。 分析期望效果针对上面的期望效果我们需要修改createAccessToken、refreshAccessToken两个方法的源码，调用createAccessToken方法时不再判定是否使用已经存在的有效令牌，而调用refreshAccessToken方法时需要删除响应的refresh_token的返回字段并把新的请求令牌与刷新令牌进行绑定。 OverrideTokenServices复制DefaultTokenServices类内的全部代码，创建一个名为OverrideTokenServices的类，为了兼容原来的逻辑，需要添加一个全局变量alwaysCreateToken，用于判定是否始终创建令牌。 重写创建令牌逻辑1234567891011121314151617181920212223242526272829303132333435@Transactional public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException { OAuth2RefreshToken refreshToken = null; OAuth2AccessToken existingAccessToken = this.tokenStore.getAccessToken(authentication); // 根据alwaysCreateToken字段判定是否始终创建令牌 if (!this.alwaysCreateToken &amp;&amp; existingAccessToken != null) { if (!existingAccessToken.isExpired()) { this.tokenStore.storeAccessToken(existingAccessToken, authentication); return existingAccessToken; } if (existingAccessToken.getRefreshToken() != null) { refreshToken = existingAccessToken.getRefreshToken(); this.tokenStore.removeRefreshToken(refreshToken); } this.tokenStore.removeAccessToken(existingAccessToken); } if (refreshToken == null) { refreshToken = this.createRefreshToken(authentication); } else if (refreshToken instanceof ExpiringOAuth2RefreshToken) { ExpiringOAuth2RefreshToken expiring = (ExpiringOAuth2RefreshToken)refreshToken; if (System.currentTimeMillis() &gt; expiring.getExpiration().getTime()) { refreshToken = this.createRefreshToken(authentication); } } OAuth2AccessToken accessToken = this.createAccessToken(authentication, refreshToken); this.tokenStore.storeAccessToken(accessToken, authentication); refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) { this.tokenStore.storeRefreshToken(refreshToken, authentication); } return accessToken; } 如果我们想使用原来的逻辑，在初始化OverrideTokenServices类时需要设置alwaysCreateToken变量的值为false。 重写刷新令牌逻辑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public OAuth2AccessToken refreshAccessToken(String refreshTokenValue, TokenRequest tokenRequest) throws AuthenticationException { if (!this.supportRefreshToken) { throw new InvalidGrantException(&quot;Invalid refresh token: &quot; + refreshTokenValue); } else { OAuth2RefreshToken refreshToken = this.tokenStore.readRefreshToken(refreshTokenValue); if (refreshToken == null) { throw new InvalidGrantException(&quot;Invalid refresh token: &quot; + refreshTokenValue); } else { OAuth2Authentication authentication = this.tokenStore.readAuthenticationForRefreshToken(refreshToken); if (this.authenticationManager != null &amp;&amp; !authentication.isClientOnly()) { Authentication userAuthentication = authentication.getUserAuthentication(); PreAuthenticatedAuthenticationToken preAuthenticatedToken = new PreAuthenticatedAuthenticationToken(userAuthentication, &quot;&quot;, authentication.getAuthorities()); if (userAuthentication.getDetails() != null) { preAuthenticatedToken.setDetails(userAuthentication.getDetails()); } Authentication user = this.authenticationManager.authenticate(preAuthenticatedToken); Object details = authentication.getDetails(); authentication = new OAuth2Authentication(authentication.getOAuth2Request(), user); authentication.setDetails(details); } String clientId = authentication.getOAuth2Request().getClientId(); if (clientId != null &amp;&amp; clientId.equals(tokenRequest.getClientId())) { this.tokenStore.removeAccessTokenUsingRefreshToken(refreshToken); if (this.isExpired(refreshToken)) { this.tokenStore.removeRefreshToken(refreshToken); throw new InvalidTokenException(&quot;Invalid refresh token (expired): &quot; + refreshToken); } else { authentication = this.createRefreshedAuthentication(authentication, tokenRequest); if (!this.reuseRefreshToken) { this.tokenStore.removeRefreshToken(refreshToken); refreshToken = this.createRefreshToken(authentication); } DefaultOAuth2AccessToken accessToken = (DefaultOAuth2AccessToken) this.createAccessToken(authentication, refreshToken); // If you reuse the refresh token, set the refresh token to the new AccessToken // 如果重复使用刷新令牌，将刷新令牌与新生成的请求令牌进行绑定 if (this.reuseRefreshToken) { accessToken.setRefreshToken(refreshToken); } this.tokenStore.storeAccessToken(accessToken, authentication); if (!this.reuseRefreshToken) { this.tokenStore.storeRefreshToken(accessToken.getRefreshToken(), authentication); } // No new token will be returned after refresh // 刷新令牌后不再返回refresh_token accessToken.setRefreshToken(null); return accessToken; } } else { throw new InvalidGrantException(&quot;Wrong client for this refresh token: &quot; + refreshTokenValue); } } } } 在DefaultTokenServices类中默认定义了全局变量reuseRefreshToken，该变量的值为true，表示默认情况下刷新令牌（refresh_token）是可以重复使用的，一般刷新令牌的过期时间都比较久，当请求令牌（access_token）失效后根据刷新令牌进行获取新的有效请求令牌。 配置TokenServices我们需要在AuthorizationServerConfigurerAdapter实现类内进行配置TokenServices的替换使用，如下所示： 12345678910111213141516171819202122/** * 实例化{@link OverrideTokenServices} * * @return {@link OverrideTokenServices} */private AuthorizationServerTokenServices tokenServices() { OverrideTokenServices tokenServices = new OverrideTokenServices(); tokenServices.setTokenStore(tokenStore()); tokenServices.setAlwaysCreateToken(true); tokenServices.setSupportRefreshToken(true); tokenServices.setClientDetailsService(clientDetailsService); return tokenServices;}@Overridepublic void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .authenticationManager(authenticationManager) .tokenStore(tokenStore()) // 配置替换使用TokenServices .tokenServices(tokenServices());} 测试获取令牌示例： 123456789101112131415161718192021222324第一次获取令牌：yuqiyu@hengyu ~&gt; curl -X POST -u &quot;local:123456&quot; http://localhost:9091/oauth/token -d &quot;grant_type=password&amp;username=hengboy&amp;password=123456&quot; | jsonpp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 199 0 147 100 52 362 128 --:--:-- --:--:-- --:--:-- 491{ &quot;access_token&quot;: &quot;qoL7Kg33-deYw-aw8PnIKK-qxEk&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;-OfFqllKZJC6-r_v_uR9KGUBXl0&quot;, &quot;expires_in&quot;: 7199, &quot;scope&quot;: &quot;read&quot;}第二次获取令牌：yuqiyu@hengyu ~&gt; curl -X POST -u &quot;local:123456&quot; http://localhost:9091/oauth/token -d &quot;grant_type=password&amp;username=hengboy&amp;password=123456&quot; | jsonpp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 199 0 147 100 52 896 317 --:--:-- --:--:-- --:--:-- 1213{ &quot;access_token&quot;: &quot;hfo01xMTVE1xxxbzQLY7vPfLXPE&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;refresh_token&quot;: &quot;QuLgm-H3xHzo71M_XSLrglsRs_o&quot;, &quot;expires_in&quot;: 7199, &quot;scope&quot;: &quot;read&quot;} 可以看到上面使用同一个账号获取了两次令牌，而这两次的令牌内容是完全不同的，这也就是实现了针对同一个账号不同人登录时返回新的令牌的需求。 刷新令牌示例： 12345678910111213141516171819202122根据第一次获取的刷新令牌刷新：yuqiyu@hengyu ~&gt; curl -X POST -u &quot;local:123456&quot; http://localhost:9091/oauth/token -d &quot;grant_type=refresh_token&amp;refresh_token=-OfFqllKZJC6-r_v_uR9KGUBXl0&quot; | jsonpp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 167 0 101 100 66 1109 725 --:--:-- --:--:-- --:--:-- 1835{ &quot;access_token&quot;: &quot;KuOprmzBCzC78NXlTkHvZGs9rhs&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;expires_in&quot;: 7199, &quot;scope&quot;: &quot;read&quot;}根据第二次获取的刷新令牌刷新：yuqiyu@hengyu ~&gt; curl -X POST -u &quot;local:123456&quot; http://localhost:9091/oauth/token -d &quot;grant_type=refresh_token&amp;refresh_token=QuLgm-H3xHzo71M_XSLrglsRs_o&quot; | jsonpp % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 167 0 101 100 66 1122 733 --:--:-- --:--:-- --:--:-- 1855{ &quot;access_token&quot;: &quot;aLPOEkfUCxn87XkTkcwyixaUO1s&quot;, &quot;token_type&quot;: &quot;bearer&quot;, &quot;expires_in&quot;: 7200, &quot;scope&quot;: &quot;read&quot;} 同一个账户，上面虽然刷新了两次，但是令牌的有效期不会相互影响，第一次刷新使用的是第一次获取的刷新令牌，这样其实也就是刷新的第一次的请求令牌，与第二次的无关！！！ 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为oauth2-always-create-token： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/oauth2-always-create-token.html"},{"title":"长期免费开放一台Eureka Server服务","text":"恒宇少年为了大家学习SpringCloud方便，特意给大家提供了一个在线开放的Eureka Server服务，大家可以直接在学习使用服务注册时配置使用开放的Eureka Server进行服务注册。 如何使用？Eureka Server 管理地址：http://open.eureka.yuqiyu.com SpringBoot应用程序配置文件application.properties内添加eureka.client.service-url.defaultZone=http://open.eureka.yuqiyu.com/eureka/。 该服务长期有效。","link":"/open-eureka-server.html"},{"title":"长期免费开放一台Nacos Server服务","text":"恒宇少年准备着手更新SpringCloud Alibaba系列文章教程，为了方便大家的学习特意免费长期开放了一台Nacos Server，可以用来当做服务注册中心使用，也可以当做配置中心使用。 注意事项 请使用本Nacos Server作为测试环境（由于是公开的，所以建议不要用作生产环境） 请不要对本Nacos Server进行压力测试，服务器配置有限 如果出现无法访问的情况请联系作者的微信公众号「程序员恒宇少年」 已禁用修改密码功能（公共服务不允许修改） 如何使用？管理地址：http://open.nacos.yuqiyu.com/nacos 当作服务注册中心，请在application.properties配置文件内添加spring.cloud.nacos.discovery.server-add=open.nacos.yuqiyu.com:80 当作配置中心，请在application.properties配置文件内添加spring.cloud.nacos.config.server-addr=open.nacos.yuqiyu.com:80 如果你使用的是Eureka，可以使用另外一台开放的Eureka Server，/open-eureka-server.html。 登录信息使用Nacos默认的用户名：nacos，密码：nacos即可登陆。 1.登录界面 2. 服务列表","link":"/open-nacos-server.html"},{"title":"PostgreSQL和MySQL到底选哪一个？","text":"PostgreSQL VS MySQL VS PostgreSQL MySQL 开源 PostgreSQL是一个免费的开源系统，它受PostgreSQL许可证（自由的开源许可证）的约束。 MySQL属于Oracle旗下产品，并提供几种付费版本供用户使用 管理 PostgreSQL是全球用户共同发展的产品 MySQL是GNU通用公共许可以及各种专有协议条款下的产品 性能 PostgreSQL适合对读写速度要求很高的大型系统中使用 MySQL主要用于Web应用程序，该Web应用程序仅需要数据库来进行数据交易。 遵循ACID PostgreSQL从头到尾都遵循ACID原则，并确保满足需求 MySQL只有在使用InnoDB和NDB集群存储引擎时才符合ACID要求。 SQL 兼容性 “从文档看，PostgreSQL是兼容大部分SQL的。 PostgreSQL支持SQL:2011的大多数功能。在核心一致性所需的179个强制性功能中，PostgreSQL至少兼容160个。此外，还有一系列受支持的可选功能。” “从文档看，MySQL在某些版本是兼容部分SQL。 我们对该产品的主要目标之一是继续努力达到SQL标准的要求，但又不牺牲速度或可靠性。我们可以添加SQL扩展或对非SQL功能的支持，如果这样可以极大地提高MySQL服务器在我们大部分用户群中的可用性。” 支持平台 PostgreSQL可以运行在Linux, Windows (Win2000 SP4 及以上)，FreeBSD，OpenBSD，NetBSD , Mac OS X, AIX, IRIX ,Solaris和 Tu64. 也支持由技术巨头惠普开发的HP-UX OS，以及开源的Unix OS。 MySQL可以运行在Oracle Solaris，Microsoft Windows, Linux Mac OS X。MySQL扩展了对开源FreeBSD OS的支持 编程语言支持 PostgreSQL是用C语言编写的，它支持多种编程语言，最突出的C/C++, Delphi, JavaScript, Java, Python, R , Tcl , Go, Lisp, Erlang和.Net. PostgreSQL是用C和C++编写的，它支持C/C++, Erlang，PHP，Lisp,和Go, Perl，Java, Delphi, R ,和 Node.js. 物化视图 PostgreSQL支持物化视图 MySQL不支持物化视图 数据备份 PostgreSQL支持主备复制，并且还可以通过实现第三方扩展来处理其他类型的复制 MySQL支持主备复制，其中每个节点都是主节点，并且有权更新数据 可拓展性 PostgreSQL是高度可扩展的，您可以添加和拥有数据类型，运算符，索引类型和功能语言。 MySQL不支持拓展性。 访问方法 PostgreSQL支持所有标准。 MySQL支持所有标准。 社区支持 PostgreSQL有一个活跃的社区支持，该社区帮助改善现有功能，其富有创造力的提交者竭尽全力确保该数据库保持最新的功能和最大的安全性，成为最先进的数据库。 MySQL也有一个庞大的追随者社区，这些社区贡献者，特别是在被Oracle收购之后，主要关注一些偶尔出现的新功能，并维护现有功能。 安全性 PostgreSQL为连接提供本机SSL支持，以加密客户端/服务器通信。 PSQL还具有行级安全性。 MySQL是高度安全的，并且包含多个安全功能。 总结本文中，我们讨论了两种最广泛使用的关系型数据库管理系统 PostgreSQL和MySQL的最先进的特性。这两种数据库管理系统既有相似之处，也有不同之处。如果您需要一个用于Web应用程序的，高安全性的关系型数据库管理系统，或者想要构建一个活跃用户超过数百万的面向消费者的app，那么MySQL将适合您的项目。如果你的需求围绕复杂的程序,复杂的设计,集成和数据完整性、事务支持,而不是在高速，那么,PostgreSQL将会是你项目理想的选择。","link":"/postgresql-vs-mysql.html"},{"title":"记一次操蛋的方案降级（云上冷热分离的坎坷之路）","text":"系统的数据，就是公司的生命。哪怕是狗屎，我们也要将它冷冻起来冰封以备后用。垃圾的产品设计就比较让人费解，会时不时从冰柜中将屎取出，想要品尝其中残留的味道。不过这其中，还是有些有价值的需求。这种情况，就需要将数据进行冷热分离，对数据进行隔离。不至于让一颗老鼠屎，坏了一锅粥。 xjjdog今天给大家分享的，是一个非常常见的冷热分离的功能，方案有很多，只举例最常见的。最终，在rds的限制下，只能选了一个不是最美的方案。这从侧面证明了老婆不是最漂亮的好，要最合适的才能幸福圆满。 问题场景随着业务的发展，数据库增长的很快。老板不明白其中道理，但作为数据库的维护者，却看的胆颤心惊。终于，数据库慢慢的接近数瓶颈点，管理员也越来越焦虑。使用分区表吧，不行。就如上面所说，有些挖祖坟的请求，会加载一些很久之前的数据，分区表并不能解决问题。明显要对数据进行一下切割，进行冷热分离了。大体的结构如上图。我们有一个数据路由，负责根据时间维度区分数据，定位到相应的数据库中进行查询。 热库和冷库，可能是异构的。 解决思路问题已经进行了转化。我们接下来的目标，变成了怎么根据时间维度，构建热数据和冷数据的分离。 目前使用最多的数据库是mysql，我们也从它说起。 其实，冷热分离的两份数据，查询“最近时间”的数据，是没什么差别的。唯一不同的是，热库，会定时的删除旧的数据。 双写双写是最简单，但是又最不靠谱的方案。结构如下图。但是注意，操作步骤1、2，涉及到分布式事务，需要同时保证两个库的写入成功。 这就让事情变的麻烦了一些。作为一个吃过无数次事务问题的亏的人，不会重蹈这样的覆辙。 所以，这种方案，直接pass。 走消息细心的同学应该发现了上图的优化点，通过引入一个叫做消息队列的东西，就可以把分布式事务这座大山给绕过去，只保证最终一致性即可。多么美好的设想。理想很丰满，现实很骨感。由于冷热分离涉及到非常多的数据表，需要修改不可预知的业务代码，遭到了大家的一致反对。此方案无疾而终。直接看图，变了两根线而已。 使用binlog有的同学可能已经憋不住了：为什么不用binlog？接下来我们就谈下这种方案。不可否认，这是种非常优雅的方式。数据只需要写入热库就可以了，通过数据订阅的方式，增量的将数据写入到冷库。但是等等。我们的定时任务，删除数据的时候，同样也要产生binlog。如何区别数据的删除，是定时任务产生的，还是正常的业务产生？还好，xjjdog知晓一个非常隐秘的方式去操作。对对对，就是下面的过程。 123set session sql_log_bin=0;//optset session sql_log_bin=1; binlog可以设置session级别的，也就是在此session中操作的语句，并不会产生binlog。 这样，我们在定时任务执行时，先关闭binlog，然后，执行删除语句，然后，重新恢复binlog。这些删除的数据，就不会通过canal同步到冷库中了。 万万没想到mmp? 为什么不支持呢？为什么呢？容我小心翼翼的猜想一下。你的rds啊，有可能在和别人在共用一个实例呢。 其实，除了rds的限制，此方案还存在一个bug。比如热库有冷热分离的时候。想想为甚么吧。 标记清除得了，xjjdog只能曲线救国了。用最2的方式完成这个操蛋的功能。标记清除。这四个醒目的大字，让人不由自主的想到jvm的垃圾回收算法。原理其实也类似，步骤也是一分为二。第一、标记阶段给每一张数据表，都加一个叫做mark2Del字段。然后，通过定时，标记所有要过期（也就是要放入冷库的数据）。第二、清除阶段在下一次定时来临时，将上次标记要删除的数据，逐条搬迁到冷库。搬迁完毕后，进行下一轮标记。此方案非常简单，但有个致命弱点。由于所有的库表，都是老表，都需要增加一个叫做mark2Del的字段，甚是麻烦。然而，上面的介绍，只是解决了数据的删除，并没有解决数据的同步。 最终方案结合以上的描述，以及环境的限制。我们选择了使用binlog+标记清除的方式。标记清除负责删除数据。binlog负责增量同步数据。只是，在这个同步逻辑中，多了一个判断，如果mark2Del的值被设置成了true，则忽略此binlog。也就是说，我们强行给每条删除的记录，追加了一个判断标志。这样，系统终于跑起来了。 End上文描述的，是mysql到mysql之间的冷热分离。但如果，我想要做一个分层的数据仓库。第一层，是热库。第二层，是冷库。第三层，是存档库，可能是druid这种大数据存储。该如何设计？本文不做过多介绍。架构的难点不在结果，而在于过程。你看起来很挫的方案，总有它背后的故事，尝试着去理解，大有裨益。除非它是真的挫。不过，这不也是你的机会么？","link":"/program-downgrade.html"},{"title":"Quartz分布式集群多节点实现任务漂移","text":"在上一章中我们已经完成了任务的持久化，当我们创建一个任务时任务会被quartz定时任务框架自动持久化到数据库，我们采用的是SpringBoot项目托管的dataSource来完成的数据源提供，当然也可以使用quartz内部配置数据源方式，我们的标题既然是提到了定时任务的分布式多节点，那么怎么才算是多节点呢？当有节点故障或者手动停止运行后是否可以自动漂移任务到可用的分布式节点呢？ 本章目标 完成定时任务分布式多节点配置，当单个节点关闭时其他节点自动接管定时任务。 创建任务时传递自定义参数，方便任务处理后续业务逻辑。 构建项目 注意：我们本章项目需要结合上一章共同完成，有一点要注意的是任务在持久化到数据库内时会保存任务的全路径，如：com.hengyu.chapter39.timers.GoodStockCheckTimer ，quartz在运行任务时会根据任务全路径去执行，如果不一致则会提示找不到指定类，我们本章在创建项目时package需要跟上一章完全一致。 我们这里就不去直接创建新项目了，直接复制上一章项目的源码为新的项目命名为Chapter40 配置分布式在上一章配置文件quartz.properties中我们其实已经为分布式做好了相关配置，下面我们就来看一下分布式相关的配置。分布式相关配置： 1. org.quartz.scheduler.instanceId ： 定时任务的实例编号，如果手动指定需要保证每个节点的唯一性，因为quartz不允许出现两个相同instanceId的节点，我们这里指定为Auto就可以了，我们把生成编号的任务交给quartz。 2. org.quartz.jobStore.isClustered： 这个属性才是真正的开启了定时任务的分布式配置，当我们配置为true时quartz框架就会调用ClusterManager来初始化分布式节点。 3. org.quartz.jobStore.clusterCheckinInterval：配置了分布式节点的检查时间间隔，单位：毫秒。下面是quartz.properties配置文件配置信息： 1234567891011121314151617181920212223242526272829303132333435363738#调度器实例名称org.quartz.scheduler.instanceName = quartzScheduler#调度器实例编号自动生成org.quartz.scheduler.instanceId = AUTO#持久化方式配置org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX#持久化方式配置数据驱动，MySQL数据库org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate#quartz相关数据表前缀名org.quartz.jobStore.tablePrefix = QRTZ_#开启分布式部署org.quartz.jobStore.isClustered = true#配置是否使用org.quartz.jobStore.useProperties = false#分布式节点有效性检查时间间隔，单位：毫秒org.quartz.jobStore.clusterCheckinInterval = 10000#线程池实现类org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool#执行最大并发线程数量org.quartz.threadPool.threadCount = 10#线程优先级org.quartz.threadPool.threadPriority = 5#配置为守护线程，设置后任务将不会执行#org.quartz.threadPool.makeThreadsDaemons=true#配置是否启动自动加载数据库内的定时任务，默认trueorg.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true 当我们启动任务节点时，会根据org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread属性配置进行是否自动加载任务，默认true自动加载数据库内的任务到节点。 测试分布式上一章项目节点名称：quartz-cluster-node-first本章项目节点名称：quartz-cluster-node-second 由于我们quartz-cluster-node-first的商品库存检查定时任务是每隔30秒执行一次，所以任务除非手动清除否则是不会被清空的，在运行项目测试之前需要将application.yml配置文件的端口号、项目名称修改下，保证quartz-cluster-node-second与quartz-cluster-node-first端口号不一致，可以同时运行，修改后为： 12345spring: application: name: quzrtz-cluster-node-secondserver: port: 8082 然后修改相应控制台输出，为了能够区分任务执行者是具体的节点。 12345678Chapter40Application启动类修改日志输出：logger.info(&quot;【【【【【【定时任务分布式节点 - quartz-cluster-node-second 已启动】】】】】】&quot;);GoodAddTimer商品添加任务类修改日志输出：logger.info(&quot;分布式节点quartz-cluster-node-second，商品添加完成后执行任务，任务时间：{}&quot;,new Date());GoodStockCheckTimer商品库存检查任务类修改日志输出：logger.info(&quot;分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：{}&quot;,new Date()); 下面我们启动本章项目，查看控制台输出内容，如下所示： 12345672017-11-12 10:28:39.969 INFO 11048 --- [ main] c.hengyu.chapter39.Chapter40Application : 【【【【【【定时任务分布式节点 - quartz-cluster-node-second 已启动】】】】】】2017-11-12 10:28:41.930 INFO 11048 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-12 10:28:41.959 INFO 11048 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1510453719308 started.2017-11-12 10:28:51.963 INFO 11048 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: detected 1 failed or restarted instances.2017-11-12 10:28:51.963 INFO 11048 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: Scanning for instance &quot;yuqiyu1510450938654&quot;'s failed in-progress jobs.2017-11-12 10:28:51.967 INFO 11048 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: ......Freed 1 acquired trigger(s).2017-11-12 10:29:00.024 INFO 11048 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 10:29:00 CST 2017 可以看到项目启动完成后自动分配的instanceId为yuqiyu1510450938654，生成的规则是当前用户的名称+时间戳。然后ClusterManager分布式管理者自动介入进行扫描是否存在匹配的触发器任务，如果存在则会自动执行任务逻辑，而商品库存检查定时任务确实由quartz-cluster-node-second进行输出的。 测试任务自动漂移下面我们也需要把quartz-cluster-node-first的输出进行修改，如下所示： 12345678Chapter39Application启动类修改日志输出：logger.info(&quot;【【【【【【定时任务分布式节点 - quartz-cluster-node-first 已启动】】】】】】&quot;);GoodAddTimer商品添加任务类修改日志输出：logger.info(&quot;分布式节点quartz-cluster-node-first，商品添加完成后执行任务，任务时间：{}&quot;,new Date());GoodStockCheckTimer商品库存检查任务类修改日志输出：logger.info(&quot;分布式节点quartz-cluster-node-first，执行库存检查定时任务，执行时间：{}&quot;,new Date()); 接下来我们启动quartz-cluster-node-first，并查看控制台的输出内容： 1232017-11-12 10:34:09.750 INFO 192 --- [ main] c.hengyu.chapter39.Chapter39Application : 【【【【【【定时任务分布式节点 - quartz-cluster-node-first 已启动】】】】】】2017-11-12 10:34:11.690 INFO 192 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-12 10:34:11.714 INFO 192 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1510454049066 started. 项目启动完成后，定时节点并没有实例化ClusterManager来完成分布式节点的初始化，因为quartz检测到有其他的节点正在处理任务，这样也是保证了任务执行的唯一性。 关闭quartz-cluster-node-second我们关闭quartz-cluster-node-second运行的项目，预计的目的可以达到quartz-cluster-node-first会自动接管数据库内的任务，完成任务执行的自动漂移，我们来查看quartz-cluster-node-first的控制台输出内容： 12345672017-11-12 10:34:09.750 INFO 192 --- [ main] c.hengyu.chapter39.Chapter39Application : 【【【【【【定时任务分布式节点 - quartz-cluster-node-first 已启动】】】】】】2017-11-12 10:34:11.690 INFO 192 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-12 10:34:11.714 INFO 192 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1510454049066 started.2017-11-12 10:41:11.793 INFO 192 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: detected 1 failed or restarted instances.2017-11-12 10:41:11.793 INFO 192 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: Scanning for instance &quot;yuqiyu1510453719308&quot;'s failed in-progress jobs.2017-11-12 10:41:11.797 INFO 192 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: ......Freed 1 acquired trigger(s).2017-11-12 10:41:11.834 INFO 192 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-first，执行库存检查定时任务，执行时间：Sun Nov 12 10:41:11 CST 2017 控制台已经输出了持久的定时任务，输出节点是quartz-cluster-node-first，跟我们预计的一样，节点quartz-cluster-node-first完成了自动接管quartz-cluster-node-second的工作，而这个过程肯定有一段时间间隔，而这个间隔可以修改quartz.properties配置文件内的属性org.quartz.jobStore.clusterCheckinInterval进行调节。 关闭quartz-cluster-node-first我们同样可以测试启动任务节点quartz-cluster-node-second后，再关闭quartz-cluster-node-first任务节点，查看quartz-cluster-node-second控制台的输出内容： 12345672017-11-12 10:53:31.010 INFO 3268 --- [ main] c.hengyu.chapter39.Chapter40Application : 【【【【【【定时任务分布式节点 - quartz-cluster-node-second 已启动】】】】】】2017-11-12 10:53:32.967 INFO 3268 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-12 10:53:32.992 INFO 3268 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1510455210493 started.2017-11-12 10:53:52.999 INFO 3268 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: detected 1 failed or restarted instances.2017-11-12 10:53:52.999 INFO 3268 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: Scanning for instance &quot;yuqiyu1510454049066&quot;'s failed in-progress jobs.2017-11-12 10:53:53.003 INFO 3268 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: ......Freed 1 acquired trigger(s).2017-11-12 10:54:00.020 INFO 3268 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 10:54:00 CST 2017 得到的结果是同样可以完成任务的自动漂移。 如果两个节点同时启动，哪个节点先把节点信息注册到数据库就获得了优先执行权。 传递参数到任务我们平时在使用任务时，如果是针对性比较强的业务逻辑，肯定需要特定的参数来完成业务逻辑的实现。 下面我们来模拟商品秒杀的场景，当我们添加商品后自动添加一个商品提前五分钟的秒杀提醒，为关注该商品的用户发送提醒消息。我们在节点quartz-cluster-node-first中添加秒杀提醒任务，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.hengyu.chapter39.timers;import org.quartz.JobDataMap;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.scheduling.quartz.QuartzJobBean;/** * 商品秒杀提醒定时器 * 为关注该秒杀商品的用户进行推送提醒 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/12 * Time：9:23 * 码云：http://git.oschina.net/jnyqy * ======================== */public class GoodSecKillRemindTimerextends QuartzJobBean{ /** * logback */ private Logger logger = LoggerFactory.getLogger(GoodSecKillRemindTimer.class); /** * 任务指定逻辑 * @param jobExecutionContext * @throws JobExecutionException */ @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { //获取任务详情内的数据集合 JobDataMap dataMap = jobExecutionContext.getJobDetail().getJobDataMap(); //获取商品编号 Long goodId = dataMap.getLong(&quot;goodId&quot;); logger.info(&quot;分布式节点quartz-cluster-node-first，开始处理秒杀商品：{}，关注用户推送消息.&quot;,goodId); //.../ }} 在秒杀提醒任务逻辑中，我们通过获取JobDetail的JobDataMap集合来获取在创建任务的时候传递的参数集合，我们这里约定了goodId为商品的编号，在创建任务的时候传递到JobDataMap内，这样quartz在执行该任务的时候就会自动将参数传递到任务逻辑中，我们也就可以通过JobDataMap获取到对应的参数值。 设置秒杀提醒任务我们找到节点项目quartz-cluster-node-first中的GoodInfoService，编写方法buildGoodSecKillRemindTimer设置秒杀提醒任务，如下所示： 1234567891011121314151617181920212223242526/** * 构建商品秒杀提醒定时任务 * 设置五分钟后执行 * @throws Exception */ public void buildGoodSecKillRemindTimer(Long goodId) throws Exception { //任务名称 String name = UUID.randomUUID().toString(); //任务所属分组 String group = GoodSecKillRemindTimer.class.getName(); //秒杀开始时间 long startTime = System.currentTimeMillis() + 1000 * 5 * 60; JobDetail jobDetail = JobBuilder .newJob(GoodSecKillRemindTimer.class) .withIdentity(name,group) .build(); //设置任务传递商品编号参数 jobDetail.getJobDataMap().put(&quot;goodId&quot;,goodId); //创建任务触发器 Trigger trigger = TriggerBuilder.newTrigger().withIdentity(name,group).startAt(new Date(startTime)).build(); //将触发器与任务绑定到调度器内 scheduler.scheduleJob(jobDetail,trigger); } 我们模拟秒杀提醒时间是添加商品后的5分钟，我们通过调用jobDetail 实例的getJobDataMap方法就可以获取该任务数据集合，直接调用put方法就可以进行设置指定key的值，该集合继承了StringKeyDirtyFlagMap并且实现了Serializable序列化，因为需要将数据序列化到数据库的qrtz_job_details表内。修改保存商品方法，添加调用秒杀提醒任务： 12345678910111213141516/** * 保存商品基本信息 * @param good 商品实例 * @return */public Long saveGood(GoodInfoEntity good) throws Exception{ goodInfoRepository.save(good); //构建创建商品定时任务 buildCreateGoodTimer(); //构建商品库存定时任务 buildGoodStockTimer(); //构建商品描述提醒定时任务 buildGoodSecKillRemindTimer(good.getId()); return good.getId();} 添加测试商品下面我们调用节点quartz-cluster-node-first的测试Chapter39ApplicationTests.addGood方法完成商品的添加，由于我们的quartz-cluster-node-second项目并没有停止，所以我们在quartz-cluster-node-second项目的控制台查看输出内容： 123456789101112132017-11-12 11:45:00.008 INFO 11652 --- [ryBean_Worker-5] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:45:00 CST 20172017-11-12 11:45:30.013 INFO 11652 --- [ryBean_Worker-6] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:45:30 CST 20172017-11-12 11:45:48.230 INFO 11652 --- [ryBean_Worker-7] c.hengyu.chapter39.timers.GoodAddTimer : 分布式节点quartz-cluster-node-second，商品添加完成后执行任务，任务时间：Sun Nov 12 11:45:48 CST 20172017-11-12 11:46:00.008 INFO 11652 --- [ryBean_Worker-8] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:46:00 CST 20172017-11-12 11:46:30.016 INFO 11652 --- [ryBean_Worker-9] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:46:30 CST 20172017-11-12 11:47:00.011 INFO 11652 --- [yBean_Worker-10] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:47:00 CST 20172017-11-12 11:47:30.028 INFO 11652 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:47:30 CST 20172017-11-12 11:48:00.014 INFO 11652 --- [ryBean_Worker-2] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:48:00 CST 20172017-11-12 11:48:30.013 INFO 11652 --- [ryBean_Worker-3] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:48:30 CST 20172017-11-12 11:49:00.010 INFO 11652 --- [ryBean_Worker-4] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:49:00 CST 20172017-11-12 11:49:30.028 INFO 11652 --- [ryBean_Worker-5] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:49:30 CST 20172017-11-12 11:49:48.290 INFO 11652 --- [ryBean_Worker-6] c.h.c.timers.GoodSecKillRemindTimer : 分布式节点quartz-cluster-node-second，开始处理秒杀商品：15，关注用户推送消息.2017-11-12 11:50:00.008 INFO 11652 --- [ryBean_Worker-7] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Sun Nov 12 11:50:00 CST 2017 秒杀任务在添加完成商品后的五分钟开始执行的，而我们也正常的输出了传递过去的goodId商品编号的参数，而秒杀提醒任务执行一次后也被自动释放了。 总结本章主要是结合上一章完成了分布式任务的讲解，完成了测试持久化的定时任务自动漂移，以及如何向定时任务传递参数。当然在实际的开发过程中，任务创建是需要进行封装的，目的也是为了减少一些冗余代码以及方面后期统一维护定时任务。","link":"/quartz-cluster-node.html"},{"title":"Quartz分布式单节点持久化任务","text":"定时任务在企业项目比较常用到，几乎所有的项目都会牵扯该功能模块，定时任务一般会处理指定时间点执行某一些业务逻辑、间隔时间执行某一些业务逻辑等。 我们在之前有讲过SpringBoot是已经集成了定时任务的，详见：第二十六章：SpringBoot使用@Scheduled创建定时任务，那么我们本章将会采用外置的quartz定时任务框架来完成定时任务的分布式单节点持久化，我们为什么要持久化定时任务呢？ 在一些项目中定时任务可能是必不可少的，由于某种特殊的原因定时任务可能丢失，如重启定时任务服务项目后，原内存中的定时任务就会被完全释放！那对于我们来说可能是致命的问题。当然也有强制的办法解决这类问题，但是如果我们把定时任务持久化到数据库，像维护普通逻辑数据那样维护任务，就会避免项目中遇到的种种的特殊情况。 本章目标基于SpringBoot架构整合定时任务框架quartz来完成分布式单节点定时任务持久化，将任务持久化到数据库，更好的预防任务丢失。 构建项目我们使用idea开发工具创建一个SpringBoot项目，pom.xml依赖配置如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758...省略部分配置 &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;druid.version&gt;1.1.5&lt;/druid.version&gt; &lt;quartz.version&gt;2.3.0&lt;/quartz.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--spring data jpa相关--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据库相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--quartz相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--定时任务需要依赖context模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...省略部分配置 我们采用的是quartz官方最新版本2.3.0，新版本的任务调度框架做出了很多封装，使用也变得简易明了。创建初始化完成，下面我们来创建定时任务相关的Configuration配置。 QuartzConfigurationquartz与Spring相关框架的整合方式有很多种，我们今天采用jobDetail使用Spring Ioc托管方式来完成整合，我们可以在定时任务实例中使用Spring注入注解完成业务逻辑处理，下面我先把全部的配置贴出来再逐步分析，配置类如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.hengyu.chapter39.configuration;import org.quartz.spi.JobFactory;import org.quartz.spi.TriggerFiredBundle;import org.springframework.beans.factory.annotation.Autowire;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.ClassPathResource;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.quartz.SchedulerFactoryBean;import org.springframework.scheduling.quartz.SpringBeanJobFactory;import javax.sql.DataSource;/** * quartz定时任务配置 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/11/5 * Time：14:07 * 码云：http://git.oschina.net/jnyqy * ======================== * @author 恒宇少年 */@Configuration@EnableSchedulingpublic class QuartzConfiguration{ /** * 继承org.springframework.scheduling.quartz.SpringBeanJobFactory * 实现任务实例化方式 */ public static class AutowiringSpringBeanJobFactory extends SpringBeanJobFactory implements ApplicationContextAware { private transient AutowireCapableBeanFactory beanFactory; @Override public void setApplicationContext(final ApplicationContext context) { beanFactory = context.getAutowireCapableBeanFactory(); } /** * 将job实例交给spring ioc托管 * 我们在job实例实现类内可以直接使用spring注入的调用被spring ioc管理的实例 * @param bundle * @return * @throws Exception */ @Override protected Object createJobInstance(final TriggerFiredBundle bundle) throws Exception { final Object job = super.createJobInstance(bundle); /** * 将job实例交付给spring ioc */ beanFactory.autowireBean(job); return job; } } /** * 配置任务工厂实例 * @param applicationContext spring上下文实例 * @return */ @Bean public JobFactory jobFactory(ApplicationContext applicationContext) { /** * 采用自定义任务工厂 整合spring实例来完成构建任务 * see {@link AutowiringSpringBeanJobFactory} */ AutowiringSpringBeanJobFactory jobFactory = new AutowiringSpringBeanJobFactory(); jobFactory.setApplicationContext(applicationContext); return jobFactory; } /** * 配置任务调度器 * 使用项目数据源作为quartz数据源 * @param jobFactory 自定义配置任务工厂 * @param dataSource 数据源实例 * @return * @throws Exception */ @Bean(destroyMethod = &quot;destroy&quot;,autowire = Autowire.NO) public SchedulerFactoryBean schedulerFactoryBean(JobFactory jobFactory, DataSource dataSource) throws Exception { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); //将spring管理job自定义工厂交由调度器维护 schedulerFactoryBean.setJobFactory(jobFactory); //设置覆盖已存在的任务 schedulerFactoryBean.setOverwriteExistingJobs(true); //项目启动完成后，等待2秒后开始执行调度器初始化 schedulerFactoryBean.setStartupDelay(2); //设置调度器自动运行 schedulerFactoryBean.setAutoStartup(true); //设置数据源，使用与项目统一数据源 schedulerFactoryBean.setDataSource(dataSource); //设置上下文spring bean name schedulerFactoryBean.setApplicationContextSchedulerContextKey(&quot;applicationContext&quot;); //设置配置文件位置 schedulerFactoryBean.setConfigLocation(new ClassPathResource(&quot;/quartz.properties&quot;)); return schedulerFactoryBean; }} AutowiringSpringBeanJobFactory可以看到上面配置类中，AutowiringSpringBeanJobFactory我们继承了SpringBeanJobFactory 类，并且通过实现ApplicationContextAware 接口获取ApplicationContext设置方法，通过外部实例化时设置ApplicationContext实例对象，在createJobInstance方法内，我们采用AutowireCapableBeanFactory 来托管SpringBeanJobFactory 类中createJobInstance方法返回的定时任务实例，这样我们就可以在定时任务类内使用Spring Ioc相关的注解进行注入业务逻辑实例了。 JobFactory任务工厂是在本章配置调度器时所需要的实例，我们通过jobFactory方法注入ApplicationContext实例，来创建一个AutowiringSpringBeanJobFactory对象，并且将对象实例托管到Spring Ioc容器内。 SchedulerFactoryBean我们本章采用的是项目内部数据源的方式来设置调度器的jobSotre，官方quartz有两种持久化的配置方案。 第一种：采用quartz.properties配置文件配置独立的定时任务数据源，可以与使用项目的数据库完全独立。第二种：采用与创建项目统一个数据源，定时任务持久化相关的表与业务逻辑在同一个数据库内。 可以根据实际的项目需求采取不同的方案，我们本章主要是通过第二种方案来进行讲解，在上面配置类中可以看到方法schedulerFactoryBean内自动注入了JobFactory 实例，也就是我们自定义的AutowiringSpringBeanJobFactory任务工厂实例，另外一个参数就是DataSource，在我们引入spring-starter-data-jpa依赖后会根据application.yml文件内的数据源相关配置自动实例化DataSource实例，这里直接注入是没有问题的。 我们通过调用SchedulerFactoryBean对象的setConfigLocation方法来设置quartz定时任务框架的基本配置，配置文件所在位置：resources/quartz.properties =&gt; classpath:/quartz.properties下。 注意：quartz.properties配置文件一定要放在classpath下，放在别的位置有部分功能不会生效。 下面我们来看下quartz.properties文件内的配置，如下所示： 12345678910111213141516171819202122232425262728293031323334353637#调度器实例名称org.quartz.scheduler.instanceName = quartzScheduler#调度器实例编号自动生成org.quartz.scheduler.instanceId = AUTO#持久化方式配置org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX#持久化方式配置数据驱动，MySQL数据库org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate#quartz相关数据表前缀名org.quartz.jobStore.tablePrefix = QRTZ_#开启分布式部署org.quartz.jobStore.isClustered = true#配置是否使用org.quartz.jobStore.useProperties = false#分布式节点有效性检查时间间隔，单位：毫秒org.quartz.jobStore.clusterCheckinInterval = 20000#线程池实现类org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool#执行最大并发线程数量org.quartz.threadPool.threadCount = 10#线程优先级org.quartz.threadPool.threadPriority = 5#配置为守护线程，设置后任务将不会执行#org.quartz.threadPool.makeThreadsDaemons=true#配置是否启动自动加载数据库内的定时任务，默认trueorg.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true 由于我们下一章需要做分布式多节点自动交付高可用，本章的配置文件加入了分布式相关的配置。在上面配置中org.quartz.jobStore.class与org.quartz.jobStore.driverDelegateClass是定时任务持久化的关键配置，配置了数据库持久化定时任务以及采用MySQL数据库进行连接，当然这里我们也可以配置其他的数据库，如下所示：PostgreSQL ： org.quartz.impl.jdbcjobstore.PostgreSQLDelegateSybase : org.quartz.impl.jdbcjobstore.SybaseDelegateMSSQL : org.quartz.impl.jdbcjobstore.MSSQLDelegateHSQLDB : org.quartz.impl.jdbcjobstore.HSQLDBDelegateOracle : org.quartz.impl.jdbcjobstore.oracle.OracleDelegate org.quartz.jobStore.tablePrefix属性配置了定时任务数据表的前缀，在quartz官方提供的创建表SQL脚本默认就是qrtz_，在对应的XxxDelegate驱动类内也是使用的默认值，所以这里我们如果修改表名前缀，配置可以去掉。 org.quartz.jobStore.isClustered 属性配置了开启定时任务分布式功能，再开启分布式时对应属性org.quartz.scheduler.instanceId 改成Auto配置即可，实例唯一标识会自动生成，这个标识具体生成的内容，我们一会在运行的控制台就可以看到了，定时任务分布式准备好后会输出相关的分布式节点配置信息。 创建表SQL会在本章源码resources目录下，源码地址https://gitee.com/hengboy/spring-boot-chapter。 准备测试我们先来创建一个简单的商品数据表，建表SQL如下所示： 12345678DROP TABLE IF EXISTS `basic_good_info`;CREATE TABLE `basic_good_info` ( `BGI_ID` int(11) NOT NULL AUTO_INCREMENT COMMENT '商品编号', `BGI_NAME` varchar(20) DEFAULT NULL COMMENT '商品名称', `BGI_PRICE` decimal(8,2) DEFAULT NULL COMMENT '单价', `BGI_UNIT` varchar(10) DEFAULT NULL COMMENT '单位', PRIMARY KEY (`BGI_ID`)) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8 COMMENT='商品基本信息'; GoodEntity我们先来针对表basic_good_info创建一个实体，并且添加JPA相关的配置，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.hengyu.chapter39.good.entity;import lombok.Data;import javax.persistence.*;import java.math.BigDecimal;/** * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/5 * Time：14:59 * 码云：http://git.oschina.net/jnyqy * ======================== */@Entity@Table(name = &quot;basic_good_info&quot;)@Datapublic class GoodInfoEntity{ /** * 商品编号 */ @Id @GeneratedValue @Column(name = &quot;bgi_id&quot;) private Long id; /** * 商品名称 */ @Column(name = &quot;bgi_name&quot;) private String name; /** * 商品单位 */ @Column(name = &quot;bgi_unit&quot;) private String unit; /** * 商品单价 */ @Column(name = &quot;bgi_price&quot;) private BigDecimal price;} 下面我们根据商品实体来创建JPA接口，如下所示： 12345678910111213/** * ======================== * Created with IntelliJ IDEA. * Date：2017/11/5 * Time：14:55 * 码云：http://git.oschina.net/jnyqy * ======================== * @author 恒宇少年 */public interface GoodInfoRepository extends JpaRepository&lt;GoodInfoEntity,Long&gt;{} 接下来我们再来添加一个商品添加的控制器方法，如下所示： 1234567891011121314151617181920212223242526272829/** * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/5 * Time：15:02 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestController@RequestMapping(value = &quot;/good&quot;)public class GoodController{ /** * 商品业务逻辑实现 */ @Autowired private GoodInfoService goodInfoService; /** * 添加商品 * @return */ @RequestMapping(value = &quot;/save&quot;) public Long save(GoodInfoEntity good) throws Exception { return goodInfoService.saveGood(good); }} 在请求商品添加方法时，我们调用了GoodInfoService内的saveGood方法，传递一个商品的实例作为参数。我们接下来看看该类内相关代码，如下所示： 123456789101112131415161718192021222324252627282930313233343536/** * 商品业务逻辑 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/5 * Time：15:04 * 码云：http://git.oschina.net/jnyqy * ======================== */@Service@Transactional(rollbackFor = Exception.class)public class GoodInfoService{ /** * 注入任务调度器 */ @Autowired private Scheduler scheduler; /** * 商品数据接口 */ @Autowired private GoodInfoRepository goodInfoRepository; /** * 保存商品基本信息 * @param good 商品实例 * @return */ public Long saveGood(GoodInfoEntity good) throws Exception { goodInfoRepository.save(good); return good.getId(); } 我们只是作为保存商品的操作，下面我们来模拟一个需求，在商品添加完成后1分钟我们通知后续的逻辑进行下一步处理，同时开始商品库存定时检查的任务。 定义商品添加定时任务我们先来创建一个任务实例，并且继承org.springframework.scheduling.quartz.QuartzJobBean抽象类，重写父抽象类内的executeInternal方法来实现任务的主体逻辑。如下所示： 12345678910111213141516171819202122232425262728/** * 商品添加定时任务实现类 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/11/5 * Time：14:47 * 码云：http://git.oschina.net/jnyqy * ======================== * @author 恒宇少年 */public class GoodAddTimer extends QuartzJobBean{ /** * logback */ static Logger logger = LoggerFactory.getLogger(GoodAddTimer.class); /** * 定时任务逻辑实现方法 * 每当触发器触发时会执行该方法逻辑 * @param jobExecutionContext 任务执行上下文 * @throws JobExecutionException */ @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { logger.info(&quot;商品添加完成后执行任务，任务时间：{}&quot;,new Date()); } 在任务主体逻辑内，我们只是做了一个简单的输出任务执行的时间，下面我们再来创建库存定时检查任务。 定义商品库存检查任务同样需要继承org.springframework.scheduling.quartz.QuartzJobBean抽象类实现抽象类内的executeInternal方法，如下所示： 123456789101112131415161718192021222324/** * 商品库存检查定时任务 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/5 * Time：15:47 * 码云：http://git.oschina.net/jnyqy * ======================== */public class GoodStockCheckTimer extends QuartzJobBean{ /** * logback */ static Logger logger = LoggerFactory.getLogger(GoodStockCheckTimer.class); @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { logger.info(&quot;执行库存检查定时任务，执行时间：{}&quot;,new Date()); }} 都是简单的做了下日志的输出，下面我们需要重构GoodInfoService内的saveGood方法，对应的添加上面两个任务的创建。 设置商品添加任务到调度器在GoodInfoService类内添加buildCreateGoodTimer方法用于实例化商品添加任务，如下所示： 123456789101112131415161718/** * 构建创建商品定时任务 */ public void buildCreateGoodTimer() throws Exception { //设置开始时间为1分钟后 long startAtTime = System.currentTimeMillis() + 1000 * 60; //任务名称 String name = UUID.randomUUID().toString(); //任务所属分组 String group = GoodAddTimer.class.getName(); //创建任务 JobDetail jobDetail = JobBuilder.newJob(GoodAddTimer.class).withIdentity(name,group).build(); //创建任务触发器 Trigger trigger = TriggerBuilder.newTrigger().withIdentity(name,group).startAt(new Date(startAtTime)).build(); //将触发器与任务绑定到调度器内 scheduler.scheduleJob(jobDetail, trigger); } 在上面方法中我们定义的GoodAddTimer实例只运行一次，在商品添加完成后延迟1分钟进行调用任务主体逻辑。 其中任务的名称以及任务的分组是为了区分任务做的限制，在同一个分组下如果加入同样名称的任务，则会提示任务已经存在，添加失败的提示。 我们通过JobDetail来构建一个任务实例，设置GoodAddTimer类作为任务运行目标对象，当任务被触发时就会执行GoodAddTimer内的executeInternal方法。 一个任务需要设置对应的触发器，触发器也分为很多种，该任务中我们并没有采用cron表达式来设置触发器，而是调用startAt方法设置任务开始执行时间。 最后将任务以及任务的触发器共同交付给任务调度器，这样就完成了一个任务的设置。 设置商品库存检查到任务调度器在GoodInfoService类内添加buildGoodStockTimer方法用于实例化商品添加任务，如下所示： 12345678910111213141516171819/** * 构建商品库存定时任务 * @throws Exception */ public void buildGoodStockTimer() throws Exception { //任务名称 String name = UUID.randomUUID().toString(); //任务所属分组 String group = GoodStockCheckTimer.class.getName(); CronScheduleBuilder scheduleBuilder = CronScheduleBuilder.cronSchedule(&quot;0/30 * * * * ?&quot;); //创建任务 JobDetail jobDetail = JobBuilder.newJob(GoodStockCheckTimer.class).withIdentity(name,group).build(); //创建任务触发器 Trigger trigger = TriggerBuilder.newTrigger().withIdentity(name,group).withSchedule(scheduleBuilder).build(); //将触发器与任务绑定到调度器内 scheduler.scheduleJob(jobDetail, trigger); } 该任务的触发器我们采用了cron表达式来设置，每隔30秒执行一次任务主体逻辑。 任务触发器在创建时cron表达式可以搭配startAt方法来同时使用。 下面我们修改GoodInfoService内的saveGood方法，分别调用设置任务的两个方法，如下所示： 1234567891011121314/** * 保存商品基本信息 * @param good 商品实例 * @return */ public Long saveGood(GoodInfoEntity good) throws Exception { goodInfoRepository.save(good); //构建创建商品定时任务 buildCreateGoodTimer(); //构建商品库存定时任务 buildGoodStockTimer(); return good.getId(); } 下面我们就来测试下任务是否可以顺序的被持久化到数据库，并且是否可以在重启服务后执行重启前添加的任务。 测试下面我们来启动项目，启动成功后，我们来查看控制台输出的分布式节点的信息，如下所示： 1234562017-11-05 18:09:40.052 INFO 7708 --- [ main] c.hengyu.chapter39.Chapter39Application : 【【【【【【定时任务分布式节点 - 1 已启动】】】】】】2017-11-05 18:09:42.005 INFO 7708 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-05 18:09:42.027 INFO 7708 --- [lerFactoryBean]] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: detected 1 failed or restarted instances.2017-11-05 18:09:42.027 INFO 7708 --- [lerFactoryBean]] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: Scanning for instance &quot;yuqiyu1509876084785&quot;'s failed in-progress jobs.2017-11-05 18:09:42.031 INFO 7708 --- [lerFactoryBean]] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: ......Freed 1 acquired trigger(s).2017-11-05 18:09:42.033 INFO 7708 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1509876579404 started. 定时任务是在项目启动后2秒进行执行初始化，并且通过ClusterManager来完成了instance的创建，创建的节点唯一标识为yuqiyu1509876084785。 编写商品控制器请求方法测试用例，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041@RunWith(SpringRunner.class)@SpringBootTestpublic class Chapter39ApplicationTests { /** * 模拟mvc测试对象 */ private MockMvc mockMvc; /** * web项目上下文 */ @Autowired private WebApplicationContext webApplicationContext; /** * 所有测试方法执行之前执行该方法 */ @Before public void before() { //获取mockmvc对象实例 mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); } /** * 测试添加商品 * @throws Exception */ @Test public void addGood() throws Exception { MvcResult result = mockMvc.perform(MockMvcRequestBuilders.post(&quot;/good/save&quot;) .param(&quot;name&quot;,&quot;西瓜&quot;) .param(&quot;unit&quot;,&quot;斤&quot;) .param(&quot;price&quot;,&quot;12.88&quot;) ) .andDo(MockMvcResultHandlers.print()) .andExpect(MockMvcResultMatchers.status().is(200)) .andReturn(); result.getResponse().setCharacterEncoding(&quot;UTF-8&quot;); System.out.println(result.getResponse().getContentAsString()); } 测试用例相关文章请访问第三十五章：SpringBoot与单元测试的小秘密，我们来执行addGood测试方法，查看控制台输出，如下所示： 12345678....省略部分输出Hibernate: insert into basic_good_info (bgi_name, bgi_price, bgi_unit) values (?, ?, ?)2017-11-05 18:06:35.699 TRACE 7560 --- [ main] o.h.type.descriptor.sql.BasicBinder : binding parameter [1] as [VARCHAR] - [西瓜]2017-11-05 18:06:35.701 TRACE 7560 --- [ main] o.h.type.descriptor.sql.BasicBinder : binding parameter [2] as [NUMERIC] - [12.88]2017-11-05 18:06:35.701 TRACE 7560 --- [ main] o.h.type.descriptor.sql.BasicBinder : binding parameter [3] as [VARCHAR] - [斤]....省略部分输出8....省略部分输出 可以看到我们的商品已被成功的写入到数据库并且输出的主键值，我们的任务是否也成功的被写入到数据库了呢？我们来查看qrtz_job_details表内任务列表，如下所示： 123schedulerFactoryBean 7567c9d7-76f5-47f3-bc5d-b934f4c1063b com.hengyu.chapter39.timers.GoodStockCheckTimer com.hengyu.chapter39.timers.GoodStockCheckTimer 0 0 0 0 0xACED0005737200156F72672E71756172747A2E4A6F62446174614D61709FB083E8BFA9B0CB020000787200266F72672E71756172747A2E7574696C732E537472696E674B65794469727479466C61674D61708208E8C3FBC55D280200015A0013616C6C6F77735472616E7369656E74446174617872001D6F72672E71756172747A2E7574696C732E4469727479466C61674D617013E62EAD28760ACE0200025A000564697274794C00036D617074000F4C6A6176612F7574696C2F4D61703B787000737200116A6176612E7574696C2E486173684D61700507DAC1C31660D103000246000A6C6F6164466163746F724900097468726573686F6C6478703F40000000000010770800000010000000007800schedulerFactoryBean e5e08ab0-9be3-43fb-93b8-b9490432a5d7 com.hengyu.chapter39.timers.GoodAddTimer com.hengyu.chapter39.timers.GoodAddTimer 0 0 0 0 0xACED0005737200156F72672E71756172747A2E4A6F62446174614D61709FB083E8BFA9B0CB020000787200266F72672E71756172747A2E7574696C732E537472696E674B65794469727479466C61674D61708208E8C3FBC55D280200015A0013616C6C6F77735472616E7369656E74446174617872001D6F72672E71756172747A2E7574696C732E4469727479466C61674D617013E62EAD28760ACE0200025A000564697274794C00036D617074000F4C6A6176612F7574696C2F4D61703B787000737200116A6176612E7574696C2E486173684D61700507DAC1C31660D103000246000A6C6F6164466163746F724900097468726573686F6C6478703F40000000000010770800000010000000007800 任务已经被成功的持久化到数据库内，等待1分钟后查看控制台输出内容如下所示： 1232017-11-05 18:12:30.017 INFO 7708 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 执行库存检查定时任务，执行时间：Sun Nov 05 18:12:30 CST 20172017-11-05 18:13:00.009 INFO 7708 --- [ryBean_Worker-2] c.h.c.timers.GoodStockCheckTimer : 执行库存检查定时任务，执行时间：Sun Nov 05 18:13:00 CST 20172017-11-05 18:13:02.090 INFO 7708 --- [ryBean_Worker-3] c.hengyu.chapter39.timers.GoodAddTimer : 商品添加完成后执行任务，任务时间：Sun Nov 05 18:13:02 CST 2017 根据输出的内容来判定完全吻合我们的配置参数，库存检查为30秒执行一次，而添加成功后的提醒则是1分钟后执行一次。执行完成后就会被直接销毁，我们再来查看数据库表qrtz_job_details，这时就可以看到还剩下1个任务。 重启服务任务是否自动执行？下面我们把项目重启下，然后观察控制台的输出内容，如下所示： 12345672017-11-05 18:15:54.018 INFO 7536 --- [ main] c.hengyu.chapter39.Chapter39Application : 【【【【【【定时任务分布式节点 - 1 已启动】】】】】】2017-11-05 18:15:55.975 INFO 7536 --- [lerFactoryBean]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2017-11-05 18:15:56.000 INFO 7536 --- [lerFactoryBean]] org.quartz.core.QuartzScheduler : Scheduler schedulerFactoryBean_$_yuqiyu1509876953202 started.2017-11-05 18:16:15.999 INFO 7536 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: detected 1 failed or restarted instances.2017-11-05 18:16:16.000 INFO 7536 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: Scanning for instance &quot;yuqiyu1509876579404&quot;'s failed in-progress jobs.2017-11-05 18:16:16.005 INFO 7536 --- [_ClusterManager] o.s.s.quartz.LocalDataSourceJobStore : ClusterManager: ......Freed 1 acquired trigger(s).2017-11-05 18:16:16.041 INFO 7536 --- [ryBean_Worker-1] c.h.c.timers.GoodStockCheckTimer : 执行库存检查定时任务，执行时间：Sun Nov 05 18:16:16 CST 2017 可以看到成功的自动执行了我们在重启之前配置的任务。 总结本章主要讲解了SpringBoot整合quartz定时任务框架，完成了分布式单节点任务持久化，下一章我们会讲解任务参数传递以及分布式多节点任务自动负载。","link":"/quartz-single-node.html"},{"title":"Quartz在SpringBoot2.x内的自动化配置","text":"在新版本的SpringBoot2.0发布后，急迫尝鲜的我将相关的项目已经更换为最新版本，在SpringBoot源码GitHub看到更新日志，表明了针对Quartz新版本进行了 AutoConfiguration自动化配置，省去了很多繁琐的配置。 官网更新日志 Auto-configuration support is now include for the Quartz Scheduler. We’ve also added a new spring-boot-starter-quartz starter POM.You can use in-memory JobStores, or a full JDBC-based store. All JobDetail, Calendar and Trigger beans from your Spring application context will be automatically registered with the Scheduler.For more details read the new “Quartz Scheduler” section of the reference documentation. SpringBoot2.0版本集成了Quartz2.3.0官网最新版本。 本章目标使用SpringBoot2.0新特性完成Quartz自动化配置。 构建项目在前面章节第四十章：基于SpringBoot &amp; Quartz完成定时任务分布式多节点负载持久化内我们已经通过添加配置的方式完成集成，为了本章的方便直接复制之前的项目，在基础上进行修改。打开pom.xml配置文件，SpringBoot为我们提供了对应的依赖，我们将之前的quartz相关依赖删除，替换为spring-boot-starter-quartz，如下所示： 123456789101112131415161718&lt;!--quartz相关依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt;&lt;/dependency&gt;&gt;&gt;&gt;&gt;替换为：&gt;&gt;&gt;&gt;&lt;!--quartz依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt;...... 删除QuartzConfiguration配置类在之前章节我们使用QuartzConfiguration配置类来完成了Quartz需要的一系列配置，如：JobFactory、SchedulerFactoryBean等，在我们添加spring-boot-starter-quartz依赖后就不需要主动声明工厂类，因为spring-boot-starter-quartz已经为我们自动化配置好了。 自动化配置源码我们找到Idea的External Libraries并且展开spring-boot-autoconfigure-2.0.0.RELEASE.jar，找到org.springframework.boot.autoconfigure.quartz，该目录就是SpringBoot为我们提供的Quartz自动化配置源码实现，在该目录下有如下所示几个类： AutowireCapableBeanJobFactory该类替代了我们之前在QuartzConfiguration配置类的AutowiringSpringBeanJobFactory内部类实现，主要作用是我们自定义的QuartzJobBean子类被Spring IOC进行托管，可以在定时任务类内使用注入任意被Spring IOC托管的类。 JobStoreType该类是一个枚举类型，定义了对应application.yml、application.properties文件内spring.quartz.job-store-type配置，其目的是配置quartz任务的数据存储方式，分别为：MEMORY（内存方式：默认）、JDBC（数据库方式）。 QuartzAutoConfiguration该类是自动配置的主类，内部配置了SchedulerFactoryBean以及JdbcStoreTypeConfiguration，使用QuartzProperties作为属性自动化配置条件。 QuartzDataSourceInitializer该类主要用于数据源初始化后的一些操作，根据不同平台类型的数据库进行选择不同的数据库脚本。 QuartzProperties该类对应了spring.quartz在application.yml、application.properties文件内开头的相关配置。 SchedulerFactoryBeanCustomizer这是一个接口，我们实现该接口后并且将实现类使用Spring IOC托管，可以完成SchedulerFactoryBean的个性化设置，这里的设置完全可以对SchedulerFactoryBean做出全部的设置变更。 spring.quartz配置看到QuartzAutoConfiguration类源码，我们知道了，想要使用自动化配置，需要满足QuartzProperties属性配置类的初始化，所以我们需要再application.yml、application.properties配置文件内添加对应的配置信息，如下所示： 1234567891011121314151617181920212223242526spring: quartz: #相关属性配置 properties: org: quartz: scheduler: instanceName: clusteredScheduler instanceId: AUTO jobStore: class: org.quartz.impl.jdbcjobstore.JobStoreTX driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate tablePrefix: QRTZ_ isClustered: true clusterCheckinInterval: 10000 useProperties: false threadPool: class: org.quartz.simpl.SimpleThreadPool threadCount: 10 threadPriority: 5 threadsInheritContextClassLoaderOfInitializingThread: true #数据库方式 job-store-type: jdbc #初始化表结构 #jdbc: #initialize-schema: never spring.quartz.properties该配置其实代替了之前的quartz.properties，我们把之前quartz.properties配置文件内的所有配置转换成YAML风格，对应的添加在该配置下即可，在QuartzAutoConfiguration类内，会自动调用SchedulerFactoryBean的setQuartzProperties方法，把spring.quartz.properties内的所有配置进行设置。1234567891011@Bean@ConditionalOnMissingBeanpublic SchedulerFactoryBean quartzScheduler() { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); schedulerFactoryBean.setJobFactory(new AutowireCapableBeanJobFactory(this.applicationContext.getAutowireCapableBeanFactory())); // 如果配置了spring.quartz.properties if (!this.properties.getProperties().isEmpty()) { // 将所有properties设置到QuartzProperties schedulerFactoryBean.setQuartzProperties(this.asProperties(this.properties.getProperties())); }......省略部分代码 spring.quartz.job-store-type设置quartz任务的数据持久化方式，默认是内存方式，我们这里沿用之前的方式，配置JDBC以使用数据库方式持久化任务。 spring.quartz.jdbc.initialize-schema 该配置目前版本没有生效，根据官网文档查看，其目的是自动将quartz需要的数据表通过配置方式进行初始化。 测试 启动项目 打开浏览器访问http://localhost:8083/good/save?name=abcd&amp;unit=斤&amp;price=12.5进行添加定时任务 查看控制台输出123456789101112131415161718 22:55:18.812 INFO 17161 --- [ main] c.hengyu.chapter39.Chapter47Application : 【【【【【【定时任务分布式节点 - quartz-cluster-node-second 已启动】】】】】】2018-03-06 22:55:20.772 INFO 17161 --- [uartzScheduler]] o.s.s.quartz.SchedulerFactoryBean : Starting Quartz Scheduler now, after delay of 2 seconds2018-03-06 22:55:20.793 INFO 17161 --- [uartzScheduler]] org.quartz.core.QuartzScheduler : Scheduler quartzScheduler_$_yuqiyudeMacBook-Pro.local1520348117910 started.2018-03-06 22:56:20.103 INFO 17161 --- [nio-8083-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2018-03-06 22:56:20.103 INFO 17161 --- [nio-8083-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2018-03-06 22:56:20.121 INFO 17161 --- [nio-8083-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 18 msHibernate: select next_val as id_val from hibernate_sequence for updateHibernate: update hibernate_sequence set next_val= ? where next_val=?Hibernate: insert into basic_good_info (bgi_name, bgi_price, bgi_unit, bgi_id) values (?, ?, ?, ?)2018-03-06 22:56:20.268 TRACE 17161 --- [nio-8083-exec-1] o.h.type.descriptor.sql.BasicBinder : binding parameter [1] as [VARCHAR] - [abcd]2018-03-06 22:56:20.269 TRACE 17161 --- [nio-8083-exec-1] o.h.type.descriptor.sql.BasicBinder : binding parameter [2] as [NUMERIC] - [12.5]2018-03-06 22:56:20.269 TRACE 17161 --- [nio-8083-exec-1] o.h.type.descriptor.sql.BasicBinder : binding parameter [3] as [VARCHAR] - [斤]2018-03-06 22:56:20.269 TRACE 17161 --- [nio-8083-exec-1] o.h.type.descriptor.sql.BasicBinder : binding parameter [4] as [BIGINT] - [1]2018-03-06 22:56:47.253 INFO 17161 --- [eduler_Worker-1] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Tue Mar 06 22:56:47 CST 20182018-03-06 22:57:00.012 INFO 17161 --- [eduler_Worker-2] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Tue Mar 06 22:57:00 CST 20182018-03-06 22:57:20.207 INFO 17161 --- [eduler_Worker-3] c.hengyu.chapter39.timers.GoodAddTimer : 分布式节点quartz-cluster-node-second，商品添加完成后执行任务，任务时间：Tue Mar 06 22:57:20 CST 20182018-03-06 22:57:30.013 INFO 17161 --- [eduler_Worker-4] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Tue Mar 06 22:57:30 CST 20182018-03-06 22:58:00.014 INFO 17161 --- [eduler_Worker-5] c.h.c.timers.GoodStockCheckTimer : 分布式节点quartz-cluster-node-second，执行库存检查定时任务，执行时间：Tue Mar 06 22:58:00 CST 2018 根据控制台内容，可以看到我们的定时任务已经正常的开始执行，当然我们如果打开多个节点同样可以实现任务自动漂移的效果。 总结综上所述我们已经完成了SpringBoot2.0集成Quartz，我们只需要添加依赖、添加配置即可，别的不需要做任何代码编写。","link":"/quartz-springboot2-starter.html"},{"title":"消息队列RabbitMQ消息延时消费","text":"在2018-3-1日SpringBoot官方发版了2.0.0.RELEASE最新版本，新版本完全基于Spring5.0来构建，JDK最低支持也从原来的1.6也改成了1.8，不再兼容1.8以下的版本，更多新特性请查看官方文档。 本章目标基于SpringBoot整合RabbitMQ完成消息延迟消费。 构建项目注意前言 由于SpringBoot的内置扫描机制，我们如果不自动配置扫描路径，请保持下面rabbitmq-common模块内的配置可以被SpringBoot扫描到，否则不会自动创建队列，控制台会输出404的错误信息。 我们本章采用2.0.0.RELEASE版本的SpringBoot，添加相关的依赖如下所示： 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;......&lt;dependencies&gt; &lt;!--rabbbitMQ相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--spring boot tester--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--fast json依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.40&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...... 我们仍然采用多模块的方式来测试队列的Provider以及Consumer。 队列公共模块我们先来创建一个名为rabbitmq-common公共依赖模块（Create New Maven Module）在公共模块内添加一个QueueEnum队列枚举配置，该枚举内配置队列的Exchange、QueueName、RouteKey等相关内容，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.hengyu.rabbitmq.lazy.enums;import lombok.Getter;/** * 消息队列枚举配置 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/3 * Time：下午4:33 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Getterpublic enum QueueEnum { /** * 消息通知队列 */ MESSAGE_QUEUE(&quot;message.center.direct&quot;, &quot;message.center.create&quot;, &quot;message.center.create&quot;), /** * 消息通知ttl队列 */ MESSAGE_TTL_QUEUE(&quot;message.center.topic.ttl&quot;, &quot;message.center.create.ttl&quot;, &quot;message.center.create.ttl&quot;); /** * 交换名称 */ private String exchange; /** * 队列名称 */ private String name; /** * 路由键 */ private String routeKey; QueueEnum(String exchange, String name, String routeKey) { this.exchange = exchange; this.name = name; this.routeKey = routeKey; }} 可以看到MESSAGE_QUEUE队列配置跟我们之前章节的配置一样，而我们另外新创建了一个后缀为ttl的消息队列配置。我们采用的这种方式是RabbitMQ消息队列其中一种的延迟消费模块，通过配置队列消息过期后转发的形式。 这种模式比较简单，我们需要将消息先发送到ttl延迟队列内，当消息到达过期时间后会自动转发到ttl队列内配置的转发Exchange以及RouteKey绑定的队列内完成消息消费。 下面我们来模拟消息通知的延迟消费场景，先来创建一个名为MessageRabbitMqConfiguration的队列配置类，该配置类内添加消息通知队列配置以及消息通过延迟队列配置，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * 消息通知 - 消息队列配置信息 * * @author：恒宇少年 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/3 * Time：下午4:32 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Configurationpublic class MessageRabbitMqConfiguration { /** * 消息中心实际消费队列交换配置 * * @return */ @Bean DirectExchange messageDirect() { return (DirectExchange) ExchangeBuilder .directExchange(QueueEnum.MESSAGE_QUEUE.getExchange()) .durable(true) .build(); } /** * 消息中心延迟消费交换配置 * * @return */ @Bean DirectExchange messageTtlDirect() { return (DirectExchange) ExchangeBuilder .directExchange(QueueEnum.MESSAGE_TTL_QUEUE.getExchange()) .durable(true) .build(); } /** * 消息中心实际消费队列配置 * * @return */ @Bean public Queue messageQueue() { return new Queue(QueueEnum.MESSAGE_QUEUE.getName()); } /** * 消息中心TTL队列 * * @return */ @Bean Queue messageTtlQueue() { return QueueBuilder .durable(QueueEnum.MESSAGE_TTL_QUEUE.getName()) // 配置到期后转发的交换 .withArgument(&quot;x-dead-letter-exchange&quot;, QueueEnum.MESSAGE_QUEUE.getExchange()) // 配置到期后转发的路由键 .withArgument(&quot;x-dead-letter-routing-key&quot;, QueueEnum.MESSAGE_QUEUE.getRouteKey()) .build(); } /** * 消息中心实际消息交换与队列绑定 * * @param messageDirect 消息中心交换配置 * @param messageQueue 消息中心队列 * @return */ @Bean Binding messageBinding(DirectExchange messageDirect, Queue messageQueue) { return BindingBuilder .bind(messageQueue) .to(messageDirect) .with(QueueEnum.MESSAGE_QUEUE.getRouteKey()); } /** * 消息中心TTL绑定实际消息中心实际消费交换机 * * @param messageTtlQueue * @param messageTtlDirect * @return */ @Bean public Binding messageTtlBinding(Queue messageTtlQueue, DirectExchange messageTtlDirect) { return BindingBuilder .bind(messageTtlQueue) .to(messageTtlDirect) .with(QueueEnum.MESSAGE_TTL_QUEUE.getRouteKey()); }} 我们声明了消息通知队列的相关Exchange、Queue、Binding等配置，将message.center.create队列通过路由键message.center.create绑定到了message.center.direct交换上。 除此之外，我们还添加了消息通知延迟队列的Exchange、Queue、Binding等配置，将message.center.create.ttl队列通过message.center.create.ttl路由键绑定到了message.center.topic.ttl交换上。 我们仔细来看看messageTtlQueue延迟队列的配置，跟messageQueue队列配置不同的地方这里多出了x-dead-letter-exchange、x-dead-letter-routing-key两个参数，而这两个参数就是配置延迟队列过期后转发的Exchange、RouteKey，只要在创建队列时对应添加了这两个参数，在RabbitMQ管理平台看到的队列配置就不仅是单纯的Direct类型的队列类型，如下图所示： 在上图内我们可以看到message.center.create.ttl队列多出了DLX、DLK的配置，这就是RabbitMQ内死信交换的标志。满足死信交换的条件，在官方文档中表示： Messages from a queue can be ‘dead-lettered’; that is, republished to another exchange when any of the following events occur: The message is rejected (basic.reject or basic.nack) with requeue=false,The TTL for the message expires; orThe queue length limit is exceeded. 该消息被拒绝（basic.reject或 basic.nack），requeue = false 消息的TTL过期 队列长度限制已超出官方文档地址 我们需要满足上面的其中一种方式就可以了，我们采用满足第二个条件，采用过期的方式。 队列消息提供者我们再来创建一个名为rabbitmq-lazy-provider的模块(Create New Maven Module)，并且在pom.xml配置文件内添加rabbitmq-common模块的依赖，如下所示： 123456&lt;!--添加公共模块依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.hengyu&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 配置队列在resource下创建一个名为application.yml的配置文件，在该配置文件内添加如下配置信息： 123456789spring: #rabbitmq消息队列配置信息 rabbitmq: host: localhost port: 5672 username: guest password: guest virtual-host: /hengboy publisher-confirms: true 消息提供者类接下来我们来创建名为MessageProvider消息提供者类，用来发送消息内容到消息通知延迟队列，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 消息通知 - 提供者 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/3 * Time：下午4:40 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Componentpublic class MessageProvider { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(MessageProvider.class); /** * RabbitMQ 模版消息实现类 */ @Autowired private AmqpTemplate rabbitMqTemplate; /** * 发送延迟消息 * * @param messageContent 消息内容 * @param exchange 队列交换 * @param routerKey 队列交换绑定的路由键 * @param delayTimes 延迟时长，单位：毫秒 */ public void sendMessage(Object messageContent, String exchange, String routerKey, final long delayTimes) { if (!StringUtils.isEmpty(exchange)) { logger.info(&quot;延迟：{}毫秒写入消息队列：{}，消息内容：{}&quot;, delayTimes, routerKey, JSON.toJSONString(messageContent)); // 执行发送消息到指定队列 rabbitMqTemplate.convertAndSend(exchange, routerKey, messageContent, message -&gt; { // 设置延迟毫秒值 message.getMessageProperties().setExpiration(String.valueOf(delayTimes)); return message; }); } else { logger.error(&quot;未找到队列消息：{}，所属的交换机&quot;, exchange); } }} 由于我们在 pom.xml配置文件内添加了RabbitMQ相关的依赖并且在上面application.yml文件内添加了对应的配置，SpringBoot为我们自动实例化了AmqpTemplate，该实例可以发送任何类型的消息到指定队列。我们采用convertAndSend 方法，将消息内容发送到指定Exchange、RouterKey队列，并且通过setExpiration方法设置过期时间，单位：毫秒。 编写发送测试我们在test目录下创建一个测试类，如下所示： 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(classes = RabbitMqLazyProviderApplication.class)public class RabbitMqLazyProviderApplicationTests { /** * 消息队列提供者 */ @Autowired private MessageProvider messageProvider; /** * 测试延迟消息消费 */ @Test public void testLazy() { // 测试延迟10秒 messageProvider.sendMessage(&quot;测试延迟消费,写入时间：&quot; + new Date(), QueueEnum.MESSAGE_TTL_QUEUE.getExchange(), QueueEnum.MESSAGE_TTL_QUEUE.getRouteKey(), 10000); }} 注意：@SpringBootTest注解内添加了classes入口类的配置，因为我们是模块创建的项目并不是默认创建的SpringBoot项目，这里需要配置入口程序类才可以运行测试。 在测试类我们注入了MessageProvider 消息提供者，调用sendMessage方法发送消息到消息通知延迟队列，并且设置延迟的时间为10秒，这里衡量发送到指定队列的标准是要看MessageRabbitMqConfiguration配置类内的相关Binding配置，通过Exchange、RouterKey值进行发送到指定的队列。 到目前为止我们的rabbitmq-lazy-provider消息提供模块已经编写完成了，下面我们来看看消息消费者模块。 队列消息消费者我们再来创建一个名为rabbitmq-lazy-consumer的模块(Create New Maven Module)，同样需要在pom.xml配置文件内添加rabbitmq-common模块的依赖，如下所示： 123456&lt;!--添加公共模块依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.hengyu&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 当然同样需要在resource下创建application.yml并添加消息队列的相关配置，代码就不贴出来了，可以直接从rabbitmq-lazy-provider模块中复制application.yml文件到当前模块内。 消息消费者类接下来创建一个名为MessageConsumer的消费者类，该类需要监听消息通知队列，代码如下所示： 123456789101112131415161718192021222324/** * 消息通知 - 消费者 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/3 * Time：下午5:00 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Component@RabbitListener(queues = &quot;message.center.create&quot;)public class MessageConsumer { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(MessageConsumer.class); @RabbitHandler public void handler(String content) { logger.info(&quot;消费内容：{}&quot;, content); }} 在@RabbitListener注解内配置了监听的队列，这里配置内容是QueueEnum枚举内的queueName属性值，当然如果你采用常量的方式在注解属性上是直接可以使用的，枚举不支持这种配置，这里只能把QueueName字符串配置到queues属性上了。由于我们在消息发送时采用字符串的形式发送消息内容，这里在@RabbitHandler处理方法的参数内要保持数据类型一致！ 消费者入口类我们为消费者模块添加一个入口程序类，用于启动消费者，代码如下所示： 12345678910111213141516171819/** * 【第四十六章：SpringBoot &amp; RabbitMQ完成消息延迟消费】 * 队列消费者模块 - 入口程序类 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/3 * Time：下午4:55 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@SpringBootApplicationpublic class RabbitMqLazyConsumerApplication { public static void main(String[] args) { SpringApplication.run(RabbitMqLazyConsumerApplication.class, args); }} 测试我们的代码已经编写完毕，下面来测试下是否完成了我们预想的效果，步骤如下所示： 1231. 启动消费者模块2. 执行RabbitMqLazyProviderApplicationTests.testLazy()方法进行发送消息到通知延迟队列3. 查看消费者模块控制台输出内容 我们可以在消费者模块控制台看到输出内容： 12018-03-04 10:10:34.765 INFO 70486 --- [cTaskExecutor-1] c.h.r.lazy.consumer.MessageConsumer : 消费内容：测试延迟消费,写入时间：Sun Mar 04 10:10:24 CST 2018 我们在提供者测试方法发送消息的时间为10:10:24，而真正消费的时间则为10:10:34，与我们预计的一样，消息延迟了10秒后去执行消费。 总结终上所述我们完成了消息队列的延迟消费，采用死信方式，通过消息过期方式触发，在实际项目研发过程中，延迟消费还是很有必要的，可以省去一些定时任务的配置。","link":"/rabbitmq-delay-consumer.html"},{"title":"消息队列RabbitMQ的Direct类型消息多节点集群消费","text":"在上一章/rabbitmq-direct-exchange.html我们讲解到了RabbitMQ消息队列的DirectExchange路由键消息单个消费者消费，源码请访问SpringBoot对应章节源码下载查看，消息队列目的是完成消息的分布式消费，那么我们是否可以为一个Provider创建并绑定多个Consumer呢？ 本章目标基于SpringBoot平台整合RabbitMQ消息队列，完成一个Provider绑定多个Consumer进行消息消费。 构建项目我们基于上一章的项目进行升级，我们先来将Chapter41项目Copy一份命名为Chapter42。 构建 rabbitmq-consumer-node2基于我们复制的Chapter42项目，创建一个Module子项目命名为rabbitmq-consumer-node2，用于消费者的第二个节点，接下来我们为rabbitmq-consumer-node2项目创建一个入口启动类RabbitmqConsumerNode2Application，代码如下所示： 123456789101112131415161718192021222324252627/** * 消息队列消息消费者节点2入口 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：15:15 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootApplicationpublic class RabbitmqConsumerNode2Application{ static Logger logger = LoggerFactory.getLogger(RabbitmqConsumerNode2Application.class); /** * rabbitmq消费者启动入口 * @param args */ public static void main(String[] args) { SpringApplication.run(RabbitmqConsumerNode2Application.class,args); logger.info(&quot;【【【【【消息队列-消息消费者节点2启动成功.】】】】】&quot;); }} 为了区分具体的消费者节点，我们在项目启动成功后打印了相关的日志信息，下面我们来编写application.properties配置文件信息，可以直接从rabbitmq-consumer子项目内复制内容，复制后需要修改server.port以及spring.application.name，如下所示： 12345678910111213141516171819#端口号server.port=1112#项目名称spring.application.name=rabbitmq-consumer-node2#rabbitmq相关配置#用户名spring.rabbitmq.username=guest#密码spring.rabbitmq.password=guest#服务器ipspring.rabbitmq.host=localhost#虚拟空间地址spring.rabbitmq.virtual-host=/#端口号spring.rabbitmq.port=5672#配置发布消息确认回调spring.rabbitmq.publisher-confirms=true 因为我们是本地测试项目，所以需要修改对应的端口号，防止端口被占用。 创建用户注册消费者复制rabbitmq-consumer子项目内的UserConsumer类到rabbitmq-consumer-node2子项目对应的package内，如下所示： 1234567891011121314151617181920212223242526272829/** * 用户注册消息消费者 * 分布式节点2 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：15:20 * 码云：http://git.oschina.net/jnyqy * ======================== */@Component@RabbitListener(queues = &quot;user.register.queue&quot;)public class UserConsumer { /** * logback */ private Logger logger = LoggerFactory.getLogger(UserConsumer.class); @RabbitHandler public void execute(Long userId) { logger.info(&quot;用户注册消费者【节点2】获取消息，用户编号：{}&quot;,userId); //...//自行业务逻辑处理 }} 为了区分具体的消费者输出内容，我们在上面UserConsumer消费者消费方法内打印了相关日志输出，下面我们同样把rabbitmq-consumer子项目内UserConsumer的消费方法写入相关日志，如下所示： 1234567@RabbitHandler public void execute(Long userId) { logger.info(&quot;用户注册消费者【节点1】获取消息，用户编号：{}&quot;,userId); //...//自行业务逻辑处理 } 到目前为止我们的多节点RabbitMQ消费者已经编写完成，下面我们来模拟多个用户注册的场景，来查看用户注册消息是否被转发并唯一性的分配给不同的消费者节点。 运行测试我们打开上一章编写的UserTester测试类，为了模拟多用户注册请求，我们对应的创建一个内部线程类BatchRabbitTester，在线程类内编写注册请求代码，如下所示： 123456789101112131415161718192021222324252627282930/** * 批量添加用户线程测试类 * run方法发送用户注册请求 */ class BatchRabbitTester implements Runnable { private int index; public BatchRabbitTester() { } public BatchRabbitTester(int index) { this.index = index; } @Override public void run() { try { mockMvc.perform(MockMvcRequestBuilders.post(&quot;/user/save&quot;) .param(&quot;userName&quot;,&quot;yuqiyu&quot; + index) .param(&quot;name&quot;,&quot;恒宇少年&quot; + index) .param(&quot;age&quot;,&quot;23&quot;) ) .andDo(MockMvcResultHandlers.log()) .andReturn(); }catch (Exception e){ e.printStackTrace(); } } } 为了区分每一个注册信息是否都已经写入到数据库，我们为BatchRabbitTester添加了一个有参的构造方法，将for循环的i值对应的传递为index的值。下面我们来编写对应的批量注册的测试方法，如下所示： 12345678910111213141516/** * 测试用户批量添加 * @throws Exception */ @Test public void testBatchUserAdd() throws Exception { for (int i = 0 ; i &lt; 10 ; i++) { //创建用户注册线程 Thread thread = new Thread(new BatchRabbitTester(i)); //启动线程 thread.start(); } //等待线程执行完成 Thread.sleep(2000); } 我们循环10次来测试用户注册请求，每一次都会创建一个线程去完成发送注册请求逻辑，在方法底部添加了sleep方法，目的是为了阻塞测试用例的结束，因为我们测试用户完成方法后会自动停止，不会去等待其他线程执行完成，所以这里我们阻塞测试主线程来完成发送注册线程请求逻辑。 执行批量注册测试方法我们在执行测试批量注册用户消息之前，先把rabbitmq-consumer、rabbitmq-consumer-node2两个消费者子项目启动，项目启动完成后可以看到控制台输出启动成功日志，如下所示： 12345678910rabbitmq-consumer：2017-12-10 17:10:36.961 INFO 15644 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 1111 (http)2017-12-10 17:10:36.964 INFO 15644 --- [ main] c.h.r.c.RabbitmqConsumerApplication : Started RabbitmqConsumerApplication in 2.405 seconds (JVM running for 3.39)2017-12-10 17:10:36.964 INFO 15644 --- [ main] c.h.r.c.RabbitmqConsumerApplication : 【【【【【消息队列-消息消费者启动成功.】】】】】rabbitmq-consumer-node2：2017-12-10 17:11:31.679 INFO 13812 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 1112 (http)2017-12-10 17:11:31.682 INFO 13812 --- [ main] c.h.c.RabbitmqConsumerNode2Application : Started RabbitmqConsumerNode2Application in 2.419 seconds (JVM running for 3.129)2017-12-10 17:11:31.682 INFO 13812 --- [ main] c.h.c.RabbitmqConsumerNode2Application : 【【【【【消息队列-消息消费者节点2启动成功.】】】】】 接下来我们来运行testBatchUserAdd方法，查看测试控制台输出内容如下所示： 1234567891011121314151617181920212017-12-10 17:15:02.619 INFO 14456 --- [ Thread-3] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#528df369:0/SimpleConnection@39b6ba57 [delegate=amqp://guest@127.0.0.1:5672/, localPort= 60936] 回调id:194b5e67-6913-474a-b2ac-6e938e1e85e8消息发送成功 回调id:e88ce59c-3eb9-433c-9e25-9429e7076fbe消息发送成功 回调id:3e5b8382-6f63-450f-a641-e3d8eee255b2消息发送成功 回调id:39103357-6c80-4561-acb7-79b32d6171c9消息发送成功 回调id:9795d227-b54e-4cde-9993-a5b880fcfe39消息发送成功 回调id:e9b8b828-f069-455f-a366-380bf10a5909消息发送成功 回调id:6b5b4a9c-5e7f-4c53-9eef-98e06f8be867消息发送成功 回调id:619a42f3-cb94-4434-9c75-1e28a04ce350消息发送成功 回调id:6b720465-b64a-4ed9-9d8c-3e4dafa4faed消息发送成功 回调id:b4296f7f-98cc-423b-a4ef-0fc31d22cb08消息发送成功 可以看到确实已经成功的发送了10条用户注册消息到RabbitMQ服务端，那么是否已经正确的成功的将消息转发到消费者监听方法了呢？我们来打开rabbitmq-consumer子项目的启动控制台查看日志输出内容如下所示： 1234562017-12-10 17:10:36.964 INFO 15644 --- [ main] c.h.r.c.RabbitmqConsumerApplication : 【【【【【消息队列-消息消费者启动成功.】】】】】2017-12-10 17:15:02.695 INFO 15644 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.user.UserConsumer : 用户注册消费者【节点1】获取消息，用户编号：202017-12-10 17:15:02.718 INFO 15644 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.user.UserConsumer : 用户注册消费者【节点1】获取消息，用户编号：222017-12-10 17:15:02.726 INFO 15644 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.user.UserConsumer : 用户注册消费者【节点1】获取消息，用户编号：262017-12-10 17:15:02.729 INFO 15644 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.user.UserConsumer : 用户注册消费者【节点1】获取消息，用户编号：212017-12-10 17:15:02.789 INFO 15644 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.user.UserConsumer : 用户注册消费者【节点1】获取消息，用户编号：28 可以看到成功的接受了5条对应用户注册消息内容，不过这里具体接受的条数并不是固定的，这也是RabbitMQ消息转发权重内部问题。下面我们打开rabbitmq-consumer-node2子项目控制台查看日志输出内容如下所示： 1234562017-12-10 17:11:31.682 INFO 13812 --- [ main] c.h.c.RabbitmqConsumerNode2Application : 【【【【【消息队列-消息消费者节点2启动成功.】】】】】2017-12-10 17:15:02.708 INFO 13812 --- [cTaskExecutor-1] com.hengyu.consumer.user.UserConsumer : 用户注册消费者【节点2】获取消息，用户编号：252017-12-10 17:15:02.717 INFO 13812 --- [cTaskExecutor-1] com.hengyu.consumer.user.UserConsumer : 用户注册消费者【节点2】获取消息，用户编号：232017-12-10 17:15:02.719 INFO 13812 --- [cTaskExecutor-1] com.hengyu.consumer.user.UserConsumer : 用户注册消费者【节点2】获取消息，用户编号：242017-12-10 17:15:02.727 INFO 13812 --- [cTaskExecutor-1] com.hengyu.consumer.user.UserConsumer : 用户注册消费者【节点2】获取消息，用户编号：272017-12-10 17:15:02.790 INFO 13812 --- [cTaskExecutor-1] com.hengyu.consumer.user.UserConsumer : 用户注册消费者【节点2】获取消息，用户编号：29 同样获得了5条用户注册消息，不过并没有任何规律可言，编号也不是顺序的。 所以多节点时消息具体分发到哪个节点并不是固定的，完全是RabbitMQ分发机制来控制。 总结本章完成了基于SpringBoot平台整合RabbitMQ单个Provider对应绑定多个Consumer来进行多节点分布式消费者消息消费，实际生产项目部署时完全可以将消费节点分开到不同的服务器，只要消费节点可以访问到RabbitMQ服务端，可以正常通讯，就可以完成消息消费。","link":"/rabbitmq-direct-exchange-cluster.html"},{"title":"消息队列RabbitMQ的Direct类型消息消费","text":"消息队列目前流行的有KafKa、RabbitMQ、ActiveMQ等，它们的诞生无非不是为了解决消息的分布式消费，完成项目、服务之间的解耦动作。消息队列提供者与消费者之间完全采用异步通信方式，极力的提高了系统的响应能力，从而提高系统的网络请求吞吐量。每一种的消息队列都有它在设计上的独一无二的优势，在实际的项目技术选型时根据项目的需求来确定。 本章目标基于SpringBoot项目整合RabbitMQ消息队列，完成DirectExchange（路由键）分布式消息消费。 Exchange在RabbitMQ中有三种常用的转发方式，分别是： DirectExchange：路由键方式转发消息。FanoutExchange：广播方式转发消息。TopicExchange：主题匹配方式转发消息。 我们本章先来讲解DirectExchange路由键方式，根据设置的路由键的值进行完全匹配时转发，下面我们来看一张图，形象的介绍了转发消息匹配流程，如下图所示： 我们可以看到上图，当消息被提供者发送到RabbitMQ后，会根据配置队列的交换以及绑定实例进行转发消息，上图只会将消息转发路由键为KEY的队列消费者对应的实现方法逻辑中，从而完成消息的消费过程。 安装RabbitMQ因为RabbitMQ是跨平台的分布式消息队列服务，可以部署在任意的操作系统上，下面我们分别介绍在不同的系统下该怎么去安装RabbitMQ服务。 我们本章采用的环境版本如下： RabbitMQ Server 3.6.14 Erlang/OTP_X64 20.1 Windows下安装我们先去RabbitMQ官方网站下载最新版的安装包，下载地址：https://www.rabbitmq.com/download.html，可以根据不同的操作系统选择下载。我们在安装RabbitMQ服务端时需要Erlang环境的支持，所以我们需要先安装Erlang。 我们通过Erlang官方网站http://www.erlang.org/downloads下载最新的安装包 我们访问RabiitmQ官方下载地址https://www.rabbitmq.com/download.html下载最新安装包。 因为是国外的网站所以下载比较慢，大家下载时会浪费时间，我已经将安装包分享到了百度网盘，下载地址：安装包下载地址，密码：pexf 运行安装Erlang 运行安装RabbitMQ 5.检查服务是否安装完成，RabbitMQ安装完成后会以服务的形式创建，并且随着开机启动，如下所示： Mac OS X 安装在Mac OS X中我们使用brew工具可以很简单的安装RabbitMQ服务端，步骤如下： brew更新到最新版本，执行：brew update 接下来我们安装Erlang，执行：brew install erlang 最后安装RabbitMQ，执行：brew install rabbitmq 我们通过上面的步骤安装后，RabbitMQ会被自动安装到/usr/local/Cellar/rabbitmq/目录下，下面我们进入cd sbin目录执行： 1sudo ./rabbitmq-server 可以直接启动RabbitMQ服务。 Ubuntu 安装在Ubuntu操作系统中，我们可以直接使用APT仓库进行安装，我使用的系统版本是16.04，系统版本并不影响安装。 安装Erlang，执行命令：sudo apt-get install erlang 下面我们需要将RabbitMQ的安装源配置信息写入到系统的/etc/apt/sources.list.d配置文件内，执行如下命令：1echo 'deb http://www.rabbitmq.com/debian/ testing main' | sudo tee /etc/apt/sources.list.d/rabbitmq.list 下面我们更新APT本地仓库的安装包列表，执行命令：sudo apt-get update 最后安装RabbitMQ服务，执行命令：sudo apt-get install rabbitmq-server 启用界面管理插件RabbitMQ提供了界面管理的web插件，我们只需要启用指定的插件就可以了，下面我们来看看Windows操作系统下该怎么启动界面管理插件。我们使用CMD进入RabbitMQ安装目录C:\\Program Files\\RabbitMQ Server\\rabbitmq_server-3.6.14，然后我们进入sbin目录，可以看到目录内存在很多个bat脚本程序，我们找到rabbitmq-plugins.bat，这个脚本程序可以控制RabbitMQ插件启用禁用，我们执行如下脚本命令来启用界面管理插件： 1rabbitmq-plugins.bat enable rabbitmq_management 命令行输出内容如下所示： 123456789The following plugins have been enabled: amqp_client cowlib cowboy rabbitmq_web_dispatch rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@yuqiyu... started 6 plugins. 可以看到输出的内容RabbitMQ自动启动了6个插件，我们现在访问http://127.0.0.1:15672地址可以直接打开RabbitMQ的界面管理平台，而默认的用户名/密码分别为：guest/guest，通过该用户可以直接登录管理平台。 禁用界面管理插件我们同样可以禁用RabbitMQ指定插件，执行如下命令： 1rabbitmq-plugins.bat disable rabbitmq_management 命令创建输出内容则是相关停止插件的日志，如下： 123456789The following plugins have been disabled: amqp_client cowlib cowboy rabbitmq_web_dispatch rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@yuqiyu... stopped 6 plugins. 这样我们再访问http://127.0.0.1:15672就会发现我们无法访问到界面。 构建项目我们使用idea开发工具创建一个SpringBoot项目，添加依赖，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930&lt;dependencies&gt; &lt;!--rabbitmq依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--fastjson依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.40&lt;/version&gt; &lt;/dependency&gt; &lt;!--测试依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们本章来模拟用户注册完成后，将注册用户的编号通过Provider模块发送到RabbitMQ ，然后RabbitMQ 根据配置的DirectExchange的路由键进行异步转发。 初始化用户表下面我们先来创建所需要的用户基本信息表，建表SQL如下所示： 1234567CREATE TABLE `user_info` ( `UI_ID` int(11) DEFAULT NULL COMMENT '用户编号', `UI_USER_NAME` varchar(20) DEFAULT NULL COMMENT '用户名称', `UI_NAME` varchar(20) DEFAULT NULL COMMENT '真实姓名', `UI_AGE` int(11) DEFAULT NULL COMMENT '用户年龄', `UI_BALANCE` decimal(10,0) DEFAULT NULL COMMENT '用户余额') ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='用户基本信息表'; 构建 rabbitmq-provider 项目基于我们上述的项目创建一个Maven子模块，命名为：rabbitmq-provider，因为是直接创建的Module项目，IDEA并没有给我创建SpringApplication启用类。 创建入口类下面我们自行创建一个Provider项目启动入口程序，如下所示： 123456789101112131415161718192021222324252627/** * 消息队列消息提供者启动入口 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:14 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootApplicationpublic class RabbitmqProviderApplication{ static Logger logger = LoggerFactory.getLogger(RabbitmqProviderApplication.class); /** * 消息队列提供者启动入口 * @param args */ public static void main(String[] args) { SpringApplication.run(RabbitmqProviderApplication.class,args); logger.info(&quot;【【【【【消息队列-消息提供者启动成功.】】】】】&quot;); }} application.properties配置文件下面我们在src/main/resource目录下创建application.properties并将对应RabbitMQ以及Druid的配置加入，如下所示： 123456789101112131415161718#用户名spring.rabbitmq.username=guest#密码spring.rabbitmq.password=guest#服务器ipspring.rabbitmq.host=localhost#虚拟空间地址spring.rabbitmq.virtual-host=/#端口号spring.rabbitmq.port=5672#配置发布消息确认回调spring.rabbitmq.publisher-confirms=true#数据源配置spring.datasource.druid.driver-class-name=com.mysql.jdbc.Driverspring.datasource.druid.url=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=truespring.datasource.druid.username=rootspring.datasource.druid.password=123456 在RabbitMQ内有个virtual-host即虚拟主机的概念，一个RabbitMQ服务可以配置多个虚拟主机，每一个虚拟机主机之间是相互隔离，相互独立的，授权用户到指定的virtual-host就可以发送消息到指定队列。 用户实体本章数据库操作采用spring-data-jpa，相关文章请访问：第十三章：SpringBoot实战SpringDataJPA，我们基于user_info数据表对应创建实体，如下所示： 12345678910111213141516171819202122232425262728293031323334@Data@Table(name = &quot;user_info&quot;)@Entitypublic class UserEntity implements Serializable{ /** * 用户编号 */ @Id @GeneratedValue @Column(name = &quot;UI_ID&quot;) private Long id; /** * 用户名称 */ @Column(name = &quot;UI_USER_NAME&quot;) private String userName; /** * 姓名 */ @Column(name = &quot;UI_NAME&quot;) private String name; /** * 年龄 */ @Column(name = &quot;UI_AGE&quot;) private int age; /** * 余额 */ @Column(name = &quot;UI_BALANCE&quot;) private BigDecimal balance;} 用户数据接口创建UserRepository用户数据操作接口，并继承JpaRepository获得spring-data-jpa相关的接口定义方法。如下所示： 123456789101112131415/** * 用户数据接口定义 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:35 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface UserRepository extends JpaRepository&lt;UserEntity,Long&gt;{} 用户业务逻辑实现本章只是简单完成了数据的添加，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 用户业务逻辑实现类 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:37 * 码云：http://git.oschina.net/jnyqy * ======================== */@Service@Transactional(rollbackFor = Exception.class)public class UserService{ @Autowired private UserRepository userRepository; /** * 消息队列业务逻辑实现 */ @Autowired private QueueMessageService queueMessageService; /** * 保存用户 * 并写入消息队列 * @param userEntity * @return */ public Long save(UserEntity userEntity) throws Exception { /** * 保存用户 */ userRepository.save(userEntity); /** * 将消息写入消息队列 */ queueMessageService.send(userEntity.getId(), ExchangeEnum.USER_REGISTER, QueueEnum.USER_REGISTER); return userEntity.getId(); } 在上面业务逻辑实现类内出现了一个名为QueueMessageService消息队列实现类，该类是我们定义的用于发送消息到消息队列的统一入口，在下面我们会详细讲解。 用户控制器创建一个名为UserController的控制器类，对应编写一个添加用户的请求方法，如下所示： 123456789101112131415161718192021222324252627282930313233/** * 用户控制器 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:41 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestController@RequestMapping(value = &quot;/user&quot;)public class UserController{ /** * 用户业务逻辑 */ @Autowired private UserService userService; /** * 保存用户基本信息 * @param userEntity * @return */ @RequestMapping(value = &quot;/save&quot;) public UserEntity save(UserEntity userEntity) throws Exception { userService.save(userEntity); return userEntity; }} 到这我们添加用户的流程已经编写完成了，那么我们就来看下消息队列QueueMessageService接口的定义以及实现类的定义。 消息队列方法定义接口创建一个名为QueueMessageService的接口并且继承了RabbitTemplate.ConfirmCallback接口，而RabbitTemplate.ConfirmCallback接口是用来回调消息发送成功后的方法，当一个消息被成功写入到RabbitMQ服务端时，就会自动的回调RabbitTemplate.ConfirmCallback接口内的confirm方法完成通知，QueueMessageService接口如下所示： 1234567891011121314151617181920212223/** * 消息队列业务 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:50 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface QueueMessageService extends RabbitTemplate.ConfirmCallback{ /** * 发送消息到rabbitmq消息队列 * @param message 消息内容 * @param exchangeEnum 交换配置枚举 * @param queueEnum 队列配置枚举 * @throws Exception */ public void send(Object message, ExchangeEnum exchangeEnum, QueueEnum queueEnum) throws Exception;} 接下来我们需要实现该接口内的所有方法，并做出一些业务逻辑的处理。 消息队列业务实现创建名为QueueMessageServiceSupport实体类实现QueueMessageService接口，并实现接口内的所有方法，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 消息队列业务逻辑实现 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:52 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class QueueMessageServiceSupport implements QueueMessageService{ /** * 消息队列模板 */ @Autowired private RabbitTemplate rabbitTemplate; @Override public void send(Object message, ExchangeEnum exchangeEnum, QueueEnum queueEnum) throws Exception { //设置回调为当前类对象 rabbitTemplate.setConfirmCallback(this); //构建回调id为uuid CorrelationData correlationId = new CorrelationData(UUID.randomUUID().toString()); //发送消息到消息队列 rabbitTemplate.convertAndSend(exchangeEnum.getValue(),queueEnum.getRoutingKey(),message,correlationId); } /** * 消息回调确认方法 * @param correlationData 请求数据对象 * @param ack 是否发送成功 * @param cause */ @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) { System.out.println(&quot; 回调id:&quot; + correlationData.getId()); if (ack) { System.out.println(&quot;消息发送成功&quot;); } else { System.out.println(&quot;消息发送失败:&quot; + cause); } }} convertAndSend方法用于将Object类型的消息转换后发送到RabbitMQ服务端，发送是的消息类型要与消息消费者方法参数保持一致。 在confirm方法内，我们仅仅打印了消息发送时的id，根据ack参数输出消息发送状态。 在上面代码中我们注入了RabbitTemplate消息队列模板实例，而通过该实例我们可以将消息发送到RabbitMQ服务端。那么这个实例具体在什么地方定义的呢？我们带着这个疑问来创建下面的模块，我们需要将RabbitMQ相关的配置抽取出来作为一个单独的Module存在。 构建 rabbitmq-common 项目该模块项目很简单，只是添加RabbitMQ相关的配置信息，由于Module是一个子模块所以继承了parent所有的依赖，当然我们用到的RabbitMQ相关依赖也不例外。 配置rabbitmq在创建配置类之前，我们先来定义两个枚举，分别存放了队列的交换信息、队列路由信息， ExchangeEnum (存放了队列交换配置信息) 12345678910111213141516171819202122232425/** * rabbitmq交换配置枚举 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：13:56 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum ExchangeEnum{ /** * 用户注册交换配置枚举 */ USER_REGISTER(&quot;user.register.topic.exchange&quot;) ; private String value; ExchangeEnum(String value) { this.value = value; }} QueueEnum (存放了队列信息以及队列的路由配置信息) 123456789101112131415161718192021222324252627282930313233/** * 队列配置枚举 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:05 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum QueueEnum{ /** * 用户注册枚举 */ USER_REGISTER(&quot;user.register.queue&quot;,&quot;user.register&quot;) ; /** * 队列名称 */ private String name; /** * 队列路由键 */ private String routingKey; QueueEnum(String name, String routingKey) { this.name = name; this.routingKey = routingKey; }} 创建名为UserRegisterQueueConfiguration的实体类用于配置本章用到的用户注册队列信息，如果你得项目中使用多个队列，建议每一个业务逻辑创建一个配置类，分开维护，这样不容易出错。配置信息如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 用户注册消息队列配置 * ======================== * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：16:58 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configurationpublic class UserRegisterQueueConfiguration { /** * 配置路由交换对象实例 * @return */ @Bean public DirectExchange userRegisterDirectExchange() { return new DirectExchange(ExchangeEnum.USER_REGISTER.getValue()); } /** * 配置用户注册队列对象实例 * 并设置持久化队列 * @return */ @Bean public Queue userRegisterQueue() { return new Queue(QueueEnum.USER_REGISTER.getName(),true); } /** * 将用户注册队列绑定到路由交换配置上并设置指定路由键进行转发 * @return */ @Bean public Binding userRegisterBinding() { return BindingBuilder.bind(userRegisterQueue()).to(userRegisterDirectExchange()).with(QueueEnum.USER_REGISTER.getRoutingKey()); }} 该配置类大致分为如下三部分： 配置交换实例配置DirectExchange实例对象，为交换设置一个名称，引用ExchangeEnum枚举配置的交换名称，消息提供者与消息消费者的交换名称必须一致才具备的第一步的通讯基础。 配置队列实例配置Queue实例对象，为消息队列设置一个名称，引用QueueEnum枚举配置的队列名称，当然队列的名称同样也是提供者与消费者之间的通讯基础。 绑定队列实例到交换实例配置Binding实例对象，消息绑定的目的就是将Queue实例绑定到Exchange上，并且通过设置的路由Key进行消息转发，配置了路由Key后，只有符合该路由配置的消息才会被转发到绑定交换上的消息队列。 我们的rabbitmq-common模块已经编写完成。 添加 rabbitmq-provider 依赖 rabbitmq-common下面我们回到rabbitmq-provider模块，修改pom.xml配置文件，如下所示： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;!--添加common模块依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.hengyu&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--druid数据源依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--data jpa依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 可以看到我们将rabbitmq-common模块添加到了rabbitmq-provider模块的pom配置文件内，完成了模块之间的相互依赖，这样我们rabbitmq-provider就自动添加了对应的消息队列配置。 构建rabbitmq-consumer我们再来创建一个rabbitmq-consumer队列消息消费者模块，用于接受消费用户注册消息。 创建入口类同样我们先来创建一个SpringApplication入口启动类，如下所示： 123456789101112131415161718192021222324252627/** * 消息队列消息消费者入口 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：15:15 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootApplicationpublic class RabbitmqConsumerApplication{ static Logger logger = LoggerFactory.getLogger(RabbitmqConsumerApplication.class); /** * rabbitmq消费者启动入口 * @param args */ public static void main(String[] args) { SpringApplication.run(RabbitmqConsumerApplication.class,args); logger.info(&quot;【【【【【消息队列-消息消费者启动成功.】】】】】&quot;); }} application.properties配置文件配置文件的消息队列配置信息要与rabbitmq-provider配置文件一致，如下所示： 123456789101112131415spring.application.name=rabbitmq-consumer#启动端口server.port=1111#用户名spring.rabbitmq.username=guest#密码spring.rabbitmq.password=guest#服务器ipspring.rabbitmq.host=localhost#虚拟空间地址spring.rabbitmq.virtual-host=/#端口号spring.rabbitmq.port=5672#配置发布消息确认回调spring.rabbitmq.publisher-confirms=true 我们修改了程序启动的端口号，为了我们下面进行测试的时候不出现端口占用的情况。 如果RabbitMQ配置信息与rabbitmq-provider不一致，就不会收到消费消息。 用户注册消息消费者创建名为UserConsumer类，用于完成消息监听，并且实现消息消费，如下所示： 1234567891011121314151617181920212223/** * 用户注册消息消费者 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：15:20 * 码云：http://git.oschina.net/jnyqy * ======================== */@Component@RabbitListener(queues = &quot;user.register.queue&quot;)public class UserConsumer { @RabbitHandler public void execute(Long userId) { System.out.println(&quot;用户：&quot; + userId+&quot;，完成了注册&quot;); //...//自行业务逻辑处理 }} 在消息消费者类内，有两个陌生的注解： @RabbitListenerRabbitMQ队列消息监听注解，该注解配置监听queues内的队列名称列表，可以配置多个。队列名称对应本章rabbitmq-common模块内QueueEnum枚举name属性。 @RabbitHandlerRabbitMQ消息处理方法，该方法的参数要与rabbitmq-provider发送消息时的类型保持一致，否则无法自动调用消费方法，也就无法完成消息的消费。 #运行测试我们接下来在rabbitmq-provider模块src/test/java下创建一个测试用例，访问用户注册控制器请求路径，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940@RunWith(SpringRunner.class)@SpringBootTest(classes = RabbitmqProviderApplication.class)public class UserTester{ /** * 模拟mvc测试对象 */ private MockMvc mockMvc; /** * web项目上下文 */ @Autowired private WebApplicationContext webApplicationContext; /** * 所有测试方法执行之前执行该方法 */ @Before public void before() { //获取mockmvc对象实例 mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); } /** * 测试添加用户 * @throws Exception */ @Test public void testUserAdd() throws Exception { mockMvc.perform(MockMvcRequestBuilders.post(&quot;/user/save&quot;) .param(&quot;userName&quot;,&quot;yuqiyu&quot;) .param(&quot;name&quot;,&quot;恒宇少年&quot;) .param(&quot;age&quot;,&quot;23&quot;) ) .andDo(MockMvcResultHandlers.log()) .andReturn(); }} 调用测试用例时会自动将参数保存到数据库，并且将用户编号发送到RabbitMQ服务端，而RabbitMQ根据交换配置以及队列配置转发消息到消费者实例。 启动 rabbitmq-consumer我们先来把rabbitmq-consumer项目启动，控制台输出启动日志如下所示： 12345678.....51.194 INFO 2340 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Bean with name 'rabbitConnectionFactory' has been autodetected for JMX exposure2017-12-03 16:58:51.196 INFO 2340 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Located managed bean 'rabbitConnectionFactory': registering with JMX server as MBean [org.springframework.amqp.rabbit.connection:name=rabbitConnectionFactory,type=CachingConnectionFactory]2017-12-03 16:58:51.216 INFO 2340 --- [ main] o.s.c.support.DefaultLifecycleProcessor : Starting beans in phase 21474836472017-12-03 16:58:51.237 INFO 2340 --- [cTaskExecutor-1] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#443ff8ef:0/SimpleConnection@4369ac5c [delegate=amqp://guest@127.0.0.1:5672/, localPort= 62107]2017-12-03 16:58:51.287 INFO 2340 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 1111 (http)2017-12-03 16:58:51.290 INFO 2340 --- [ main] c.h.r.c.RabbitmqConsumerApplication : Started RabbitmqConsumerApplication in 2.354 seconds (JVM running for 3.026)2017-12-03 16:58:51.290 INFO 2340 --- [ main] c.h.r.c.RabbitmqConsumerApplication : 【【【【【消息队列-消息消费者启动成功.】】】】】 该部分启动日志就是我们配置的RabbitMQ初始化信息，我们可以看到项目启动时会自动与配置的RabbitMQ进行关联： 1[delegate=amqp://guest@127.0.0.1:5672/, localPort= 62107] 运行测试用例接下来我们执行rabbitmq-provider项目的测试用例，来查看控制台的输出内容如下所示： 1234...... 回调id:e08f6d82-57bc-4c3f-9899-31c4b990c5be消息发送成功...... 已经可以正常的将消息发送到RabbitMQ服务端，并且接收到了回调通知，那么我们的rabbitmq-consumer项目是不是已经执行了消息的消费呢？我们打开rabbitmq-consumer控制台查看输出内容如下所示： 1用户：2，完成了注册 看以看到已经可以成功的执行UserConsumer消息监听类内的监听方法逻辑，到这里消息队列路由一对一的方式已经讲解完了。 总结本章主要讲解了RabbitMQ在不同操作系统下的安装方式，以及通过三个子模块形象的展示了消息的分布式处理，整体流程：rabbitmq-provider -&gt; RabbitMQ服务端 -&gt; rabbitmq-consumer，消息的转发是非常快的，RabbitMQ在收到消息后就会检索当前服务端是否存在该消息的消费者，如果存在将会马上将消息转发。","link":"/rabbitmq-direct-exchange.html"},{"title":"消息队列RabbitMQ的Topic类型消息消费","text":"我们在之前的两个章节第四十一章： 基于SpringBoot &amp; RabbitMQ完成DirectExchange分布式消息消费、第四十二章： 基于SpringBoot &amp; RabbitMQ完成DirectExchange分布式消息多消费者消费提高了RabbitMQ消息队列的DirectExchange交换类型的消息消费，我们之前的章节提到了RabbitMQ比较常用的交换类型有三种，我们今天来看看TopicExchange主题交换类型。 本章目标基于SpringBoot平台完成RabbitMQ的TopicExchange消息类型交换。 解决问题之前少年也遇到了一个问题，分类了多模块后消息队列无法自动创建，说来也好笑，之前没有时间去看这个问题，今天在编写本章文章时发现原因竟然是SpringBoot没有扫描到common模块内的配置类。让我一阵的头大~~~，我们在XxxApplication启动类上添加@ComponentScan(value = &quot;com.hengyu.rabbitmq&quot;)就可以自动创建队列了！！！ 构建项目本章构建项目时同样采用多模块的方式进行设计，可以很好的看到消息处理的效果，因为是多模块项目，我们先来创建一个SpringBoot项目，pom.xml配置文件依赖配置如下所示： 123456789101112131415161718192021222324252627282930&lt;dependencies&gt; &lt;!--rabbbitMQ相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--spring boot tester--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--fast json依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.40&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 下面我们先来构建公共RabbitMQ模块，因为我们的消费者以及生产者都是需要RabbitMQ相关的配置信息，这里我们可以提取出来，使用时进行模块之间的引用。 rabbitmq-topic-common创建子模块rabbitmq-topic-common，在resources下添加application.yml配置文件并配置RabbitMQ相关的依赖配置，如下所示： 123456789spring: #rabbitmq消息队列配置信息 rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtual-host: / publisher-confirms: true 定义交换配置信息我们跟之前的章节一张，独立编写一个枚举类型来配置消息队列的交换信息，如下所示： 12345678910111213141516171819202122232425/** * rabbitmq交换配置枚举 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：13:56 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum ExchangeEnum{ /** * 用户注册交换配置枚举 */ USER_REGISTER_TOPIC_EXCHANGE(&quot;register.topic.exchange&quot;) ; private String name; ExchangeEnum(String name) { this.name = name; }} 定义队列配置信息同样消息队列的基本信息配置也同样采用枚举的形式配置，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839/** * 队列配置枚举 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:05 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum QueueEnum{ /** * 用户注册 * 创建账户消息队列 */ USER_REGISTER_CREATE_ACCOUNT(&quot;register.account&quot;,&quot;register.#&quot;), /** * 用户注册 * 发送注册成功邮件消息队列 */ USER_REGISTER_SEND_MAIL(&quot;register.mail&quot;,&quot;register.#&quot;) ; /** * 队列名称 */ private String name; /** * 队列路由键 */ private String routingKey; QueueEnum(String name, String routingKey) { this.name = name; this.routingKey = routingKey; }} 消息队列枚举内添加了两个属性，分别对应了队列名称、队列路由，我们本章所讲解的TopicExchange类型消息队列可以根据路径信息配置多个消息消费者，而转发的匹配规则信息则是我们定义的队列的路由信息。 定义发送消息路由信息我们在发送消息到队列时，需要我们传递一个路由相关的配置信息，RabbitMQ会根据发送时的消息路由规则信息与定义消息队列时的路由信息进行匹配，如果可以匹配则调用该队列的消费者完成消息的消费，发送消息路由信息配置如下所示： 12345678910111213141516171819202122232425/** * 消息队列topic交换路由key配置枚举 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：21:58 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic enum TopicEnum { /** * 用户注册topic路由key配置 */ USER_REGISTER(&quot;register.user&quot;) ; private String topicRouteKey; TopicEnum(String topicRouteKey) { this.topicRouteKey = topicRouteKey; }} 路由特殊字符 #我们在QueueEnum内配置的路由键时有个特殊的符号：#，在RabbitMQ消息队列内路由配置#时表示可以匹配零个或多个字符，我们TopicEnum 枚举内定义的register.user，则是可以匹配QueueEnum枚举定义register.#队列的路由规则。当然发送消息时如果路由传递：register.user.account也是可以同样匹配register.#的路由规则。 路由特殊字符 *除此之外比较常用到的特殊字符还有一个*，在RabbitMQ消息队列内路由配置*时表示可以匹配一个字符，我们QueueEnum定义路由键如果修改成register.*时，发送消息时路由为register.user则是可以接受到消息的。但如果发送时的路由为register.user.account时，则是无法匹配该消息。 消息队列配置配置准备工作已经做好，接下来我们开始配置队列相关的内容，跟之前一样我们需要配置Queue、Exchange、Binding将消息队列与交换绑定。下面我们来看看配置跟之前的章节有什么差异的地方，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 用户注册消息队列配置 * ======================== * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：16:58 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configurationpublic class UserRegisterQueueConfiguration { private Logger logger = LoggerFactory.getLogger(UserRegisterQueueConfiguration.class); /** * 配置用户注册主题交换 * @return */ @Bean public TopicExchange userTopicExchange() { TopicExchange topicExchange = new TopicExchange(ExchangeEnum.USER_REGISTER_TOPIC_EXCHANGE.getName()); logger.info(&quot;用户注册交换实例化成功。&quot;); return topicExchange; } /** * 配置用户注册 * 发送激活邮件消息队列 * 并设置持久化队列 * @return */ @Bean public Queue sendRegisterMailQueue() { Queue queue = new Queue(QueueEnum.USER_REGISTER_SEND_MAIL.getName()); logger.info(&quot;创建用户注册消息队列成功&quot;); return queue; } /** * 配置用户注册 * 创建账户消息队列 * 并设置持久化队列 * @return */ @Bean public Queue createAccountQueue() { Queue queue = new Queue(QueueEnum.USER_REGISTER_CREATE_ACCOUNT.getName()); logger.info(&quot;创建用户注册账号队列成功.&quot;); return queue; } /** * 绑定用户发送注册激活邮件队列到用户注册主题交换配置 * @return */ @Bean public Binding sendMailBinding(TopicExchange userTopicExchange,Queue sendRegisterMailQueue) { Binding binding = BindingBuilder.bind(sendRegisterMailQueue).to(userTopicExchange).with(QueueEnum.USER_REGISTER_SEND_MAIL.getRoutingKey()); logger.info(&quot;绑定发送邮件到注册交换成功&quot;); return binding; } /** * 绑定用户创建账户到用户注册主题交换配置 * @return */ @Bean public Binding createAccountBinding(TopicExchange userTopicExchange,Queue createAccountQueue) { Binding binding = BindingBuilder.bind(createAccountQueue).to(userTopicExchange).with(QueueEnum.USER_REGISTER_CREATE_ACCOUNT.getRoutingKey()); logger.info(&quot;绑定创建账号到注册交换成功。&quot;); return binding; }} 我们从上面开始分析。第一步： 首先我们创建了TopicExchange消息队列对象，使用ExchangeEnum枚举内的USER_REGISTER_TOPIC_EXCHANGE类型作为交换名称。 第二步：我们创建了发送注册邮件的队列sendRegisterMailQueue，使用QueueEnum枚举内的类型USER_REGISTER_SEND_MAIL作为队列名称。 第三步：与发送邮件队列一致，用户创建完成后需要初始化账户信息，而createAccountQueue 消息队列后续逻辑就是来完成该工作，使用QueueEnum枚举内的USER_REGISTER_CREATE_ACCOUNT枚举作为创建账户队列名称。 第四步：在上面步骤中已经将交换、队列创建完成，下面就开始将队列绑定到用户注册交换，从而实现注册用户消息队列消息消费，sendMailBinding绑定了QueueEnum.USER_REGISTER_SEND_MAIL的RoutingKey配置信息。 createAccountBinding 绑定了QueueEnum.USER_REGISTER_CREATE_ACCOUNT的RoutingKey 配置信息。 到目前为止我们完成了rabbitmq-topic-common模块的所有配置信息，下面我们开始编写用户注册消息消费者模块。 rabbitmq-topic-consumer我们首先来创建一个子模块命名为rabbitmq-topic-consumer，在pom.xml配置文件内添加rabbitmq-topic-common模块的引用，如下所示： 12345678910....//&lt;dependencies&gt; &lt;!--公共模块依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.hengyu&lt;/groupId&gt; &lt;artifactId&gt;rabbitmq-topic-common&lt;/artifactId&gt; &lt;version&gt;${parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;....// 消费者程序入口下面我们来创建程序启动类RabbitMqTopicConsumerApplication，在这里需要注意，手动配置下扫描路径@ComponentScan，启动类代码如下所示： 12345678910111213141516171819202122232425262728293031/** * 消息消费者程序启动入口 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：21:48 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootApplication@ComponentScan(value = &quot;com.hengyu.rabbitmq&quot;)public class RabbitMqTopicConsumerApplication { /** * logback */ private static Logger logger = LoggerFactory.getLogger(RabbitMqTopicConsumerApplication.class); /** * 程序入口 * @param args */ public static void main(String[] args) { SpringApplication.run(RabbitMqTopicConsumerApplication.class,args); logger.info(&quot;【【【【【Topic队列消息Consumer启动成功】】】】】&quot;); }} 手动配置扫描路径在文章的开始解释过了，主要目的是为了扫描到RabbitMQConfiguration配置类内的信息，让RabbitAdmin自动创建配置信息到server端。 发送邮件消费者发送邮件消息费监听register.mail消息队列信息，如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * 发送用户注册成功邮件消费者 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：22:07 * 码云：http://git.oschina.net/jnyqy * ======================== */@Component@RabbitListener(queues = &quot;register.mail&quot;)public class SendMailConsumer{ /** * logback */ Logger logger = LoggerFactory.getLogger(SendMailConsumer.class); /** * 处理消息 * 发送用户注册成功邮件 * @param userId 用户编号 */ @RabbitHandler public void handler(String userId) { logger.info(&quot;用户：{}，注册成功，自动发送注册成功邮件.&quot;,userId); //... 发送注册成功邮件逻辑 }} 在这里我只是完成了消息的监听，具体的业务逻辑可以根据需求进行处理。 创建账户消费者创建用户账户信息消费者监听队列register.account，代码如下所示： 1234567891011121314151617181920212223242526272829303132/** * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：22:04 * 码云：http://git.oschina.net/jnyqy * ======================== */@Component@RabbitListener(queues = &quot;register.account&quot;)public class CreateAccountConsumer { /** * logback */ Logger logger = LoggerFactory.getLogger(CreateAccountConsumer.class); /** * 处理消息 * 创建用户账户 * @param userId 用户编号 */ @RabbitHandler public void handler(String userId) { logger.info(&quot;用户：{}，注册成功，自动创建账户信息.&quot;,userId); //... 创建账户逻辑 }} 创建账户，账户初始化逻辑都可以在handler方法进行处理，本章没有做数据库复杂的处理，所以没有过多的逻辑处理在消费者业务内。 rabbitmq-topic-provider接下来是我们的消息提供者的模块编写，我们依然先来创建程序入口类，并添加扫描配置@ComponentScan路径，代码如下所示： 12345678910111213141516171819202122232425262728293031/** * 消息生产者程序启动入口 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：21:48 * 码云：http://git.oschina.net/jnyqy * ======================== */@SpringBootApplication@ComponentScan(value = &quot;com.hengyu.rabbitmq&quot;)public class RabbitMqTopicProviderApplication { /** * logback */ private static Logger logger = LoggerFactory.getLogger(RabbitMqTopicProviderApplication.class); /** * 程序入口 * @param args */ public static void main(String[] args) { SpringApplication.run(RabbitMqTopicProviderApplication.class,args); logger.info(&quot;【【【【【Topic队列消息Provider启动成功】】】】】&quot;); }} 定义消息发送接口创建QueueMessageService队列消息发送接口并添加send方法，如下所示： 12345678910111213141516171819202122/** * 消息队列业务 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:50 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface QueueMessageService{ /** * 发送消息到rabbitmq消息队列 * @param message 消息内容 * @param exchangeEnum 交换配置枚举 * @param routingKey 路由key * @throws Exception */ public void send(Object message, ExchangeEnum exchangeEnum, String routingKey) throws Exception;} send方法内有三个参数，解析如下： message：发送消息内容，可以为任意类型，当然本章内仅仅是java.lang.String。 exchangeEnum：我们自定义的交换枚举类型，方便发送消息到指定交换。 routingKey：发送消息时的路由键内容，该值采用TopicEnum枚举内的topicRouteKey作为参数值。 下面我们来看看该接口的实现类QueueMessageServiceSupport内send方法实现，如下所示： 123456789101112131415161718192021222324252627/** * 消息队列业务逻辑实现 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/11/26 * Time：14:52 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class QueueMessageServiceSupport implements QueueMessageService{ /** * 消息队列模板 */ @Autowired private RabbitTemplate rabbitTemplate; @Override public void send(Object message, ExchangeEnum exchangeEnum, String routingKey) throws Exception { //发送消息到消息队列 rabbitTemplate.convertAndSend(exchangeEnum.getName(),routingKey,message); }} 我们通过RabbitTemplate实例的convertAndSend方法将对象类型转换成JSON字符串后发送到消息队列服务端，RabbitMQ接受到消息后根据注册的消费者并且路由规则筛选后进行消息转发，并实现消息的消费。 运行测试为了方便测试我们创建一个名为UserService的实现类，如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * 用户业务逻辑 * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：22:10 * 码云：http://git.oschina.net/jnyqy * ======================== */@Servicepublic class UserService{ /** * 消息队列发送业务逻辑 */ @Autowired private QueueMessageService queueMessageService; /** * 随机创建用户 * 随机生成用户uuid编号，发送到消息队列服务端 * @return * @throws Exception */ public String randomCreateUser() throws Exception { //用户编号 String userId = UUID.randomUUID().toString(); //发送消息到rabbitmq服务端 queueMessageService.send(userId, ExchangeEnum.USER_REGISTER_TOPIC_EXCHANGE, TopicEnum.USER_REGISTER.getTopicRouteKey()); return userId; }} 该类内添加了一个名为randomCreateUser随机创建用户的方法，通过UUID随机生成字符串作为用户的编号进行传递给用户注册消息队列，完成用户的模拟创建。 编写测试用例接下来我们创建RabbitMqTester测试类来完成随机用户创建消息发送，测试用例完成简单的UserService注入，并调用randomCreateUser 方法，如下所示： 123456789101112131415161718192021222324252627282930/** * ======================== * * @author 恒宇少年 * Created with IntelliJ IDEA. * Date：2017/12/11 * Time：22:10 * 码云：http://git.oschina.net/jnyqy * ======================== */@RunWith(SpringRunner.class)@SpringBootTest(classes = RabbitMqTopicProviderApplication.class)public class RabbitMqTester{ /** * 用户业务逻辑 */ @Autowired private UserService userService; /** * 模拟随机创建用户 &amp; 发送消息到注册用户消息队列 * @throws Exception */ @Test public void testTopicMessage() throws Exception { userService.randomCreateUser(); }} 到目前为止，我们的编码已经完成，下面我们按照下面的步骤启动测试： 启动rabbitmq-topic-consumer消息消费者模块，并查看控制台输出内容是否正常 运行rabbitmq-topic-provider模块测试用例方法testTopicMessage 查看rabbitmq-topic-consumer控制台输出内容 最终效果： 12342017-12-30 18:39:16.819 INFO 2781 --- [ main] c.h.r.c.RabbitMqTopicConsumerApplication : 【【【【【Topic队列消息Consumer启动成功】】】】】2017-12-30 18:39:29.376 INFO 2781 --- [cTaskExecutor-1] c.h.r.consumer.CreateAccountConsumer : 用户：c6ef682d-da2e-4cac-a004-c244ff4c4503，注册成功，自动创建账户信息.2017-12-30 18:39:29.376 INFO 2781 --- [cTaskExecutor-1] c.h.rabbitmq.consumer.SendMailConsumer : 用户：c6ef682d-da2e-4cac-a004-c244ff4c4503，注册成功，自动发送注册成功邮件. 总结本章主要讲解了TopicExchange交换类型如何消费队列消息，讲解了常用到了的特殊字符#、*如何匹配，解决了多模块下的队列配置信息无法自动创建问题。还有一点需要注意TopicExchange交换类型在消息消费时不存在固定的先后顺序！！！","link":"/rabbitmq-topic-exchange.html"},{"title":"消息队列RabbitMQ设置信任package","text":"在这次SpringBoot升级后，之前的系统内使用实体传输受到了限制，如果使用SpringBoot默认的序列化方式不会出现信任package的问题，之所以出现这个问题是因为项目使用fastjson方式进行类的序列化已经反序列化，在之前SpringBoot 1.5.10版本的时候 RabbitMQ依赖内的DefaultClassMapper类在构造函数内配置*，表示信任项目内的所有package，在SpringBoot 2.0.0版本时，DefaultClassMapper类源码构造函数进行了修改，不再信任全部package而是仅仅信任java.util、java.lang。 本章目标基于SpringBoot2.0使用RabbitMQ自定义MessageConverter配置信任指定package或者全部package。 构建项目创建项目添加对应依赖，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930&lt;dependencies&gt; &lt;!--消息队列依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--fastjson依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--测试依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 消息队列配置文件我们需要在application.properties配置文件内添加RabbitMQ相应的配置信息，如下所示： 1234spring.rabbitmq.host=localhostspring.rabbitmq.username=adminspring.rabbitmq.password=adminspring.rabbitmq.virtual-host=/hengyu 具体消息队列的连接配置信息需要根据实际情况填写。 队列常量配置我们之前的文章都是采用的Enum方式来配置队列相关的Exchange、Name、 RouteKey等相关的信息，使用枚举有个弊端，无法在注解内作为属性的值使用，所以我们之前的Consumer类配置监听的队列时都是字符串的形式，这样后期修改时还要修改多个地方（当然队列信息很少变动），我们本章使用Constants常量的形式进行配置，如下所示： 123456789101112131415161718192021222324/** * 队列常量配置 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/7 * Time：下午10:10 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */public interface QueueConstants { /** * 消息交换 */ String MESSAGE_EXCHANGE = &quot;message.direct.exchange&quot;; /** * 消息队列名称 */ String MESSAGE_QUEUE_NAME = &quot;message.queue&quot;; /** * 消息路由键 */ String MESSAGE_ROUTE_KEY = &quot;message.send&quot;;} 示例消息队列JavaConfig配置本章是为了设置信任package，所以这里使用消息中心队列来模拟，配置代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 消息队列配置类 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/7 * Time：下午10:07 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Configurationpublic class MessageRabbitMqConfiguration { /** * 交换配置 * * @return */ @Bean public DirectExchange messageDirectExchange() { return (DirectExchange) ExchangeBuilder.directExchange(QueueConstants.MESSAGE_EXCHANGE) .durable(true) .build(); } /** * 消息队列声明 * * @return */ @Bean public Queue messageQueue() { return QueueBuilder.durable(QueueConstants.MESSAGE_QUEUE_NAME) .build(); } /** * 消息绑定 * * @return */ @Bean public Binding messageBinding() { return BindingBuilder.bind(messageQueue()) .to(messageDirectExchange()) .with(QueueConstants.MESSAGE_ROUTE_KEY); }} 上面配置类内添加Exchange、Queue、Binding等配置，将messageQueue使用message.send路由键与messageDirectExchange交换配置进行绑定。 我们在之前说了只有传递实体类时才会出现信任package问题，下面我们需要创建一个简单的消息传输实体，如下所示： 123456789101112131415161718/** * 消息实体 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/11 * Time：下午5:18 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Datapublic class MessageEntity implements Serializable { /** * 消息内容 */ private String content;} 该实体类仅添加了一个content字段，这样足够模拟我们的场景了，到这里我们的配置已经处理完，下面就是我们的队列的Provider以及Consumer的相关实体类编写。 消息提供者为队列message.queue添加Provider的代码实现，如下所示： 123456789101112131415161718192021222324252627/** * 消息队列 - 消息提供者 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/11 * Time：下午6:16 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Componentpublic class MessageProvider { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(MessageProvider.class); /** * 消息队列模板 */ @Autowired private AmqpTemplate amqpTemplate; public void sendMessage(Object object) { logger.info(&quot;写入消息队列内容：{}&quot;, JSON.toJSONString(object)); amqpTemplate.convertAndSend(QueueConstants.MESSAGE_EXCHANGE, QueueConstants.MESSAGE_ROUTE_KEY, object); }} 消息消费者当然我们有了Provider必然要有对应的Consumer，消费者代码实现如下所示： 1234567891011121314151617181920212223/** * 消息队列 - 消息消费者 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/11 * Time：下午5:32 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Component@RabbitListener(queues = QueueConstants.MESSAGE_QUEUE_NAME)public class MessageConsumer { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(MessageConsumer.class); @RabbitHandler public void handler(@Payload MessageEntity messageEntity) { logger.info(&quot;消费内容：{}&quot;, JSON.toJSONString(messageEntity)); }} 创建测试控制器我们采用控制器发送Get请求的方式进行发送消息，创建名为TestController的控制器，并添加测试方法，如下代码所示： 12345678910111213141516171819202122232425262728293031/** * 测试控制器 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/11 * Time：下午5:43 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@RestControllerpublic class TestController { /** * 消息队列 - 消息提供者 注入 */ @Autowired private MessageProvider messageProvider; /** * 测试发送消息队列方法 * * @param messageEntity 发送消息实体内容 * @return */ @RequestMapping(value = &quot;/index&quot;) public String index(MessageEntity messageEntity) { // 将实体实例写入消息队列 messageProvider.sendMessage(messageEntity); return &quot;Success&quot;; }} 测试RabbitMQ默认实体传输 下面我们启动项目，首先先来测试RabbitMQ默认的实体类方式，当然这种默认的方式不会产生信任package的情况。 我们为了证实这一点，来访问(http://localhost:8080/index?content=admin)[http://localhost:8080/index?content=admin]，我们传递`content`的值为`admin`，访问效果控制台输出内容如下： 122018-03-13 21:59:08.844 INFO 16047 --- [nio-8080-exec-1] c.h.chapter48.provider.MessageProvider : 写入消息队列内容：{&quot;content&quot;:&quot;admin&quot;}2018-03-13 21:59:08.898 INFO 16047 --- [cTaskExecutor-1] c.h.chapter48.consumer.MessageConsumer : 消费内容：{&quot;content&quot;:&quot;admin&quot;} 可以看到控制台的输出内容，直接完成了消息的消费，是没有任何问题的，下面我们对RabbitMQ添加自定义MessageConverter的配置，使用fastjson替代默认转换方式。 MessageConverter我们先来创建一个转换的实现类，只需要继承抽象类AbstractMessageConverter并实现内部的createMessage、fromMessage两个方法就可以完成实体类的序列化与反序列化的转换，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/** * 自定义消息转换器 * 采用FastJson完成消息转换 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with Eclipse. * Date：2017/10/26 * Time：19:28 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */public class RabbitMqFastJsonConverter extends AbstractMessageConverter { /** * 日志对象实例 */ private Logger logger = LoggerFactory.getLogger(RabbitMqFastJsonConverter.class); /** * 消息类型映射对象 */ private static ClassMapper classMapper = new DefaultClassMapper(); /** * 默认字符集 */ private static String DEFAULT_CHART_SET = &quot;UTF-8&quot;; /** * 创建消息 * * @param o 消息对象 * @param messageProperties 消息属性 * @return */ @Override protected Message createMessage(Object o, MessageProperties messageProperties) { byte[] bytes = null; try { String jsonString = JSON.toJSONString(o); bytes = jsonString.getBytes(DEFAULT_CHART_SET); } catch (IOException e) { throw new MessageConversionException( &quot;Failed to convert Message content&quot;, e); } messageProperties.setContentType(MessageProperties.CONTENT_TYPE_JSON); messageProperties.setContentEncoding(DEFAULT_CHART_SET); if (bytes != null) { messageProperties.setContentLength(bytes.length); } classMapper.fromClass(o.getClass(), messageProperties); return new Message(bytes, messageProperties); } /** * 转换消息为对象 * * @param message 消息对象 * @return * @throws MessageConversionException */ @Override public Object fromMessage(Message message) throws MessageConversionException { Object content = null; MessageProperties properties = message.getMessageProperties(); if (properties != null) { String contentType = properties.getContentType(); if (contentType != null &amp;&amp; contentType.contains(&quot;json&quot;)) { String encoding = properties.getContentEncoding(); if (encoding == null) { encoding = DEFAULT_CHART_SET; } try { Class&lt;?&gt; targetClass = classMapper.toClass( message.getMessageProperties()); content = convertBytesToObject(message.getBody(), encoding, targetClass); } catch (IOException e) { throw new MessageConversionException( &quot;Failed to convert Message content&quot;, e); } } else { logger.warn(&quot;Could not convert incoming message with content-type [&quot; + contentType + &quot;]&quot;); } } if (content == null) { content = message.getBody(); } return content; } /** * 将字节数组转换成实例对象 * * @param body Message对象主体字节数组 * @param encoding 字符集 * @param clazz 类型 * @return * @throws UnsupportedEncodingException */ private Object convertBytesToObject(byte[] body, String encoding, Class&lt;?&gt; clazz) throws UnsupportedEncodingException { String contentAsString = new String(body, encoding); return JSON.parseObject(contentAsString, clazz); }} 在该转换类内我们使用了DefaultClassMapper来作为类的映射，我们可以先来看下该类相关信任package的源码，如下所示： 12345678910111213141516171819202122......public class DefaultClassMapper implements ClassMapper, InitializingBean { public static final String DEFAULT_CLASSID_FIELD_NAME = &quot;__TypeId__&quot;; private static final String DEFAULT_HASHTABLE_TYPE_ID = &quot;Hashtable&quot;; // 默认信任的package列表 private static final List&lt;String&gt; TRUSTED_PACKAGES = Arrays.asList(&quot;java.util&quot;, &quot;java.lang&quot;); private final Set&lt;String&gt; trustedPackages; private volatile Map&lt;String, Class&lt;?&gt;&gt; idClassMapping; private volatile Map&lt;Class&lt;?&gt;, String&gt; classIdMapping; private volatile Class&lt;?&gt; defaultMapClass; private volatile Class&lt;?&gt; defaultType; public DefaultClassMapper() { // 构造函数初始化信任的package为默认的pakcage列表 // 仅支持java.util、java.lang两个package this.trustedPackages = new LinkedHashSet(TRUSTED_PACKAGES); this.idClassMapping = new HashMap(); this.classIdMapping = new HashMap(); this.defaultMapClass = LinkedHashMap.class; this.defaultType = LinkedHashMap.class; }...... RabbitMqConfiguration下面我们需要将该转换设置到RabbitTemplate、SimpleRabbitListenerContainerFactory内，让RabbitMQ支持自定义的消息转换，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * rabbitmq 相关配置 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/11 * Time：下午5:42 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Configurationpublic class RabbitMqConfiguration { /** * 配置消息队列模版 * 并且设置MessageConverter为自定义FastJson转换器 * @param connectionFactory * @return */ @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) { RabbitTemplate template = new RabbitTemplate(connectionFactory); template.setMessageConverter(new RabbitMqFastJsonConverter()); return template; } /** * 自定义队列容器工厂 * 并且设置MessageConverter为自定义FastJson转换器 * @param connectionFactory * @return */ @Bean public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory) { SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setMessageConverter(new RabbitMqFastJsonConverter()); factory.setDefaultRequeueRejected(false); return factory; }} 重启测试上面的代码配置我们已经把MessageConverter改成了fastjson，重启项目，再次访问http://localhost:8080/index?content=admin路径，看下控制台输出日志内容如下所示： 123456789101112Caused by: java.lang.IllegalArgumentException: The class 'com.hengyu.chapter48.entity.MessageEntity' is not in the trusted packages: [java.util, java.lang]. If you believe this class is safe to deserialize, please provide its name. If the serialization is only done by a trusted source, you can also enable trust all (*). at org.springframework.amqp.support.converter.DefaultClassMapper.toClass(DefaultClassMapper.java:211) ~[spring-amqp-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.support.converter.DefaultClassMapper.toClass(DefaultClassMapper.java:199) ~[spring-amqp-2.0.2.RELEASE.jar:2.0.2.RELEASE] at com.hengyu.chapter48.RabbitMqFastJsonConverter.fromMessage(RabbitMqFastJsonConverter.java:88) ~[classes/:na] at org.springframework.amqp.rabbit.listener.adapter.AbstractAdaptableMessageListener.extractMessage(AbstractAdaptableMessageListener.java:246) ~[spring-rabbit-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter$MessagingMessageConverterAdapter.extractPayload(MessagingMessageListenerAdapter.java:266) ~[spring-rabbit-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.support.converter.MessagingMessageConverter.fromMessage(MessagingMessageConverter.java:118) ~[spring-amqp-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.toMessagingMessage(MessagingMessageListenerAdapter.java:168) ~[spring-rabbit-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:115) ~[spring-rabbit-2.0.2.RELEASE.jar:2.0.2.RELEASE] at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1414) ~[spring-rabbit-2.0.2.RELEASE.jar:2.0.2.RELEASE] ... 8 common frames omitted 可以看到控制台已经输出了不信任com.hengyu.chapter48.entity.MessageEntity实体的错误信息，也表明了仅信任java.util、java.lang两个package，下面我们就需要继承DefaultClassMapper来重写构造函数完成信任指定的package。 重写DefaultClassMapper构造函数创建一个名为RabbitMqFastJsonClassMapper的类并且继承DefaultClassMapper，如下所示： 1234567891011121314151617181920/** * fastjson 转换映射 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/13 * Time：下午10:17 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */public class RabbitMqFastJsonClassMapper extends DefaultClassMapper { /** * 构造函数初始化信任所有pakcage */ public RabbitMqFastJsonClassMapper() { super(); setTrustedPackages(&quot;*&quot;); }} 在上面构造函数内我们设置了信任全部的package，添加了RabbitMqFastJsonClassMapper类后，需要让MessageConverter使用该类作为映射，修改RabbitMqFastJsonConverter部分代码如下所示： 123456789/** * 消息类型映射对象 */private static ClassMapper classMapper = new DefaultClassMapper();&gt;&gt;&gt; 修改为 &gt;&gt;&gt;/*** 消息类型映射对象*/private static ClassMapper classMapper = new RabbitMqFastJsonClassMapper(); 再次重启测试我们再次重启项目后，仍然访问http://localhost:8080/index?content=admin路径，查看控制台日志如下所示： 122018-03-13 22:23:35.414 INFO 16121 --- [nio-8080-exec-1] c.h.chapter48.provider.MessageProvider : 写入消息队列内容：{&quot;content&quot;:&quot;admin&quot;}2018-03-13 22:23:35.493 INFO 16121 --- [cTaskExecutor-1] c.h.chapter48.consumer.MessageConsumer : 消费内容：{&quot;content&quot;:&quot;admin&quot;} 根据日志输出已经证明可以正常的完成消息的消费。 总结如果使用RabbitMQ默认的转换方式，并不会涉及到本章遇到的信任package问题，如果想自定义消息转换并且使用DefaultClassMapper作为映射，肯定会出现信任package的问题，所以如果需要自定义转换的小伙伴，记住要设置trustedPackages。","link":"/rabbitmq-trust-package.html"},{"title":"实践：了解Redis Geo范围查询，获取当前位置最近的经纬度点","text":"近期有个获取车辆所处道路的需求，车辆行驶的范围在一个城市的市区内，针对一个城市的道路经纬度节点的数据量会比较大（就济南市而言，目前数据量在20万左右），数据的准确性以及检索效率是首要考虑的问题。 推荐阅读 SpringBoot2.x 教程汇总 Redis Geo经过一系列的调研后，由于数据的量级也还可以，决定采用Redis Geo来解决这个问题。 Redis从**3.2+**版本开始对Geo的支持进行了增强，提供了可以根据给定经纬度点位置作为中心点，在指定范围内进行检索距离最近的经纬度点。 美团外卖、饿了么等APP上根据手机位置定位范围中（1km内）的商家，类似于这种的需求也可以使用Redis Geo来实现。 123456789101112131415161718192021222324252627yuqiyu@hengyu ~&gt; redis-cli127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; geoadd road:nodes:370100 117.1087416 36.7148919 point1 (integer) 1127.0.0.1:6379&gt; geoadd road:nodes:370100 117.1087006 36.7152294 point2 (integer) 1127.0.0.1:6379&gt; keys *1) &quot;road:nodes:370100&quot;# 查询一条经纬度127.0.0.1:6379&gt; georadius road:nodes:370100 117.1089668 36.7151653 100 m withdist withcoord count 11) 1) &quot;point2&quot; 2) &quot;24.5815&quot; 3) 1) &quot;117.10870295763015747&quot; 2) &quot;36.7152294132502206&quot;# 查询两条经纬度127.0.0.1:6379&gt; georadius road:nodes:370100 117.1089668 36.7151653 100 m withdist withcoord count 21) 1) &quot;point2&quot; 2) &quot;24.5815&quot; 3) 1) &quot;117.10870295763015747&quot; 2) &quot;36.7152294132502206&quot;2) 1) &quot;point1&quot; 2) &quot;36.4573&quot; 3) 1) &quot;117.10874050855636597&quot; 2) &quot;36.71489229533602838&quot; geoadd 命令1geoadd key longitude latitude member [longitude latitude member ...] key：geo集合的唯一键 longitude：新增GPS位置的经度 latitude：新增GPS位置的纬度 member：该GPS位置的唯一标识 georadius 命令1georadius key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] key：geo集合的唯一键 longitude：待检索的GPS经度 latutude：待检索的GPS纬度 radius：检索的范围，单位可选择：米（m）、千米（km）、英里（mi）、英尺（ft） withcoord：将匹配的经纬度输出 withdist：将匹配经纬度的距离输出 count：输出匹配的数量 asc|desc：根据距离排序，asc：由近到远，desc：由远到近 georadius指令会将给定的经纬度作为检索的中心点，在指定范围内进行检索匹配的经纬度点的位置。 检索实现在实践的过程中，使用了两种方式来进行测试，发现在检索的效率上有着轻微的差异，下面通过代码实践来进行比对。 Spring Data 方式检索spring-boot-starter-data-redis是SpringBoot提供用于操作Redis的依赖，内部集成的是lettuce，下面是通过RedisTemplate的方式来检索范围内的点的代码实现。 12345678910111213141516171819202122232425262728293031323334353637383940/** * Spring Data方式测试Redis Geo * * @author 恒宇少年 */@SpringBootTest@Slf4jpublic class SpringDataRedisGeoTest { /** * Redis Geo Key */ private static final String GEO_KEY = &quot;road:nodes:370100&quot;; @Autowired private RedisTemplate redisTemplate; /** * 检索geo集合内的最近位置 */ @Test public void searchPoint() { double longitude = 117.1089668; double latitude = 36.7151653; Point centerPoint = new Point(longitude, latitude); Distance distance = new Distance(100, RedisGeoCommands.DistanceUnit.METERS); Circle circle = new Circle(centerPoint, distance); RedisGeoCommands.GeoRadiusCommandArgs args = RedisGeoCommands .GeoRadiusCommandArgs .newGeoRadiusArgs() .includeDistance() .includeCoordinates() .sortAscending() .limit(1); GeoResults&lt;RedisGeoCommands.GeoLocation&lt;String&gt;&gt; radius = redisTemplate.boundGeoOps(GEO_KEY).radius(circle, args); for (GeoResult&lt;RedisGeoCommands.GeoLocation&lt;String&gt;&gt; result : radius) { RedisGeoCommands.GeoLocation&lt;String&gt; content = result.getContent(); log.info(&quot;检索的结果，唯一标识：{}，位置：{}，距离：{}.&quot;, content.getName(), content.getPoint(), result.getDistance()); } }} Redission方式检索Redisson内部自定义封装了操作Redis的逻辑，对Redis Geo也做了支持，经过测试发现，Redisson方式要比Spring Data方式检索的效率高。 以10万条数据为例，Spring Data方式检索需要300ms左右，而Redisson方式检索仅需要90ms左右。 1234567891011121314151617181920212223242526/** * Redisson方式测试Redis Geo * * @author 恒宇少年 */@SpringBootTest@Slf4jpublic class RedissonRedisGeoTest { private static final String GEO_KEY = &quot;road:nodes:370100&quot;; @Autowired private RedissonClient redissonClient; @Test public void searchPoint() { double longitude = 117.1089668; double latitude = 36.7151653; RGeo&lt;String&gt; geo = redissonClient.getGeo(GEO_KEY, new StringCodec()); GeoSearchArgs args = GeoSearchArgs.from(longitude, latitude) .radius(100, GeoUnit.METERS) .order(GeoOrder.ASC) .count(1); Map&lt;String, Double&gt; resultMap = geo.searchWithDistance(args); resultMap.keySet().stream().forEach(member -&gt; log.info(&quot;检索结果，匹配位置的标识：{}，距离：{}.&quot;, member, resultMap.get(member))); }} 总结以上两种方式操作Redis Geo 都是可以的，有一点要注意，如果集成了Redisson依赖，Spring Data方式无法获取范围内点的Distance（距离）。","link":"/redis-geo-practice.html"},{"title":"SpringBoot2.x使用Redis缓存数据","text":"自从SpringBoot升级到了2.0版本后集成Redis作为缓存就更为简单了，我们只需要配置Redis相关的链接信息以及使用注解@EnableCaching开启缓存，这样我们就直接可以在项目内使用缓存相关的内容。 本章目标基于SpringBoot2完成快速集成Reids作为项目缓存，并讲解一些缓存常用的配置。 构建项目如果之前本地没有Redis环境，请访问第十六章：使用Redis作为SpringBoot项目数据缓存文章阅读配置，接下来我们先来创建一个新的SpringBoot项目，添加本站所使用的依赖，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960...省略部分配置&lt;dependencies&gt; &lt;!--spring data jpa依赖添加--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--redis依赖添加--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据库依赖添加--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--druid依赖添加--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.8&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok依赖添加--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--性能测试依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.databene&lt;/groupId&gt; &lt;artifactId&gt;contiperf&lt;/artifactId&gt; &lt;version&gt;2.3.4&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...省略部分配置 在本章的依赖内我们添加了contiperf性能测试工具，用于测试分别从数据库、缓存内读取的性能差异。 配置Redis信息我比较喜欢使用yml文件方式进行配置，先来删除之前项目自动创建的application.properties文件，新创建一个名为application.yml的配置文件，添加Redis相关的配置信息到application.yml文件内，如下所示： 1234567891011121314spring: application: name: spring-boot-redis jpa: database: mysql show-sql: true datasource: druid: username: root password: 123456 url: jdbc:mysql://localhost:3306/test # 配置Redis的连接密码 redis: password: hengyuboy 由于Redis有很多默认的配置，默认连接localhost上的Redis，我们这里仅仅配置连接的密码就可以了，其他的都使用默认的配置。 开启缓存我们找到创建的XxxApplication入口程序类，在该类上添加@EnableCaching注解完成开启缓存，如下所示： 12345678910/** * spring-boot-redis集成项目启动类入口 * * @author yuqiyu * @EnableCaching 注解配置启用缓存，自动配置配置文件的配置信息进行条件注入缓存所需实例 */@SpringBootApplication@EnableCachingpublic class SpringBootRedisApplication {} 测试到现在我们的缓存已经配置完成了，是不是比之前SpringBoot1.x.x版本的时候要简单很多，当然如果你有一些额外的自定义配置也是可以很简单的集成。我们本章使用的数据读取是SpringDataJPA，如果你之前并没有使用过SpringDataJPA请访问第十三章：SpringBoot实战SpringDataJPA来阅读学习。 测试添加缓存我们先来创建一个查询方法完成简单的数据缓存，方法如下所示： 123456789/** * 查询全部用户 * * @return */@Cacheable(cacheNames = &quot;user.service.all&quot;)public List&lt;TestUserEntity&gt; findAll() { return userRepository.findAll();} 接下来编写一个简单的单元测试，我们直接使用创建项目时创建的测试类，在测试类内添加一个测试方法，如下所示： 1234567/** * 测试全部缓存 */@Testpublic void findAll() { userService.findAll();} 当我们第一次启动findAll测试方法时可以看到控制台输出的SQL，如下所示： 1Hibernate: select testuseren0_.ui_id as ui_id1_0_, testuseren0_.ui_age as ui_age2_0_, testuseren0_.ui_name as ui_name3_0_, testuseren0_.ui_password as ui_passw4_0_ from test_user_info testuseren0_ 本次的数据是从数据库内查询到的，接下来我们再次执行 findAll方法来看下控制台，这时我们并没有看到输出的SQL，证明本次的数据是从Redis缓存内读取得到的。 性能测试我们在pom.xml配置文件内已经添加了性能测试的依赖contiperf，那么下面我们来测试下从 Redis内读取数据与 数据库内读取输出的性能差异。 123456789101112@Rulepublic ContiPerfRule i = new ContiPerfRule();/** * 性能测试 * 10万次查询，100个线程同时操作findAll方法 */@Test@PerfTest(invocations = 100000, threads = 100)public void contextLoads() { userService.findAll();} 我们的测试是查询10万次，并且开启100个线程来完成这个测试方法，我们先来测试使用缓存的性能，如下图所示：这是contiperf执行生成的数据统计，当我们运行性能测试方法完成后，contiperf就会自动在target-&gt;contiperf-report下自动生成一个index.html来统计本次执行的状况。我们使用Redis缓存时一共耗时23秒，下面我们把@Cacheable(cacheNames = &quot;user.service.all&quot;)注解注释掉，再来执行一遍性能测试方法。 我们在运行测试的时候可以看到控制台的查询SQL在不停的输出，这也证明了我们的数据是直接从数据库内获取的，测试结果如下图所示：从上图内可以看到一共耗时：43秒，效果已经很明显了，当然我这是本机模拟测试，如果是读取正在大并发高IO读取的服务器上时差距会更大。 总结本章主要讲解了SpringBoot2.0版本如何快速的集成Redis。 1234第一步：添加spring-boot-starter-data-redis依赖第二步：配置@EnableCaching开启缓存第三步：在application.yml内配置Redis相关的信息第四步：配置@Cacheable注解完成数据缓存","link":"/redis-springboot2-starter.html"},{"title":"RESTful规范Api最佳设计实践","text":"RESTful是目前比较流行的接口路径设计规范，基于HTTP，一般使用JSON方式定义，通过不同HttpMethod来定义对应接口的资源动作，如：新增（POST）、删除（DELETE）、更新（PUT、PATCH）、查询（GET）等。 路径设计在RESTful设计规范内，每一个接口被认为是一个资源请求，下面我们针对每一种资源类型来看下API路径设计。 路径设计的注意事项如下所示： 资源名使用复数 资源名使用名词 路径内不带特殊字符 避免多级URL 新增资源 请求方式 示例路径 POST https://api.yuqiyu.com/v1/users 新增资源使用POST方式来定义接口，新增资源数据通过RequestBody方式进行传递，如下所示： 12345curl -X POST -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users -d '{ &quot;name&quot;: &quot;恒宇少年&quot;, &quot;age&quot;: 25, &quot;address&quot;: &quot;山东济南&quot;}' 新增资源后接口应该返回该资源的唯一标识，比如：主键值。 1234{ &quot;id&quot; : 1, &quot;name&quot; : &quot;恒宇少年&quot;} 通过返回的唯一标识来操作该资源的其他数据接口。 删除资源 请求方式 示例路径 备注 DELETE https://api.yuqiyu.com/v1/users 批量删除资源 DELETE https://api.yuqiyu.com/v1/users/{id} 删除单个资源 删除资源使用DELETE方式来定义接口。 根据主键值删除单个资源 1curl -X DELETE https://api.yuqiyu.com/v1/users/1 将资源的主键值通过路径的方式传递给接口。 删除多个资源 1234567curl -X DELETE -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users -d '{ &quot;userIds&quot;: [ 1, 2, 3 ]}' 删除多个资源时通过RequestBody方式进行传递删除条件的数据列表，上面示例中通过资源的主键值集合作为删除条件，当然也可以通过资源的其他元素作为删除的条件，比如：name 更新资源 请求方式 示例路径 备注 PUT https://api.yuqiyu.com/v1/users/{id} 更新单个资源的全部元素 PATCH https://api.yuqiyu.com/v1/users/{id} 更新单个资源的部分元素 在更新资源数据时使用PUT方式比较多，也是比较常见的，如下所示： 12345curl -X PUT -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users/1 -d '{ &quot;name&quot;: &quot;恒宇少年&quot;, &quot;age&quot;: 25, &quot;address&quot;: &quot;山东济南&quot;}' 查询单个资源 请求方式 示例路径 备注 GET https://api.yuqiyu.com/v1/users/{id} 查询单个资源 GET https://api.yuqiyu.com/v1/users?name={name} 非唯一标识查询资源 唯一标识查询单个资源 1curl https://api.yuqiyu.com/v1/users/1 通过唯一标识查询资源时，使用路径方式传递标识值，体现出层级关系。 非唯一标识查询单个资源 1curl https://api.yuqiyu.com/v1/users?name=恒宇少年 查询资源数据时不仅仅都是通过唯一标识值作为查询条件，也可能会使用资源对象内的某一个元素作为查询条件。 分页查询资源 请求方式 示例路径 GET https://api.yuqiyu.com/v1/users?page=1&amp;size=20 分页查询资源时，我们一般需要传递两个参数作为分页的条件，page代表了当前分页的页码，size则代表了每页查询的资源数量。 1curl https://api.yuqiyu.com/v1/users?page=1&amp;size=20 如果分页时需要传递查询条件，可以继续追加请求参数。 1https://api.yuqiyu.com/v1/users?page=1&amp;size=20&amp;name=恒宇少年 动作资源有时我们需要有动作性的修改某一个资源的元素内容，比如：重置密码。 请求方式 示例路径 备注 POST https://api.yuqiyu.com/v1/users/{id}/actions/forget-password - 用户的唯一标识在请求路径中进行传递，而修改后的密码通过RequestBody方式进行传递，如下所示： 123curl -X POST -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users/1/actions/forget-password -d '{ &quot;newPassword&quot;: &quot;123456&quot;}' 版本号版本号是用于区分Api接口的新老标准，比较流行的分别是接口路径、头信息这两种方式传递。 接口路径方式 我们在部署接口时约定不同版本的请求使用HTTP代理转发到对应版本的接口网关，常用的请求转发代理比如使用：Nginx等。 这种方式存在一个弊端，如果多个版本同时将请求转发到同一个网关时，会导致具体版本的请求转发失败，我们访问v1时可能会转发到v2，这并不是我们期望的结果，当然可以在网关添加一层拦截器，通过提取路径上班的版本号来进行控制转发。 1234# v1版本的请求curl https://api.yuqiyu.com/v1/users/1# v2版本的请求curl https://api.yuqiyu.com/v2/users/1 头信息方式 我们可以将访问的接口版本通过HttpHeader的方式进行传递，在网关根据提取到的头信息进行控制转发到对应版本的服务，这种方式资源路径的展现形式不会因为版本的不同而变化。 1234# v1版本的请求curl -H 'Accept-Version：v1' https://api.yuqiyu.com/users/1# v2版本的请求curl -H 'Access-Version: v2' https://api.yuqiyu.com/users/1 这两个版本的请求可能请求参数、返回值都不一样，但是请求的路径是一样的。 版本头信息的Key可以根据自身情况进行定义，推荐使用Accpet形式，详见Versioning REST Services。 状态码在RESTful设计规范内我们需要充分的里面HttpStatus请求的状态码来判断一个请求发送状态，本次请求是否有效，常见的HttpStatus状态码如下所示： 状态码 发生场景 200 请求成功 201 新资源创建成功 204 没有任何内容返回 400 传递的参数格式不正确 401 没有权限访问 403 资源受保护 404 访问的路径不正确 405 访问方式不正确，GET请求使用POST方式访问 410 地址已经被转移，不可用 415 要求接口返回的格式不正确，比如：客户端需要JSON格式，接口返回的是XML 429 客户端请求次数超过限额 500 访问的接口出现系统异常 503 服务不可用，服务一般处于维护状态。 针对不同的状态码我们要做出不同的反馈，下面我们先来看一个常见的参数异常错误响应设计方式： 12345678910111213# 发起请求curl -X POST -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users -d '{ &quot;name&quot;: &quot;&quot;, &quot;age&quot;: 25, &quot;address&quot;: &quot;山东济南&quot;}'# 响应状态HttpStatus 200# 响应内容{ &quot;code&quot;: &quot;400&quot;, &quot;message&quot;: &quot;用户名必填.&quot;} 在服务端我们可以控制不同状态码、不同异常的固定返回格式，不应该将所有的异常请求都返回200，然后对应返回错误，正确的方式： 12345678910111213# 发起请求curl -X POST -H 'Content-Type: application/json' https://api.yuqiyu.com/v1/users -d '{ &quot;name&quot;: &quot;&quot;, &quot;age&quot;: 25, &quot;address&quot;: &quot;山东济南&quot;}'# 响应状态HttpStatus 400# 响应内容{ &quot;error&quot;: &quot;Bad Request&quot;, &quot;message&quot;: &quot;用户名必填.&quot;} 响应格式接口的响应格式应该统一。 每一个请求成功的接口返回值外层格式应该统一，在服务端可以采用实体方式进行泛型返回。 如下所示： 12345678910111213141516/** * Api统一响应实体 * {@link #data } 每个不同的接口响应的数据内容 * {@link #code } 业务异常响应状态码 * {@link #errorMsg} 业务异常消息内容 * {@link #timestamp} 接口响应的时间戳 * * @author 恒宇少年 - 于起宇 */@Datapublic class ApiResponse&lt;T&gt; implements Serializable { private T data; private String code; private String errorMsg; private Long timestamp;} data 由于每一个API的响应数据类型不一致，所以在上面采用的泛型的泛型进行返回，data可以返回任意类型的数据。 code 业务逻辑异常码，比如：USER_NOT_FOUND（用户不存在）这是接口的约定 errorMsg 对应code值得描述。 timestamp 请求响应的时间戳 总结RESTful是API的设计规范，并不是所有的接口都应该遵循这一套规范来设计，不过我们在设计初期更应该规范性，这样我们在后期阅读代码时根据路径以及请求方式就可以了解接口的主要完成的工作。","link":"/restful-api-uri.html"},{"title":"深入理解RocketMq普通消息和顺序消息使用，原理，优化","text":"最近一直再做一些系统上的压测，并对一些问题做了优化，从这些里面收获了一些很多好的优化经验，后续的文章都会以这方面为主。 1. 背景这次打压的过程中收获比较的大的是，对RocketMq的一些优化。最开始我们公司使用的是RabbitMq,再一些流量高峰的场景下，发现队列堆积比较严重，导致RabbitMq挂了。为了应对这个场景，最终我们引入了阿里云的RocketMq，RocketMq可以处理可以处理很多消息堆积，并且服务的稳定不挂也可以由阿里云保证。引入了RocketMq了之后，的确解决了队列堆积导致消息队列宕机的问题。本来以为使用了RocketMq之后，可以万事无忧，但是其实在打压过程中发现了不少问题，这里先提几个问题，大家带着这几个问题在文中去寻找答案： 在RocketMq中,如果消息队列发生堆积，consumer会发生什么样的影响？ 在RocketMq中，普通消息和顺序消息有没有什么办法提升消息消费速度？ 消息失败重试次数怎么设置较为合理？顺序消息和普通消息有不同吗？ 2. 普通消息 VS 顺序消息在RocketMq中提供了多种消息类型让我们进行配置： 普通消息：没有特殊功能的消息。 分区顺序消息：以分区纬度保持顺序进行消费的消息。 全局顺序消息：全局顺序消息可以看作是只分一个区，始终再同一个分区上进行消费。 定时/延时消息：消息可以延迟一段特定时间进行消费。 事务消息：二阶段事务消息，先进行prepare投递消息，此时不能进行消息消费，当二阶段发出commit或者rollback的时候才会进行消息的消费或者回滚。 虽然配置种类比较繁多，但是使用得还是普通消息和分区顺序消息。后续主要讲得也是这两种消息。 2.1 发送消息2.1.1 普通消息 普通消息的发送的代码比较简单，如下所示： 1234567891011 public static void main(String[] args) throws MQClientException, InterruptedException { DefaultMQProducer producer = new DefaultMQProducer(&quot;test_group_producer&quot;); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); producer.start(); Message msg = new Message(&quot;Test_Topic&quot;, &quot;test_tag&quot;, (&quot;Hello World&quot;).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf(&quot;%s%n&quot;, sendResult); producer.shutdown();}其内部核心代码为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { // 1. 根据 topic找到publishInfo TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) { boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; // 如果是同步 就三次 否则就1次 int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; // 循环 for (; times &lt; timesTotal; times++) { String lastBrokerName = null == mq ? null : mq.getBrokerName(); MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) { mq = mqSelected; brokersSent[times] = mq.getBrokerName(); try { beginTimestampPrev = System.currentTimeMillis(); if (times &gt; 0) { //Reset topic with namespace during resend. msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); } long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout &lt; costTime) { callTimeout = true; break; } sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); // 更新延迟 this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) { case ASYNC: return null; case ONEWAY: return null; case SYNC: if (sendResult.getSendStatus() != SendStatus.SEND_OK) { if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) { continue; } } return sendResult; default: break; } } } else { break; } } // 省略 } 主要流程如下： Step 1： 根据Topic 获取TopicPublishInfo，TopicPublishInfo中有我们的Topic发布消息的信息()，这个数据先从本地获取如果本地没有，则从NameServer去拉取，并且定时每隔20s会去获取TopicPublishInfo。 Step 2： 获取总共执行次数(用于重试)，如果发送方式是同步，那么总共次数会有3次，其他情况只会有1次。 Step 3: 从MessageQueue中选取一个进行发送，MessageQueue的概念可以等同于Kafka的partion分区，看作发送消息的最小粒度。这个选择有两种方式： 根据发送延迟进行选择，如果上一次发送的Broker是可用的，则从当前Broker选择遍历循环选择一个，如果不可用那么需要选择一个延迟最低的Broker从当前Broker上选择MessageQueue。 通过轮训的方式进行选择MessageQueue。 Step 4: 将Message发送至选择出来的MessageQueue上的Broker。 Step 5: 更新Broker的延迟。 Step 6: 根据不同的发送方式来处理结果： Async: 异步发送，通过callBack关心结果，所以这里不进行处理。 OneWay: 顾名思义，就是单向发送，只需要发给broker，不需要关心结果，这里连callback都不需要。 Sync: 同步发送，需要关心结果，根据结果判断是否需要进行重试，然后回到Step3。 可以看见Rocketmq发送普通消息的流程比较清晰简单，下面来看看顺序消息。 2.1.2 顺序消息顺序消息分为分区顺序消息和全局顺序消息，全局顺序消息比较容易理解，也就是哪条消息先进入，哪条消息就会先被消费，符合我们的FIFO，很多时候全局消息的实现代价很大，所以就出现了分区顺序消息。分区顺序消息的概念可以如下图所示:我们通过对消息的key，进行hash，相同hash的消息会被分配到同一个分区里面，当然如果要做全局顺序消息，我们的分区只需要一个即可，所以全局顺序消息的代价是比较大的。对RocketMq熟悉的小伙伴会发现，它其实并没有提供顺序消息发送相关的API,但是在阿里云的RocketMq版本提供了顺序消息的API，原理比较简单，其实也是对现有API的一个封装： 123456789101112SendResult sendResultRMQ = this.defaultMQProducer.send(msgRMQ, new MessageQueueSelector() { @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object shardingKey) { int select = Math.abs(shardingKey.hashCode()); if (select &lt; 0) { select = 0; } return mqs.get(select % mqs.size()); } }, shardingKey); 可以看见顺序消息将MessageQueue的选择交由我们发送方去做，所以我们直接利用我们shardingKey的hashCode进行发送分区。 3.1 消费消息3.1.1 普通消息普通消息使用比较简单，如下面代码所示： 123456789101112131415161718public static void main(String[] args) throws InterruptedException, MQClientException { DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;Test_Consumer&quot;); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) { System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); consumer.setConsumeThreadMin(10); consumer.setConsumeThreadMax(10); consumer.start(); System.out.printf(&quot;Consumer Started.%n&quot;);} Step1：首先新建一个DefaultMQPushConsumer，并注册对应的Topic和NameServer的信息。 Step2: 注册消息监听器，再RocketMq中有两种消息监听器，一个是MessageListenerConcurrently，用于我们普通消息并发消费，还有一个是MessageListenerOrderly，用于我们顺序消息。这里我们使用的MessageListenerConcurrently。 Step3: 设置ConsumeThread大小，用于控制我们的线程池去消费他。 Step4: 启动Consumer。 启动Consumer之后，我们就开始真正的从Broker去进行消费了，但是我们如何从Broker去消费的呢？首先在我们的第一步里面我们订阅了一个Topic，我们就会定时去刷新Topic的相关信息比如MessageQueue的变更，然后将对应的MessageQueue分配给当前Consumer: 12345678910111213141516171819202122232425262728293031323334353637383940414243// 这个数据 是10s更新一次 从内存中获取Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);// 这个数据实时去拉取List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);if (null == mqSet) { if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) { log.warn(&quot;doRebalance, {}, but the topic[{}] not exist.&quot;, consumerGroup, topic); }}if (null == cidAll) { log.warn(&quot;doRebalance, {} {}, get consumer id list failed&quot;, consumerGroup, topic);}if (mqSet != null &amp;&amp; cidAll != null) { List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; List&lt;MessageQueue&gt; allocateResult = null; try { //通过默认的分配策略进行分配 allocateResult = strategy.allocate(this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); } catch (Throwable e) { log.error( &quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName={}&quot;, strategy.getName(), e); return; } Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;(); if (allocateResult != null) { allocateResultSet.addAll(allocateResult); } boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); 这里首先向Broker拿到当前消费所有的ConsumerId默认是对应机器的Ip+实例名字，Broker中的ConsumerId信息是Consumer通过心跳定时进行上报得来的，然后根据消费分配策略将消息分配给Consumer,这里默认是平均分配，将我们分配到的消息队列，记录在processQueueTable中，如果出现了新增，那么我们需要创建一个PullRequst代表这拉取消息的请求，异步去处理： 12345678910111213141516171819202122232425262728293031323334List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;();for (MessageQueue mq : mqSet) { if (!this.processQueueTable.containsKey(mq)) { if (isOrder &amp;&amp; !this.lock(mq)) { log.warn(&quot;doRebalance, {}, add a new mq failed, {}, because lock failed&quot;, consumerGroup, mq); continue; } this.removeDirtyOffset(mq); ProcessQueue pq = new ProcessQueue(); // 这里就是获取我们第一次应该拿什么offset long nextOffset = this.computePullFromWhere(mq); if (nextOffset &gt;= 0) { ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq); if (pre != null) { log.info(&quot;doRebalance, {}, mq already exists, {}&quot;, consumerGroup, mq); } else { log.info(&quot;doRebalance, {}, add a new mq, {}&quot;, consumerGroup, mq); PullRequest pullRequest = new PullRequest(); pullRequest.setConsumerGroup(consumerGroup); pullRequest.setNextOffset(nextOffset); pullRequest.setMessageQueue(mq); pullRequest.setProcessQueue(pq); pullRequestList.add(pullRequest); changed = true; } } else { log.warn(&quot;doRebalance, {}, add new mq failed, {}&quot;, consumerGroup, mq); } }}this.dispatchPullRequest(pullRequestList); 在PullService中会不断的从PullRequestQueue拿取数据，然后进行拉取数据。 1234567891011while (!this.isStopped()) { try { // rebalance 之后第一次向这个队列放数据 后续消费的时候会继续放 PullRequest pullRequest = this.pullRequestQueue.take(); this.pullMessage(pullRequest); } catch (InterruptedException ignored) { } catch (Exception e) { log.error(&quot;Pull Message Service Run Method exception&quot;, e); }} 拉取数据之后，这里会给PullCallBack进行响应： 123456789101112131415161718192021222324252627PullCallback pullCallback = new PullCallback() { @Override public void onSuccess(PullResult pullResult) { if (pullResult != null) { pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult, subscriptionData); switch (pullResult.getPullStatus()) { case FOUND: firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset(); boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList()); DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume); if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) { DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval()); } else { DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest); } 如果这里成功拉取到消息的话，我们首先将拉取的消息存入到我们的ProcessQueue中,ProcessQueue用于我们消费者处理的状态以及待处理的消息，然后提交到我们的Consumer线程池中进行真正的业务逻辑消费，然后再提交一个PullRequest用于我们下次消费。大家看到这里有没有发现这个模式和我们的netty中的单线程accpet，多个线程来处理业务逻辑很相似，其原理都是一样，由一个线程不断的去拉取，然后由我们业务上定义的线程池进行处理。如下图所示： 我们发现我们拉取消息其实是一个循环的过程，这里就来到了第一个问题，如果消息队列消费的速度跟不上消息发送的速度，那么就会出现消息堆积，很多同学根据过程来看可能会以为，我们的拉取消息一直在进行，由于我们的消费速度比较慢，会有很多message以队列的形式存在于我们的内存中，那么会导致我们的JVM出现OOM也就是内存溢出。那么到底会不会出现OOM呢？其实是不会的，RocketMq对安全性方面做得很好，有下面两段代码: 1234567891011if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) { System.out.println(cachedMessageCount + &quot;:&quot;+pullRequest); this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return;}if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) { this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); return;} 首先是会判断当前内存缓存的Message数量是否大于限制的值默认是1000，如果大于则延迟一段时间再次提交pullRequest。然后判断当前内存缓存的Size大小是否大于了某个值，默认是100M，如果大于也会延迟一段时间再次提交pullRequest。所以在我们consumer上如果出现消息堆积，基本也没有什么影响。 那我们想想第二个问题应该怎么解决呢？再普通消息的场景下，如何提升消费速度？ 首先肯定是需要提升我们本身的处理速度，处理速度提升，消费速度自然就会提升。 其次是要设置一个合理大小的consumer线程池，太小的话机器的资源得不到充分利用，太大的话线程的上下文切换可能会很快,一般来说根据消费者的业务来判断，如果是cpu密集型线程设置cpu大小就好，如果是io密集型设置两倍cpu大小。 还有个就是MessageQueue,细心的同学肯定在上面看见我们消费者消费消息之前，会被分配MessageQueue来进行获取消费，所以自然而然就会想到，如果多分配一点MessageQueue数量是不是就会加快我们的消费速度，其实MessageQueue对于我们的普通消息消费提升帮助是很小的，因为所有的消费请求会被提交到线程池里面去消费，MessageQueue再多也无济于事，除非当我们的Consumer机器很多的时候，MessageQueue数量小于Consumer机器的时候，这个时候增加MessageQueue才会有提升效果，正所谓让我们的机器雨露均沾嘛。 3.1.1.1普通消息-消费结果处理在rocketmq中对消息的消费结果处理也比较重要，这里还是先提三个问题： 我们的普通消息是怎么处理结果的呢？ 如果消费失败会怎么办呢？ 在普通消息消费的时候，是并发处理，如果出现offset靠后的消息先被消费完，但是我们的offset靠前的还没有被消费完，这个时候出现了宕机，我们的offset靠前的这部分数据是否会丢失呢？也就是下次消费的时候是否会从offset靠后的没有被消费的开始消费呢？如果不是的话，rocketmq是怎么做到的呢？首先我们来看第一个问题，怎么处理消费结果，在processResult中有如下代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void processConsumeResult( final ConsumeConcurrentlyStatus status, final ConsumeConcurrentlyContext context, final ConsumeRequest consumeRequest ) { int ackIndex = context.getAckIndex(); switch (status) { case CONSUME_SUCCESS: int ok = ackIndex + 1; int failed = consumeRequest.getMsgs().size() - ok; this.getConsumerStatsManager().incConsumeOKTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), ok); this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), failed); break; case RECONSUME_LATER: ackIndex = -1; this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), consumeRequest.getMsgs().size()); break; default: break; } switch (this.defaultMQPushConsumer.getMessageModel()) { case BROADCASTING: for (int i = ackIndex + 1; i &lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); log.warn(&quot;BROADCASTING, the message consume failed, drop it, {}&quot;, msg.toString()); } break; case CLUSTERING: List&lt;MessageExt&gt; msgBackFailed = new ArrayList&lt;MessageExt&gt;(consumeRequest.getMsgs().size()); for (int i = ackIndex + 1; i &lt; consumeRequest.getMsgs().size(); i++) { MessageExt msg = consumeRequest.getMsgs().get(i); boolean result = this.sendMessageBack(msg, context); if (!result) { msg.setReconsumeTimes(msg.getReconsumeTimes() + 1); msgBackFailed.add(msg); } } if (!msgBackFailed.isEmpty()) { consumeRequest.getMsgs().removeAll(msgBackFailed); this.submitConsumeRequestLater(msgBackFailed, consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue()); } break; default: break; } long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs()); if (offset &gt;= 0 &amp;&amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore().updateOffset(consumeRequest.getMessageQueue(), offset, true); } } Step 1: 首先获取ackIndex，即确认成功的数量，默认是int的最大数，代表着全部成功。 Step 2: 获取 ConsumeConcurrentlyStatus，根据不同的状态进行处理，ConsumeConcurrentlyStatus有两个： CONSUME_SUCCESS: 代表着消费成功，记录成功的TPS和失败的TPS。 RECONSUME_LATER: 代表着需要重新消费，一般是失败才会返回这个状态，记录失败的TPS。 Step 3: 然后根据消息类型，进行不同的逻辑重试，消息消费类型有两种： BROADCASTING: 广播消费，广播消费不会进行重试，这里会直接打一个warn日志然后丢弃。 CLUSTERING：集群消费，这里会首先将失败的消息发送回当前的topic，如果发送失败，这里会继续进行本地消费重试。如果在Broker中发现这个消息重试次数已经达到上限，就会将这个消息发送至RetryTopic，然后由RetryTopic发送至死信队列。 Step 4: 获取message的offset,更新当前消费进度 在上面的第四步中，如果不深入进去看内部逻辑，这里会误以为，他会将当前消息的offset给更新到最新的消费进度，那问题三中说的中间的offset是有可能被丢失的，但实际上是不会发生的，具体的逻辑保证在removeMessage中： 1234567891011121314151617181920212223242526272829303132public long removeMessage(final List&lt;MessageExt&gt; msgs) { long result = -1; final long now = System.currentTimeMillis(); try { this.lockTreeMap.writeLock().lockInterruptibly(); this.lastConsumeTimestamp = now; try { if (!msgTreeMap.isEmpty()) { result = this.queueOffsetMax + 1; int removedCnt = 0; for (MessageExt msg : msgs) { MessageExt prev = msgTreeMap.remove(msg.getQueueOffset()); if (prev != null) { removedCnt--; msgSize.addAndGet(0 - msg.getBody().length); } } msgCount.addAndGet(removedCnt); if (!msgTreeMap.isEmpty()) { result = msgTreeMap.firstKey(); } } } finally { this.lockTreeMap.writeLock().unlock(); } } catch (Throwable t) { log.error(&quot;removeMessage exception&quot;, t); } return result;} 在removeMessage中通过msgTreeMap去做了一个保证，msgTreeMap是一个TreeMap，根据offset升序排序，如果treeMap中有值的话，他返回的offset就会是当前msgTreeMap中的firstKey，而不是当前的offset，从而就解决了问题三。 上面的过程总结为下图所示： 3.1.2 顺序消息顺序消息的消费前面过程和普通消息基本一样，这里我们需要关注的是将消息丢给我们消费线程池之后的逻辑： 12345678final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) { // 省略 List&lt;MessageExt&gt; msgs = this.processQueue.takeMessags(consumeBatchSize); status = messageListener.consumeMessage(Collections.unmodifiableList(msgs), context); // 省略} 可以发现这里比普通消息多了一个步骤，那就是加锁，这里会获取到以messageQueue为纬度去加锁，然后去我们的processQueue中获取到我们的Message, 这里也是用的我们的msgTreeMap, 获取的最小offset的Message。所以我们之前的线程池提高并发速度的策略在这里没有用了，那么应该怎么办呢？既然我们加锁是以messageQueue为纬度，那么增加MessageQueue就好了，所以这里的提升消费速度刚好和普通消息相反，再普通消息中提升Messagequeue可能效果并没有那么大，但是在顺序消息的消费中提升就很大了。我们在压测的时候，发现顺序消息消费很慢，消息堆积很严重，经过调试发现阿里云上的rocketmq默认读写队列为16，我们consumer机器有10台，每个consumer线程池大小为10，理论并发应该有100，但是由于顺序消息的原因导致实际并发只有16，最后找阿里的技术人员将读写队列扩至100，这样充分利用我们的资源，极大的增加了顺序消息消费的速度，消息基本不会再堆积。 3.1.2.1 顺序消息-消费结果处理顺序消息的结果处理和普通消息的处理流程，稍有不同，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public boolean processConsumeResult( final List&lt;MessageExt&gt; msgs, final ConsumeOrderlyStatus status, final ConsumeOrderlyContext context, final ConsumeRequest consumeRequest ) { boolean continueConsume = true; long commitOffset = -1L; if (context.isAutoCommit()) { switch (status) { case SUCCESS: commitOffset = consumeRequest.getProcessQueue().commit(); this.getConsumerStatsManager().incConsumeOKTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), msgs.size()); break; case SUSPEND_CURRENT_QUEUE_A_MOMENT: this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), msgs.size()); if (checkReconsumeTimes(msgs)) { consumeRequest.getProcessQueue().makeMessageToCosumeAgain(msgs); this.submitConsumeRequestLater( consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue(), context.getSuspendCurrentQueueTimeMillis()); continueConsume = false; } else { commitOffset = consumeRequest.getProcessQueue().commit(); } break; default: break; } } else { switch (status) { case SUCCESS: this.getConsumerStatsManager().incConsumeOKTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), msgs.size()); break; case SUSPEND_CURRENT_QUEUE_A_MOMENT: this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), msgs.size()); if (checkReconsumeTimes(msgs)) { consumeRequest.getProcessQueue().makeMessageToCosumeAgain(msgs); this.submitConsumeRequestLater( consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue(), context.getSuspendCurrentQueueTimeMillis()); continueConsume = false; } break; default: break; } } if (commitOffset &gt;= 0 &amp;&amp; !consumeRequest.getProcessQueue().isDropped()) { this.defaultMQPushConsumerImpl.getOffsetStore().updateOffset(consumeRequest.getMessageQueue(), commitOffset, false); } return continueConsume; } Step 1: 判断当前offset是否是自动提交更新，一般autoCommit不需要设置，默认是自动提交，除非有特别的需求才会做这样一个设置。 Step 2: 如果是自动提交，需要判断状态： SUCCESS: 如果是成功状态则获取当前需要提交的offset，然后记录到OK的TPS中 SUSPEND_CURRENT_QUEUE_A_MOMENT：注意在普通消息中如果失败会返回RECONSUME_LATER，有什么不同呢？再这个状态下面，并不会向当前topic再次发送，而是会在本地线程池再次提交一个ConsumeRequest，延迟重试，这里默认时间是1s。如果大于了最大重试次数这里会将数据发送至RetryTopic。 Step 3: 如果不是自动提交的话，和步骤2类似，但是不会获取提交的offset。 Step 4: 更新offset。 这里回到我们的第三个问题，如何设置消息消费的重试次数呢？由于我们直接使用的阿里云的mq，所以我们又包装了一层，方便接入。再接入层中我们最开始统一配置了最大重试2000次，这里设置2000次的原因主要是想让我们的消息队列尽量无限重试，因为我们默认消息基本最终会成功，但是为了以防万一，所以这里设置了一个较大的数值2000次。设置2000次对于我们的普通消息，基本没什么影响，因为他会重新投递至broker，但是我们的顺序消息是不行的，如果顺序消息设置重试2000次，当遇到了这种不可能成功的消息的时候就会导致消息一直在本地进行重试，并且由于对队列加锁了，所以当前MessageQueue将会一直被阻塞，导致后续消息不会被消费，如果设置2000次那么至少会阻塞半个小时以上。所以这里应该将顺序消息设置一个较小的值，目前我们设置为16。 4. 最后之前没怎么看过Rocketmq的源码，经过这次打压，从Rocketmq中学习到了很多精妙优秀的设计，将一些经验提炼成了文中的一些问题，希望大家能仔细阅读，找到答案。","link":"/rocketmq-message-use-away.html"},{"title":"SpringCloud与Seata分布式事务初体验","text":"在本篇文章中我们在SpringCloud环境下通过使用Seata来模拟用户购买商品时由于用户余额不足导致本次订单提交失败，来验证下在MySQL数据库内事务是否会回滚。 本章文章只涉及所需要测试的服务列表以及Seata配置部分。 用户提交订单购买商品大致分为以下几个步骤： 减少库存 扣除金额 提交订单 1. 准备环境 Seata Server 如果对Seata Server部署方式还不了解，请访问：/seata-init-env.html Eureka Server 服务注册中心，如果对Eureka Server部署方式还不了解，请访问/eureka-server.html 2. 准备测试服务为了方便学习的同学查看源码，我们本章节源码采用Maven Module（多模块）的方式进行构建。 我们用于测试的服务所使用的第三方依赖都一致，各个服务的pom.xml文件内容如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign接口定义--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.chapter&lt;/groupId&gt; &lt;artifactId&gt;openfeign-service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--公共依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.chapter&lt;/groupId&gt; &lt;artifactId&gt;common-service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-mybatis-enhance&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.1 Openfeign接口定义模块由于我们服务之间采用的Openfeign方式进行相互调用，所以创建了一个模块openfeign-service来提供服务接口的定义。 账户服务提供的接口定义 账户服务对外所提供的Openfeign接口定义如下所示： 1234567891011121314151617/** * 账户服务接口 * * @author 恒宇少年 */@FeignClient(name = &quot;account-service&quot;)@RequestMapping(value = &quot;/account&quot;)public interface AccountClient { /** * 扣除指定账户金额 * * @param accountId 账户编号 * @param money 金额 */ @PostMapping void deduction(@RequestParam(&quot;accountId&quot;) Integer accountId, @RequestParam(&quot;money&quot;) Double money);} 商品服务提供的接口定义 商品服务对外所提供的Openfeign接口定义如下所示： 1234567891011121314151617181920212223242526/** * 商品服务接口定义 * * @author 恒宇少年 */@FeignClient(name = &quot;good-service&quot;)@RequestMapping(value = &quot;/good&quot;)public interface GoodClient { /** * 查询商品基本信息 * * @param goodId {@link Good#getId()} * @return {@link Good} */ @GetMapping Good findById(@RequestParam(&quot;goodId&quot;) Integer goodId); /** * 减少商品的库存 * * @param goodId {@link Good#getId()} * @param stock 减少库存的数量 */ @PostMapping void reduceStock(@RequestParam(&quot;goodId&quot;) Integer goodId, @RequestParam(&quot;stock&quot;) int stock);} 2.2 公共模块公共模块common-service内所提供的类是共用的，各个服务都可以调用，其中最为重要的是将Seata所提供的数据源代理（DataSourceProxy）实例化配置放到了这个模块中，数据库代理相关配置代码如下所示： 12345678910111213141516171819202122232425262728293031323334/** * Seata所需数据库代理配置类 * * @author 恒宇少年 */@Configurationpublic class DataSourceProxyAutoConfiguration { /** * 数据源属性配置 * {@link DataSourceProperties} */ private DataSourceProperties dataSourceProperties; public DataSourceProxyAutoConfiguration(DataSourceProperties dataSourceProperties) { this.dataSourceProperties = dataSourceProperties; } /** * 配置数据源代理，用于事务回滚 * * @return The default datasource * @see DataSourceProxy */ @Primary @Bean(&quot;dataSource&quot;) public DataSource dataSource() { HikariDataSource dataSource = new HikariDataSource(); dataSource.setJdbcUrl(dataSourceProperties.getUrl()); dataSource.setUsername(dataSourceProperties.getUsername()); dataSource.setPassword(dataSourceProperties.getPassword()); dataSource.setDriverClassName(dataSourceProperties.getDriverClassName()); return new DataSourceProxy(dataSource); }} 该配置类在所需要的服务中使用@Import注解进行导入使用。 2.3 账户服务 服务接口实现 账户服务用于提供接口的服务实现，通过实现openfeign-service内提供的AccountClient服务定义接口来对应提供服务实现，实现接口如下所示： 123456789101112131415161718/** * 账户接口实现 * * @author 恒宇少年 */@RestControllerpublic class AccountController implements AccountClient { /** * 账户业务逻辑 */ @Autowired private AccountService accountService; @Override public void deduction(Integer accountId, Double money) { accountService.deduction(accountId, money); }} 服务配置（application.yml） 12345678910111213141516171819202122# 服务名spring: application: name: account-service # seata分组 cloud: alibaba: seata: tx-service-group: minbox-seata # 数据源 datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver# eurekaeureka: client: service-url: defaultZone: http://service:nodev2@10.180.98.83:10001/eureka/ 通过spring.cloud.alibaba.seata.tx-service-group我们可以指定服务所属事务的分组，该配置非必填，默认为spring.application.name配置的内容加上字符串-fescar-service-group，如：account-service-fescar-service-group，详见com.alibaba.cloud.seata.GlobalTransactionAutoConfiguration配置类源码。 在我本地测试环境的Eureka Server在10.180.98.83服务器上，这里需要修改成你们自己的地址，数据库连接信息也需要修改成你们自己的配置。 导入Seata数据源代理配置 12345678910111213141516/** * @author 恒宇少年 */@SpringBootApplication@Import(DataSourceProxyAutoConfiguration.class)public class AccountServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(AccountServiceApplication.class); public static void main(String[] args) { SpringApplication.run(AccountServiceApplication.class, args); logger.info(&quot;账户服务启动成功.&quot;); }} 通过@Import导入我们common-service内提供的Seata数据源代理配置类DataSourceProxyAutoConfiguration。 2.4 商品服务 服务接口实现 商品服务提供商品的查询以及库存扣减接口服务，实现openfeign-service提供的GoodClient服务接口定义如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * 商品接口定义实现 * * @author 恒宇少年 */@RestControllerpublic class GoodController implements GoodClient { /** * 商品业务逻辑 */ @Autowired private GoodService goodService; /** * 查询商品信息 * * @param goodId {@link Good#getId()} * @return */ @Override public Good findById(Integer goodId) { return goodService.findById(goodId); } /** * 扣减商品库存 * * @param goodId {@link Good#getId()} * @param stock 减少库存的数量 */ @Override public void reduceStock(Integer goodId, int stock) { goodService.reduceStock(goodId, stock); }} 服务配置（application.yml） 123456789101112131415161718192021spring: application: name: good-service cloud: alibaba: seata: tx-service-group: minbox-seata datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Drivereureka: client: service-url: defaultZone: http://service:nodev2@10.180.98.83:10001/eureka/server: port: 8081 导入Seata数据源代理配置 12345678910111213141516/** * @author 恒宇少年 */@SpringBootApplication@Import(DataSourceProxyAutoConfiguration.class)public class GoodServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(GoodServiceApplication.class); public static void main(String[] args) { SpringApplication.run(GoodServiceApplication.class, args); logger.info(&quot;商品服务启动成功.&quot;); }} 2.5 订单服务 服务接口 订单服务提供了下单的接口，通过调用该接口完成下单功能，下单接口会通过Openfeign调用account-service、good-service所提供的服务接口来完成数据验证，如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/order&quot;)public class OrderController { /** * 账户服务接口 */ @Autowired private AccountClient accountClient; /** * 商品服务接口 */ @Autowired private GoodClient goodClient; /** * 订单业务逻辑 */ @Autowired private OrderService orderService; /** * 通过{@link GoodClient#reduceStock(Integer, int)}方法减少商品的库存，判断库存剩余数量 * 通过{@link AccountClient#deduction(Integer, Double)}方法扣除商品所需要的金额，金额不足由account-service抛出异常 * * @param goodId {@link Good#getId()} * @param accountId {@link Account#getId()} * @param buyCount 购买数量 * @return */ @PostMapping @GlobalTransactional public String submitOrder( @RequestParam(&quot;goodId&quot;) Integer goodId, @RequestParam(&quot;accountId&quot;) Integer accountId, @RequestParam(&quot;buyCount&quot;) int buyCount) { Good good = goodClient.findById(goodId); Double orderPrice = buyCount * good.getPrice(); goodClient.reduceStock(goodId, buyCount); accountClient.deduction(accountId, orderPrice); Order order = toOrder(goodId, accountId, orderPrice); orderService.addOrder(order); return &quot;下单成功.&quot;; } private Order toOrder(Integer goodId, Integer accountId, Double orderPrice) { Order order = new Order(); order.setGoodId(goodId); order.setAccountId(accountId); order.setPrice(orderPrice); return order; }} 服务配置（application.yml） 123456789101112131415161718192021spring: application: name: order-service cloud: alibaba: seata: tx-service-group: minbox-seata datasource: url: jdbc:mysql://localhost:3306/test username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Drivereureka: client: service-url: defaultZone: http://service:nodev2@10.180.98.83:10001/eureka/server: port: 8082 启用Openfeign &amp; 导入Seata数据源代理配置 1234567891011121314151617/** * @author 恒宇少年 */@SpringBootApplication@EnableFeignClients(basePackages = &quot;org.minbox.chapter.seata.openfeign&quot;)@Import(DataSourceProxyAutoConfiguration.class)public class OrderServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(OrderServiceApplication.class); public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); logger.info(&quot;订单服务启动成功.&quot;); }} 我们仅在order-service调用了其他服务的Openfeign接口，所以我们只需要在order-service内通过@EnableFeignClients注解启用Openfeign接口实现代理。 3. 服务连接Seata Server服务想要连接到Seata Server需要添加两个配置文件，分别是registry.conf、file.conf。 registry.conf 注册到Seata Server的配置文件，里面包含了注册方式、配置文件读取方式，内容如下所示： 1234567891011121314151617registry { # file、nacos、eureka、redis、zk、consul type = &quot;file&quot; file { name = &quot;file.conf&quot; }}config { type = &quot;file&quot; file { name = &quot;file.conf&quot; }} file.conf 该配置文件内包含了使用file方式连接到Eureka Server的配置信息以及存储分布式事务信息的方式，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667transport { # tcp udt unix-domain-socket type = &quot;TCP&quot; #NIO NATIVE server = &quot;NIO&quot; #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = &quot;NettyBoss&quot; worker-thread-prefix = &quot;NettyServerNIOWorker&quot; server-executor-thread-prefix = &quot;NettyServerBizHandler&quot; share-boss-worker = false client-selector-thread-prefix = &quot;NettyClientSelector&quot; client-selector-thread-size = 1 client-worker-thread-prefix = &quot;NettyClientWorkerThread&quot; # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 }}## transaction log storestore { ## store mode: file、db mode = &quot;file&quot; ## file store file { dir = &quot;sessionStore&quot; # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { datasource = &quot;druid&quot; db-type = &quot;mysql&quot; driver-class-name = &quot;com.mysql.jdbc.Driver&quot; url = &quot;jdbc:mysql://10.180.98.83:3306/iot-transactional&quot; user = &quot;dev&quot; password = &quot;dev2019.&quot; }}service { vgroup_mapping.minbox-seata = &quot;default&quot; default.grouplist = &quot;10.180.98.83:8091&quot; enableDegrade = false disable = false}client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 }} 配置文件内service部分需要注意，我们在application.yml配置文件内配置了事务分组为minbox-seata，在这里需要进行对应配置vgroup_mapping.minbox-seata = &quot;default&quot;,通过 default.grouplist = &quot;10.180.98.83:8091&quot;配置Seata Server的服务列表。 将上面两个配置文件在各个服务resources目录下创建。 4. 编写下单逻辑在前面说了那么多，只是做了准备工作，我们要为每个参与下单的服务添加对应的业务逻辑。 账户服务 在account-service内添加账户余额扣除业务逻辑类，AccountService如下所示： 12345678910111213141516171819202122232425262728293031/** * 账户业务逻辑处理 * * @author 恒宇少年 */@Service@Transactional(rollbackFor = Exception.class)public class AccountService { @Autowired private EnhanceMapper&lt;Account, Integer&gt; mapper; /** * {@link EnhanceMapper} 具体使用查看ApiBoot官网文档https://apiboot.minbox.org/zh-cn/docs/api-boot-mybatis-enhance.html * * @param accountId {@link Account#getId()} * @param money 扣除的金额 */ public void deduction(Integer accountId, Double money) { Account account = mapper.selectOne(accountId); if (ObjectUtils.isEmpty(account)) { throw new RuntimeException(&quot;账户：&quot; + accountId + &quot;，不存在.&quot;); } if (account.getMoney() - money &lt; 0) { throw new RuntimeException(&quot;账户：&quot; + accountId + &quot;，余额不足.&quot;); } account.setMoney(account.getMoney().doubleValue() - money); mapper.update(account); }} 商品服务 在good-service内添加查询商品、扣减商品库存的逻辑类，GoodService如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 商品业务逻辑实现 * * @author 恒宇少年 */@Service@Transactional(rollbackFor = Exception.class)public class GoodService { @Autowired private EnhanceMapper&lt;Good, Integer&gt; mapper; /** * 查询商品详情 * * @param goodId {@link Good#getId()} * @return {@link Good} */ public Good findById(Integer goodId) { return mapper.selectOne(goodId); } /** * {@link EnhanceMapper} 具体使用查看ApiBoot官网文档https://apiboot.minbox.org/zh-cn/docs/api-boot-mybatis-enhance.html * 扣除商品库存 * * @param goodId {@link Good#getId()} * @param stock 扣除的库存数量 */ public void reduceStock(Integer goodId, int stock) { Good good = mapper.selectOne(goodId); if (ObjectUtils.isEmpty(good)) { throw new RuntimeException(&quot;商品：&quot; + goodId + &quot;,不存在.&quot;); } if (good.getStock() - stock &lt; 0) { throw new RuntimeException(&quot;商品：&quot; + goodId + &quot;库存不足.&quot;); } good.setStock(good.getStock() - stock); mapper.update(good); }} 5. 提交订单测试我们在执行测试之前在数据库内的seata_account、seata_good表内对应添加两条测试数据，如下所示： 12345-- seata_goodINSERT INTO `seata_good` VALUES (1,'华为Meta 30',10,5000.00); -- seata_accountINSERT INTO `seata_account` VALUES (1,10000.00,'2019-10-11 02:37:35',NULL); 5.1 启动服务将我们本章所使用good-server、order-service、account-service三个服务启动。 5.2 测试点：正常购买我们添加的账户余额测试数据够我们购买两件商品，我们先来购买一件商品验证下接口访问是否成功，通过如下命令访问下单接口： 12~ curl -X POST http://localhost:8082/order\\?goodId\\=1\\&amp;accountId\\=1\\&amp;buyCount\\=1下单成功. 通过我们访问/order下单接口，根据响应的内容我们确定商品已经购买成功。 通过查看order-service控制台内容： 12342019-10-11 16:52:15.477 INFO 13142 --- [nio-8082-exec-4] i.seata.tm.api.DefaultGlobalTransaction : [10.180.98.83:8091:2024417333] commit status:Committed2019-10-11 16:52:16.412 INFO 13142 --- [atch_RMROLE_2_8] i.s.core.rpc.netty.RmMessageListener : onMessage:xid=10.180.98.83:8091:2024417333,branchId=2024417341,branchType=AT,resourceId=jdbc:mysql://localhost:3306/test,applicationData=null2019-10-11 16:52:16.412 INFO 13142 --- [atch_RMROLE_2_8] io.seata.rm.AbstractRMHandler : Branch committing: 10.180.98.83:8091:2024417333 2024417341 jdbc:mysql://localhost:3306/test null2019-10-11 16:52:16.412 INFO 13142 --- [atch_RMROLE_2_8] io.seata.rm.AbstractRMHandler : Branch commit result: PhaseTwo_Committed 我们可以看到本次事务已经成功Committed。 再去验证下数据库内的账户余额、商品库存是否有所扣减。 5.3 测试点：库存不足测试商品添加了10个库存，在之前测试已经销售掉了一件商品，我们测试购买数量超过库存数量时，是否有回滚日志，执行如下命令： 12~ curl -X POST http://localhost:8082/order\\?goodId\\=1\\&amp;accountId\\=1\\&amp;buyCount\\=10{&quot;timestamp&quot;:&quot;2019-10-11T08:57:13.775+0000&quot;,&quot;status&quot;:500,&quot;error&quot;:&quot;Internal Server Error&quot;,&quot;message&quot;:&quot;status 500 reading GoodClient#reduceStock(Integer,int)&quot;,&quot;path&quot;:&quot;/order&quot;} 在我们good-service服务控制台已经打印了商品库存不足的异常信息： 123java.lang.RuntimeException: 商品：1库存不足. at org.minbox.chapter.seata.service.GoodService.reduceStock(GoodService.java:42) ~[classes/:na] .... 我们再看order-service的控制台打印日志： 12Begin new global transaction [10.180.98.83:8091:2024417350]2019-10-11 16:57:13.771 INFO 13142 --- [nio-8082-exec-5] i.seata.tm.api.DefaultGlobalTransaction : [10.180.98.83:8091:2024417350] rollback status:Rollbacked 通过日志可以查看本次事务进行了回滚。 由于库存的验证在账户余额扣减之前，所以我们本次并不能从数据库的数据来判断事务是真的回滚。 5.4 测试点：余额不足既然商品库存不足我们不能直接验证数据库事务回滚，我们从账户余额不足来下手，在之前成功购买了一件商品，账户的余额还够购买一件商品，商品库存目前是9件，我们本次测试购买5件商品，这样就会出现购买商品库存充足而余额不足的应用场景，执行如下命令发起请求： 12~ curl -X POST http://localhost:8082/order\\?goodId\\=1\\&amp;accountId\\=1\\&amp;buyCount\\=5{&quot;timestamp&quot;:&quot;2019-10-11T09:03:00.794+0000&quot;,&quot;status&quot;:500,&quot;error&quot;:&quot;Internal Server Error&quot;,&quot;message&quot;:&quot;status 500 reading AccountClient#deduction(Integer,Double)&quot;,&quot;path&quot;:&quot;/order&quot;} 我们通过查看account-service控制台日志可以看到： 12java.lang.RuntimeException: 账户：1，余额不足. at org.minbox.chapter.seata.service.AccountService.deduction(AccountService.java:33) ~[classes/:na] 已经抛出了余额不足的异常。 通过查看good-service、order-serivce控制台日志，可以看到事务进行了回滚操作。 接下来查看seata_account表数据，我们发现账户余额没有改变，账户服务的事务回滚验证成功。 查看seata_good表数据，我们发现商品的库存也没有改变，商品服务的事务回滚验证成功。 6. 总结本章主要来验证分布式事务框架Seata在MySQL下提交与回滚有效性，是否能够完成我们预期的效果，Seata作为SpringCloud Alibaba的核心框架，更新频率比较高，快速的解决使用过程中遇到的问题，是一个潜力股，不错的选择。 由于本章设计的代码比较多，请结合源码进行学习。 7. 本章源码请访问https://gitee.com/hengboy/spring-cloud-chapter查看本章源码，建议使用git clone https://gitee.com/hengboy/spring-cloud-chapter.git将源码下载到本地。","link":"/seata-first-application.html"},{"title":"阿里巴巴分布式事务利器Seata环境准备","text":"阿里巴巴自从跟SpringCloud共同发起创建微服务开源社区时，开启了SpringCloud Alibaba分支，而且在生态内提供了一款适用于分布式应用程序（Dubbo、SpringCloud等）的事务框架Seata，该框架经过多个大版本的发布，已经支持MySQL、Oracle这两种数据库事务回滚（Rollback）以及提交（Commit）控制，每次发版都会修复一些用户反馈的Issue以及添加一些新特性。 安装Seata ServerSeata目前在github托管开源源代码，源码地址：https://github.com/seata/seata Seata每次发版都会提供Server在不同系统下的执行脚本，可以在Linux/Mac/Windows系统环境下直接执行脚本来启动。 下载Seata Server我们通过github的releases界面下载seata最新发布的server编译后的启动程序，下载地址：https://github.com/seata/seata/releases 根据系统运行环境下载不同的压缩文件，Mac/Linux可以选择下载seata-server-xxx.tar.gz，Windows可以选择下载seata-server-xxx.zip。 解压Seata Server在Mac/Linux系统下我们通过以下命令来解压tar.gz压缩文件： 1234~ tar -xvf seata-server-xxx.tar.gz~ cd seata~ lsbin conf lib LICENSE 解压完成后我们得到了几个文件夹。 bin 存放各个系统的seata server启动脚本 conf 存在seata server启动时所需要的配置信息、数据库模式下所需要的建表语句 lib 运行seata server所需要的依赖包列表 配置Seata Serverseata server所有的配置都在conf文件夹内，该文件夹内有两个文件我们必须要详细介绍下。 seata server默认使用file（文件方式）进行存储事务日志、事务运行信息，我们可以通过-m db脚本参数的形式来指定，目前仅支持file、db这两种方式。 file.conf 该文件用于配置存储方式、透传事务信息的NIO等信息，默认对应registry.conf文件内的file方式配置。 registry.conf seata server核心配置文件，可以通过该文件配置服务注册方式、配置读取方式。 注册方式目前支持file 、nacos 、eureka、redis、zk、consul、etcd3、sofa等方式，默认为file，对应读取file.conf内的注册方式信息。 读取配置信息的方式支持file、nacos 、apollo、zk、consul、etcd3等方式，默认为file，对应读取file.conf文件内的配置。 启动Seata Server启动seata server的脚本位于bin文件内，Linux/Mac环境使用seata-server.sh脚本启动，Windows环境使用seata-server.bat脚本启动。 Linux/Mac启动方式示例如下所示： 1nohup sh seata-server.sh -p 8091 -h 127.0.0.1 -m file &amp;&gt; seata.log &amp; 通过nohup命令让seata server在系统后台运行。 脚本参数： -p 指定启动seata server的端口号。 -h 指定seata server所绑定的主机，这里配置要注意指定的主机IP要与业务服务内的配置文件保持一致，如：-h 192.168.1.10，业务服务配置文件内应该配置192.168.1.10，即使在同一台主机上也要保持一致。 -m 事务日志、事务执行信息存储的方式，目前支持file（文件方式）、db（数据库方式，建表语句请查看config/db_store.sql、config/db_undo_log.sql） 查看启动日志执行完启动脚本后要查看日志来确认是否启动成功，使用如下命令： 123~ tail -1000f seata.log.....2019-10-10 14:33:51.340 INFO [main]io.seata.core.rpc.netty.AbstractRpcRemotingServer.start:156 -Server started ... 当我们看到-Server started时并未发现其他错误信息，我们的seata server已经启动成功。","link":"/seata-init-env.html"},{"title":"SpringBoot激活profiles你知道几种方式？","text":"多环境是最常见的配置隔离方式之一，可以根据不同的运行环境提供不同的配置信息来应对不同的业务场景，在SpringBoot内支持了多种配置隔离的方式，可以激活单个或者多个配置文件。 激活Profiles的方式激活的profiles要在项目内创建对应的配置文件，格式为application-{profile}.yml。 命令行方式命令行方式是一种外部配置的方式，在执行java -jar命令时可以通过--spring.profiles.active=test的方式进行激活指定的profiles列表。 使用方式如下所示： 1java -jar order-service-v1.0.jar --spring.profiles.active=dev &amp;&gt; order-service.log &amp; 系统变量方式Mac/Linux系统配置环境变量 编辑环境变量配置文件/etc/profile，添加名为SPRING_PROFILES_ACTIVE的环境变量，如下所示： 12# spring 环境激活export SPRING_PROFILES_ACTIVE=dev Windows系统配置环境变量 环境变量的配置方式请参考Java环境变量配置，新建一个名为SPRING_PROFILES_ACTIVE的系统环境变量，设置变量的值为dev即可。 系统变量的方式适用于系统下所部署统一环境的SpringBoot应用程序，如统一部署的都是prod环境的应用程序。 Java系统属性方式Java系统属性方式也是一种外部配置的方式，在执行java -jar命令时可以通过-Dspring.profiles.active=test的方式进行激活指定的profiles列表。 使用方式如下所示： 1java -Dspring.profiles.active=dev -jar order-service-v1.0.jar &amp;&gt; order-service.log &amp; 注意：-D方式设置Java系统属性要在-jar前定义。 配置文件方式配置文件方式是最常用的方式，不过灵活性不强，局限性比较大，不建议使用这种方式来激活配置文件。 我们只需要在application.yml配置文件添加配置即可，使用方式如下所示： 1234spring: profiles: # 激活profiles active: dev 优先级1命令行方式 &gt; Java系统属性方式 &gt; 系统变量方式 &gt; 配置文件方式 经过测试**命令行方式的优先级最高，而内部配置文件方式则是最低的**。 激活多个profile如果需要激活多个profile可以使用逗号隔开，如：--spring.profiles.active=dev,test 敲黑板划重点每一个应用项目都会用到大量的配置文件或者外部配置中心，而配置信息的激活是必不可少的一步，尤为重要。 建议大家使用系统环境变量的方式来激活指定profile的配置，这种方式比较简单，系统全局都可以使用（注意：系统全局代表着该系统下所运行的全部SpringBoot应用都会采用该配置），当然也可以采用优先级替换的规则进行单独指定。","link":"/several_ways_to_activate_springboot_profiles.html"},{"title":"SpringBoot1.x版本专题文章汇总","text":"专题愿景旨在打造全网免费精而全的SpringBoot系列技术文章学习专题，从简单了解到核心技术再到源码分析都涵盖在其中，作者在在简书开通的SpringBoot核心技术专题，原创的文章总阅读量已达到数百万，这跟大家的关注与支持息息相关！！！ 请给我支持您的支持是给我创作的最大动力，我会将编写原创技术类文章并在第一时间分享给大家。 请关注作者的公众号“程序员恒宇少年”，二维码在页面底部，关注后回复“资料”有惊喜哟~ 请将该页面分享给更多需要它的技术学习爱好者 请给文章对应的代码案例仓库点个Star，Follow我更可以第一时间了解更新动向 Gitee 作者推荐如果文字类教程对您吸引度不高或者想要综合学习Spring全家桶，推荐给您几个视频教程，价格良心，内容精辟。 “玩转Spring全家桶” 30000+ 人已学习 更多视频教程 如果你已经对SpringBoot有一定的了解，这个框架应该是你目前所需要的，可以助力让你成为服务架构师。 阅读指南基础入门 用一个HelloWord来阐述SpringBoot的简单与快速 SpringBoot与JSP间不可描述的秘密 SpringBoot使用SpringDataJPA完成CRUD 自定义项目的启动Banner SpringBoot1.x - 配置WebMvcConfiguration 配置使用FastJson返回Json视图 SpringBoot内置SpringMvc静态文件地址修改 配置SpringBoot支持自动装载Servlet 实现SpringBoot单个、多个文件的上传 SpringBoot项目多模块运用与设计 SpringBoot项目多模块打包与部署 SpringBoot添加支持CORS跨域访问 非注入方式获取ApplicationContext上下文 核心技术 SpringBoot1.x - 激活项目配置的多环境 资源与业务分离Aop的实现方式 如何在SpringBoot项目中使用拦截器 使用ControllerAdvice完成异常统一处理 基于SpringBoot 设计业务逻辑异常统一处理 SpringBoot整合JavaMail发送邮件 使用SpringBoot validator让数据更真实 SpringBoot项目中使用WebSocket配置广播式通信 业务解耦利器Event/Listener 优雅工具 使用Lombok奇淫技巧 使用MapStruct自动化转换实体 消息队列 消息队列RabbitMQ的Direct类型消息消费 消息队列RabbitMQ的Direct类型消息多节点集群消费 消息队列RabbitMQ的Topic类型消息消费 消息队列RabbitMQ消息延时消费 消息队列RabbitMQ设置信任package 定时任务 Quartz分布式单节点持久化任务 Quartz分布式集群多节点实现任务漂移 SpringBoot使用@Scheduled创建定时任务 日志 使用拦截器记录你的SpringBoot的请求日志 SpringBoot使用LogBack作为日志组件 安全 使用SpringSecurity让SpringBoot项目更安全 SpringBoot项目中使用SpringSecurity整合OAuth2设计项目API安全接口服务 使用JWT设计SpringBoot项目api接口安全服务 缓存 使用Redis作为SpringBoot项目数据缓存 数据 使用Druid作为SpringBoot项目数据源（添加监控） SpringBoot实战SpringDataJPA QueryDSL与SpringDataJPA共同服务于SpringBoot SpringBoot项目整合JPA多数据源配置 作者公众号","link":"/spring-boot-1-x-articles.html"},{"title":"SpringBoot2.x版本专题文章汇总","text":"专题愿景旨在打造全网免费精而全的SpringBoot系列技术文章学习专题，从简单了解到核心技术再到源码分析都涵盖在其中，作者在在简书开通的SpringBoot核心技术专题，原创的文章总阅读量已达到数百万，这跟大家的关注与支持息息相关！！！ 本专题采用SpringBoot2.x版本进行编写，陆续更新，请多多关注。 请给我支持您的支持是给我创作的最大动力，我会将编写原创技术类文章并在第一时间分享给大家。 请关注作者的公众号“程序员恒宇少年”，二维码在页面右侧，可获取专属福利 请将该页面分享给更多需要它的技术学习爱好者 请给文章对应的代码案例仓库点个Star，Follow我更可以第一时间了解更新动向 Gitee 作者推荐如果文字类教程对您吸引度不高或者想要综合学习Spring全家桶，推荐给您几个视频教程，价格良心，内容精辟。 “玩转Spring全家桶” 30000+ 人已学习 更多视频教程 如果你已经对SpringBoot有一定的了解，这个框架应该是你目前所需要的，可以助力让你成为服务架构师。 阅读指南最近更新 Spring OAuth2 实现始终获取新的令牌 将OpenStreetMap导出的OSM数据导入MySQL数据库 实践：了解Redis Geo范围查询，获取当前位置最近的经纬度点 基础篇 SpringBoot2.x基础篇：使用CommandLineRunner或ApplicationRunner SpringBoot2.x基础篇：将静态资源打包为WebJars SpringBoot2.x基础篇：谈谈SpringBoot内提供的这几种配置绑定 SpringBoot2.x基础篇：使用YAML代替Properties的对应配置 SpringBoot2.x基础篇：配置文件中占位符的使用 SpringBoot2.x基础篇：配置文件的加载顺序以及优先级覆盖 SpringBoot2.x基础篇：探索配置文件中随机数的实现方式 SpringBoot2.x基础篇：应用程序在启动时访问启动项参数 SpringBoot2.x基础篇：编写应用程序时常用的ApplicationEvents SpringBoot2.x基础篇：带你了解默认扫描的Package SpringBoot2.x基础篇：Linux后台运行Jar以及Jvm参数调优 SpringBoot2.x基础篇：将应用程序打包为可执行Jar SpringBoot2.x基础篇：灵活的使用外部化配置信息 SpringBoot2.x基础篇：开发你的第一个SpringBoot应用程序 新特性 Spring Security灵活的PasswordEncoder加密方式 Quartz在SpringBoot2.x内的自动化配置 消息队列RabbitMQ设置信任package SpringBoot2.x内配置WebMvc SpringBoot2.2版本配置绑定是不是有点坑了？ SpringBoot使用@ConstructorBinding注解进行配置属性绑定 核心技术 SpringBoot详细打印启动时异常堆栈信息 SpringBoot激活profiles你知道几种方式？ SpringBoot整合Flyway完成数据库持久化迭代更新 使用nginx的负载均衡机制实现用户无感更新服务 数据 SpringBoot2.x使用Redis缓存数据 SpringBoot2.x使用MongoDB存储数据 SpringBoot2.x使用MongoDB的Rest端点访问数据 作者公众号","link":"/spring-boot-2-x-articles.html"},{"title":"SpringBoot基础教程专题","text":"关于专题这篇文章涵盖了本博客SpringBoot相关的技术文章，由于文章编写的先后时间不同，所以采用的SpringBoot版本也有一些差异，不过各个版本的变化不会太大，近期的文章都是采用最新的SpringBoot2.x版本进行编写。 专题愿景旨在打造全网免费精而全的SpringBoot系列技术文章学习专题，从简单了解到核心技术再到源码分析都涵盖在其中，作者在在简书开通的SpringBoot核心技术专题，原创的文章总阅读量已达到数百万，这跟大家的关注与支持息息相关！！！ 请给我支持您的支持是给我创作的最大动力，我会将编写原创技术类文章并在第一时间分享给大家。 请关注作者的公众号“程序员恒宇少年”，二维码在页面右侧，可获取专属福利 请将该页面分享给更多需要它的技术学习爱好者 请给文章对应的代码案例仓库点个Star，Follow我更可以第一时间了解更新动向 https://gitee.com/hengboy/spring-boot-chapter 作者推荐如果文字类教程对您吸引度不高或者想要综合学习Spring全家桶，推荐给您几个视频教程，价格良心，内容精辟。 “玩转Spring全家桶” 20000+ 人已学习 更多视频教程 如果你已经对SpringBoot有一定的了解，这个框架应该是你目前所需要的，可以助力让你成为服务架构师。 教程列表由于使用SpringBoot的版本区分1.x跟2.x，请按需选择你想要的教程。 SpringBoot 1.x系列文章：单文阅读量超过20万 SpringBoot 2.x系列文章：正在火热连载中… 作者公众号","link":"/spring-boot-all-articles.html"},{"title":"SpringBoot2.x基础篇：应用程序在启动时访问启动项参数","text":"SpringBoot应用程序在启动时，我们可以传递自定义的参数来进行动态控制逻辑，比如我们使用--debug启动参数时就会使用debug启动应用程序，在控制台打印一些调试日志信息。 推荐阅读 SpringBoot2.x 教程汇总 什么是启动项参数？启动项参数的格式一般是--开头的，如：java -jar service.jar --debug --skip，启动时我们就可以获取[debug,skip]两个启动项参数。 SpringBoot 内部提供了一个接口org.springframework.boot.ApplicationArguments来接收应用程序在启动时所传递的选项参数（Option Args），源码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface ApplicationArguments { /** * 返回未处理的原始参数列表 * @return the arguments */ String[] getSourceArgs(); /** * 返回所有选项参数的名称 * For example, if the arguments were * &quot;--foo=bar --debug&quot; would return the values {@code [&quot;foo&quot;, &quot;debug&quot;]}. * @return the option names or an empty set */ Set&lt;String&gt; getOptionNames(); /** * 根据选项参数名称判断是否在启动时传递 * option with the given name. * @param name the name to check * @return {@code true} if the arguments contain an option with the given name */ boolean containsOption(String name); /** * 返回与具有给定名称的arguments选项关联的值的集合。 * &lt;ul&gt; * &lt;li&gt;if the option is present and has no argument (e.g.: &quot;--foo&quot;), return an empty * collection ({@code []})&lt;/li&gt; * &lt;li&gt;if the option is present and has a single value (e.g. &quot;--foo=bar&quot;), return a * collection having one element ({@code [&quot;bar&quot;]})&lt;/li&gt; * &lt;li&gt;if the option is present and has multiple values (e.g. &quot;--foo=bar --foo=baz&quot;), * return a collection having elements for each value ({@code [&quot;bar&quot;, &quot;baz&quot;]})&lt;/li&gt; * &lt;li&gt;if the option is not present, return {@code null}&lt;/li&gt; * &lt;/ul&gt; * @param name the name of the option * @return a list of option values for the given name */ List&lt;String&gt; getOptionValues(String name); /** * 返回分析的非选项参数的集合。 * @return the non-option arguments or an empty list */ List&lt;String&gt; getNonOptionArgs();} 该接口有一个默认的实现DefaultApplicationArguments，它实现了ApplicationArguments接口的全部定义方法。 DefaultApplicationArguments类在org.springframework.boot.SpringApplication#run(java.lang.String...)方法内通过new进行实例化，该对象实例主要用于启动时的相关配置。 而在启动过程中的org.springframework.boot.SpringApplication#prepareContext方法内通过ConfigurableListableBeanFactory进行注册到IOC容器，并且把springApplicationArguments作为唯一名称。 获取启动项参数上面我们说道，在应用启动时会将ApplicationArguments接口的实现类实例注册到IOC容器，所以我们可以使用注入ApplicationArguments接口的形式来获取启动项参数，如下所示： 123456789101112131415161718192021222324/** * 加载启动项参数 * * @author 恒宇少年 */@Componentpublic class LoadArguments { /** * 构造函数注入{@link ApplicationArguments} * * @param applicationArguments */ @Autowired public LoadArguments(ApplicationArguments applicationArguments) { // 判断是否存在名为skip的启动项参数 boolean isHaveSkip = applicationArguments.containsOption(&quot;skip&quot;); System.out.println(&quot;skip：&quot; + isHaveSkip); // 遍历输出全部的非启动项参数 List&lt;String&gt; arguments = applicationArguments.getNonOptionArgs(); for (int i = 0; i &lt; arguments.size(); i++) { System.out.println(&quot;非启动项参数：&quot; + arguments.get(i)); } }} 我们把项目通过mvn package命令进行打包后，使用如下命令启动： 1java -jar spring-boot-basic-accessing-application-arguments-0.0.1-SNAPSHOT.jar --skip noway 当我们启动后控制台会输出如下内容： 1234...skip：true非启动项参数：noway... 其中--skip为启动项参数，而后面携带的noway其实是不属于skip启动参数，如果我们使用--skip=noway作为启动参数时，调用ApplicationArguments#getOptionValues(&quot;skip&quot;)方法获取到的值则是noway。 ApplicationRunner除了通过注入ApplicationArguments的方式获取启动参数外，通过实现ApplicationRunner接口也可以获取ApplicationArguments对象实例，使用方法如下所示： 1234567891011121314/** * {@link ApplicationRunner} 实现类 * * @author 恒宇少年 */@Componentpublic class ApplicationRunnerSupport implements ApplicationRunner { @Override public void run(ApplicationArguments args) throws Exception { boolean isHaveSkip = args.containsOption(&quot;skip&quot;); System.out.println(&quot;skip：&quot; + isHaveSkip); System.out.println(args.getOptionValues(&quot;skip&quot;)); }} 注意事项：实现ApplicationRunner接口的类需要通过@Component标注，通过注解方式注册到IOC容器。 敲黑板，划重点我们可以通过注入、ApplicationRunner这两种方法来获取ApplicationArguments对象，那你知道这两种方法的执行先后顺序吗？带着这个疑问可以动手实验下。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为spring-boot-basic-accessing-application-arguments： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/spring-boot-basic-accessing-application-arguments.html"},{"title":"SpringBoot2.x基础篇：Linux后台运行Jar以及Jvm参数调优","text":"我们将编写的应用程序打包为Jar可执行文件后，如果在Linux服务器环境下，可直接使用java -jar xxx.jar命令运行应用程序，不过当我们关闭命令窗口后启动中的应用程序也会停止，那我们需要通过什么方式才可以成为后台服务方式运行呢？ 推荐阅读 SpringBoot2.x 教程汇总 Nohup命令Linux系统或者OS X都提供了一个解决应用程序后台运行的命令，那就是nohup，我们使用该命令可以直接将要执行的任务放置在后台运行，想要停止运行时需要通过结束pid的方式，使用方式如下所示： 123➜ developing-first-application git:(2.x) ✗ nohup java -jar target/service-application-0.0.1-SNAPSHOT.jar &amp;[1] 2349appending output to nohup.out 我们通过以上的命令执行后可以看到控制台输出了本次运行程序的PID为 2349，我们可以使用kill命令杀死这个PID，从而达到了结束进程的效果。 注意事项：appending output to nohup.out这句话很有必要了解下，要知道我们之前通过java -jar xxx.jar直接运行应用程序时会有运行日志输出到控制台的，我们通过nohup方式运行时我们貌似并没有发现日志的输出，日志去了哪里呢？ 运行日志当你看到appending output to nohup.out这句话在控制台打印时，应该可以猜测到了，日志的内容已经输出到了名为nohup.out的文件内，该文件所处的位置就是我们运行nohup命令的同级目录（注意：不是jar文件的目录），我们可以通过tail -1000f nohup.out命令查看运行日志内容，如下所示： 123456789101112➜ developing-first-application git:(2.x) ✗ tail -1000f nohup.out . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.2.4.RELEASE) ... 2020-02-21 14:31:42.614 INFO 2349 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2020-02-21 14:31:42.617 INFO 2349 --- [ main] o.m.c.d.f.a.DevelopingFirstApplication : Started DevelopingFirstApplication in 1.437 seconds (JVM running for 1.75) 通过nohup执行的命令所产生的日志都会输出到默认nohup.out文件内。 指定日志文件在同一台服务器上、同一个目录下可能会存在多个需要运行的Jar文件，为了区分每个应用程序的日志输出，这时我们就需要指定日志输出的文件名，如下所示： 12➜ developing-first-application git:(2.x) ✗ nohup java -jar target/service-application-0.0.1-SNAPSHOT.jar &amp;&gt; service-application-0.0.1.log &amp; [1] 2579 这时我们在nohup命令执行的同级目录下就可以看到创建了一个名为service-application-0.0.1.log的日志文件。 建议：日志文件的名称格式：Service ID + Service Version，相同ServiceID的服务可能存在部署不同版本的情况。 JVM Server模式在JVM内有一个模式的概念，开发环境中一般使用的是client模式，不过生产服务器上一般都是使用server模式，我们要怎么选择呢？ 推荐开发环境使用client模式，因为它启动快，可以提高一部分开发效率，节省每一次项目启动的时间，而生产环境则是推荐使用server模式，内部使用了代号为C2的重量级编译器，这样虽然导致应用程序启动时间有所提高，不过编译的比较彻底，服务在运行期间相对于client性能高一些。 设置使用server模式也比较简单，我们只需要执行java -server命令即可，如下所示： 12➜ developing-first-application git:(2.x) ✗ nohup java -server -jar target/service-application-0.0.1-SNAPSHOT.jar &amp;&gt; service-application-0.0.1.log &amp;[1] 2707 初始内存(-Xms)JVM在client模式下运行，默认Xms大小为1M，而在server模式下默认Xms大小为128M，可以根据实际情况进行修改分配，如下所示： 12➜ developing-first-application git:(2.x) ✗ nohup java -server -Xms256M -jar target/service-application-0.0.1-SNAPSHOT.jar &amp;&gt; service-application-0.0.1.log &amp;[1] 2846 通过-Xms256M，修改初始化分配的内存为256M。 最大内存(-Xmx)JVM在client模式下运行，默认Xmx大小为64M，而在server模式下默认Xmx大小为1024M，可以根据实际情况进行修改分配，如下所示： 12➜ developing-first-application git:(2.x) ✗ nohup java -server -Xms256M -Xmx2048M -jar target/service-application-0.0.1-SNAPSHOT.jar &amp;&gt; service-application-0.0.1.log &amp;[1] 2340 通过-Xmx2048M，修改最大分配内存为2048M。 JVM调优脚本JVM的调优尤为最重，服务器的配置有限，可使用的资源我们则是要珍惜，做出最大的贡献！！！ 为了每次部署服务的便利性，我把启动服务的命令进行了封装，并命名为boot-jar.sh，内容如下所示： 12345#!/bin/bash# author 恒宇少年 - 于起宇# http://blog.minbox.orgnohup java -server -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=128m -Xms256m -Xmx1024m -Xmn256m -Xss256k -XX:SurvivorRatio=8 -XX:+UseConcMarkSweepGC -jar &quot;$1&quot; &gt; &quot;$1.log&quot; 2&gt;&amp;1 &amp;tail -1000f &quot;$1.log&quot; 使用touch boot-jar.sh创建启动脚本，创建完成后将上面内容复制到脚本内，并通过chmod u+x boot-jar.sh命令修改权限为可执行文件。 boot-jar.sh脚本使用如下： 1➜ developing-first-application git:(2.x) ✗ ./boot-jar.sh target/service-application-0.0.1-SNAPSHOT.jar 由于脚本内添加了tail命令，应用程序启动后会自动输出运行日志。 建议：boot-jar.sh应用程序启动脚本位置尽量放在与Jar同级目录下。","link":"/spring-boot-basic-back-run-jar.html"},{"title":"SpringBoot2.x基础篇：谈谈SpringBoot内提供的这几种配置绑定","text":"常见配置绑定方式 SpringBoot在不断地版本迭代中陆续提供了不同的配置参数绑定的方式，我们可以单独获取一个配置参数也可以将一系列的配置映射绑定到JavaBean的属性字段，下面我们来看看这几种方式的配置绑定哪一种是你最常用到的。 示例配置参数1234system: config: app-id: hengboy app-secret: yuqiyu@admin 上面是一段示例的配置参数，提供给下面的配置绑定方式来使用。 @Configuration方式绑定当我们需要将一个配置前缀下的参数映射绑定到JavaBean的属性字段时，我们可以考虑使用@ConfigurationProperties + @Configuration注解组合的方式，使用如下所示： 1234567891011121314151617/** * 系统配置 * * @author 恒宇少年 */@Configuration@ConfigurationProperties(prefix = SYSTEM_CONFIG_PREFIX)@Datapublic class SystemConfig { /** * 系统配置前缀 */ public static final String SYSTEM_CONFIG_PREFIX = &quot;system.config&quot;; private String appId; private String appSecret;} 注意事项：配置参数与JavaBean属性之间的绑定是通过调用JavaBean属性的Setter方法来赋值的，所以我们需要提供对应属性字段的Setter方法。 由于@Configuration注解被@Component修饰，所以我们在使用时只需要注入SystemConfig配置绑定映射类即可，通过Getter方法来获取对应配置参数的值。 配置扫描路径方式绑定如果你系统中需要创建的配置映射类较多，而且每一个类都需要交付给IOC容器进行托管，那么可以考虑使用@ConfigurationPropertiesScan + @ConfigurationProperties注解组合的方式，使用如下所示： 12345678@SpringBootApplication@ConfigurationPropertiesScanpublic class ConfigureBindingAwayApplication { public static void main(String[] args) { SpringApplication.run(ConfigureBindingAwayApplication.class, args); }} 我们首先需要在XxxApplication应用程序启动类上添加@ConfigurationPropertiesScan注解，表示我们需要使用自动扫描的方式来注册配置映射类，注解配置参数如下所示： value：配置扫描的基础package，与basePackages作用一致，通过数组的形式来接收配置。 basePackages：配置扫描的基础package。 basePackageClasses：配置基础扫描类，会将每一个扫描类所处于的package作为扫描基础package。 当我们在使用@ConfigurationPropertiesScan注解时，如果不进行自定义扫描路径，默认使用SpringBoot应用程序扫描的packages。 使用这种方式我们配置映射类就不再需要添加@Configuration注解了，这是因为我们在使用@ConfigurationPropertiesScan注解时，会通过@Import方式来引用配置映射类的注册实现，详见：org.springframework.boot.context.properties.ConfigurationPropertiesScanRegistrar#registerBeanDefinitions，配置映射类如下所示： 12345678910111213141516/** * 系统配置 * * @author 恒宇少年 */@ConfigurationProperties(prefix = SYSTEM_CONFIG_PREFIX)@Datapublic class SystemConfig { /** * 系统配置前缀 */ public static final String SYSTEM_CONFIG_PREFIX = &quot;system.config&quot;; private String appId; private String appSecret;} 构造函数方式绑定在上面的两种方式都是通过Setter方法来进行映射字段的赋值，而构造函数绑定方式是通过构造函数来进行赋值的，我们只需要在配置映射类上添加@ConstructorBinding注解并提供对应的构造函数即可，使用方式如下所示： 12345678910111213141516171819202122/** * 系统配置 * * @author 恒宇少年 */@ConfigurationProperties(prefix = SYSTEM_CONFIG_PREFIX)@ConstructorBinding@Getterpublic class SystemConfig { /** * 系统配置前缀 */ public static final String SYSTEM_CONFIG_PREFIX = &quot;system.config&quot;; public SystemConfig(String appId, String appSecret) { this.appId = appId; this.appSecret = appSecret; } private String appId; private String appSecret;} 在之前我也写过一篇关于构造函数映射配置参数的问题，详情访问：@ConstructorBinding注解的使用 第三方类绑定如果我们需要将配置参数映射绑定到第三方依赖内提供的JavaBean，我们该使用什么方式呢？由于接收参数的类并不是我们自己编写的，所以没有办法对.class文件源码进行修改。 这时我们可以将第三方提供的JavaBean交给IOC容器托管，然后结合@ConfigurationProperties注解来映射绑定配置参数，使用方式如下所示： 12345@Bean@ConfigurationProperties(prefix = SYSTEM_CONFIG_PREFIX)public SystemConfig systemConfig() { return new SystemConfig();} 这种方式也需要第三方提供的JavaBean有映射字段的Setter方法，否则无法进行赋值。 我们知道通过@Bean注解修饰的方法，会将方法的返回值加入到IOC容器内，那我们在使用配置时，直接注入配置映射类就可以了。 总结上面这几种配置绑定方式都遵循OOP实现，当然如果你只需要获取一个配置参数，使用@Value也是一个好的选择，没有更好，只有更合适，根据每一种绑定方式的特点合理的选择一个合适业务的方式。","link":"/spring-boot-basic-configure-binding-away.html"},{"title":"SpringBoot2.x基础篇：探索配置文件中随机数的实现方式","text":"随机数的使用你是不是经常用到？我们在进行运行SpringBoot单元测试时一般不会指定应用程序启动时的端口号，可以在application.properties文件内配置server.port的值为${random.int(10000)}，代表了随机使用0~10000的端口号。 既然这种方式使用这么方便，那你知道${random.int}是通过什么方式实现的吗？ 推荐阅读 SpringBoot2.x 教程汇总 概述 配置文件方式在我们分析源码之前，我们先来看看${random.xxx}具体提供了哪几种的随机配置。 int随机数使用${random.int}方式配置，结果从int的最大值、最小值中间产生，int的最小值为-2147483648，最大值为2147483647，配置如下所示： 12server: port: ${random.int} int范围随机数使用${random.int(10000)}方式配置，这种方式我们可以指定随机数的最大值，当然不能超过2147483647，配置如下所示： 12server: port: ${random.int(10000)} 注意事项：${random.int(10000)}随机数的值将会在0~10000之间产生，配置的最大值必须为正整数， 如果需要指定随机数的最小值，可以使用${random.int[100,200]}方式配置，这样只会从100~200之间产生随机数（包括最小值，不包括最大值）。 long随机数使用${random.long}方式配置，结果会从long的最大值、最小值中间产生，long的最小值为-9223372036854775808，最大值为9223372036854775807，配置方式如下所示： 12config: longValue: ${random.long} long范围随机数使用${random.long(10000)}方式配置，我们可以指定0~9223372036854775807之间的任意数值作为随机的最大上限，配置方式如下所示： 12config: maxLongValue: ${random.long(102400)} 如果需要指定最小值，可以使用${random.long[1024,2048]}方式配置，这样只会从1024~2048中产生随机数（包括最小值，不包括最大值）。 uuid随机数uuid因为它的唯一性，应该是我们平时开发中比较常用到的。 SpringBoot也为我们考虑到了这一点，我们只需要使用${random.uuid}就可以获得一个随机的uuid字符串，配置方式如下所示： 12config: uuid: ${random.uuid} @Value方式如果在我们在编码中需要用到随机数的生成，${random}是支持注入使用的，主要还是因为它的实现继承自PropertySource。 我们可以在Spring IOC所管理的类内直接使用@Value注解进行注入使用，如下所示： 123456789101112131415/** * 随机生成uuid字符串 */@Value(&quot;${random.uuid}&quot;)private String uuid;/** * 随机生成0~1000的正整数 */@Value(&quot;${random.int(1000)}&quot;)private int maxInt;/** * 随机生成0~102400的long类型数值 */@Value(&quot;${random.long(102400)}&quot;)private long maxLong; 源码解析我们之所以可以这么方便的使用随机数，都归功于SpringBoot为我们提供了一个名为RandomValuePropertySource的PropertySource实现类，该实现类位于org.springframework.boot.env包内，该类部分源码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * {@link PropertySource} that returns a random value for any property that starts with * {@literal &quot;random.&quot;}. Where the &quot;unqualified property name&quot; is the portion of the * requested property name beyond the &quot;random.&quot; prefix, this {@link PropertySource} * ... */public class RandomValuePropertySource extends PropertySource&lt;Random&gt; { private static final String PREFIX = &quot;random.&quot;; private static final Log logger = LogFactory.getLog(RandomValuePropertySource.class); @Override public Object getProperty(String name) { // 仅处理random.开头的配置 if (!name.startsWith(PREFIX)) { return null; } if (logger.isTraceEnabled()) { logger.trace(&quot;Generating random property for '&quot; + name + &quot;'&quot;); } // 获取数据数，将random.后的内容作为类型参数传递到getRandomValue方法 return getRandomValue(name.substring(PREFIX.length())); } private Object getRandomValue(String type) { // 处理random.int类型的随机数 if (type.equals(&quot;int&quot;)) { return getSource().nextInt(); } // 处理random.long类型的随机数 if (type.equals(&quot;long&quot;)) { return getSource().nextLong(); } // 处理random.int(100)类型的随机数 String range = getRange(type, &quot;int&quot;); if (range != null) { // 生成有范围的int类型随机数 return getNextIntInRange(range); } // 处理random.long(1024)类型的随机数 range = getRange(type, &quot;long&quot;); if (range != null) { // 生成有范围的long类型随机数 return getNextLongInRange(range); } // 处理random.uuid类型的随机数 if (type.equals(&quot;uuid&quot;)) { // 生成随机的uuid返回 return UUID.randomUUID().toString(); } // 默认返回随机字节 return getRandomBytes(); } private String getRange(String type, String prefix) { if (type.startsWith(prefix)) { int startIndex = prefix.length() + 1; if (type.length() &gt; startIndex) { return type.substring(startIndex, type.length() - 1); } } return null; } private int getNextIntInRange(String range) { String[] tokens = StringUtils.commaDelimitedListToStringArray(range); int start = Integer.parseInt(tokens[0]); if (tokens.length == 1) { return getSource().nextInt(start); } return start + getSource().nextInt(Integer.parseInt(tokens[1]) - start); } private long getNextLongInRange(String range) { String[] tokens = StringUtils.commaDelimitedListToStringArray(range); if (tokens.length == 1) { return Math.abs(getSource().nextLong() % Long.parseLong(tokens[0])); } long lowerBound = Long.parseLong(tokens[0]); long upperBound = Long.parseLong(tokens[1]) - lowerBound; return lowerBound + Math.abs(getSource().nextLong() % upperBound); }} 当我们使用${random.xxx}这种方式获取随机数时，无论是配置文件方式还是@Value方式都会通过org.springframework.boot.env.RandomValuePropertySource#getProperty方法来获取对应类型的随机数。 注意事项：RandomValuePropertySource在继承PropertySource时泛型类型为Random，java.util.Random类内包含了全部的随机生成逻辑，该类由java提供，有兴趣可以研究下源码。 总结SpringBoot内的配置都是通过ConfigurablePropertyResolver属性配置解析器来获取的，而该类的实例化在AbstractEnvironment内，我们通过AbstractEnvironment#getProperty(java.lang.String)方法可以获取由多个PropertySource实现类提供的属性配置。","link":"/spring-boot-basic-configuring-random-values.html"},{"title":"SpringBoot2.x基础篇：带你了解扫描Package自动注册Bean","text":"我们一直在使用SpringBoot来开发应用程序，但是为什么在项目启动时就会自动注册使用注解@Component、@Service、@RestController…标注的Bean呢？ 推荐阅读 SpringBoot2.x 教程汇总 默认扫描目录SpringBoot把入口类所在的Package作为了默认的扫描目录，这也是一个约束，如果我们把需要被注册到IOC的类创建在扫描目录下就可以实现自动注册，否则则不会被注册。 如果你入口类叫做ExampleApplication，它位于org.minbox.chapter目录下，当我们启动应用程序时就会自动扫描org.minbox.chapter同级目录、子级目录下全部注解的类，如下所示： 12345678910. src/main/java├── org.minbox.chapter│ ├── ExampleApplication.java│ ├── HelloController.java│ ├── HelloExample.java│ └── index│ │ └── IndexController.java├── com.hengboy│ ├── TestController.java└── HelloController.java、HelloExample.java与入口类ExampleApplication.java在同一级目录下，所以在项目启动时可以被扫描到。 IndexController.java则是位于入口类的下级目录org.minbox.chapter.index内，因为支持下级目录扫描，所以它也可以被扫描到。 TestController.java位于com.hengboy目录下，默认无法扫描到。 自定义扫描目录在上面目录结构中位于com.hengboy目录下的TestController.java类，默认情况下是无法被扫描并注册到IOC容器内的，如果想要扫描该目录下的类，下面有两种方法。 方法一：使用@ComponentScan注解 1@ComponentScan({&quot;org.minbox.chapter&quot;, &quot;com.hengboy&quot;}) 方法二：使用scanBasePackages属性 1@SpringBootApplication(scanBasePackages = {&quot;org.minbox.chapter&quot;, &quot;com.hengboy&quot;}) 注意事项：配置自定义扫描目录后，会覆盖掉默认的扫描目录，如果你还需要扫描默认目录，那么你要进行配置扫描目录，在上面自定义配置中，如果仅配置扫描com.hengboy目录，则org.minbox.chapter目录就不会被扫描。 追踪源码下面我们来看下SpringBoot源码是怎么实现自动化扫描目录下的Bean，并将Bean注册到容器内的过程。 由于注册的流程比较复杂，挑选出具有代表性的流程步骤来进行讲解。 获取BasePackages在org.springframework.context.annotation.ComponentScanAnnotationParser#parse方法内有着获取basePackages的业务逻辑，源码如下所示： 12345678910111213141516171819Set&lt;String&gt; basePackages = new LinkedHashSet&lt;&gt;();// 获取@ComponentScan注解配置的basePackages属性值String[] basePackagesArray = componentScan.getStringArray(&quot;basePackages&quot;);// 将basePackages属性值加入Set集合内for (String pkg : basePackagesArray) { String[] tokenized = StringUtils.tokenizeToStringArray(this.environment.resolvePlaceholders(pkg), ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); Collections.addAll(basePackages, tokenized);}// 获取@ComponentScan注解的basePackageClasses属性值for (Class&lt;?&gt; clazz : componentScan.getClassArray(&quot;basePackageClasses&quot;)) { // 获取basePackageClasses所在的package并加入Set集合内 basePackages.add(ClassUtils.getPackageName(clazz));}// 如果并没有配置@ComponentScan的basePackages、basePackageClasses属性值if (basePackages.isEmpty()) { // 使用Application入口类的package作为basePackage basePackages.add(ClassUtils.getPackageName(declaringClass));} 获取basePackages分为了那么三个步骤，分别是： 获取@ComponentScan注解basePackages属性值 获取@ComponentScan注解basePackageClasses属性值 将Application入口类所在的package作为默认的basePackages 注意事项：根据源码也就证实了，为什么我们配置了basePackages、basePackageClasses后会把默认值覆盖掉，这里其实也不算是覆盖，是根本不会去获取Application入口类的package。 扫描Packages下的Bean获取到全部的Packages后，通过org.springframework.context.annotation.ClassPathBeanDefinitionScanner#doScan方法来扫描每一个Package下使用注册注解（@Component、@Service、@RestController…）标注的类，源码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { // 当basePackages为空时抛出IllegalArgumentException异常 Assert.notEmpty(basePackages, &quot;At least one base package must be specified&quot;); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;(); // 遍历每一个basePackage，扫描package下的全部Bean for (String basePackage : basePackages) { // 获取扫描到的全部Bean Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); // 遍历每一个Bean进行处理注册相关事宜 for (BeanDefinition candidate : candidates) { // 获取作用域的元数据 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); // 获取Bean的Name String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) { postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); } // 如果是注解方式注册的Bean if (candidate instanceof AnnotatedBeanDefinition) { // 处理Bean上的注解属性，相应的设置到BeanDefinition（AnnotatedBeanDefinition）类内字段 AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); } // 检查是否满足注册的条件 if (checkCandidate(beanName, candidate)) { // 声明Bean具备的基本属性 BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); // 应用作用域代理模式 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); // 写入返回的集合 beanDefinitions.add(definitionHolder); // 注册Bean registerBeanDefinition(definitionHolder, this.registry); } } } return beanDefinitions;} 在上面源码中会扫描每一个basePackage下通过注解定义的Bean，获取Bean注册定义对象后并设置一些基本属性。 注册Bean扫描到basePackage下的Bean后会直接通过org.springframework.beans.factory.support.BeanDefinitionReaderUtils#registerBeanDefinition方法进行注册，源码如下所示： 1234567891011121314151617public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { // 注册Bean的唯一名称 String beanName = definitionHolder.getBeanName(); // 通过BeanDefinitionRegistry注册器进行注册Bean registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 如果存在别名，进行注册Bean的别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) { for (String alias : aliases) { registry.registerAlias(beanName, alias); } }} 通过org.springframework.beans.factory.support.BeanDefinitionRegistry#registerBeanDefinition注册器内的方法可以直接将Bean注册到IOC容器内，而BeanName则是它生命周期内的唯一名称。 总结通过本文的讲解我想你应该已经了解了SpringBoot应用程序启动时为什么会自动扫描package并将Bean注册到IOC容器内，虽然项目启动时间很短暂，不过这是一个非常复杂的过程，在学习过程中大家可以使用Debug模式来查看每一个步骤的逻辑处理。","link":"/spring-boot-basic-default-scan-package.html"},{"title":"SpringBoot2.x基础篇：开发你的第一个SpringBoot应用程序","text":"本篇文章是2020年的开篇之作，希望能带给你不一样的阅读体验，能带给给你清晰的阅读思路。 推荐阅读 SpringBoot2.x 教程汇总 我从2017年开始一直在编写相关SpringBoot的技术点使用文章，最开始的版本还是1.5.2，由于SpringBoot大小版本发布的速度太快，旧版本的文章与新版本SpringBoot构建的应用程序存在一定差异，为了让大家更快的入门学习SpringBoot 2.x版本的核心技术点，会陆续更新一些基础知识点的使用文章，基础文章命名格式：SpringBoot2.x基础篇：文章标题... 开发环境SpringBoot2.x版本是基于Java8来编写的，由于内部使用到了很多新的特性，比如：lambda、interface default…，所以需要本地开发环境有java8的支持。 不仅如此，SpringBoot在构建项目时默认使用Maven方式，所以本地开发环境也需要配置Maven环境变量。 1234~ java -versionjava version &quot;1.8.0_231&quot;Java(TM) SE Runtime Environment (build 1.8.0_231-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode) 123456~ mvn -version Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)Maven home: /Users/yuqiyu/soft/apache-maven-3.6.3Java version: 1.8.0_231, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.15.3&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 如果你更喜欢使用Gradle方式来构建项目，那么本地就应该Gradle环境变量支持。 构建工具版本限制使用如下表所示： 构建工具 版本 Maven 3.3+ Gradle 5.x 或 6.x 新的项目创建一个新SpringBoot应用程序的方式有多种： 使用IDEA内置的Spring Initializr创建（File -&gt; New -&gt; Project -&gt; Spring Initializr） 创建基础Maven项目，修改pom.xml添加spring-boot-parent 访问 https://start.spring.io 选择依赖后，生成项目并下载 我一般采用第一种方式，这种方式比较快捷，IDEA内部也是通过 https://start.spring.io 这种方式将构建完成的zip文件下载到本地然后解压，所以你需要连接互联网才可以创建项目。 新项目的pom.xml文件内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;org.minbox.chapter&lt;/groupId&gt; &lt;artifactId&gt;developing-first-application&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;developing-first-application&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--添加你需要的依赖...--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 新创建的应用程序会自动spring-boot-parent作为父项目，这时我们就拥有了一些默认的资源配置、默认的依赖版本、默认的插件配置等。 添加依赖当我们需要项目支持SpringMvc时，修改pom.xml文件在添加如下依赖即可： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 添加spring-boot-starter-web依赖主要目的是演示Hello World输出。 示例代码要完成我们的应用程序，需要来创建一个Java文件，默认情况下Maven会编译src/main/java目录下的源代码，我们可以在该目录下创建package来进行源代码的归类，下面我们来创建一个名为HelloExample.java的示例源代码文件，内容如下所示： 12345678910111213141516171819package org.minbox.chapter.developing.first.application;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * Hello Example * * @author 恒宇少年 */@RestControllerpublic class HelloExample { @GetMapping public String hello() { return &quot;hello world!&quot;; }} 运行示例到目前为止，我们新创建的应用程序应该可以工作了，由于应用程序的parent是spring-boot-parent，因此具有了可运行的内置环境支持，可以直接通过命令行的方式来运行应用程序，当我们在应用程序的根目录下输入命令： 1~ developing-first-application ✗ mvn spring-boot:run 通过Maven会将相关的依赖下载到本地默认的依赖仓库（~/.m2/repository），编译通过后自动运行项目，控制台输出如下所示： 1234567891011 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.2.4.RELEASE)....... . . ........ . . . (log output here)....... . . ......... Started Example in 2.222 seconds (JVM running for 6.514) 当看到上面的内容在控制台输出时，我们的应用程序就已经运行成功了，在浏览器访问 http://localhost:8080 地址可以看到如下输出内容： 1hello world! 如果想要退出运行中的应用程序，使用Crtl + C。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为developing-first-application： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/spring-boot-basic-developing-first-application.html"},{"title":"SpringBoot2.x基础篇：应用程序在启动时发布ApplicationEvents要怎么注册监听？","text":"在SpringFramework编写过程中使用了大量的Event/Listener来做一些解耦的任务工作，当然在SpringBoot内同样也沿用了这一点，如果你看过我写的 业务解耦利器Event/Listener ，你应该了解事件的发布都是由ApplicationContext进行控制，但是在SpringBoot启动过程中有一些Event是在ApplicationContext实例化之前发布的，那我们要怎么去监听这些Events呢？ 推荐阅读 SpringBoot2.x 教程汇总 ApplicationEvents在SpringBoot编写的应用程序启动过程中会发布一些Event，它们都是org.springframework.boot.context.event.SpringApplicationEvent的实现类，分别对应了应用程序在启动过程中的每一个生命周期阶段，ApplicationEvents在应用程序运行过程中顺序如下图所示： ApplicationStartingEvent 在应用程序开始运行时发布。 ApplicationEnvironmentPreparedEvent 在ApplicationContext使用应用环境时并在创建ApplicationContext之前发布。 ApplicationContextInitializedEvent 在准备ApplicationContext并调用ApplicationContextInitializers之后但在加载任何Bean之前发布。 ApplicationPreparedEvent 在刷新开始之前但在加载bean定义之后发布。 ApplicationStartedEvent 在刷新ApplicationContext之后但在调用任何应用程序和命令行运行程序之前发布。 ApplicationReadyEvent 在调用任何应用程序和命令行运行程序之后发布。 表示应用程序已准备就绪，可以处理请求。 ApplicationFailedEvent 在应用程序启动时发生异常后发布。 上图中是继承于SpringApplicationEvent事件的全部子类，而且这些事件都有一个共性，使用@Bean标注的监听器是没有办法监听到的，主要原因还是有些事件在ApplicationContext创建之前就已经发布了，那我们该怎么进行注册监听呢？继续往下看，你就会明白了。 创建示例Event下面我们来创建一个ApplicationStartedEvent事件的示例监听器，在项目启动时打印系统的全部环境变量，如下所示： 12345678910111213141516171819202122232425262728/** * {@link ApplicationStartedEvent} 示例 * * @author 恒宇少年 */public class ApplicationStartedEventListener implements SmartApplicationListener { @Override public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) { // 判断事件的类型，只监听ApplicationStartedEvent事件类型 return eventType == ApplicationStartedEvent.class; } @Override public void onApplicationEvent(ApplicationEvent event) { // 将ApplicationEvent转换为ApplicationStartedEvent实例 ApplicationStartedEvent startedEvent = (ApplicationStartedEvent) event; ConfigurableEnvironment environment = startedEvent.getApplicationContext().getEnvironment(); // 获取系统环境变量 Map&lt;String, Object&gt; props = environment.getSystemEnvironment(); Iterator&lt;String&gt; iterator = props.keySet().iterator(); while (iterator.hasNext()) { String key = iterator.next(); Object value = props.get(key); System.out.println(&quot;Key : &quot; + key + &quot; , Value : &quot; + value); } System.out.println(&quot;启动成功了.&quot;); }} 监听ApplicationEventsSpringApplicationEvent类型的事件有两种方式可以实现注册监听器，我么可以通过启动类SpringApplication#addListeners方法进行手动注册，也可以在META-INF目录下创建spring.factories文件来自动注册，接下来我们分别介绍下使用方式。 手动注册手动注册是通过SpringApplication#addListeners方法实现，如下所示： 12345678910111213141516@SpringBootApplicationpublic class DevelopingFirstApplication { public static void main(String[] args) { // 注释掉原启动方式 //SpringApplication.run(DevelopingFirstApplication.class, args); // 手动实例化SpringApplication方式 SpringApplication application = new SpringApplication(DevelopingFirstApplication.class); // 添加注册监听器 application.addListeners(new ApplicationStartedEventListener()); // 启动应用程序 application.run(args); }} 由于我们需要使用addListeners方法，原本SpringApplication#run方法的使用需要进行修改。 自动注册自动注册相对于手动注册比较简单明了，我们只需要在resources/META-INF目录下创建名为spring.factories的文件，内容如下所示： 12org.springframework.context.ApplicationListener=\\ org.minbox.chapter.developing.first.application.ApplicationStartedEventListener org.springframework.context.ApplicationListener用来配置接收事件监听器列表。 由于内部采用的是反射的机制，所以我们在配置监听器时要填写类全路径，如果有多个监听器需要配置时在末尾添加,\\，如下所示： 123org.springframework.context.ApplicationListener=\\ org.minbox.chapter.developing.first.application.ApplicationStartedEventListener,\\ org.minbox.chapter.developing.first.application.ApplicationStartedEventListener 运行测试当我们应用启动成功后会在控制台看到以下内容： 12345678910111213141516171819202122232425262728293031323334 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.2.4.RELEASE)......2020-02-27 15:39:00.723 INFO 1630 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2020-02-27 15:39:00.725 INFO 1630 --- [ main] o.m.c.d.f.a.DevelopingFirstApplication : Started DevelopingFirstApplication in 1.343 seconds (JVM running for 1.938)Key : PATH , Value : /usr/local/opt/node@10/bin:/usr/local/opt/node@10/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/MacGPG2/bin:/Users/yuqiyu/soft/apache-maven-3.6.3/binKey : SHELL , Value : /bin/zshKey : PAGER , Value : lessKey : LSCOLORS , Value : GxfxcxdxbxegedabagacadKey : OLDPWD , Value : /Applications/IntelliJ IDEA.app/Contents/binKey : USER , Value : yuqiyuKey : ZSH , Value : /Users/yuqiyu/.oh-my-zshKey : TMPDIR , Value : /var/folders/f3/5bk_kqsn3ljf3z2ccjqcx4440000gn/T/Key : SSH_AUTH_SOCK , Value : /private/tmp/com.apple.launchd.VyfCdMBxH6/ListenersKey : XPC_FLAGS , Value : 0x0Key : VERSIONER_PYTHON_VERSION , Value : 2.7Key : M2_HOME , Value : /Users/yuqiyu/soft/apache-maven-3.6.3Key : __CF_USER_TEXT_ENCODING , Value : 0x1F5:0x19:0x34Key : LOGNAME , Value : yuqiyuKey : LESS , Value : -RKey : JAVA_MAIN_CLASS_1630 , Value : org.minbox.chapter.developing.first.application.DevelopingFirstApplicationKey : LC_CTYPE , Value : zh_CN.UTF-8Key : PWD , Value : /Users/yuqiyu/study/article-source-code/spring-boot-chapter/developing-first-applicationKey : XPC_SERVICE_NAME , Value : com.jetbrains.intellij.9644Key : HOME , Value : /Users/yuqiyu启动成功了. 总结其实有很多事件并不是经常使用的，我们也应该知道它们的存在，这样方便在有业务使用时能够得心应手，在SpringBoot内部是使用事件来处理各种任务的，而从本文来看，了解应用启动的生命周期也是尤为重要的。","link":"/spring-boot-basic-events-and-listeners.html"},{"title":"SpringBoot2.x基础篇：灵活的使用外部化配置信息","text":"SpringBoot提供了内部配置application.yml文件的方式来进行全局配置，还支持使用profiles来激活不同环境下使用不同的配置文件，而这种方式毕竟是已经打包完成了，因此存在一定的局限性，像数据库特殊敏感配置也可能存在泄露的风险，如何解决这种问题呢？我们来看看本章要讲到的外部配置的方式吧！！！ 推荐阅读 SpringBoot2.x 教程汇总 前言SpringBoot提供了多种的外部化配置方式，主要是为了方便在不同的环境中运行相同的代码。 我们可以通过Properties文件、YAML文件、环境变量、命令行参数等来配置，获取配置的值时可以通过@Value注解进行注入，也可以使用@ConfigurationProperties注解进行层级结构化绑定到实体类的字段中。 加载顺序SpringBoot配置参数存在一定的顺序，当然对相同名称的属性配置，会因为加载的优先级存在覆盖，顺序如下所示： DevTools全局设置属性 @TestPropertySource注解 properties测试中的属性 命令行参数 SPRING_APPLICATION_JSON属性配置（嵌入在环境变量或者系统属性中的嵌入式JSON字符串） ServletConfig初始化参数 ServletContext初始化参数 JNDI属性java:comp/env Java系统属性 操作系统环境变量 打包在jar内的配置文件（application.properties和YAML文件） @PropertySource注解 默认属性（通过SpringApplication.setDefaultProperties设置） 配置示例我们从上面挑选几种来进行测试下配置输出，首先创建一个名为LoadConfig的配置类，内容如下所示： 1234567891011121314151617/** * 加载配置类 * * @author 恒宇少年 */@Configurationpublic class LoadConfig { /** * 配置读取name属性，不存在时使用空字符为默认值 */ @Value(&quot;${name:''}&quot;) private String name; public String getName() { return name; }} 在LoadConfig配置类中，我们添加了一个name字段，由于该字段使用了@Value注解，所以它的值会从配置环境中加载名为name的属性值（配置的方式并没有限制）。 为了方便演示，我们在应用程序启动时通过实现CommandLineRunner接口在启动成功后输出name的值，SpringBootApplication入口类代码如下所示： 123456789101112131415161718192021/** * 启动类入口 */@SpringBootApplicationpublic class SpringBootBasicExternalizedConfigurationApplication implements CommandLineRunner { /** * 注入配置类{@link LoadConfig} */ @Autowired private LoadConfig loadConfig; public static void main(String[] args) { SpringApplication.run(SpringBootBasicExternalizedConfigurationApplication.class, args); } @Override public void run(String... args) throws Exception { System.out.println(&quot;name config value：&quot; + loadConfig.getName()); }} YAML文件配置这种我们在开发应用程序中最常用的方式，只需要在src/main/resources目录下创建一个名为application.yml的配置文件，然后在该文件内添加对应属性名称的配置，如下所示： 123# 配置name属性name: default 我们如果直接启动应用程序，会在控制台输出name的值为default。 注意事项：application.yml与application.properties作用、优先级相同，只是配置的展现形式不一样而已，我个人更喜欢YAML文件的形式，层级分明，阅读性高一些。 命令行环境变量配置在执行java -jar启动应用程序时，可以通过添加SPRING_APPLICATION_JSON配置来进行自定义属性配置，该配置是一个JSON字符串的形式，使用方式如下所示： 1SPRING_APPLICATION_JSON='{&quot;name&quot;:&quot;system_env&quot;}' java -jar spring-boot-basic-externalized-configuration-0.0.1-SNAPSHOT.jar 运行结果：这种方式启用应用程序时，会在控制台输出name的值为system_env。 命令行参数配置命令行参数这种方式也比较常用，通过--进行配置，比较常见的命令--spring.profiles.active，启动时用于修改激活的profile，而我们如果想要修改name属性配置的值，如下所示： 1java -jar spring-boot-basic-externalized-configuration-0.0.1-SNAPSHOT.jar --name=hengboy 或者使用--spring.application.json方式也可以配置，如下所示： 1java -jar spring-boot-basic-externalized-configuration-0.0.1-SNAPSHOT.jar --spring.application.json='{&quot;name&quot;:&quot;hengboy&quot;}' 运行结果：以上两种方式都可以，控制台都会输出name的值为hengboy。 Java系统属性配置Java系统属性的方式进行配置时，不仅使用@Value可以获取到属性值，使用java.lang.System#getProperty(java.lang.String)方法也是可以获取到的，通过-D进行配置，如下所示： 1java -Dname=JavaSystemConfig -jar spring-boot-basic-externalized-configuration-0.0.1-SNAPSHOT.jar 或者使用-Dspring.application.json方式配置（这种方式使用System.getProperty方法无法获取到属性值），如下所示： 1java -Dspring.application.json='{&quot;name&quot;:&quot;JavaSystemConfig&quot;}' -jar spring-boot-basic-externalized-configuration-0.0.1-SNAPSHOT.jar 运行结果：以上两种方式启动应用程序，控制台会输出name的值为JavaSystemConfig。 注意事项：Java属性配置必须在-jar xxx.jar之前，配置在后面无法读取到属性值。 总结多样化的配置属性的方式，使SpringBoot变的是那么的灵活，如果有兴趣可以把上面全部的配置方式都尝试一遍，你会有意想不到的收获的。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为spring-boot-basic-externalized-configuration： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/spring-boot-basic-externalized-configuration.html"},{"title":"SpringBoot2.x基础篇：配置文件的加载顺序以及优先级覆盖","text":"SpringBoot约定了配置文件，默认为application.properties，通过该文件可以修改很多默认的配置，当然我们还可以在该配置文件内添加自定义的配置，该文件通过key=value的形式进行配置。 推荐阅读 SpringBoot2.x 教程汇总 疑惑配置提示？当我们使用开发工具来配置时，就会出现相应的提示，这要完全要归功于spring-configuration-metadata.json配置元数据文件，该文件内记录了配置的名称、类型、归属类等信息，如果配置类型为枚举还可以实现选择性配置。 SpringBoot提供了一个依赖，它的主要任务就是自动生成配置元数据，该依赖的名称为spring-boot-configuration-processor，在打包时会在META-INF目录生成一个名为spring-configuration-metadata.json的文件。 配置方式虽然默认使用properties格式的配置文件，不过这种方式会导致配置的部分前缀冗余，可阅读性稍差，SpringBoot内部还支持使用yaml方式的配置文件，只需要在src/main/resources目录下创建一个名为application.yml文件即可，使用配置时同样也有提供功能。 项目内可以同时存在application.properties、application.yml两个文件，经过测试发现，properties优先级会高一些，相同名称的配置，会将yml内的配置覆盖掉。 指定配置文件如果你的应用程序配置文件的名称不是application，你想要进行自定义，可以通过--spring.config.name命令行参数进行指定，如下所示： 1java -jar project-sample.jar --spring.config.name=custome 注意事项：我们只需要指定配置文件的名称即可，可以使用properties或yaml文件格式，上面的配置会加载src/main/resources/custome.yml或src/main/resources/custome.properties。 通过--spring.config.name仅仅是修改了配置文件的名称，那如果是修改配置文件所处的目录位置，我们需要怎么做呢？ SpringBoot已经给我们准备好了，通过--spring.config.location参数就可以指定配置文件的位置，如下所示： 1java -jar project-sample.jar --spring.config.location=classpath:/configs/custome.yml 如果一个配置文件无法满足你的需求，那你看看下面这个方式： 1java -jar project-sample.jar --spring.config.location=classpath:/configs/custome.yml,classpath:/configs/default.properties 注意事项：支持通过命令行参数的方式指定多个配置文件，使用英文半角 , 隔开即可。 如果你通过spring.config.location指定的不是一个文件而是一个目录，在路径最后务必添加一个”/“结束，然后结合spring.config.name进行组合配置文件，组合示例如下： 123456# 加载/configs/application.properties 或 /configs/application.yml（默认文件名）java -jar project-sample.jar --spring.config.location=classpath:/configs/# 加载/configs/custome.properties 或 /configs/custome.ymljava -jar project-sample.jar --spring.config.location=classpath:/configs/ --spring.config.name=custome 注意事项：spring.config.name该配置参数默认值为application，所以如果只是指定了spring.config.location并为目录形式，上面示例中会自动将spring.config.name追加到目录路径后，如果指定的spring.config.location并非是一个目录，这里会忽略spring.config.name的值。 加载顺序SpringBoot应用程序在启动时会遵循下面的顺序进行加载配置文件： 类路径下的配置文件 类路径内config子目录的配置文件 当前项目根目录下的配置文件 当前项目根目录下config子目录的配置文件 示例项目配置文件存放结构如下所示： 12345678. project-sample├── config│ ├── application.yml （4）│ └── src/main/resources| │ ├── application.yml （1）| │ └── config| | │ ├── application.yml （2）├── application.yml （3） 启动时加载配置文件顺序：1 &gt; 2 &gt; 3 &gt; 4 src/main/resources下的配置文件在项目编译时，会放在target/classes下。 优先级覆盖SpringBoot配置文件存在一个特性，优先级较高的配置加载顺序比较靠后，相同名称的配置优先级较高的会覆盖掉优先级较低的内容。 为了更好地解释这一点，我们根据对应的加载顺序分别创建一个application.yml配置文件，来验证根据优先级的不同是否存在覆盖问题，如下图所示： 在上面四个配置文件中都有一个名为name的配置，而红色字体标注的内容就是每个配置文件name的配置内容，下面我们来启动项目测试下输出内容。 运行测试在测试之前我们让启动类实现CommandLineRunner接口，如下所示： 123456789101112131415@SpringBootApplicationpublic class LoadOrderOfConfigFilesApplication implements CommandLineRunner { public static void main(String[] args) { SpringApplication.run(LoadOrderOfConfigFilesApplication.class, args); } @Value(&quot;${name}&quot;) private String name; @Override public void run(String... args) throws Exception { System.out.println(&quot;配置名称：&quot; + name); }} 项目启动后通过run方法进行打印${name}配置的内容。 测试一：顺序覆盖保留上面四个对应加载顺序的配置文件，启动项目，控制台输出内容： 1配置名称：project/config 期望与实际输出是符合的，项目根下的config目录是最后加载的，所以它的优先级相对其他三个来说是最高的，覆盖顺序为：4 &gt; 3 &gt; 2 &gt; 1。 测试二：跨顺序覆盖上一个测试点我们对每一个加载顺序都对应添加了一个配置文件，那如果我们只有两个project/config、classes/config两个目录的配置文件，是否按照优先级进行覆盖呢？ 删除另外两个，只保留project/config、classes/config两个位置的配置文件，启动项目控制台输出如下所示： 1配置名称：project/config 同样是输出了优先级最高的project/config配置文件的内容，覆盖顺序为：4 &gt; 1 测试点：单顺序加载平时在项目开发中一般都是将application.yml配置文件放在src/main/resources目录下，然而根据上面的加载顺序来看，我们可以将配置文件放置在任意一处，启动时都会进行加载。 仅保留classes/config位置的配置文件，启动项目控制台输出内容如下所示： 1配置名称：classes/config IDEA对SpringBoot的支持真的很强大， classes/config下的配置文件同样提供了关键字提醒功能。 总结了解配置文件的加载顺序，才能得心应手的进行配置覆盖，完全控制在不同环境下使用不同的配置内容，要记住classes/application.yml优先级最低，project/config/application.yml优先级最高。","link":"/spring-boot-basic-load-order-of-config-files.html"},{"title":"SpringBoot2.x基础篇：将应用程序打包为可执行Jar","text":"应用程序在编写完成后，有一个重要的阶段就是发布，当我们发布时需要将应用程序进行打包，那通过SpringBoot编写的应用程序该如何打包呢？ 推荐阅读 SpringBoot2.x 教程汇总 打包方式应用程序的发布一般有两种形式。 比较传统的方式是外置Tomcat，将应用程序打包成一个xx.war文件，该文件内只有应用程序源码编译后的.class以及配置文件。 而SpringBoot还提供了另外一种高效率的打包方式，在pom.xml内通过配置maven plugin，执行mvn package打包命令时会将src/main/java、src/main/resources目录下的全部文件进行打包，最终生成一个xx.jar的文件，由于SpringBoot打包时默认会将Tomcat的相关依赖一并放入到xx.jar内，所以通过java -jar xx.jar命令行的方式可以直接运行。 打包插件我们通过IDEA创建SpringBoot项目时，一般在pom.xml文件内默认已经添加了打包maven plugin，如下所示： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 注意事项：如果你不是通过spring-boot-starter-parenter方式构建的SpringBoot应用程序，需要手动配置&lt;executions&gt;，有关插件的使用文档，详见 Spring Boot Maven Plugin 执行打包使用Maven构建的SpringBoot应用程序打包方式很简单，我们只需要通过命令在应用程序的根目录下执行mvn package即可，如下所示： 12345678910111213141516171819➜ developing-first-application git:(2.x) mvn package [INFO] Scanning for projects...[INFO] [INFO] ----------&lt; org.minbox.chapter:developing-first-application &gt;-----------[INFO] Building developing-first-application 0.0.1-SNAPSHOT[INFO] --------------------------------[ jar ]---------------------------------省略部分编译日志......[INFO] --- maven-jar-plugin:3.1.2:jar (default-jar) @ developing-first-application ---[INFO] Building jar: /Users/yuqiyu/study/article-source-code/spring-boot-chapter/developing-first-application/target/developing-first-application-0.0.1-SNAPSHOT.jar[INFO] [INFO] --- spring-boot-maven-plugin:2.2.4.RELEASE:repackage (repackage) @ developing-first-application ---[INFO] Replacing main artifact with repackaged archive[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 4.711 s[INFO] Finished at: 2020-02-20T15:02:24+08:00[INFO] ------------------------------------------------------------------------ 当控制台出现BUILD SUCCESS时，证明我们本次package已经成功了，当前应用程序的可执行Jar也已经生成，位于target目录下。 打包文件命名spring-boot-maven-plugin插件打包完成后生成的文件名默认的格式为：&lt;artifactId&gt; + &lt;version&gt;.jar，如：developing-first-application-0.0.1-SNAPSHOT.jar，如果这并不是你想要的格式化，可以通过如下方式进行自定义： 123&lt;build&gt; &lt;finalName&gt;service-application-${version}&lt;/finalName&gt;&lt;/build&gt; 注意事项：&lt;finalName&gt;与&lt;plugins&gt;是同级的配置，可以使用占位符属性${属性名}的方式来进行格式化命名内容，这只是文件的名称，在打包完成后后缀名.jar会自动追加。 跳过测试项目在打包过程中会自动运行测试，来检查项目是否可以通过运行测试以及测试脚本的执行是否有效，一般这个过程是需要一定时间的，项目内容越多需要的时间就会越久，如果你想跳过这个测试过程，只需要添加一个很简单的&lt;properties&gt;属性配置即可，如下所示： 123&lt;properties&gt; &lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;&lt;/properties&gt; 这样我们再运行mvn package时，就会跳过测试步骤。 运行Jar要运行该应用程序，可以使用java -jar命令，如下所示： 12345678910111213141516➜ developing-first-application git:(2.x) ✗ java -jar target/service-application-0.0.1-SNAPSHOT.jar . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.2.4.RELEASE)2020-02-20 15:29:39.615 INFO 3208 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2020-02-20 15:29:39.626 INFO 3208 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2020-02-20 15:29:39.626 INFO 3208 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.30]2020-02-20 15:29:39.953 INFO 3208 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2020-02-20 15:29:39.955 INFO 3208 --- [ main] o.m.c.d.f.a.DevelopingFirstApplication : Started DevelopingFirstApplication in 1.539 seconds (JVM running for 1.868) 如果想要退出该应用程序，请按Ctrl + C。","link":"/spring-boot-basic-packaging-executable-jar.html"},{"title":"SpringBoot2.x基础篇：将静态资源打包为WebJars","text":"概述我们在编写前后分离项目时，前端的项目一般需要静态资源（Image、CSS、JavaScript…）来进行渲染界面，而如果我们对外采用依赖的方式提供使用时，我们的静态资源文件也应该放入打包文件内，这样才能更便捷的提供我们的功能，在我的开源分布式日志框架 minbox-logging 内提供了管理界面的功能，就是采用的这种方式实现，将静态资源以及编译后的HTML页面存放到minbox-logging-admin-ui依赖内，下面我们来看下具体的实现方式。 推荐阅读 SpringBoot2.x 教程汇总 了解Resources Static Locations在我们打包静态资源前，首先来了解下SpringBoot提供的spring.resources.static-locations配置默认值，该配置用于配置ResourceHandler，项目启动后会将该参数的配置值列表作为直接可访问的静态目录进行映射，通过这种方式我们就可以直接访问到我们需要的静态资源内容。 spring.resources.static-locations配置位于org.springframework.boot.autoconfigure.web.ResourceProperties配置类内，其默认值是使用本类内的静态常量CLASSPATH_RESOURCE_LOCATIONS的值，如下所示： 12345678private static final String[] CLASSPATH_RESOURCE_LOCATIONS = { &quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; };/** * Locations of static resources. Defaults to classpath:[/META-INF/resources/, * /resources/, /static/, /public/]. */private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS; 通过查看源码我们得知，classpath:/META-INF/resources/目录下的资源是可以直接通过默认的映射绑定关系访问到的，通过这一点，我们可以将静态资源依赖内的资源文件存放到META-INF/resources目录下。 资源打包我们使用Maven方式构建一个普通的项目，在pom.xml文件内添加资源目录配置，在编译过程中将src/main/resources目录下的文件全部复制到META-INF/resources下，如下所示： 12345678&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;META-INF/resources&lt;/targetPath&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 为了验证资源访问，我们在src/main/resources目录下存放一个名为head.jpg的图片。 我们为了本地演示使用，将Maven项目通过mvn install命令安装到本地仓库，以便于提供给其他项目使用。 使用WebJars依赖我们来创建一个SpringBoot项目，在项目的pom.xml文件内添加如下依赖： 123456789101112&lt;dependencies&gt; &lt;!--静态资源的访问映射绑定需要web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;webjars-sample&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 由于我们在之前通过mvn install命令将静态资源项目安装到了本地仓库，所以我们可以使用依赖。 通过IDEA工具我们可以查看webjars-sample依赖内的资源文件，如下图所示： 由于SpringBoot提供的spring.resources.static-locations参数默认值，会将classpath:/META-INF/resources目录作为静态资源映射，所以我们可以直接进行访问head.jpg文件。 运行SpringBoot项目，通过访问 http://localhost:8080/head.jpg，效果如下图： 静态资源访问前缀我们在访问静态资源的时候并没有直接加前缀，而是通过ip:port/head.jpg直接访问，这主要是SpringBoot还提供了另外一个配置spring.mvc.static-path-pattern，其作用是用来配置静态资源的访问前缀，默认值为/**，如果需要修改直接在application.yml文件内进行赋值即可， application.yml配置文件，如下所示： 12345spring: application: name: example mvc: static-path-pattern: /static/** 我们修改了spring.mvc.static-path-pattern配置的值为/static/**，当我们重启项目后需要通过 http://localhost:8080/static/head.jpg 才可以访问到资源。 总结如果你有一些资源不希望被别人修改，让使用者更加便利的集成时，可以采用这种方式来封装自己的webjars，只需要添加依赖引用就可以访问到静态资源，也可以将静态HTML网页通过这种方式打包。","link":"/spring-boot-basic-packaging-webjars.html"},{"title":"SpringBoot2.x基础篇：配置文件中占位符的使用","text":"概念占位符是一种灵活的配置方式，可以让我们很灵活的使用配置参数，@Value注解的配置也是占位符的一种体现方式，这种方式可以从Environment内获取对应的配置值。 推荐阅读 SpringBoot2.x 教程汇总 配置方式在application.yml/properties配置文件内可以直接使用占位符来进行配置的相互引用，如下所示： 12345system: name: ${spring.application.name}spring: application: name: project-sample 在上面的配置中，name配置直接引用了spring.application.name的配置值，这样我们在系统中通过@Value(&quot;${name}&quot;)或者通过@ConfigurationProperties方式使用时，得到的值都为project-sample。 123456789101112131415161718// @Value方式@Value(&quot;${system.name}&quot;)private String name;// @ConfigurationProperties方式@Configuration@ConfigurationProperties(prefix = &quot;system&quot;)static class LoadConfig { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; }} 这样方式极大地减少了相同的配置出现，让我们在配置文件中也可以实现类似于常量的定义。 使用默认值当我们使用@Value注解来注入配置参数时，如果所引入的配置为NULL，启动项目时会抛出异常，项目无法正常启动，所以我们有必要添加一个默认值，如下所示： 12345system: name: ${spring.application.name:default}#spring:# application:# name: project-sample 在上面配置中把spring.application.name注释掉，当我们使用${spring.application.name}占位符时其实并未引用到有效的值，通过${xxx:defaultValue}的形式可以配置默认值，当占位符所引用的配置为NULL时，将会使用默认值（默认值的类型要对配置匹配）。 也可以通过@Value(&quot;${system.name:default}&quot;)这种方式配置默认值，不建议使用这种方式，默认值有变动时，我们还要一个一个修改，太麻烦了，不要给自己找事干… 当然对于配置的注入还是推荐使用@ConfigurationProperties，完全遵循OOP设计方式，在应用程序启动时进行赋值，就算是引用的配置为NULL没有默认值，也不会出现启动异常的问题。 “短”命令行参数如果你对命令行参数不熟悉，可以访问 SpringBoot2.x基础篇：灵活的使用外部化配置信息 学习。 在实际部署应用程序时，有很多的配置是动态的，命令行参数是一个不错的方式，不过SpringBoot所提供的配置参数名称都比较长，对此我们完全可以利用占位符配置方式实现自定义。 占位符是从Environment内读取对应的配置值，而命令行参数在应用程序启动时会被一并加入到Environment中，因此也就实现了占位符动态配置，其实这个“短”的含义，是你定义的新的配置名称比较短而已。 假设我们的端口号需要动态指定，配置文件中可以通过如下的方式配置： 12server: port: ${port:8080} port是我们定义的“短”占位符，在应用程序启动时并未指定则使用默认值8080。 1java -jar project-sample.jar --port=9090 通过--port=9090命令行参数，应用程序启动时端口号就变为了9090。","link":"/spring-boot-basic-placeholders-in-config-file.html"},{"title":"SpringBoot2.x基础篇：使用CommandLineRunner或ApplicationRunner","text":"如果你想要使用SpringBoot构建的项目在启动后运行一些特定的代码，那么CommandLineRunner、ApplicationRunner都是很好的选择。 推荐阅读 SpringBoot2.x 教程汇总 使用方式我们以CommandLineRunner创建了一个简单的例子，如下所示： 123456789101112131415161718/** * {@link CommandLineRunner}接口使用示例 * * @author 恒宇少年 */@Componentpublic class CommandLineRunnerExample implements CommandLineRunner { /** * 实例化本类的日志采集器 */ static LoggingCollector logging = LoggingCollectorFactory.getCollector(CommandLineRunnerExample.class); @Override public void run(String... args) throws Exception { // 执行特定的代码 logging.debug(&quot;main方法参数列表：{}&quot;, args); }} CommandLineRunner接口的定义很简单，只提供了一个名为#run()的方法，我们只需要实现该方法做一些自定义的业务逻辑即可，ApplicationRunner接口的使用方式也是一样的。 两者的区别？从源码上分析，CommandLineRunner与ApplicationRunner两者之间只有#run()方法的参数不一样而已。 CommandLineRunner： 1234567891011@FunctionalInterfacepublic interface CommandLineRunner { /** * Callback used to run the bean. * @param args incoming main method arguments * @throws Exception on error */ void run(String... args) throws Exception;} ApplicationRunner： 1234567891011@FunctionalInterfacepublic interface ApplicationRunner { /** * Callback used to run the bean. * @param args incoming application arguments * @throws Exception on error */ void run(ApplicationArguments args) throws Exception;} CommandLineRunner#run()方法的参数是启动SpringBoot应用程序main方法的参数列表，而ApplicationRunner#run()方法的参数则是ApplicationArguments对象。 在之前的文章中也提到过ApplicatgionArguments对象，并使用它获取外部的配置参数，查看：应用程序在启动时访问启动项参数。 建议：如果你在项目启动时需要获取类似 “–xxx” 的启动参数值建议使用ApplicationRunner 什么时候会被调用？我们已经了解CommandLineRunner与ApplicationRunner两个接口的使用以及区别，是不是很想知道SpringBoot在启动时在什么时候调用它们的呢？ 我们大家都知道SpringBoot应用程序的启动主要归功于SpringApplication这个类，我们在创建项目时在启动类内会调用SpringApplication#run()方法，如下所示： 123public static void main(String[] args) { SpringApplication.run(LoggingServiceApplication.class, args);} 那我们来查看下SpringApplication类#run()方法的源码，根据查看方法之间的相互调用，最终我们会定位到org.springframework.boot.SpringApplication#run(java.lang.String...)这个方法，阅读该方法时发现有关调用Runner的定义，如下所示： 1234// 省略部分源码listeners.started(context);callRunners(context, applicationArguments);// 省略部分源码 #callRunnners()方法的调用确实是在应用程序启动完成后，而且把ApplicationContext与ApplicationArguments对象都作为参数进行了传递，那么我们来看看这个方法究竟干了些什么事情？ SpringApplication#callRunners： 1234567891011121314private void callRunners(ApplicationContext context, ApplicationArguments args) { List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;&gt;(runners)) { if (runner instanceof ApplicationRunner) { callRunner((ApplicationRunner) runner, args); } if (runner instanceof CommandLineRunner) { callRunner((CommandLineRunner) runner, args); } }} 我想大家看到这里就应该明白了，这个方法就是在执行CommandLineRunner以及ApplicationRunner实现类实例的#run()方法，首先会从ApplicationContext中获取CommandLineRunner、ApplicationRunner接口实现类的实例，然后根据不同类型的Runner实例去调用了callRunner方法。 SpringApplication#callRunner： 12345678910111213141516171819// 调用ApplicationRunner实现类实例#run()private void callRunner(ApplicationRunner runner, ApplicationArguments args) { try { (runner).run(args); } catch (Exception ex) { throw new IllegalStateException(&quot;Failed to execute ApplicationRunner&quot;, ex); }}// 调用CommandLineRunner实现类实例#run()private void callRunner(CommandLineRunner runner, ApplicationArguments args) { try { (runner).run(args.getSourceArgs()); } catch (Exception ex) { throw new IllegalStateException(&quot;Failed to execute CommandLineRunner&quot;, ex); }} 设置执行顺序那如果我们创建了多个CommandLineRunner、ApplicationRunner实现类，还想要实现类在执行的时候有一定的先后顺序，那你不妨试下org.springframework.core.annotation.Order这个注解或者实现org.springframework.core.Ordered接口。 CommandLineRunnerExample： 1234567891011121314/** * {@link CommandLineRunner}接口使用示例 * * @author 恒宇少年 */@Component@Order(100)public class CommandLineRunnerExample implements CommandLineRunner, Ordered { // 省略部分代码 @Override public int getOrder() { return 100; }} 接口与注解的方式选择其中一种就可以了。","link":"/spring-boot-basic-use-commandlinerunner-or-applicationrunner.html"},{"title":"SpringBoot2.x基础篇：使用YAML代替Properties的对应配置","text":"YAML是一种用于指定层次结构配置数据的便捷格式，SpringBoot内部通过集成SnakeYAML来支持解析，那我们如果来使用YAML格式来代替Properties，我们需要了解每一种Properties对应YAML的配置代替方式。 推荐阅读 SpringBoot2.x 教程汇总 普通配置普通的方式比较简单直接，不存在数组、集合、子类等相关配置，我们通过Properties方式编写了如下的配置内容： 123system.config.max-value=100system.config.min-value=10system.config.location=classpath:/configs 那这种方式对应的YAML配置是什么样子的呢？ 如下所示： 12345system: config: min-value: 10 max-value: 100 location: classpath:/configs 这两种方式对比之下，YAML层次感鲜明，更直观的查看配置信息，而Properties这种方式配置前缀相对来说是冗余的，如果配置前缀过长，每一行的配置内容则会更长。 List配置如果你需要添加List/Set/Array类型的配置信息，使用Properties方式编写如下所示： 123system.config.ports[0]=8080system.config.ports[1]=8081system.config.ports[2]=8082 注意事项：配置的索引从0开始。 对应上面配置的YAML实现如下所示： 123456system: config: ports: - 8080 - 8081 - 8082 无论是Properties还是YAML格式，这种List的配置内容都可以通过如下的方式获取： 123456@Configuration@ConfigurationProperties(prefix = &quot;system.config&quot;)@Datapublic class LoadListConfig { private List&lt;String&gt; ports;} List内实体配置如果你的List内不是基本数据类型，而是一个实体类，使用Properties的配置方式如下所示： 1234system.users[0].username=adminsystem.users[0].email=yuqiyu@vip.qq.comsystem.users[1].username=hengboysystem.users[1].email=jnyuqy@gmail.com 其实跟上面的List配置差不多，不过如果你需要配置每一个索引内字段的值，就要一一指定配置值。 对应上面的YAML实现如下所示： 123456system: users: - username: admin email: yuqiyu@vip.qq.com - username: hengboy email: jnyuqy@gmail.com 每一个 - 其实代表集合内的一个元素。 获取List实体配置时我们可以通过如下的方式： 12345678910111213@Data@Configuration@ConfigurationProperties(prefix = &quot;system&quot;)public class LoadSystemUserConfig { private List&lt;User&gt; users; @Getter @Setter public static class User { private String username; private String email; }} YAML缺点一种方案的诞生是为了解决相应的问题，虽然说存在既有道理，但是每一种方案也不是完美的都有自身的缺点。 下面简单说说YAML的缺点： 配置时缩进要特别注意，如果存在空格缩进对应不齐就会出现问题 在SpringBoot内无法通过@PropertySource注解加载YAML文件。","link":"/spring-boot-basic-using-yaml-instead-of-properties.html"},{"title":"SpringCloud基础教程专题","text":"关于专题SpringCloud目前有两个主流的体系：原生体系、Alibaba体系，本专题会涵盖这两个主流体系的核心技术讲解文章，提供给大家一整套的微服务架构搭建以及部署方案。 专题愿景旨在打造全网免费主流、全面、最新的SpringCloud整套体系的系列技术文章学习专题，让微服务的搭建变的更简单~ 请给我支持您的支持是给我创作的最大动力，我会将编写原创技术类文章并在第一时间分享给大家。 请关注作者的公众号“程序员恒宇少年”，二维码在页面右侧，可获取专属福利 请将该页面分享给更多需要它的技术学习爱好者 请给文章对应的代码案例仓库点个Star，Follow我更可以第一时间了解更新动向 https://gitee.com/hengboy/spring-cloud-chapter 作者推荐如果文字类教程对您吸引度不高或者想要综合学习Spring全家桶，推荐给您几个视频教程，价格良心，内容精辟。 微服务架构实战160讲 10000+ 人已学习 更多视频教程 阅读指南SpringCloud 初识SpringCloud ApiBoot v2.2.5版本无法兼容Hoxton.SR5的SpringCloud Gateway 注册中心 搭建Eureka服务注册中心 将服务注册到Eureka SpringCloud下使用Eureka的服务发现与消费 SpringCloud下使用Eureka高可用集群部署 Eureka服务注册中心的失效剔除与自我保护机制 Eureka服务注册中心内置的REST节点列表 你的Eureka服务注册中心安全吗？ Eureka服务注册方式流程源码分析 Eureka服务注册是采用主机名还是IP地址？ 自定义你自己的Eureka管理界面 统一网关 SpringCloud Gateway路由转发规则 SpringCloud Gateway整合Eureka转发服务请求 SpringCloud Alibaba配置中心 Nacos 作为配置中心 &amp; 读取Properties配置信息 Nacos 作为配置中心 &amp; 读取Yaml配置信息 Nacos Config的多环境（Profile）配置信息读取 Nacos Config 使用自定义的NameSpace &amp; Group 分布式事务 阿里巴巴分布式事务利器Seata环境准备 SpringCloud与Seata分布式事务初体验 作者公众号","link":"/spring-cloud-all-articles.html"},{"title":"ApiBoot v2.2.5版本无法兼容Hoxton.SR5的SpringCloud Gateway","text":"使用ApiBoot最新发布的v2.2.5版本整合SpringCloud Gateway的Hoxton.SR5版本时导致项目无法启动，控制台抛出的错误如下所示： 1234567891011121314151617181920212223242526***************************APPLICATION FAILED TO START***************************Description:An attempt was made to call a method that does not exist. The attempt was made from the following location: org.springframework.boot.web.embedded.netty.NettyReactiveWebServerFactory.lambda$createHttpServer$0(NettyReactiveWebServerFactory.java:158)The following method did not exist: reactor.netty.tcp.TcpServer.bindAddress(Ljava/util/function/Supplier;)Lreactor/netty/tcp/TcpServer;The method's class, reactor.netty.tcp.TcpServer, is available from the following locations: jar:file:/Users/yuqiyu/.m2/repository/io/projectreactor/netty/reactor-netty/0.9.6.RELEASE/reactor-netty-0.9.6.RELEASE.jar!/reactor/netty/tcp/TcpServer.classThe class hierarchy was loaded from the following locations: reactor.netty.tcp.TcpServer: file:/Users/yuqiyu/.m2/repository/io/projectreactor/netty/reactor-netty/0.9.6.RELEASE/reactor-netty-0.9.6.RELEASE.jarAction:Correct the classpath of your application so that it contains a single, compatible version of reactor.netty.tcp.TcpServer 从控制台打印的错误信息我们可以发现这是版本不兼容的问题导致的，reactor-netty作为SpringCloud Gateway的重要组成部分之一，为什么会出现版本不兼容的问题呢？ reactor-bom我们在构建项目时，SpringBoot使用最新发布的v2.3.1，在v2.3.1版本的spring-boot-dependencies固化版本依赖模块内定义reactor-bom的依赖，如下所示： 1234567&lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-bom&lt;/artifactId&gt; &lt;version&gt;${reactor-bom.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; ${reactor-bom}占位符对应的使用版本为Dysprosium-SR8，通过查看reactor-bom内定义的依赖列表发现了reactor-netty的踪迹，而它对应的版本为v0.9.8，如下所示： 12345&lt;dependency&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;0.9.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 那为什么我们在启动项目时控制台抛出了使用v0.9.6版本的reactor-netty导致不兼容的问题呢？ 项目依赖的reactor-netty版本查看idea开发工具内项目的External Libraries发现，项目编译时使用的reactor-netty的版本确实是为v0.9.6，如下图所示： SpringCloud Gateway依赖的reactor-netty版本Hoxton.SR5版本的spring-cloud-dependencies依赖内使用的spring-cloud-gateway版本为2.2.3.RELEASE，我们从GitHub拉取spring-cloud-gateway源码到本地，使用idea工具打开项目并切换到2.2.x分支后发现External Libraries依赖列表内所使用的reactory-netty版本为v0.9.7，这是编译spring-cloud-gateway时所依赖的版本。 spring-cloud-gateway仓库在GitHub的地址为：git@github.com:spring-cloud/spring-cloud-gateway.git 问题分析 从上面的分析步骤中我们发现，spring-cloud-gateway编译时所使用的reactory-netty版本为v0.9.7，而v2.3.1版本的SpringBoot所使用的reactory-netty版本为v0.9.8，依赖的版本是支持向下兼容的，所以这样不会出现什么问题。 但是我们项目在编译时使用的reactory-netty版本却为v0.9.6，版本肯定是不支持向上兼容的，所以才导致了项目启动时控制台打印的不兼容异常。 问题定位在ApiBoot的固化版本依赖api-boot-dependencies内默认添加了SpringCloud的依赖，为了方便项目集成SpringCloud时使用组件，不过这也导致了这个问题的发生。 v2.2.5版本的ApiBoot内集成的SpringCloud版本为Hoxton.RELEASE，要比Hoxton.SR5版本发布的更早，它所使用的reactory-netty依赖版本为v0.9.6。 解决问题既然找到了问题，对症下药，解决起来就容易了，我们只需要把项目中所依赖的reactory-netty版本修改为v0.9.6以上版本即可，在项目的pom.xml内添加如下依赖： 12345678910&lt;dependencyManagement&gt; &lt;!--省略其他依赖--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;0.9.8&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;","link":"/spring-cloud-gateway-not-compatible.html"},{"title":"初识SpringCloud","text":"最近这几个月文章更新处于停滞状态，因为公司的事情比较多，公司系统一直处于高速的迭代更新阶段，尽管如此，我这段时间也一直在整理接下来要更新的文章大纲以及知识点的梳理，希望在后续的文章更新中能给这段时间关注我的朋友以及将要关注我的朋友帮助。 程序员应该保持一颗好奇心程序员应该保持一颗好奇心这句话我经常告诫我部门的员工，无论在什么情况下你都应该一颗好奇的心，敢于去追寻，敢于去创新，技术行业是一个以新型技术驱动的行业。 初识分布式解决方案公司系统在最早是一套原始的SSM框架搭建的整体架构，这种方式的弊端相信大家也都有很多的了解，从SSM到SpringBoot项目的整合然后再到SpringCloud分布式部署是一个很漫长的过程，系统内部有很多原始的业务在里面，有很多比较繁琐以及冗余的代码在里面，正因如此，我们才开展了代码的重构。 由于我一直在编写SpringBoot方面的文章，所以无疑采用了SpringCloud作为分布式部署的解决方案，在这个过程中是比较艰辛的，要考虑的地方比较多，原始业务的正常运营，新业务的扩展以及部署。 虽然会遇到各种各样的问题，还是毅然的选择了这条道路，因为系统要在不断的升级维护、重构过程中才能更不断的完善。 原业务请求转发由于时间问题，原始的业务不能快速的全部采用分布式编码方式进行重新编写，通过SpringCloud的gateway统一网关来进行转原业务的请求分流，在做路径路由设置时要注意转发的前缀，因为我们原接口都是以版本号进行前缀访问的，所以比较容易根据指定的版本号进行过滤，如：/v2/**，然后配置url进行转发到原nginx入口。 原始业务的服务拆分那么接下来的一步就是对原始业务的拆分，对于微服务(microservice)的拆分，一般都是采用具体的业务原子性，比如：我提供一个用户服务，这样其他的服务通过feign可以直接调用该服务内的方法并获取相应的数据。 通过这种原子性的服务拆分规则，我们就可以罗列出原始业务能够拆分成的服务列表，当然建议把每一个服务对应的端口号范围进行提前约定，这样在编写的过程中也不会出现端口号的占用。 可以参考下面的表格进行记录： 服务名称 服务描述 服务端口号 api-service-user 用户微服务 10000~10004 api-service-good 商品微服务 10005~10009 整合部署通过前期的技术选型到实现方案再到集成部署都是一个比较敏感的阶段，如果你的团队刚开始使用SpringCloud中间肯定会有很多需要磨合的地方，不过对于团队的开发其实影响也不是特别大，开发人员只不过是需要了解： 服务之间的调用 服务注册 服务调用 部署人员把相关的服务注册中心、统一网关、统一认证中心等搭建完成后，服务也就是简单的配置下对应的就可以实现对应的功能！！！ 写在最后微服务是目前比较流行的一种搭建部署解决方案，不过不要盲目的更换公司的部署方案以及编码框架，前期要做好详细的调研，把可能会遇到的问题进行汇总并找出相应的解决方案，这样才不会在重构过程中走的比较困难，甚至寸步难行！！！","link":"/spring-cloud-look.html"},{"title":"SpringBoot使用spring.config.import多种方式导入配置文件","text":"SpringBoot从2.4.x版本开始支持了导入文件的方式来加载配置参数，与spring.config.additional-location不同的是不用提前设置而且支持导入的文件类型相对来说要丰富很多。 我们只需要在application.properties/application.yml配置文件中通过spring.config.import属性配置需要导入的文件列表即可。 通过spring.config.import属性支持导入多种途径的配置文件，下面简单介绍几种。 导入classpath下的配置文件可以导入classpath下任意目录的文件，使用方式如下所示： 1234567spring: config: import: # 导入classpath下default目录下的default.properties配置文件 - classpath:/default/default.properties # 导入classpath下service目录下的service.yml配置文件 - classpath:/service/service.yml 在src/main/resource下分别创建default、service目录，在default目录下创建default.properties、在service目录下创建sevice.yml。 通过上面配置的属性导入后我们直接就可以在项目中通过@ConfigurationProperties或@Value来注入使用。 src/main/resource、src/main/java目录编译后都会到classpath根目录下。 1234567// default.propertiesdefault.password=111111// service.ymlservice: id: example port: 9999 index-path: /index 12345678910111213// default.properties@Value(&quot;${default.password}&quot;)private String defaultPassword;---// service.yml@Configuration@ConfigurationProperties(prefix = &quot;service&quot;)@Datapublic class ServiceProperties { private String id; private int port; private String indexPath;} 导入系统目录下的配置文件可以导入操作系统目录下的配置文件，我在/Users/yuqiyu/Downloads目录下创建了名为system.properties的文件，导入方式如下所示： 12345spring: config: import: # 导入系统目录/Users/yuqiyu/Downloads下的system.properties配置文件 - optional:/Users/yuqiyu/Downloads/system.properties 使用@ConfigurationProperties方式注入映射如下所示： 123456789101112// system.propertiessystem.os=osxsystem.jdk-version=11// SystemProperties.java@Data@Configuration@ConfigurationProperties(prefix = &quot;system&quot;)public class SystemProperties { private String os; private String jdkVersion;} 导入Nacos配置中心的配置文件Nacos在SpringCloud Alibaba发布了2021.0.1.0版本后对spring.config.import做了支持，可以直接通过加载Nacos Server内指定的配置文件。 首先我们使用Docker来创建一个Nacos Server容器，步骤如下所示： 1234# 拉取nacos-server镜像docker pull nacos/nacos-server# 创建并启动nacos-server容器docker run --name nacos-quick -e MODE=standalone -p 8848:8848 -p 9848:9848 -d nacos/nacos-server:latest 访问http://localhost:8848/nacos，使用默认账号nacos登录后在public命名空间下创建一个名为spring-config-import-example.yaml的YAML格式的配置文件，内容如下所示： 12config: source: nacos 在SpringBoot项目中如果需要集成nacos，可以直接添加spring-cloud-starter-alibaba-nacos-config依赖，如下所示： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;2021.0.1.0&lt;/version&gt;&lt;/dependency&gt; 导入方式如下所示： 12345678spring: cloud: nacos: server-addr: localhost:8848 config: import: # 导入nacos配置中心的配置文件 - optional:nacos:spring-config-import-example.yaml 在项目中同样可以使用@ConfigurationProperties、@Value来注入配置参数，如下所示： 12@Value(&quot;${config.source}&quot;)private String configSource; 总结spring.config.import使用方式是多样化的，如果你需要自定义导入的方式，可以借鉴nacos对其实现的部分代码。","link":"/spring-config-import-use-aways.html"},{"title":"业务解耦利器Event&#x2F;Listener","text":"ApplicationEvent以及Listener是Spring为我们提供的一个事件监听、订阅的实现，内部实现原理是观察者设计模式，设计初衷也是为了系统业务逻辑之间的解耦，提高可扩展性以及可维护性。事件发布者并不需要考虑谁去监听，监听具体的实现内容是什么，发布者的工作只是为了发布事件而已。 我们平时日常生活中也是经常会有这种情况存在，如：我们在平时拔河比赛中，裁判员给我们吹响了开始的信号，也就是给我们发布了一个开始的事件，而拔河双方人员都在监听着这个事件，一旦事件发布后双方人员就开始往自己方使劲。而裁判并不关心你比赛的过程，只是给你发布事件你执行就可以了。 本章目标我们本章在SpringBoot平台上通过ApplicationEvents以及Listener来完成简单的注册事件流程。 构建项目我们本章只是简单的讲解如何使用ApplicationEvent以及Listener来完成业务逻辑的解耦，不涉及到数据交互所以依赖需要引入的也比较少，项目pom.xml配置文件如下所示： 123456789101112131415161718192021.....//省略&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;.....//省略 其中lombok依赖大家有兴趣可以去深研究下，这是一个很好的工具，它可以结合Idea开发工具完成对实体的动态添加构造函数、Getter/Setter方法、toString方法等。 创建UserRegisterEvent事件我们先来创建一个事件，监听都是围绕着事件来挂起的。事件代码如下所示： 12345678910111213141516171819202122232425262728293031package com.yuqiyu.chapter27.event;import com.yuqiyu.chapter27.bean.UserBean;import lombok.Getter;import org.springframework.context.ApplicationEvent;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:08 * 码云：http://git.oschina.net/jnyqy * ======================== */@Getterpublic class UserRegisterEvent extends ApplicationEvent{ //注册用户对象 private UserBean user; /** * 重写构造函数 * @param source 发生事件的对象 * @param user 注册用户对象 */ public UserRegisterEvent(Object source,UserBean user) { super(source); this.user = user; }} 我们自定义事件UserRegisterEvent继承了ApplicationEvent，继承后必须重载构造函数，构造函数的参数可以任意指定，其中source参数指的是发生事件的对象，一般我们在发布事件时使用的是this关键字代替本类对象，而user参数是我们自定义的注册用户对象，该对象可以在监听内被获取。 在Spring内部中有多种方式实现监听如：@EventListener注解、实现ApplicationListener泛型接口、实现SmartApplicationListener接口等，我们下面来讲解下这三种方式分别如何实现。 创建UserBean我们简单创建一个用户实体，并添加两个字段：用户名、密码。实体代码如下所示： 12345678910111213141516171819package com.yuqiyu.chapter27.bean;import lombok.Data;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:05 * 码云：http://git.oschina.net/jnyqy * ======================== */@Datapublic class UserBean{ //用户名 private String name; //密码 private String password;} 创建UserServiceUserService内添加一个注册方法，该方法只是实现注册事件发布功能，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536package com.yuqiyu.chapter27.service;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.event.UserRegisterEvent;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.ApplicationContext;import org.springframework.stereotype.Service;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:11 * 码云：http://git.oschina.net/jnyqy * ======================== */@Servicepublic class UserService{ @Autowired ApplicationContext applicationContext; /** * 用户注册方法 * @param user */ public void register(UserBean user) { //../省略其他逻辑 //发布UserRegisterEvent事件 applicationContext.publishEvent(new UserRegisterEvent(this,user)); }} 事件发布是由ApplicationContext对象管控的，我们发布事件前需要注入ApplicationContext对象调用publishEvent方法完成事件发布。 创建UserController创建一个@RestController控制器，对应添加一个注册方法简单实现，代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.yuqiyu.chapter27.controller;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 用户控制器 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:05 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestControllerpublic class UserController{ //用户业务逻辑实现 @Autowired private UserService userService; /** * 注册控制方法 * @param user 用户对象 * @return */ @RequestMapping(value = &quot;/register&quot;) public String register ( UserBean user ) { //调用注册业务逻辑 userService.register(user); return &quot;注册成功.&quot;; }} @EventListener实现监听注解方式比较简单，并不需要实现任何接口，具体代码实现如下所示： 123456789101112131415161718192021222324252627282930313233343536package com.yuqiyu.chapter27.listener;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.event.UserRegisterEvent;import org.springframework.context.event.EventListener;import org.springframework.stereotype.Component;/** * 使用@EventListener方法实现注册事件监听 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:50 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class AnnotationRegisterListener { /** * 注册监听实现方法 * @param userRegisterEvent 用户注册事件 */ @EventListener public void register(UserRegisterEvent userRegisterEvent) { //获取注册用户对象 UserBean user = userRegisterEvent.getUser(); //../省略逻辑 //输出注册用户信息 System.out.println(&quot;@EventListener注册信息，用户名：&quot;+user.getName()+&quot;，密码：&quot;+user.getPassword()); }} 我们只需要让我们的监听类被Spring所管理即可，在我们用户注册监听实现方法上添加@EventListener注解，该注解会根据方法内配置的事件完成监听。下面我们启动项目来测试下我们事件发布时是否被监听者所感知。 测试事件监听使用SpringBootApplication方式启动成功后，我们来访问下地址：http://127.0.0.1:8080/register?name=admin&password=123456，界面输出内容肯定是“注册成功”，这个是没有问题的，我们直接查看控制台输出内容，如下所示： 12342017-07-21 11:09:52.532 INFO 10460 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2017-07-21 11:09:52.532 INFO 10460 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2017-07-21 11:09:52.545 INFO 10460 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 13 ms@EventListener注册信息，用户名：admin，密码：123456 可以看到我们使用@EventListener注解配置的监听已经生效了，当我们在UserService内发布了注册事件时，监听方法自动被调用并且输出内信息到控制台。 ApplicationListener实现监听这种方式也是Spring之前比较常用的监听事件方式，在实现ApplicationListener接口时需要将监听事件作为泛型传递，监听实现代码如下所示： 123456789101112131415161718192021222324252627282930313233343536package com.yuqiyu.chapter27.listener;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.event.UserRegisterEvent;import org.springframework.context.ApplicationListener;import org.springframework.stereotype.Component;/** * 原始方式实现 * 用户注册监听 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:24 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class RegisterListener implements ApplicationListener&lt;UserRegisterEvent&gt;{ /** * 实现监听 * @param userRegisterEvent */ @Override public void onApplicationEvent(UserRegisterEvent userRegisterEvent) { //获取注册用户对象 UserBean user = userRegisterEvent.getUser(); //../省略逻辑 //输出注册用户信息 System.out.println(&quot;注册信息，用户名：&quot;+user.getName()+&quot;，密码：&quot;+user.getPassword()); }} 我们实现接口后需要使用@Component注解来声明该监听需要被Spring注入管理，当有UserRegisterEvent事件发布时监听程序会自动调用onApplicationEvent方法并且将UserRegisterEvent对象作为参数传递。我们UserService内的发布事件不需要修改，我们重启下项目再次访问之前的地址查看控制台输出的内容如下所示： 12342017-07-21 13:03:35.399 INFO 4324 --- [nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2017-07-21 13:03:35.399 INFO 4324 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2017-07-21 13:03:35.411 INFO 4324 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 12 ms注册信息，用户名：admin，密码：123456 我们看到了控制台打印了我们监听内输出用户信息，事件发布后就不会考虑具体哪个监听去处理业务，甚至可以存在多个监听同时需要处理业务逻辑。 我们在注册时如果不仅仅是记录注册信息到数据库，还需要发送邮件通知用户，当然我们可以创建多个监听同时监听UserRegisterEvent事件，接下来我们先来实现这个需求。 邮件通知监听我们使用注解的方式来完成邮件发送监听实现，代码如下所示： 1234567891011121314151617181920212223242526272829package com.yuqiyu.chapter27.listener;import com.yuqiyu.chapter27.event.UserRegisterEvent;import org.springframework.context.event.EventListener;import org.springframework.stereotype.Component;/** * 注册用户事件发送邮件监听 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：13:08 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class RegisterUserEmailListener{ /** * 发送邮件监听实现 * @param userRegisterEvent 用户注册事件 */ @EventListener public void sendMail(UserRegisterEvent userRegisterEvent) { System.out.println(&quot;用户注册成功，发送邮件。&quot;); }} 监听编写完成后，我们重启项目，再次访问注册请求地址查看控制台输出内容如下所示： 123452017-07-21 13:09:20.671 INFO 7808 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2017-07-21 13:09:20.671 INFO 7808 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2017-07-21 13:09:20.685 INFO 7808 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 14 ms用户注册成功，发送邮件。注册信息，用户名：admin，密码：123456 我们看到控制台输出的内容感到比较疑惑，我注册时用户信息写入数据库应该在发送邮件前面，为什么没有在第一步执行呢？好了，证明了一点，事件监听是无序的，监听到的事件先后顺序完全随机出现的。我们接下来使用SmartApplicationListener实现监听方式来实现该逻辑。 SmartApplicationListener实现有序监听我们对注册用户以及发送邮件的监听重新编写，注册用户写入数据库监听代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.yuqiyu.chapter27.listener;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.event.UserRegisterEvent;import com.yuqiyu.chapter27.service.UserService;import org.springframework.context.ApplicationEvent;import org.springframework.context.event.SmartApplicationListener;import org.springframework.stereotype.Component;/** * 用户注册&gt;&gt;&gt;保存用户信息监听 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：10:09 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class UserRegisterListener implements SmartApplicationListener{ /** * 该方法返回true&amp;supportsSourceType同样返回true时，才会调用该监听内的onApplicationEvent方法 * @param aClass 接收到的监听事件类型 * @return */ @Override public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; aClass) { //只有UserRegisterEvent监听类型才会执行下面逻辑 return aClass == UserRegisterEvent.class; } /** * 该方法返回true&amp;supportsEventType同样返回true时，才会调用该监听内的onApplicationEvent方法 * @param aClass * @return */ @Override public boolean supportsSourceType(Class&lt;?&gt; aClass) { //只有在UserService内发布的UserRegisterEvent事件时才会执行下面逻辑 return aClass == UserService.class; } /** * supportsEventType &amp; supportsSourceType 两个方法返回true时调用该方法执行业务逻辑 * @param applicationEvent 具体监听实例，这里是UserRegisterEvent */ @Override public void onApplicationEvent(ApplicationEvent applicationEvent) { //转换事件类型 UserRegisterEvent userRegisterEvent = (UserRegisterEvent) applicationEvent; //获取注册用户对象信息 UserBean user = userRegisterEvent.getUser(); //.../完成注册业务逻辑 System.out.println(&quot;注册信息，用户名：&quot;+user.getName()+&quot;，密码：&quot;+user.getPassword()); } /** * 同步情况下监听执行的顺序 * @return */ @Override public int getOrder() { return 0; }} SmartApplicationListener接口继承了全局监听ApplicationListener，并且泛型对象使用的ApplicationEvent来作为全局监听，可以理解为使用SmartApplicationListener作为监听父接口的实现，监听所有事件发布。 既然是监听所有的事件发布，那么SmartApplicationListener接口添加了两个方法supportsEventType、supportsSourceType来作为区分是否是我们监听的事件，只有这两个方法同时返回true时才会执行onApplicationEvent方法。 可以看到除了上面的方法，还提供了一个getOrder方法，这个方法就可以解决执行监听的顺序问题，return的数值越小证明优先级越高，执行顺序越靠前。 注册成功发送邮件通知监听代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.yuqiyu.chapter27.listener.order;import com.yuqiyu.chapter27.bean.UserBean;import com.yuqiyu.chapter27.event.UserRegisterEvent;import com.yuqiyu.chapter27.service.UserService;import org.springframework.context.ApplicationEvent;import org.springframework.context.event.SmartApplicationListener;import org.springframework.stereotype.Component;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：13:38 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class UserRegisterSendMailListener implements SmartApplicationListener{ /** * 该方法返回true&amp;supportsSourceType同样返回true时，才会调用该监听内的onApplicationEvent方法 * @param aClass 接收到的监听事件类型 * @return */ @Override public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; aClass) { //只有UserRegisterEvent监听类型才会执行下面逻辑 return aClass == UserRegisterEvent.class; } /** * 该方法返回true&amp;supportsEventType同样返回true时，才会调用该监听内的onApplicationEvent方法 * @param aClass * @return */ @Override public boolean supportsSourceType(Class&lt;?&gt; aClass) { //只有在UserService内发布的UserRegisterEvent事件时才会执行下面逻辑 return aClass == UserService.class; } /** * supportsEventType &amp; supportsSourceType 两个方法返回true时调用该方法执行业务逻辑 * @param applicationEvent 具体监听实例，这里是UserRegisterEvent */ @Override public void onApplicationEvent(ApplicationEvent applicationEvent) { //转换事件类型 UserRegisterEvent userRegisterEvent = (UserRegisterEvent) applicationEvent; //获取注册用户对象信息 UserBean user = userRegisterEvent.getUser(); System.out.println(&quot;用户：&quot;+user.getName()+&quot;，注册成功，发送邮件通知。&quot;); } /** * 同步情况下监听执行的顺序 * @return */ @Override public int getOrder() { return 1; }} 在getOrder方法内我们返回的数值为“1”，这就证明了需要在保存注册用户信息监听后执行，下面我们重启项目访问注册地址查看控制台输出内容如下所示： 123452017-07-21 13:40:43.104 INFO 10128 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2017-07-21 13:40:43.104 INFO 10128 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2017-07-21 13:40:43.119 INFO 10128 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 15 ms注册信息，用户名：admin，密码：123456用户：admin，注册成功，发送邮件通知。 这次我们看到了输出的顺序就是正确的了，先保存信息然后再发送邮件通知。 如果说我们不希望在执行监听时等待监听业务逻辑耗时，发布监听后立即要对接口或者界面做出反映，我们该怎么做呢？ 使用@Async实现异步监听@Aysnc其实是Spring内的一个组件，可以完成对类内单个或者多个方法实现异步调用，这样可以大大的节省等待耗时。内部实现机制是线程池任务ThreadPoolTaskExecutor，通过线程池来对配置@Async的方法或者类做出执行动作。 线程任务池配置我们创建一个ListenerAsyncConfiguration，并且使用@EnableAsync注解开启支持异步处理，具体代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.yuqiyu.chapter27;import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.AsyncConfigurer;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.concurrent.Executor;/** * 异步监听配置 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/21 * Time：14:04 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configuration@EnableAsyncpublic class ListenerAsyncConfiguration implements AsyncConfigurer{ /** * 获取异步线程池执行对象 * @return */ @Override public Executor getAsyncExecutor() { //使用Spring内置线程池任务对象 ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); //设置线程池参数 taskExecutor.setCorePoolSize(5); taskExecutor.setMaxPoolSize(10); taskExecutor.setQueueCapacity(25); taskExecutor.initialize(); return taskExecutor; } @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return null; }} 我们自定义的监听异步配置类实现了AsyncConfigurer接口并且实现内getAsyncExecutor方法以提供线程任务池对象的获取。我们只需要在异步方法上添加@Async注解就可以实现方法的异步调用，为了证明这一点，我们在发送邮件onApplicationEvent方法内添加线程阻塞3秒，修改后的代码如下所示： 12345678910111213141516171819/** * supportsEventType &amp; supportsSourceType 两个方法返回true时调用该方法执行业务逻辑 * @param applicationEvent 具体监听实例，这里是UserRegisterEvent */ @Override @Async public void onApplicationEvent(ApplicationEvent applicationEvent) { try { Thread.sleep(3000);//静静的沉睡3秒钟 }catch (Exception e) { e.printStackTrace(); } //转换事件类型 UserRegisterEvent userRegisterEvent = (UserRegisterEvent) applicationEvent; //获取注册用户对象信息 UserBean user = userRegisterEvent.getUser(); System.out.println(&quot;用户：&quot;+user.getName()+&quot;，注册成功，发送邮件通知。&quot;); } 下面我们重启下项目，访问注册地址，查看界面反映是否也有延迟。我们测试发现访问界面时反映速度要不之前还要快一些，我们去查看控制台时，可以看到注册信息输出后等待3秒后再才输出邮件发送通知，而在这之前界面已经做出了反映。 注意：如果存在多个监听同一个事件时，并且存在异步与同步同时存在时则不存在执行顺序。 总结我们在传统项目中往往各个业务逻辑之间耦合性较强，因为我们在service都是直接引用的关联service或者jpa来作为协作处理逻辑，然而这种方式在后期更新、维护性难度都是大大提高了。然而我们采用事件通知、事件监听形式来处理逻辑时耦合性则是可以降到最小。","link":"/spring-event-listener.html"},{"title":"非注入方式获取ApplicationContext上下文","text":"ApplicationContext对象是Spring开源框架的上下文对象实例，在项目运行时自动装载Handler内的所有信息到内存。传统的获取方式有很多种，不过随着Spring版本的不断迭代，官方也慢慢的不建议使用部分方式。下面我简单介绍一种Spring官方推荐使用的方式！ 本章目标基于SpringBoot平台完成ApplicationContext对象的获取，并通过实例手动获取Spring管理的bean. 构建项目本章项目不需要太多的内容，添加Web依赖就可以了。 ApplicationContextAware这个接口对象就是我们今天的主角，其实以实现ApplicationContextAware接口的方式获取ApplicationContext对象实例并不是SpringBoot特有的功能，早在Spring3.0x版本之后就存在了这个接口，在传统的Spring项目内同样是可以获取到ApplicationContext实例的，下面我们看看该如何编码才能达到我们的效果呢？ 实现ApplicationContextAware接口创建一个实体类并实现ApplicationContextAware接口，重写接口内的setApplicationContext方法来完成获取ApplicationContext实例的方法，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.xunmei.api;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;/** * 获取Spring上下文对象 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/26 * Time：23:25 * 码云：http://git.oschina.net/jnyqy * ======================== */@Componentpublic class ApplicationContextProvider implements ApplicationContextAware{ /** * 上下文对象实例 */ private ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } /** * 获取applicationContext * @return */ public ApplicationContext getApplicationContext() { return applicationContext; } /** * 通过name获取 Bean. * @param name * @return */ public Object getBean(String name){ return getApplicationContext().getBean(name); } /** * 通过class获取Bean. * @param clazz * @param &lt;T&gt; * @return */ public &lt;T&gt; T getBean(Class&lt;T&gt; clazz){ return getApplicationContext().getBean(clazz); } /** * 通过name,以及Clazz返回指定的Bean * @param name * @param clazz * @param &lt;T&gt; * @return */ public &lt;T&gt; T getBean(String name,Class&lt;T&gt; clazz){ return getApplicationContext().getBean(name, clazz); }} 我们拿到ApplicationContext对象实例后就可以手动获取Bean的注入实例对象，在ApplicationContextProvider类内我简单的实现了几个方法来获取指定的Bean实例，当然你可以添加更多的方法来完成更多的业务逻辑。 如果你是想在非Spring管理的实体内使用ApplicationContext还不想采用注入ApplicationContextProvider来完成实例化，这时我们可以修改ApplicationContext实例对象为静态实例，方法改为静态方法，这样在外部同样是可以获取到指定Bean的实例。如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Componentpublic class ApplicationContextProvider implements ApplicationContextAware{ /** * 上下文对象实例 */ private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } /** * 获取applicationContext * @return */ public static ApplicationContext getApplicationContext() { return applicationContext; } /** * 通过name获取 Bean. * @param name * @return */ public static Object getBean(String name){ return getApplicationContext().getBean(name); } /** * 通过class获取Bean. * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz){ return getApplicationContext().getBean(clazz); } /** * 通过name,以及Clazz返回指定的Bean * @param name * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(String name,Class&lt;T&gt; clazz){ return getApplicationContext().getBean(name, clazz); }} 这里要注意ApplicationContextProvider类上的@Component注解是不可以去掉的，去掉后Spring就不会自动调用setApplicationContext方法来为我们设置上下文实例。 总结本章内容较少，主要讲解了SpringBoot平台下采用ApplicationContextAware的方式完成ApplicationContext实例的获取，并通过ApplicationContext实例完成对Spring管理的Bean实例手动获取。","link":"/spring-get-application-context.html"},{"title":"Spring Security灵活的PasswordEncoder加密方式","text":"本章基于Spring Security 5.4.1版本编写，从5.x版本开始引入了很多新的特性。为了适配老系统的安全框架升级，Spring Security也是费劲了心思，支持不同的密码加密方式，而且根据不同的用户可以使用不同的加密方式。 构建Spring Security项目Spring Security的集成使用还是很简单的，根据项目使用的框架不同大致分为两种集成方式： SpringBoot方式集成 SecurityBom方式集成 SpringBoot方式构建在pom.xml文件内添加如下内容： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; SecurityBom方式构建spring-security-bom是一个提供了Spring Security指定版本的全部默认依赖的pom类型项目，我们可以通过dependencyManagement进行配置到项目中，这样我们就可以直接添加对应的dependency了（注意：版本号因为bom已经注定，所以dependency不需要指定.）。在pom.xml文件内添加如下内容： 123456789101112131415161718192021222324252627&lt;dependencies&gt; // ...省略其他依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--配置SecurityBom--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-bom&lt;/artifactId&gt; &lt;version&gt;5.4.1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 注意事项：我们构建Web类型的安全项目时，spring-security-config、spring-security-core、spring-security-web三个依赖都是必须添加的。 PasswordEncoderPasswordEncoder是Spring Security提供的密码加密方式的接口定义，源码类如下所示： 12345678910111213141516171819202122232425262728293031public interface PasswordEncoder { /** * Encode the raw password. Generally, a good encoding algorithm applies a SHA-1 or * greater hash combined with an 8-byte or greater randomly generated salt. */ String encode(CharSequence rawPassword); /** * Verify the encoded password obtained from storage matches the submitted raw * password after it too is encoded. Returns true if the passwords match, false if * they do not. The stored password itself is never decoded. * * @param rawPassword the raw password to encode and match * @param encodedPassword the encoded password from storage to compare with * @return true if the raw password, after encoding, matches the encoded password from * storage */ boolean matches(CharSequence rawPassword, String encodedPassword); /** * Returns true if the encoded password should be encoded again for better security, * else false. The default implementation always returns false. * @param encodedPassword the encoded password to check * @return true if the encoded password should be encoded again for better security, * else false. */ default boolean upgradeEncoding(String encodedPassword) { return false; }} #encode 该方法提供了明文密码的加密处理，加密后密文的格式主要取决于PasswordEncoder接口实现类实例。 #matches 匹配存储的密码以及登录时传递的密码（登录密码是经过加密处理后的字符串）是否匹配，如果匹配该方法则会返回true. 内置的PasswordEncoder实现列表 NoOpPasswordEncoder（已废除） 明文密码加密方式，该方式已被废除（不建议在生产环境使用），不过还是支持开发阶段测试Spring Security的时候使用。 BCryptPasswordEncoder Argon2PasswordEncoder Pbkdf2PasswordEncoder SCryptPasswordEncoder DelegatingPasswordEncoder在之前版本集成Spring Secuirty时，我们需要通过@Bean的方式来配置全局统一使用的密码加密方式（PasswordEncoder），当然这种方式现在还是适用的，不过在5.x版本开始为了支持动态的多种密码加密方式，DelegatingPasswordEncoder委托加密方式类应用而生，它内部其实是一个Map集合，根据传递的Key（Key为加密方式）获取Map集合的Value，而Value则是具体的PasswordEncoder实现类。 DelegatingPasswordEncoder建立密码格式的规则，格式如：{bcrypt}encodePassword，示例如下所示： 123456789// {bcrypt}格式会委托给BCryptPasswordEncoder加密类{bcrypt}$2a$10$iMz8sMVMiOgRgXRuREF/f.ChT/rpu2ZtitfkT5CkDbZpZlFhLxO3y// {pbkdf2}格式会委托给Pbkdf2PasswordEncoder加密类{pbkdf2}cc409867e39f011f6332bbb6634f58e98d07be7fceefb4cc27e62501594d6ed0b271a25fd9f7fc2e// {MD5}格式会委托给MessageDigestPasswordEncoder加密类{MD5}e10adc3949ba59abbe56e057f20f883e// {noop}明文方式，委托给NoOpPasswordEncoder{noop}123456// ... 指定用户使用PasswordEncoderDelegatingPasswordEncoder是默认的PasswordEncoder加密方式，所以我们可以为不同的用户配置所使用不同的密码加密方式，只需要密码格式按照：{away}encodePassword来进行持久化即可。 123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration@EnableWebSecuritypublic class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .formLogin() .and() .csrf() .disable() .authorizeRequests() .antMatchers(&quot;/**&quot;) .authenticated(); } @Bean public UserDetailsService users() { // {MD5}value必须大写，value值必须是32位小写 // admin UserDetails admin = User.builder() //.passwordEncoder(encoder::encode) .username(&quot;admin&quot;).password( &quot;{MD5}e10adc3949ba59abbe56e057f20f883e&quot; ).roles(&quot;admin&quot;).build(); // hengboy UserDetails hengboy = User.builder() .username(&quot;hengboy&quot;) .password(&quot;{bcrypt}$2a$10$iMz8sMVMiOgRgXRuREF/f.ChT/rpu2ZtitfkT5CkDbZpZlFhLxO3y&quot;) .roles(&quot;admin&quot;) .build(); // yuqiyu UserDetails yuqiyu = User.builder().username(&quot;yuqiyu&quot;) //.password(&quot;{noop}123456&quot;) .password(&quot;{pbkdf2}cc409867e39f011f6332bbb6634f58e98d07be7fceefb4cc27e62501594d6ed0b271a25fd9f7fc2e&quot;) .roles(&quot;user&quot;).build(); return new InMemoryUserDetailsManager(admin, yuqiyu, hengboy); }} 上面是使用内存方式存储安全用户的实现代码，在创建UserDetailsService类的实例时将用户列表通过构造参数进行传递。 所创建的用户：admin，采用MD5的加密方式进行密码编码，这里需要注意的是MD5加密后的字符串必须为小写32位。 所创建的用户：hengboy，采用bcrypt方式进行密码编码。 所创建的用户：yuqiyu，采用pbkdf2方式进行密码编码。 覆盖默认的PasswordEncoderSpring Security 5.x版本默认的PasswordEncoder方式改成了DelegatingPasswordEncoder委托类，不过如果是通过PasswordEncoderFactories#createDelegatingPasswordEncoder方法创建的DelegatingPasswordEncoder实例时，默认其实使用的还是BCryptPasswordEncoder，源码如下所示： 12345678public static PasswordEncoder createDelegatingPasswordEncoder() { String encodingId = &quot;bcrypt&quot;; Map&lt;String, PasswordEncoder&gt; encoders = new HashMap&lt;&gt;(); encoders.put(encodingId, new BCryptPasswordEncoder()); // 省略... return new DelegatingPasswordEncoder(encodingId, encoders);} 如果我们项目中不需要使用DelegatingPasswordEncoder委托密码编码方式，可以通过@Bean的方式来统一配置全局共用的PasswordEncoder，如下所示： 1234@Beanpublic PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder();} 可以根据项目自行选择所使用的PasswordEncoder实现类。","link":"/spring-security-flexible-password-encoder.html"},{"title":"激活项目配置的多环境(profiles)","text":"在中大型企业项目开发中，环境分离是必不可少的一步，然而现在的开发人员也只是有这个概念，还是有很多项目采用普通的方式，每次打包发布部署的时候改动一大堆的配置文件，有一个地方忘记改就相当于白更新了一次系统，这种修改配置文件完成环境更换的方式给我们带来了很多的困扰，浪费了我们很多宝贵的时间！早在Spring 3.1版本就已经为我们提供了环境分离的相关注解配置方式，不过在传统的Spring项目中配置Profile确实有点麻烦，在Spring版本的不断更新直到后来SpringBoot成长起来后Profile已经能够很好支持项目配置环境分离。 本章目标基于SpringBoot平台完成简单的数据库环境操作分离，根据激活不同的Profile完成不同的数据库操作。 构建项目使用Idea工具创建一个SpringBoot项目，目前SpringBoot的版本已经更新至1.5.8，我们采用最新版本来完成本章内容，添加相关JPA、MySQL、Druid、Lombok、Web、FastJson等，pom.xml依赖相关配置如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152....省略部分配置&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入druid最新maven依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.39&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;....省略部分配置 配置数据库我们创建三个数据库分别是project_prod =&gt; 线上环境数据库、project_dev=&gt;开发环境数据库、project_beta=&gt;线上测试环境数据库，这样我们在切换Profile时可以很好的区分环境，下面我们创建一张用户基本信息表，SQL如下： 1234567891011-- ------------------------------ Table structure for system_user_info-- ----------------------------DROP TABLE IF EXISTS `system_user_info`;CREATE TABLE `system_user_info` ( `SUI_ID` int(11) NOT NULL AUTO_INCREMENT, `SUI_NICK_NAME` varchar(50) DEFAULT NULL, `SUI_LOGIN_NAME` varchar(30) DEFAULT NULL, `SUI_LOGIN_PASSWORD` varchar(32) DEFAULT NULL, PRIMARY KEY (`SUI_ID`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; 将上面SQL分别在三个数据库内分别执行一次，保证我们数据结构环境一致，然后对应数据库分别插入数据，如下： 123INSERT INTO `system_user_info` VALUES ('1', '线上测试环境用户', 'beta', 'beta_password');INSERT INTO `system_user_info` VALUES ('1', '开发环境用户', 'dev', 'dev_password');INSERT INTO `system_user_info` VALUES ('1', '正式环境用户', 'prod', 'prod_password'); 这样我们就可以区分项目正在访问的具体环境。 创建Entity对应system_user_info数据表创建一个数据实体，如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.yuqiyu.chapter38.entity;import lombok.Data;import javax.persistence.*;/** * 用户基本信息实体 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/10/29 * Time：08:25 * 码云：http://git.oschina.net/jnyqy * ======================== */@Entity@Table(name = &quot;system_user_info&quot;)@Datapublic class SystemUserInfoEntity{ /** * 主键 */ @Column(name = &quot;SUI_ID&quot;) @GeneratedValue @Id private Integer id; /** * 昵称 */ @Column(name = &quot;SUI_NICK_NAME&quot;) private String nickName; /** * 登录名 */ @Column(name = &quot;SUI_LOGIN_NAME&quot;) private String loginName; /** * 登录密码 */ @Column(name = &quot;SUI_LOGIN_PASSWORD&quot;) private String loginPassword;} 接下来我们为上面的实体创建一个JPA接口，继承JpaRepository&lt;T,PK&gt;接口完成Jpa扫描自动代理实例的动作。 创建JPASystemUserInfoJPA接口内容如下所示： 1234567891011121314151617181920package com.yuqiyu.chapter38.jpa;import com.yuqiyu.chapter38.entity.SystemUserInfoEntity;import org.springframework.data.jpa.repository.JpaRepository;/** * 系统用户信息jpa * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/10/29 * Time：08:30 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface SystemUserInfoJPA extends JpaRepository&lt;SystemUserInfoEntity,Integer&gt;{} 配置Profile环境在SpringBoot内已经为了约定好了Profile配置文件的命名规则，即：application-xxx.properties或者application-xxx.yml，我们只需要将对应环境的配置文件放到resources目录下即可，也就是classpath下，我们对应我们的数据库环境编写三个不同的配置文件。 application-dev.yml根据我们与SpringBoot的约定在application-dev.xml配置文件内配置的都是开发环境信息，里面包含了开发环境数据源配置信息，当然在实际的项目开发过程中配置信息可以任意约定。配置内容如下所示： 123456789101112131415161718192021222324252627282930313233spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/project_dev?characterEncoding=utf8 username: root password: 123456 #最大活跃数 maxActive: 20 #初始化数量 initialSize: 1 #最大连接等待超时时间 maxWait: 60000 #打开PSCache，并且指定每个连接PSCache的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 #通过connectionProperties属性来打开mergeSql功能；慢SQL记录 #connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 1 from dual testWhileIdle: true testOnBorrow: false testOnReturn: false #配置监控统计拦截的filters，去掉后监控界面sql将无法统计,'wall'用于防火墙 filters: stat, wall, log4j jpa: properties: hibernate: show_sql: true format_sql: true 在上面代码中可以看到，我们连接了本地的project_dev数据库来作为开发环境的访问数据源。 application-beta.ymlapplication-beta.yml配置文件就是我们与SpringBoot约定的线上测试环境，在我们实际的开发过程中线上测试环境肯定与开发环境不是同一个数据库，这时我们将application-dev.yml配置文件复制一份，修改下数据库链接信息即可，如果你的application-beta.yml还存在其他的配置，不要忘记修改成相关的环境配置。配置信息如下所示： 1234567891011121314151617181920212223242526272829303132spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/project_beta?characterEncoding=utf8 username: root password: 123456 #最大活跃数 maxActive: 20 #初始化数量 initialSize: 1 #最大连接等待超时时间 maxWait: 60000 #打开PSCache，并且指定每个连接PSCache的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 #通过connectionProperties属性来打开mergeSql功能；慢SQL记录 #connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 1 from dual testWhileIdle: true testOnBorrow: false testOnReturn: false #配置监控统计拦截的filters，去掉后监控界面sql将无法统计,'wall'用于防火墙 filters: stat, wall, log4j jpa: properties: hibernate: show_sql: true format_sql: true application-prod.yml而application-prod.yml配置文件则是我们与SpringBoot约定的线上生产环境的配置文件，里面保存的全部都是正式环境配置信息，一般在开发过程中线上环境配置信息是不需要变动的，配置完成后就只是在打包部署时修改spring.profiles.active为prod就可以了（注：根据实际项目的线上环境的配置约定名称而定）。配置信息如下所示： 1234567891011121314151617181920212223242526272829303132spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/project_prod?characterEncoding=utf8 username: root password: 123456 #最大活跃数 maxActive: 20 #初始化数量 initialSize: 1 #最大连接等待超时时间 maxWait: 60000 #打开PSCache，并且指定每个连接PSCache的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 #通过connectionProperties属性来打开mergeSql功能；慢SQL记录 #connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 1 from dual testWhileIdle: true testOnBorrow: false testOnReturn: false #配置监控统计拦截的filters，去掉后监控界面sql将无法统计,'wall'用于防火墙 filters: stat, wall, log4j jpa: properties: hibernate: show_sql: true format_sql: true 为了方便我们测试，我在本地创建的三个数据库，当然实际项目开发中你可能是数据库读写分离环境，也可能是多台服务器完全分离的环境，只需要针对不同的约定修改相对应的配置信息就可以了。 测试Profile下面我们来创建一个控制器，使用我们上面已经创建好的SystemUserInfoJPA完成数据库的读取动作。 创建测试控制器在上面我们为每一个环境的数据库表````都初始化了一条数据，那么我就来编写一个读取数据库的请求方法，根据我们修改的spring.profiles.active配置文件内容，是否可以改变请求数据库。控制器代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839package com.yuqiyu.chapter38;import com.yuqiyu.chapter38.entity.SystemUserInfoEntity;import com.yuqiyu.chapter38.jpa.SystemUserInfoJPA;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 测试profile环境 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/10/29 * Time：09:02 * 码云：http://git.oschina.net/jnyqy * ======================== * @author hengyu */@RestController@RequestMapping(value = &quot;/user&quot;)public class IndexController{ @Autowired private SystemUserInfoJPA systemUserInfoJPA; /** * 查询用户详情 * @param id * @return */ @RequestMapping(value = &quot;/{id}&quot;) public SystemUserInfoEntity detail(@PathVariable(&quot;id&quot;) Integer id) throws Exception { return systemUserInfoJPA.findOne(id); }} 在控制器内，我们通过访问/user/{id}请求地址，就可以获取到用户的基本信息在页面上通过Json字符串的形式展示，下面我们就来配置需要激活的Profile，访问该请求地址查看输出效果。 激活Profile由于激活Profile的配置不属于任何一个环境分离的配置文件，所以我们不可以在dev、beta、prod任意一个配置文件内添加激活配置，我们知道application.yml是SpringBoot约定的配置文件，那么我就在该配置文件内配置环境分离激活，配置如下所示： 123spring: profiles: active: dev 我们在application.yml配置文件内激活了dev开发环境，下面我们启动项目访问请求路径http://127.0.0.1:8080/user/1来查看界面输出内容，如下所示： 123456{ &quot;id&quot;: 1, &quot;nickName&quot;: &quot;开发环境用户&quot;, &quot;loginName&quot;: &quot;dev&quot;, &quot;loginPassword&quot;: &quot;dev_password&quot;} 正如我们所料，正确的输出了开发环境的用户信息，那我们修改下激活环境是不是也会编程相对应的输出呢？下面我们来证实这一点，修改激活环境为线上开发环境： 123spring: profiles: active: beta 重启项目，再次访问http://127.0.0.1:8080/user/1请求路径，界面输出内容如下所示： 123456{ &quot;id&quot;: 1, &quot;nickName&quot;: &quot;线上测试环境用户&quot;, &quot;loginName&quot;: &quot;beta&quot;, &quot;loginPassword&quot;: &quot;beta_password&quot;} 可以看到已经改成我们需要的效果，我们只是激活了不同的环境，就轻松实现了环境的分离，正式环境也是一样的，下面我们来激活正式环境完成Package打包。 正式环境打包有很多项目在上线打包部署的时候需要改动很多配置文件，访问地址等等配置信息，那我们采用了Profile后打包该怎么处理呢？答案是：省心。第一步我们只需要修改激活环境改成线上环境即可，如下所示： 123spring: profiles: active: prod 第二步运行打包命令，等待打包完成。本章是采用的Idea开发工具完成的打包，Idea工具为Maven自带了命令窗口，只需要选择不同的命令双击就可以执行，如下图1所示： 我们双击package命令，等待打包完成就可以了，完成后jar或者war会在target目录生成，下面我们使用Windows CMD命令行进入jar存在的目录，执行命令之前需要关掉Idea启动的项目： 1java -jar chapter38-0.0.1-SNAPSHOT.jar 启动完成后，我们再次访问请求地址http://127.0.0.1:8080/user/1，查看界面输出内容： 123456{ &quot;id&quot;: 1, &quot;nickName&quot;: &quot;正式环境用户&quot;, &quot;loginName&quot;: &quot;prod&quot;, &quot;loginPassword&quot;: &quot;prod_password&quot;} 正确输出了prod正式环境的用户信息。 总结Profile的加入可以让很多运维实施人员减少了太多的烦恼，在几年前部署完全都是采用修改配置文件，如果修改出错还会导致返工，既浪费了时间也浪费了精力。 建议大家项目初期尽可能的采用环境分离的方式进行构建项目！","link":"/springboot-active-profiles.html"},{"title":"Actuator自定义节点路径 &amp; 监控服务自定义配置","text":"既然Actuator给我们内置提供了节点映射，我们为什么还需要进行修改呢？ 正因为如此我们才需要进行修改！！！ 路径都是一样的，很容易就会暴露出去，导致信息泄露，发生一些无法估计的事情，如果我们可以自定义节点的映射路径或者自定义监控服务的管理信息，这样就不会轻易的暴露出去，Actuator已经为了们提供了对应的方法来解决这个问题，下面我们来看下吧。 本章目标自定义Actuator节点映射路径、监控服务配置信息等，提高监控服务的安全性。 构建项目最近这几篇有关Actuator的文章使用的源码都是同一个，源码已经上传了码云，点击下载源码汇总，源码位置：SpringBoot2.x/hengboy-spring-boot-actuator，本章也使用之前创建的项目，下载后通过idea工具打开，在原来基础上进行修改。 自定义监控节点映射路径之前章节讲到了Actuator为我们提供了org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties类，用于配置监控管理web端的信息，映射路径也在该配置类中，通过修改management.endpoints.web.path-mapping配置来修改指定的节点映射路径，如下所示： 12345678# 管理节点配置management: endpoints: web: # 自定义路径映射 path-mapping: # key=&gt;value形式，原映射路径=&gt;新映射路径 health: healthcheck path-mapping参数值需要key-&gt;value形式接收，在WebEndpointProperties类内是以Map&lt;String, String&gt;类型定义的。 key：原监控节点映射路径，如：health value，新的监控节点映射路径，如：healthcheck 修改后我们就可以通过访问/actuator/healthcheck访问监控的健康信息。 如果你修改了management.endpoints.web.base-path,那么前缀为你修改后得值，具体可以访问/springboot-actuator-default.html了解详情。 运行测试启动本章项目，打开浏览器或者终端，如下为终端示例： 12➜ ~ curl http://localhost:8080/healthcheck{&quot;status&quot;:&quot;UP&quot;,&quot;details&quot;:{&quot;diskSpace&quot;:{&quot;status&quot;:&quot;UP&quot;,&quot;details&quot;:{&quot;total&quot;:250790436864,&quot;free&quot;:75346001920,&quot;threshold&quot;:10485760}}}} 通过访问/healthcheck可以查询到详细的信息。 自定义监控端口号默认Actuator监控服务的端口号跟项目端口号一致，本章项目的端口号为8080所以我们通过http://localhost:8080前缀就可以访问到监控节点，那我们该怎么修改监控节点端口号呢？ ManagementServerPropertiesAcutator内置了配置类org.springframework.boot.actuate.autoconfigure.web.server.ManagementServerProperties来进行自定义设置监控服务基本信息，该配置类内包含了端口号(port)、服务地址(address)、安全SSL（ssl）等。我们通过修改management.server.port进行自定义监控端口号，如下所示： 12345# 管理节点配置management: # 修改监控服务端的端口号 server: port: 8001 运行测试修改完成后，重启本章项目，然后通过如下命令访问： 12➜ ~ curl http://localhost:8001/healthcheck{&quot;status&quot;:&quot;UP&quot;,&quot;details&quot;:{&quot;diskSpace&quot;:{&quot;status&quot;:&quot;UP&quot;,&quot;details&quot;:{&quot;total&quot;:250790436864,&quot;free&quot;:75105476608,&quot;threshold&quot;:10485760}}}} 通过8001端口已经可以访问到开放的监控节点，修改后再次访问同项目端口号的地址会出现404错误信息。 总结本章介绍了自定义Actuator开放的监控节点的映射路径，还简单介绍了通过修改management.server.port参数进行自定义监控服务的管理端口号。","link":"/springboot-actuator-change-mapping.html"},{"title":"探究Actuator的默认开放节点 &amp; 详细健康状态","text":"系统的监控在分布式的设计中显得尤为重要，因为分开部署的缘故，并不能及时的了解到程序运行的实时状况，之所以重要所以SpringBoot也给我提供了一套自动监控的API，可以无缝整合spring-boot-admin来完成图形化的展示，我们本章先来介绍下actuator系统监控相关内容。 本章目标通过spring-boot-actuator完成系统运行监控，实时了解程序运行的环境是否健康。 构建项目使用idea开发工具创建SpringBoot项目并添加spring-boot-starter-actuator以及spring-boot-starter-web（如果缺少web依赖会导致本章项目无法启动(没有内部集成的web容器无法运行.)，pom.xml文件部分内容如下所示： 1234567891011121314151617&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置绑定映射类 有关本章开放节点的配置都被映射到属性配置类org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties中，通过@ConfigurationProperties注解自动映射application.yml配置文件内以前缀management.endpoints.web的属性配置信息。 默认开放的节点Actuator默认开放了两个节点信息，分别是： health：健康监测节点健康节点我们在访问时默认只可以查看当前系统的运行状态，如下所示：123{ &quot;status&quot;: &quot;UP&quot;} 如果不开放相关的配置无法查看详细的运行健康信息，比如：硬盘等。 info：基本信息查看节点 我们在属性类WebEndpointProperties内也并没有看到health、info作为初始化的值赋值给exposure.include，那么是怎么进行赋值的呢？ 元数据配置文件spring-configuration-metadata.json(元数据配置文件)位于spring-boot-actuator-autoconfigure-2.0.6.jar依赖的META-INF目录下，主要作用是对应WebEndpointProperties等属性配置类的字段类型、描述、默认值、对应目标字段的定义，具体的实现我在自定义starter的文章内有讲到，我们找到name为management.endpoints.web.exposure.include的配置如下： 123456789101112.....{ &quot;sourceType&quot;: &quot;org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties$Exposure&quot;, &quot;defaultValue&quot;: [ &quot;health&quot;, &quot;info&quot; ], &quot;name&quot;: &quot;management.endpoints.web.exposure.include&quot;, &quot;description&quot;: &quot;Endpoint IDs that should be included or '*' for all.&quot;, &quot;type&quot;: &quot;java.util.Set&lt;java.lang.String&gt;&quot;},..... 通过配置的defaultValue来自动映射到WebEndpointProperties属性配置类的Exposure#include字段，下面简单介绍上面的字段： sourceType：该配置字段所关联配置类的类型（全限定名） defaultValue：默认值，根据type来设置，如上java.util.Set&lt;java.lang.String&gt;类型的默认值就可以通过[&quot;health&quot;,&quot;info&quot;]设置 name：字段的名称，对应配置类内的field名称 description：该配置字段的描述信息，可以是中文，填写后idea工具会自动识别并提示 type：该字段的类型的全限定名，如：java.lang.String 查看详细健康状态开启查看详细健康状态比较简单，通过配置参数management.endpoint.health.show-details来进行修改，该参数的值由org.springframework.boot.actuate.health.ShowDetails枚举提供配置值，ShowDetails源码如下所示： 12345678910111213141516171819202122232425/** * Options for showing details in responses from the {@link HealthEndpoint} web * extensions. * * @author Andy Wilkinson * @since 2.0.0 */public enum ShowDetails { /** * Never show details in the response. */ NEVER, /** * Show details in the response when accessed by an authorized user. */ WHEN_AUTHORIZED, /** * Always show details in the response. */ ALWAYS} 在spring-configuration-metadata.json元数据文件内，配置的showDetails的默认值为never，也就是不显示详细信息，配置如下所示： 1234567{ &quot;sourceType&quot;: &quot;org.springframework.boot.actuate.autoconfigure.health.HealthEndpointProperties&quot;, &quot;defaultValue&quot;: &quot;never&quot;, &quot;name&quot;: &quot;management.endpoint.health.show-details&quot;, &quot;description&quot;: &quot;When to show full health details.&quot;, &quot;type&quot;: &quot;org.springframework.boot.actuate.health.ShowDetails&quot;} 我们修改management.endpoint.health.show-details参数为always后重新项目再次访问/actuator/health就可以获取如下的信息： 12345678910111213{ &quot;status&quot;: &quot;UP&quot;, &quot;details&quot;: { &quot;diskSpace&quot;: { &quot;status&quot;: &quot;UP&quot;, &quot;details&quot;: { &quot;total&quot;: 250790436864, &quot;free&quot;: 77088698368, &quot;threshold&quot;: 10485760 } } }} 自定义节点访问前缀actuator默认的所有节点的访问前缀都是/actuator，在application.yml配置文件内设置management.endpoints.web.basePath参数进行修改，如下所示： 123456# 管理节点配置management: endpoints: web: # actuator的前缀地址 base-path: / basePath字段位于WebEndpointProperties属性配置类内，修改完成重启项目就可以使用修改后的路径进行访问，我们上述直接映射到了/下。 总结通过本章的讲解我们明白了spring-boot-actuator默认开放了health、info两个节点，通过配置健康检查详细信息可以查看硬盘相关的运行健康状态。","link":"/springboot-actuator-default.html"},{"title":"你了解Actuator开放指定监控节点吗？","text":"之前章节/springboot-actuator-default.html讲解了spring-boot-actuator默认开放的节点以及如何修改查看详细的健康信息，那我们怎么设置开放指定的节点访问呢？ 本章目标开放spring-boot-actuator的指定节点访问。 构建项目由于我们在[SpringBoot核心技术：探究Actuator的默认开放节点 &amp; 详细健康状态]/springboot-actuator-default.html已经创建了项目，之前章节的源码已经上传到码云，访问：SpringBoot源码汇总下载源码，下载完成后使用idea工具打开即可，我们在之前的基础上修改。 开放指定节点management.endpoints.web.exposure.include的配置字段我们已经了解到了在org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties属性配置类内，而且exposure.include的值默认为[&quot;health&quot;,&quot;info&quot;]。 除此之外通过spring-configuration-metadata.json元数据配置文件内还知道了management.endpoints.web.exposure.include配置参数的类型为java.util.Set&lt;java.lang.String&gt;，这样我们就知道了该如何进行修改配置了，修改application.yml配置文件如下所示： 12345678910111213# 管理节点配置management: endpoints: web: # actuator的前缀地址 base-path: / # 开放指定节点 exposure: include: - health - info - mappings - env 由于management.endpoints.web.exposure.include是java.util.Set&lt;java.lang.String&gt;类型，那么我就可以采用中横线换行形式进行配置(这是SpringBoot采用yaml配置文件风格的约定)，一个- xxx代表一个配置的值。 当然我们采用数组的形式也是可以的，如下所示： 123456789# 管理节点配置management: endpoints: web: # actuator的前缀地址 base-path: / # 开放指定节点 exposure: include: [&quot;health&quot;,&quot;info&quot;,&quot;mappings&quot;,&quot;env&quot;] 开放全部节点如果不做节点的开放限制，可以将management.endpoints.web.exposure.include配置为*，那么这样就可以开放全部的对外监控的节点，如下所示： 123456789# 管理节点配置management: endpoints: web: # actuator的前缀地址 base-path: / # 开放指定节点 exposure: include: &quot;*&quot; 内置节点列表开放全部节点后在项目启动时，控制台会打印已经映射的路径列表，spring-boot-actuator内置了丰富的常用监控节点，详见如下表格： 节点 节点描述 是否默认启用 auditevents 公开当前应用程序的审核事件信息。 是 beans 显示应用程序中所有Spring bean的完整列表。 是 conditions 显示在配置和自动配置类上评估的条件以及它们匹配或不匹配的原因。 是 configprops 显示所有的整理列表@ConfigurationProperties。 是 env 露出Spring的属性ConfigurableEnvironment。 是 health 显示应用健康信息。 是 httptrace 显示HTTP跟踪信息（默认情况下，最后100个HTTP请求 - 响应交换）。 是 info 显示任意应用信息。 是 loggers 显示和修改应用程序中记录器的配置。 是 metrics 显示当前应用程序的“指标”信息。 是 mappings 显示所有@RequestMapping路径的整理列表。 是 scheduledtasks 显示应用程序中的计划任务。 是 shutdown 允许应用程序正常关闭。 否 threaddump 执行线程转储。 是 sessions 允许从Spring Session支持的会话存储中检索和删除用户会话。使用Spring Session对响应式Web应用程序的支持时不可用。 是 总结通过本章详细你应该可以知道你需要开发的节点了，根据具体的业务需求开放不同的节点。 注意：节点开放一定要慎重，不要过度开放接口，也不要方便盲目填写*开放全部节点。","link":"/springboot-actuator-exposure-include.html"},{"title":"Actuator远程关闭服务“黑科技”","text":"之前章节介绍了Actuator对服务系统监控相关的知识点，了解到了开放指定监控节点、查看详细健康信息，我们本章来介绍下Actuator的黑科技，远程关闭应用服务。 本章目标通过配置Actuator完成服务远程关闭。 构建项目本章同样使用之前章节的源码基础上修改，访问源码汇总下载SpringBoot2.x/hengboy-spring-boot-actuator章节源码，通过idea工具进行打开。 配置远程关闭服务由于Autuator内置了远程关闭服务功能，所以我们可以很简单的开启这一项“黑科技”,修改application.yml配置文件，如下所示： 1234567891011121314151617# 管理节点配置management: endpoints: web: # actuator的前缀地址 base-path: / # 开放指定节点 exposure: include: - health - info - mappings - env - shutdown # 开启远程关闭服务 shutdown: enabled: true 通过management.endpoint.shutdown.enabled参数来进行设置，默认为false，默认不会开启远程关闭服务功能，然后把shutdown节点进行开放，否则无法发送远程关机请求。 注意：在/springboot-actuator-exposure-include.html文章内我们说到了Actuator内置的监控节点列表，当我们访问shutdown节点时必须发送POST类型请求，否则无法执行关机操作。 测试打开终端或者postman工具进行测试关机请求，如下是终端命令测试结果： 1curl -X POST http://localhost:8080/shutdown 通过curl命令发送POST请求类型到http://localhost:8080/shutdown，发送完成后会响应一段信息： 1{&quot;message&quot;:&quot;Shutting down, bye...&quot;} 我们去查看对应的服务实例运行状态时可以发现已经停止了。 总结本章配置比较简单，通过修改两个地方开启了远程关闭服务的操作。 不过建议没事不要打开，打开后也不要对公网开放，黑科技都是比较危险的。","link":"/springboot-actuator-remote-shutdown.html"},{"title":"SpringBoot使用@ConstructorBinding注解进行配置属性绑定","text":"SpringBoot2.2版本发行后一些新的功能也渐渐的浮出了水面，在之前版本SpringBoot的配置文件与类之间的属性绑定(@ConfigurationProperties)是通过Setter方法来进行绑定对应的配置值，而从2.2版本开始支持了构造函数的方式进行绑定。 @ConstructorBinding注解这个注解是SpringBoot在2.2发行版中添加的，添加该注解的属性配置类不再需要添加Setter方法，不过需要添加构造函数，根据构造函数进行实例化属性配置类。 创建项目使用IDEA创建一个SpringBoot项目，在pom.xml中添加依赖如下所示： 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置信息本章主要是讲解怎么把application.yml或者application.properties配置文件的内容自动映射绑定到配置类的对应属性字段上，所以我们需要在application.yml文件中添加部分我们自定义的配置内容，如下所示： 12345# 自定义配置minbox: config: author: 恒宇少年 - 于起宇 blog-address: https://blog.minbox.org 配置类我们对应application.yml的配置信息，对应编写一个名为MinBoxConfig的映射配置类，如下所示： 123456789101112131415161718192021222324252627282930313233343536/** * 配置类 * * @author 恒宇少年 */@ConfigurationProperties(prefix = PREFIX)@ConstructorBindingpublic class MinBoxConfig { /** * 映射绑定 &quot;minbox.config&quot;前缀的配置信息 */ public static final String PREFIX = &quot;minbox.config&quot;; /** * 配置信息：作者 */ private String author; /** * 配置信息：博客地址 */ private String blogAddress; public MinBoxConfig(String author, String blogAddress) { this.author = author; this.blogAddress = blogAddress; } public String getAuthor() { return author; } public String getBlogAddress() { return blogAddress; }} 在之前的版本我们都是使用@Configuration、@ConfigurationProperties这两个注解来进行配置映射，从SpringBoot2.2.1.RELEASE版本开始我们不再需要添加@Configuration，只要通过@ConfigurationPropertiesScan结合@ConfigurationProperties搭配使用即可，会自动扫描指定package下的属性配置类进行绑定。 在属性配置类上添加@ConstructorBinding注解，即可实现构造函数的方式进行对应字段设置值，我们只需要把绑定赋值的参数通过构造函数的方式定义。 在上面代码中MinBoxConfig配置类构造函数内有两个参数：author、blogAddress，所以在实例化MinBoxConfig对象时，只会从application.yml对应获取到这两个配置内容进行赋值。 运行测试使用IDEA创建项目时会自动在src/test/java/{packages}创建@SpringBootTest注解的测试类，我们通过测试类来验证配置是否已经赋值给了配置类，如下所示： 12345678910111213@SpringBootTestclass SpringbootConstructorBindingPropertiesApplicationTests { @Autowired private MinBoxConfig minBoxConfig; @Test void printConfig() { System.out.println(&quot;作者名称：&quot; + minBoxConfig.getAuthor()); System.out.println(&quot;作者博客地址：&quot; + minBoxConfig.getBlogAddress()); }} 运行printConfig()方法后输出内容如下所示： 12作者名称：恒宇少年 - 于起宇作者博客地址：https://blog.minbox.org 敲黑板，划重点@ConfigurationProperties这个注解可以让我们的配置文件的内容直接映射到Java配置类，而且通过扫描的方式自动注册到IOC，极大地方便了我们在项目中使用配置内容。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为springboot-constructor-binding-properties： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/springboot-constructor-binding-properties.html"},{"title":"自定义你的业务Starter","text":"在我们学习SpringBoot时都已经了解到starter是SpringBoot的核心组成部分，SpringBoot为我们提供了尽可能完善的封装，提供了一系列的自动化配置的starter插件，我们在使用spring-boot-starter-web时只需要在pom.xml配置文件内添加依赖就可以了，我们之前传统方式则是需要添加很多相关SpringMVC配置文件。而spring-boot-starter-web为我们提供了几乎所有的默认配置，很好的降低了使用框架时的复杂度。 因此在使用xx.starter时你就不用考虑该怎么配置，即便是有一些必要的配置在application.properties配置文件内对应配置就可以了，那好，为什么我在application.properties配置对应属性后xx.starter就可以获取到并作出处理呢？下面我们带着这个疑问来编写我们自定义的starter让我们深入了解SpringBoot 本章目标自定义starter并且通过spring-boot-autoconfigure完成自动化配置。 构建项目创建starter项目我们并不需要创建SpringBoot项目，我们创建一个Maven项目就可以满足我们的需求，创建项目完成后pom.xml配置信息如下所示： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yuqiyu&lt;/groupId&gt; &lt;artifactId&gt;chapter28&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 我们这个starter并不做其他复杂逻辑的编写，所以这里的依赖只是添加了spring-boot-autoconfigure，实战开发时可以添加任意依赖到项目中。 配置映射参数实体我们在文章开头埋下了一个疑问，starter是如何读取application.properties或者application.yml配置文件内需要的配置参数的呢？那么接下来我们就看看如何可以获取自定义的配置信息。SpringBoot在处理这种事情上早就已经考虑到了，所以提供了一个注解@ConfigurationProperties，该注解可以完成将application.properties配置文件内的有规则的配置参数映射到实体内的field内，不过需要提供setter方法，自定义配置参数实体代码如下所示： 123456789101112131415161718192021222324252627282930313233package com.yuqiyu.chapter28;import org.springframework.boot.context.properties.ConfigurationProperties;/** * 配置文件实体映射 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/22 * Time：22:51 * 码云：http://git.oschina.net/jnyqy * ======================== */@ConfigurationProperties(prefix = &quot;hello&quot;)public class HelloProperties{ //消息内容 private String msg = &quot;HengYu&quot;; //是否显示消息内容 private boolean show = true; public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public boolean isShow() { return show; } public void setShow(boolean show) { this.show = show; }} 在上面代码中，@ConfigurationProperties注解内我们使用到了属性preffix，该属性配置了读取参数的前缀，根据上面的实体属性对应配置文件内的配置则是hello.msg、hello.show，当然我们提供了默认值，配置文件内不进行配置时则是使用默认值。 编写自定义业务我们为自定义starter提供一个Service，并且提供一个名为sayHello的方法用于返回我们配置的msg内容。代码如下所示： 1234567891011121314151617181920212223242526272829303132package com.yuqiyu.chapter28;/** * 自定义业务实现 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/22 * Time：22:54 * 码云：http://git.oschina.net/jnyqy * ======================== */public class HelloService{ //消息内容 private String msg; //是否显示消息内容 private boolean show = true; public String sayHello() { return show ? &quot;Hello，&quot; + msg : &quot;Hidden&quot;; } public void setMsg(String msg) { this.msg = msg; } public void setShow(boolean show) { this.show = show; }} 我们Service内的代码比较简单，根据属性参数进行返回格式化后的字符串。 接下来我们开始编写自动配置，这一块是starter的核心部分，配置该部分后在启动项目时才会自动加载配置，当然其中有很多细节性质的配置 实现自动化配置自动化配置其实只是提供实体bean的验证以及初始化，我们先来看看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.yuqiyu.chapter28;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 自定义starter自动化配置 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/22 * Time：22:56 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configuration//开启配置@EnableConfigurationProperties(HelloProperties.class)//开启使用映射实体对象@ConditionalOnClass(HelloService.class)//存在HelloService时初始化该配置类@ConditionalOnProperty//存在对应配置信息时初始化该配置类 ( prefix = &quot;hello&quot;,//存在配置前缀hello value = &quot;enabled&quot;,//开启 matchIfMissing = true//缺失检查 )public class HelloAutoConfiguration{ //application.properties配置文件映射前缀实体对象 @Autowired private HelloProperties helloProperties; /** * 根据条件判断不存在HelloService时初始化新bean到SpringIoc * @return */ @Bean//创建HelloService实体bean @ConditionalOnMissingBean(HelloService.class)//缺失HelloService实体bean时，初始化HelloService并添加到SpringIoc public HelloService helloService() { System.out.println(&quot;&gt;&gt;&gt;The HelloService Not Found，Execute Create New Bean.&quot;); HelloService helloService = new HelloService(); helloService.setMsg(helloProperties.getMsg());//设置消息内容 helloService.setShow(helloProperties.isShow());//设置是否显示 return helloService; }} 自动化配置代码中有很多我们之前没有用到的注解配置，我们从上开始讲解 @Configuration：这个配置就不用多做解释了，我们一直在使用@EnableConfigurationProperties：这是一个开启使用配置参数的注解，value值就是我们配置实体参数映射的ClassType，将配置实体作为配置来源。 SpringBoot内置条件注解有关@ConditionalOnXxx相关的注解这里要系统的说下，因为这个是我们配置的关键，根据名称我们可以理解为具有Xxx条件，当然它实际的意义也是如此，条件注解是一个系列，下面我们详细做出解释 @ConditionalOnBean：当SpringIoc容器内存在指定Bean的条件@ConditionalOnClass：当SpringIoc容器内存在指定Class的条件@ConditionalOnExpression：基于SpEL表达式作为判断条件@ConditionalOnJava：基于JVM版本作为判断条件@ConditionalOnJndi：在JNDI存在时查找指定的位置@ConditionalOnMissingBean：当SpringIoc容器内不存在指定Bean的条件@ConditionalOnMissingClass：当SpringIoc容器内不存在指定Class的条件@ConditionalOnNotWebApplication：当前项目不是Web项目的条件@ConditionalOnProperty：指定的属性是否有指定的值@ConditionalOnResource：类路径是否有指定的值@ConditionalOnSingleCandidate：当指定Bean在SpringIoc容器内只有一个，或者虽然有多个但是指定首选的Bean@ConditionalOnWebApplication：当前项目是Web项目的条件 以上注解都是元注解@Conditional演变而来的，根据不用的条件对应创建以上的具体条件注解。 到目前为止我们还没有完成自动化配置starter，我们需要了解SpringBoot运作原理后才可以完成后续编码。 Starter自动化运作原理在注解@SpringBootApplication上存在一个开启自动化配置的注解@EnableAutoConfiguration来完成自动化配置，注解源码如下所示： 12345678910111213141516171819202122232425262728//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.boot.autoconfigure;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.context.annotation.Import;@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import({EnableAutoConfigurationImportSelector.class})public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default {}; String[] excludeName() default {};} 在@EnableAutoConfiguration注解内使用到了@import注解来完成导入配置的功能，而EnableAutoConfigurationImportSelector内部则是使用了SpringFactoriesLoader.loadFactoryNames方法进行扫描具有META-INF/spring.factories文件的jar包。我们可以先来看下spring-boot-autoconfigure包内的spring.factories文件内容，如下所示： 12345678910111213141516171819202122# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnClassCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\.....省略 可以看到配置的结构形式是Key=&gt;Value形式，多个Value时使用,隔开，那我们在自定义starter内也可以使用这种形式来完成，我们的目的是为了完成自动化配置，所以我们这里Key则是需要使用org.springframework.boot.autoconfigure.EnableAutoConfiguration 自定义spring.factories我们在src/main/resource目录下创建META-INF目录，并在目录内添加文件spring.factories，具体内容如下所示： 12#配置自定义Starter的自动化配置org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.yuqiyu.chapter28.HelloAutoConfiguration 都目前为止我们的自定义starter已经配置完成，下面我们需要新建一个SpringBoot项目来测试我们的自动化配置是否已经生效。 创建测试SpringBoot项目在使用自定义starter之前需要将starter作Maven Jar Install到本地，我们使用idea工具自带的maven命令完成该操作 步骤：工具右侧 -&gt; Maven Projects -&gt; Lifecycle -&gt; install 创建测试项目的pom.xml配置文件内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yuqiyu.sample&lt;/groupId&gt; &lt;artifactId&gt;test-spring-boot-starter-hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;test-spring-boot-starter-hello&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--自定义starter依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.yuqiyu&lt;/groupId&gt; &lt;artifactId&gt;chapter28&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 我们只需要将依赖添加到pom.xml配置文件内 运行测试在运行项目之前，我们打开application.properties配置文件开启debug模式，查看自动化配置的输出日志，配置内容如下所示： 12#显示debug日志信息debug=true 接下来我们启动项目，在控制台查找是否存在我们的HelloAutoConfiguration日志输出，控制台输出内容如下所示： 12345678910.....省略&gt;&gt;&gt;The HelloService Not Found，Execute Create New Bean......省略 HelloAutoConfiguration matched: - @ConditionalOnClass found required class 'com.yuqiyu.chapter28.HelloService'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnProperty (hello.enabled) matched (OnPropertyCondition) HelloAutoConfiguration#helloService matched: - @ConditionalOnMissingBean (types: com.yuqiyu.chapter28.HelloService; SearchStrategy: all) did not find any beans (OnBeanCondition).....省略 在控制台可以看到我们的自定义starter的自动化配置已经生效了，并且根据@ConditionalOnMissingBean(HelloService.class)做出了条件注入HelloService实体bean到SpringIoc容器内 编写测试控制器我们来编写一个简单的测试控制器，查看HelloService在不配置参数情况下输出格式化字符串内容，控制器代码如下所示： 12345678910111213141516171819202122232425262728293031323334package com.yuqiyu.sample.testspringbootstarterhello;import com.yuqiyu.chapter28.HelloService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 测试自定义starter自动化配置HelloService * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/7/23 * Time：11:42 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestControllerpublic class HelloController{ //注入自定义starter内逻辑 @Autowired HelloService helloService; /** * 测试访问地址/hello * @return 格式化字符串 */ @RequestMapping(value = &quot;/hello&quot;) public String sayHello() { return helloService.sayHello(); }} 接下来我们重启下项目，访问地址http://127.0.0.1:8080/hello，界面输出内容如下所示： 1Hello，HengYu 界面输出的内容是我们默认值，接下来我们在application.properties配置文件内对应添加hello.msg、hello.show配置参数，如下所示： 123#配置自定义starter参数hello.msg=HengYu Boyhello.show=true 重启项目，再次访问地址，界面输出内容如下所示： 1Hello，HengYu Boy 我们的配置生效了，到目前为止我相信大家已经明白了我们application.properties配置文件为什么可以作为统一配置入口，为什么配置后可以被对应starter所使用。 #总结以上内容是本章的全部讲解，本章主要讲解了我们如何自定义starter并且自动化配置到SpringBoot项目中，当然里面还有很多神奇的地方需要大家去深入挖掘。","link":"/springboot-create-starter.html"},{"title":"使用ControllerAdvice完成异常统一处理","text":"在我们平时的项目研发过程中，异常一般都是程序员最为头疼的问题，异常的抛出、捕获、处理等既涉及事务回滚，还会涉及返回前端消息提醒信息。那么我们怎么设计可以解决上面的两个的痛点呢？我们可不可以统一处理业务逻辑然后给出前端对应的异常提醒内容呢？ 本章目标基于SpringBoot平台构建业务逻辑异常统一处理，异常消息内容格式化。 构建项目我们将逻辑异常核心处理部分提取出来作为单独的jar供其他模块引用，创建项目在parent项目pom.xml添加公共使用的依赖，配置内容如下所示： 12345678910111213141516171819&lt;dependencies&gt; &lt;!--Lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--测试模块依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建完成后除了.idea、iml、pom.xml保留，其他的都删除。 异常处理核心子模块我们创建一个名为springboot-core-exception的子模块，在该模块内自定义一个LogicException运行时异常类，继承RuntimeException并重写构造函数，代码如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 自定义业务逻辑异常类 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午2:38 * 码云：http://git.oschina.net/jnyqy * ======================== * * @author yuqiyu */public class LogicException extends RuntimeException { /** * 日志对象 */ private Logger logger = LoggerFactory.getLogger(LogicException.class); /** * 错误消息内容 */ protected String errMsg; /** * 错误码 */ protected String errCode; /** * 格式化错误码时所需参数列表 */ protected String[] params; /** * 获取错误消息内容 * 根据errCode从redis内获取未被格式化的错误消息内容 * 并通过String.format()方法格式化错误消息以及参数 * * @return */ public String getErrMsg() { return errMsg; } /** * 获取错误码 * * @return */ public String getErrCode() { return errCode; } /** * 获取异常参数列表 * * @return */ public String[] getParams() { return params; } /** * 构造函数设置错误码以及错误参数列表 * * @param errCode 错误码 * @param params 错误参数列表 */ public LogicException(String errCode, String... params) { this.errCode = errCode; this.params = params; //获取格式化后的异常消息内容 this.errMsg = ErrorMessageTools.getErrorMessage(errCode, params); //错误信息 logger.error(&quot;系统遇到如下异常，异常码：{}&gt;&gt;&gt;异常信息：{}&quot;, errCode, errMsg); }} 在重写的构造函数内需要传递两个参数errCode、params，其目的是为了初始化类内的全局变量。 errCode：该字段是对应的异常码，我们在后续文章内容中创建一个存放异常错误码的枚举，而errCode就是枚举对应的字符串的值。 params：这里是对应errCode字符串含义描述时所需要的参数列表。 errMsg：格式化后的业务逻辑异常消息描述，我们在构造函数内可以看到调用了ErrorMessageTools.getErrorMessage(errCode,params);，这个方法作用是通过异常码在数据库内获取未格式化的异常描述，通过传递的参数进行格式化异常消息描述。 创建异常核心包的目的就是让其他模块直接添加依赖，那异常描述内容该怎么获取呢？ 定义异常消息获取接口我们在springboot-exception-core模块内添加一个接口LogicExceptionMessage，该接口提供通过异常码获取未格式化的异常消息描述内容方法，接口定义如下所示： 1234567891011121314151617181920212223/** * 逻辑异常接口定义 * 使用项目需要实现该接口方法并提供方法实现 * errCode对应逻辑异常码 * getMessage返回字符串为逻辑异常消息内容 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午2:41 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */public interface LogicExceptionMessage { /** * 获取异常消息内容 * @param errCode 错误码 * @return */ public String getMessage(String errCode);} 在需要加载springboot-exception-core依赖的项目中，创建实体类实现LogicExceptionMessage接口并重写getMessage(String errCode)方法我们就可以通过spring IOC获取实现类实例进行操作获取数据，下面我们在编写使用异常模块时会涉及到。 格式化异常消息工具类下面我们再回头看看构造函数格式化异常消息工具类ErrorMessageTools，该工具类内提供getErrorMessage方法用于获取格式化后的异常消息描述，代码实现如下所示： 12345678910111213141516171819202122232425262728293031323334353637/** * 异常消息描述格式化工具类 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午2:40 * 码云：http://git.oschina.net/jnyqy * ======================== * * @author yuqiyu */public class ErrorMessageTools { /** * 异常消息获取 * * @param errCode 异常消息码 * @param params 格式化异常参数所需参数列表 * @return */ public static String getErrorMessage(String errCode, Object... params) { //获取业务逻辑消息实现 LogicExceptionMessage logicExceptionMessage = SpringBeanTools.getBean(LogicExceptionMessage.class); if (ObjectUtils.isEmpty(logicExceptionMessage)) { try { throw new Exception(&quot;请配置实现LogicExceptionMessage接口并设置实现类被SpringIoc所管理。&quot;); } catch (Exception e) { e.printStackTrace(); } } //获取错误消息内容 String errMsg = logicExceptionMessage.getMessage(errCode); //格式化错误消息内容 return ObjectUtils.isEmpty(params) ? errMsg : String.format(errMsg, params); }} 注意：由于我们的工具类都是静态方法调用方式，所以无法直接使用Spring IOC注解注入的方式获取LogicExceptionMessage实例。 由于无法注入实例，在getErrorMessage方法内，我们通过工具类SpringBeanTools来获取ApplicationContext上下文实例，再通过上下文来获取指定类型的Bean；获取到LogicExceptionMessage实例后调用getMessage方法，根据传入的errCode就可以直接从接口实现类实例中获取到未格式化的异常描述！ 当然实现类可以是以Redis、Map集合、数据库、文本作为数据来源。 获取到未格式化的异常描述后通过String.format方法以及传递的参数直接就可以获取格式化后的字符串，如： 123未格式化异常消息 =&gt; 用户：%s已被冻结，无法操作.格式化代码 =&gt; String.format(&quot;%s已被冻结，无法操作.&quot;,&quot;恒宇少年&quot;);格式化后效果 =&gt; 用户：恒宇少年已被冻结，无法操作. 具体的格式化特殊字符含义可以去查看String.format文档，如何获取ApplicationContext上下文对象，请访问第三十二章：如何获取SpringBoot项目的applicationContext对象查看。 我们再回到LogicException构造函数内，这时errMsg字段对应的值就会是格式化后的异常消息描述，在外部我们调用getErrMsg方法就可以直接得到异常描述。 到目前为止，我们已经将springboot-exception-core模块代码编码完成，下面我们来看下怎么来使用我们自定义的业务逻辑异常并且获取格式化后的异常消息描述。 异常示例模块基于parent我们来创建一个名为springboot-exception-example的子模块项目，项目内需要添加一些额外的配置依赖，当然也需要将我们的springboot-exception-core依赖添加进入，pom.xml配置文件内容如下所示： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;!--异常核心依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.hengyu&lt;/groupId&gt; &lt;artifactId&gt;springboot-exception-core&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring data jpa依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!--druid依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 下面我们来配置下我们示例项目application.yml文件需要的配置，如下所示： 1234567891011121314151617spring: application: name: springboot-exception-core #数据源配置 datasource: druid: url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver jpa: properties: hibernate: #配置显示sql show_sql: true #配置格式化sql format_sql: true 在上面我们有讲到LogicExceptionMessage获取的内容可以从很多种数据源中读取，我们还是采用数据库来进行读取，建议正式环境放到redis缓存内！！！ 异常信息表接下来在数据库内创建异常信息表sys_exception_info，语句如下： 1234567891011121314151617181920DROP TABLE IF EXISTS `sys_exception_info`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `sys_exception_info` ( `EI_ID` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键自增', `EI_CODE` varchar(30) DEFAULT NULL COMMENT '异常码', `EI_MESSAGE` varchar(50) DEFAULT NULL COMMENT '异常消息内容', PRIMARY KEY (`EI_ID`)) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT='系统异常基本信息';/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `sys_exception_info`--LOCK TABLES `sys_exception_info` WRITE;/*!40000 ALTER TABLE `sys_exception_info` DISABLE KEYS */;INSERT INTO `sys_exception_info` VALUES (1,'USER_NOT_FOUND','用户不存在.'),(2,'USER_STATUS_FAILD','用户状态异常.');/*!40000 ALTER TABLE `sys_exception_info` ENABLE KEYS */;UNLOCK TABLES; 我们通过spring-data-jpa来实现数据读取，下面对应数据表创建对应的Entity。 异常信息实体123456789101112131415161718192021222324252627282930313233/** * 系统异常基本信息实体 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午3:35 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */@Data@Entity@Table(name = &quot;sys_exception_info&quot;)public class ExceptionInfoEntity implements Serializable{ /** * 异常消息编号 */ @Id @GeneratedValue @Column(name = &quot;EI_ID&quot;) private Integer id; /** * 异常消息错误码 */ @Column(name = &quot;EI_CODE&quot;) private String code; /** * 异常消息内容 */ @Column(name = &quot;EI_MESSAGE&quot;) private String message;} 异常信息数据接口123456789101112131415161718192021/** * 异常数据接口定义 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午3:34 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */public interface ExceptionRepository extends JpaRepository&lt;ExceptionInfoEntity,Integer&gt;{ /** * 根据异常码获取异常配置信息 * @param code 异常码 * @return */ ExceptionInfoEntity findTopByCode(String code);} 在数据接口内通过spring-data-jpa方法查询方式，通过errCode读取异常信息实体内容。 在开发过程中异常跑出时所用到的errCode一般存放在枚举类型或者常量接口内，在这里我们选择可扩展相对来说比较强的枚举类型，代码如下： 12345678910111213141516171819202122/** * 错误码枚举类型 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午3:25 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */public enum ErrorCodeEnum { /** * 用户不存在. */ USER_NOT_FOUND, /** * 用户状态异常. */ USER_STATUS_FAILD, //...添加其他错误码} 异常码枚举内容项是需要根据数据库异常信息表对应变动的，能够保证我们在抛出异常时，在数据库内有对应的信息。 LogicExceptionMessage实现类定义我们在springboot-exception-core核心模块内添加了LogicExceptionMessage接口定义，需要我们实现该接口的getMessage方法核心模块，这样才可以获取数据库内对应的异常信息，实现类如下所示： 123456789101112131415161718192021222324252627282930313233343536/** * 业务逻辑异常消息获取实现类 * - 消息可以从数据库内获取 * - 消息可从Redis内获取 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午3:16 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */@Componentpublic class LogicExceptionMessageSupport implements LogicExceptionMessage { /** * 异常数据接口 */ @Autowired private ExceptionRepository exceptionRepository; /** * 根据错误码获取错误信息 * @param errCode 错误码 * @return */ @Override public String getMessage(String errCode) { ExceptionInfoEntity exceptionInfoEntity = exceptionRepository.findTopByCode(errCode); if(!ObjectUtils.isEmpty(exceptionInfoEntity)) { return exceptionInfoEntity.getMessage(); } return &quot;系统异常&quot;; }} 在getMessage方法内通过ExceptionRepository数据接口定义的findTopByCode方法获取指定异常吗的异常信息，当存在异常信息时返回未格式化的异常描述。 统一返回实体定义对于接口项目（包括前后分离项目）在处理返回统一格式时，我们通常会采用固定实体的方式，这样对于前端调用接口的开发者来说解析内容是比较方便的，同样在开发过程中会约定遇到系统异常、业务逻辑异常时返回的格式内容，当然这跟请求接口正确返回的格式是一样的，只不过字段内容有差异。统一返回实体ApiResponseEntity&lt;T extends Object&gt;如下： 1234567891011121314151617181920212223/** * 接口响应实体 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/9 * Time：下午3:04 * 码云：http://git.oschina.net/jnyqy * ======================== * @author yuqiyu */@Data@Builderpublic class ApiResponseEntity&lt;T extends Object&gt; { /** * 错误消息 */ private String errorMsg; /** * 数据内容 */ private T data;} 在ApiResponseEntity实体内，采用了Lombok的构造者设计模式@Builder注解，配置该注解的实体会自动在.class文件内添加内部类实现设计模式，部分自动生成代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// ...public static class ApiResponseEntityBuilder&lt;T&gt; { private String errorMsg; private T data; ApiResponseEntityBuilder() { } public ApiResponseEntity.ApiResponseEntityBuilder&lt;T&gt; errorMsg(String errorMsg) { this.errorMsg = errorMsg; return this; } public ApiResponseEntity.ApiResponseEntityBuilder&lt;T&gt; data(T data) { this.data = data; return this; } public ApiResponseEntity&lt;T&gt; build() { return new ApiResponseEntity(this.errorMsg, this.data); } public String toString() { return &quot;ApiResponseEntity.ApiResponseEntityBuilder(errorMsg=&quot; + this.errorMsg + &quot;, data=&quot; + this.data + &quot;)&quot;; } }// ...``` 到目前为止，我们并未添加全局异常相关的配置，而全局异常配置这块，我们采用之前章节讲到的`@ControllerAdvice`来实现，`@ControllerAdvice`相关的内容请访问[第二十一章：SpringBoot项目中的全局异常处理](https://www.jianshu.com/p/1c6207d8ee9d)。#### 全局异常通知定义我们本章节仅仅添加业务逻辑异常的处理，具体编码如下所示：```java/** * 控制器异常通知类 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午5:30 * 码云：http://git.oschina.net/jnyqy * ======================== * * @author yuqiyu */@ControllerAdvice(annotations = RestController.class)@ResponseBodypublic class ExceptionAdvice { /** * logback new instance */ Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 处理业务逻辑异常 * * @param e 业务逻辑异常对象实例 * @return 逻辑异常消息内容 */ @ExceptionHandler(LogicException.class) @ResponseStatus(code = HttpStatus.OK) public ApiResponseEntity&lt;String&gt; logicException(LogicException e) { logger.error(&quot;遇到业务逻辑异常：【{}】&quot;, e.getErrCode()); // 返回响应实体内容 return ApiResponseEntity.&lt;String&gt;builder().errorMsg(e.getErrMsg()).build(); }} 最近技术群内有同学问我，既然我们用的是@RestController为什么这里还需要配置@ResponseBody？这里给大家一个解释，我们控制器通知确实是监听的@RestController，而@RestController注解的控制器统一都是返回JSON格式的数据。那么我们在遇到异常后，请求已经不再控制器内了，已经交付给控制器通知类，那么我们通知类如果同样想返回JSON数据，这里就需要配置@ResponseBody注解来实现。 我们来看上面logicException()方法，该方法返回值是我们定义的统一返回实体，目的是为了遇到业务逻辑异常时同样返回与正确请求一样的格式。 @ ExceptionHandler 配置了将要处理LogicException类型的异常，也就是只要系统遇到LogicException异常并且抛给了控制器，就会调用该方法。 @ResponseStatus配置了返回的状态值，因为我们遇到业务逻辑异常前端肯定需要的不是500错误，而是一个200状态的JSON业务异常描述。 在方法返回时使用构造者设计模式并将异常消息传递给errorMsg()方法，这样就实现了字段errorMsg的赋值。 测试异常相关的编码完成，下面我们来创建一个测试的控制器模拟业务逻辑发生时，系统是怎么做出的返回？测试控制内容如下所示： 12345678910111213141516171819202122232425262728293031/** * 测试控制器 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2018/1/7 * Time：下午3:12 * 码云：http://git.oschina.net/jnyqy * ======================== * * @author yuqiyu */@RestControllerpublic class IndexController { /** * 首页方法 * * @return */ @RequestMapping(value = &quot;/index&quot;) public ApiResponseEntity&lt;String&gt; index() throws LogicException { /** * 模拟用户不存在 * 抛出业务逻辑异常 */ if (true) { throw new LogicException(ErrorCodeEnum.USER_STATUS_FAILD.toString()); } return ApiResponseEntity.&lt;String&gt;builder().data(&quot;this is index mapping&quot;).build(); }} 根据上面代码含义，当我们在访问/index时就会发生USER_STATUS_FAILD业务逻辑异常，按照我们之前的全局异常配置以及统一返回实体实例化，访问后会出现ApiResponseEntity格式JSON数据，下面我们运行项目访问查看效果。界面输出内容如下所示： 1234{ &quot;errorMsg&quot;: &quot;用户状态异常.&quot;, &quot;data&quot;: null} 而在控制台由于我们编写了日志信息，也同样有对应的输出，如下所示： 1234567891011Hibernate: select exceptioni0_.ei_id as ei_id1_0_, exceptioni0_.ei_code as ei_code2_0_, exceptioni0_.ei_message as ei_messa3_0_ from sys_exception_info exceptioni0_ where exceptioni0_.ei_code=? limit ?2018-01-09 18:54:00.647 ERROR 2024 --- [nio-8080-exec-1] c.h.s.exception.core.LogicException : 系统遇到如下异常，异常码：USER_STATUS_FAILD&gt;&gt;&gt;异常信息：用户状态异常.2018-01-09 18:54:00.649 ERROR 2024 --- [nio-8080-exec-1] c.h.s.e.c.advice.ExceptionAdvice : 遇到业务逻辑异常：【USER_STATUS_FAILD】 如果业务逻辑异常在Service层时，我们根本不需要去操心事务回滚的问题，因为LogicException本身就是运行时异常，而项目中抛出运行时异常时事务就会自动回滚。 我们把业务逻辑异常屏蔽掉，把true改成false查看正确时返回的格式，如下所示： 1234{ &quot;errorMsg&quot;: null, &quot;data&quot;: &quot;this is index mapping&quot;} 如果想把对应的null改成空字符串，请访问查看第五章：配置使用FastJson返回Json视图。 总结本章将之前章节的部分内容进行了整合，主要是全局异常、统一格式返回等；这种方式是目前我们公司产品中正在使用的方式，已经可以满足平时的业务逻辑异常定义以及返回，将异常消息存放到数据库中我们可以随时更新提示内容，这一点还是比较易用的。","link":"/springboot-exception-handler-advice.html"},{"title":"SpringBoot详细打印启动时异常堆栈信息","text":"SpringBoot在项目启动时如果遇到异常并不能友好的打印出具体的堆栈错误信息，我们只能查看到简单的错误消息，以致于并不能及时解决发生的问题，针对这个问题SpringBoot提供了故障分析仪的概念（failure-analyzer），内部根据不同类型的异常提供了一些实现，我们如果想自定义该怎么去做？ FailureAnalyzerSpringBoot提供了启动异常分析接口FailureAnalyzer，该接口位于org.springframework.boot.diagnosticspackage内。内部仅提供一个分析的方法，源码如下所示： 123456789101112@FunctionalInterfacepublic interface FailureAnalyzer { /** * Returns an analysis of the given {@code failure}, or {@code null} if no analysis * was possible. * @param failure the failure * @return the analysis or {@code null} */ FailureAnalysis analyze(Throwable failure);} 该接口会把遇到的异常对象实例Throwable failure交付给实现类，实现类进行自定义处理。 AbstractFailureAnalyzerAbstractFailureAnalyzer是FailureAnalyzer的基础实现抽象类，实现了FailureAnalyzer定义的analyze(Throwable failure)方法，并提供了一个指定异常类型的抽象方法analyze(Throwable rootFailure, T cause)，源码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class AbstractFailureAnalyzer&lt;T extends Throwable&gt; implements FailureAnalyzer { @Override public FailureAnalysis analyze(Throwable failure) { T cause = findCause(failure, getCauseType()); if (cause != null) { return analyze(failure, cause); } return null; } /** * Returns an analysis of the given {@code rootFailure}, or {@code null} if no * analysis was possible. * @param rootFailure the root failure passed to the analyzer * @param cause the actual found cause * @return the analysis or {@code null} */ protected abstract FailureAnalysis analyze(Throwable rootFailure, T cause); /** * Return the cause type being handled by the analyzer. By default the class generic * is used. * @return the cause type */ @SuppressWarnings(&quot;unchecked&quot;) protected Class&lt;? extends T&gt; getCauseType() { return (Class&lt;? extends T&gt;) ResolvableType.forClass(AbstractFailureAnalyzer.class, getClass()).resolveGeneric(); } @SuppressWarnings(&quot;unchecked&quot;) protected final &lt;E extends Throwable&gt; E findCause(Throwable failure, Class&lt;E&gt; type) { while (failure != null) { if (type.isInstance(failure)) { return (E) failure; } failure = failure.getCause(); } return null; }} 通过AbstractFailureAnalyzer源码我们可以看到，它在实现于FailureAnalyzer的接口方法内进行了特殊处理，根据getCauseType()方法获取当前类定义的第一个泛型类型，也就是我们需要分析的指定异常类型。 获取泛型异常类型后根据方法findCause判断Throwable是否与泛型异常类型匹配，如果匹配直接返回给SpringBoot进行注册处理。 SpringBoot提供的分析实现SpringBoot内部通过实现AbstractFailureAnalyzer抽象类定义了一系列的针对性异常类型的启动分析，如下图所示： 指定异常分析SpringBoot内部提供的启动异常分析都是指定具体的异常类型实现的，最常见的一个错误就是端口号被占用（PortInUseException），虽然SpringBoot内部提供一个这个异常的启动分析，我们也是可以进行替换这一异常分析的，我们只需要创建PortInUseException异常的AbstractFailureAnalyzer，并且实现类注册给SpringBoot即可，实现自定义如下所示： 1234567891011121314151617/** * 端口号被占用{@link PortInUseException}异常启动分析 * * @author 恒宇少年 */public class PortInUseFailureAnalyzer extends AbstractFailureAnalyzer&lt;PortInUseException&gt; { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(PortInUseFailureAnalyzer.class); @Override protected FailureAnalysis analyze(Throwable rootFailure, PortInUseException cause) { logger.error(&quot;端口被占用。&quot;, cause); return new FailureAnalysis(&quot;端口号：&quot; + cause.getPort() + &quot;被占用&quot;, &quot;PortInUseException&quot;, rootFailure); }} 注册启动异常分析在上面我们只是编写了指定异常启动分析，我们接下来需要让它生效，这个生效方式比较特殊，类似于自定义SpringBoot Starter AutoConfiguration的形式，我们需要在META-INF/spring.factories文件内进行定义，如下所示： 12org.springframework.boot.diagnostics.FailureAnalyzer=\\ org.minbox.chapter.springboot.failure.analyzer.PortInUseFailureAnalyzer 那我们为什么需要使用这种方式定义呢？ 项目启动遇到的异常顺序不能确定，很可能在Spring IOC并未执行初始化之前就出现了异常，我们不能通过@Component注解的形式使其生效，所以SpringBoot提供了通过spring.factories配置文件的方式定义。 启动异常分析继承关系自定义的运行异常一般都是继承自RuntimeException，如果我们定义一个RuntimeException的异常启动分析实例会是什么效果呢？ 1234567891011121314151617/** * 项目启动运行时异常{@link RuntimeException}统一启动分析 * * @author 恒宇少年 */public class ProjectBootUnifiedFailureAnalyzer extends AbstractFailureAnalyzer&lt;RuntimeException&gt; { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(ProjectBootUnifiedFailureAnalyzer.class); @Override protected FailureAnalysis analyze(Throwable rootFailure, RuntimeException cause) { logger.error(&quot;遇到运行时异常&quot;, cause); return new FailureAnalysis(cause.getMessage(), &quot;error&quot;, rootFailure); }} 将该类也一并注册到spring.factories文件内，如下所示： 123org.springframework.boot.diagnostics.FailureAnalyzer=\\ org.minbox.chapter.springboot.failure.analyzer.PortInUseFailureAnalyzer,\\ org.minbox.chapter.springboot.failure.analyzer.ProjectBootUnifiedFailureAnalyzer 运行项目并测试端口号被占用异常我们会发现，并没有执行ProjectBootUnifiedFailureAnalyzer内的analyze方法，而是继续执行了PortInUseFailureAnalyzer类内的方法。 那我们将PortInUseFailureAnalyzer这个启动分析从spring.factories文件内暂时删除掉，再来运行项目我们会发现这时却是会执行ProjectBootUnifiedFailureAnalyzer类内分析方法。 总结根据本章我们了解了SpringBoot提供的启动异常分析接口以及基本抽象实现类的运作原理，而且启动异常分析存在分析泛型异常类的上下级继承关系，异常子类的启动分析会覆盖掉异常父类的启动分析，如果你想包含全部异常的启动分析可以尝试使用Exception作为AbstractFailureAnalyzer的泛型参数。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为spring-boot-failure-analyzer： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/springboot-failure-analyzer.html"},{"title":"SpringBoot如何加载jar包外面的配置文件？","text":"虽然现在springboot提供了多环境的支持，但是通常修改一下配置文件，都需要重新打包。在开发springboot框架集成时，我遇到一个问题，就是如何让@PropertySource能够“扫描”和加载jar包外面的properties文件。 这样，我就可以随时随地的修改配置文件，不需要重新打包。最粗暴的方式，就是用–classpath指定这些文件。但是这引入了其他问题，“易于部署”、“与容器无关”，让人棘手。而且这个问题在测试环境、多机房部署、以及与配置中心协作时还是很难巧妙解决，因为这里面涉及到不少的硬性规范、甚至沟通成本。回到技术的本质，我希望基于spring容器，开发一个兼容性套件，能够扫描jar外部的properties文件，考虑到实施便捷性，我们约定这些properties文件总是位于jar文件的临近目录中。 设计前提1、文件目录 文件目录就类似于下面的样式。可以看到配置文件是和jar包平行的。 1234567----application.jar （springboot项目，jarLaucher） | | sample.properties | config/ | | sample.properties 2、扫描策略（涉及到覆盖优先级问题）1）我们约定默认配置文件目录为config，也就是最优先的。其余application.jar同级；相对路径起始位置为jar路径。2）首先查找./config/sample.properties文件是否存在，如果存在则加载。3）查找./sample.properties文件是否存在，如果存在则加载。4）否则，使用classpath加载此文件。 3、开发策略1）尽可能使用spring机制，即Resource加载机制，而不适用本地文件或者部署脚本干预等。2）通过研究，扩展自定义的ResourceLoader可以达成此目标，但是潜在风险很高，因为springboot、cloud框架内部，对各种Context的支持都有各自的ResourceLoader实现，如果我们再扩展自己的loader会不会导致某些未知问题？于是放弃了此策略。3）spring提供了ProtocolResolver机制，用于匹配自定义的文件schema来加载文件；而且不干扰ResourceLoader的机制，最重要的是它会添加到spring环境下的所有的loader中。我们只需要扩展一个ProtocolResolver类，并将它在合适的实际加入到ResourceLoader即可，此后加载properties文件时我们的ProtocolResolver总会被执行。 代码下面是具体的代码实现。最主要的，就是配置文件解析器的编写。注释很详细，就不多做介绍了。 1、XPathProtocolResolver.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133import org.springframework.core.io.ProtocolResolver; import org.springframework.core.io.Resource; import org.springframework.core.io.ResourceLoader; import org.springframework.util.ResourceUtils; import java.util.Collection; import java.util.LinkedHashSet; /** * 用于加载jar外部的properties文件，扩展classpath : xjjdog * -- app.jar * -- config/a.property INSIDE order=3 * -- a.property INSIDE order=4 * -- config/a.property OUTSIDE order=1 * -- a.property OUTSIDE order=2 * &lt;p&gt; * 例如： * 1、@PropertySource(&quot;::a.property&quot;) * 查找路径为：./config/a.property,./a.property,如果找不到则返回null,路径相对于app.jar * 2、@PropertySource(&quot;::x/a.property&quot;) * 查找路径为：./config/x/a.property,./x/a.property,路径相对于app.jar * 3、@PropertySource(&quot;*:a.property&quot;) * 查找路径为：./config/a.property,./a.property,CLASSPATH:/config/a.property,CLASSPATH:/a.property * 4、@PropertySource(&quot;*:x/a.property&quot;) * 查找路径为：./config/x/a.property,./x/a.property,CLASSPATH:/config/x/a.property,CLASSPATH:/x/a.property * &lt;p&gt; * 如果指定了customConfigPath，上述路径中的/config则会被替换 * * @author xjjdog **/ public class XPathProtocolResolver implements ProtocolResolver { /** * 查找OUTSIDE的配置路径，如果找不到，则返回null */ private static final String X_PATH_OUTSIDE_PREFIX = &quot;::&quot;; /** * 查找OUTSIDE 和inside，其中inside将会转换为CLASS_PATH */ private static final String X_PATH_GLOBAL_PREFIX = &quot;*:&quot;; private String customConfigPath; public XPathProtocolResolver(String configPath) { this.customConfigPath = configPath; } @Override public Resource resolve(String location, ResourceLoader resourceLoader) { if (!location.startsWith(X_PATH_OUTSIDE_PREFIX) &amp;&amp; !location.startsWith(X_PATH_GLOBAL_PREFIX)) { return null; } String real = path(location); Collection&lt;String&gt; fileLocations = searchLocationsForFile(real); for (String path : fileLocations) { Resource resource = resourceLoader.getResource(path); if (resource != null &amp;&amp; resource.exists()) { return resource; } } boolean global = location.startsWith(X_PATH_GLOBAL_PREFIX); if (!global) { return null; } Collection&lt;String&gt; classpathLocations = searchLocationsForClasspath(real); for (String path : classpathLocations) { Resource resource = resourceLoader.getResource(path); if (resource != null &amp;&amp; resource.exists()) { return resource; } } return resourceLoader.getResource(real); } private Collection&lt;String&gt; searchLocationsForFile(String location) { Collection&lt;String&gt; locations = new LinkedHashSet&lt;&gt;(); String _location = shaping(location); if (customConfigPath != null) { String prefix = ResourceUtils.FILE_URL_PREFIX + customConfigPath; if (!customConfigPath.endsWith(&quot;/&quot;)) { locations.add(prefix + &quot;/&quot; + _location); } else { locations.add(prefix + _location); } } else { locations.add(ResourceUtils.FILE_URL_PREFIX + &quot;./config/&quot; + _location); } locations.add(ResourceUtils.FILE_URL_PREFIX + &quot;./&quot; + _location); return locations; } private Collection&lt;String&gt; searchLocationsForClasspath(String location) { Collection&lt;String&gt; locations = new LinkedHashSet&lt;&gt;(); String _location = shaping(location); if (customConfigPath != null) { String prefix = ResourceUtils.CLASSPATH_URL_PREFIX + customConfigPath; if (!customConfigPath.endsWith(&quot;/&quot;)) { locations.add(prefix + &quot;/&quot; + _location); } else { locations.add(prefix + _location); } } else { locations.add(ResourceUtils.CLASSPATH_URL_PREFIX + &quot;/config/&quot; + _location); } locations.add(ResourceUtils.CLASSPATH_URL_PREFIX + &quot;/&quot; + _location); return locations; } private String shaping(String location) { if (location.startsWith(&quot;./&quot;)) { return location.substring(2); } if (location.startsWith(&quot;/&quot;)) { return location.substring(1); } return location; } /** * remove protocol * * @param location * @return */ private String path(String location) { return location.substring(2); } } 2、ResourceLoaderPostProcessor.java 1234567891011121314151617181920212223242526272829import org.springframework.context.ApplicationContextInitializer; import org.springframework.context.ConfigurableApplicationContext; import org.springframework.core.Ordered; import org.springframework.core.env.Environment; /** * @author xjjdog * 调整优化环境变量，对于boot框架会默认覆盖一些环境变量，此时我们需要在processor中执行 * 我们不再需要使用单独的yml文件来解决此问题。原则： * 1）所有设置为系统属性的，初衷为&quot;对系统管理员可见&quot;、&quot;对外部接入组件可见&quot;（比如starter或者日志组件等） * 2）对设置为lastSource，表示&quot;当用户没有通过yml&quot;配置选项时的默认值--担保策略。 **/ public class ResourceLoaderPostProcessor implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered { @Override public void initialize(ConfigurableApplicationContext applicationContext) { Environment environment = applicationContext.getEnvironment(); String configPath = environment.getProperty(&quot;CONF_PATH&quot;); if (configPath == null) { configPath = environment.getProperty(&quot;config.path&quot;); } applicationContext.addProtocolResolver(new XPathProtocolResolver(configPath)); } @Override public int getOrder() { return HIGHEST_PRECEDENCE + 100; } } 加上spring.factories，我们越来越像是在做一个starter了。没错，就是要做一个。 3、spring.factories 12org.springframework.context.ApplicationContextInitializer=\\ com.github.xjjdog.commons.spring.io.ResourceLoaderPostProcessor PropertyConfiguration.java （springboot环境下，properties加载器） 123456789101112131415161718192021@Configuration @PropertySources( { @PropertySource(&quot;*:login.properties&quot;), @PropertySource(&quot;*:ldap.properties&quot;) } ) public class PropertyConfiguration { @Bean @ConfigurationProperties(prefix = &quot;login&quot;) public LoginProperties loginProperties() { return new LoginProperties(); } @Bean @ConfigurationProperties(prefix = &quot;ldap&quot;) public LdapProperties ldapProperties() { return new LdapProperties(); } } 这样，我们的自定义加载器就完成了。我们也为SpringBoot组件，增加了新的功能。 EndSpringBoot通过设置”spring.profiles.active”可以指定不同的环境，但是需求总是多变的。比如本文的配置需求，可能就是某个公司蛋疼的约定。SpringBoot提供了多种扩展方式来支持这些自定义的操作，这也是魅力所在。没有什么，不是开发一个spring boot starter不能解决的。","link":"/springboot-how-to-load-outside-config.html"},{"title":"SpringBoot整合Flyway完成数据库持久化迭代更新","text":"每次服务的代码更新部署，难免会存在数据库结构的变更以及字典数据的添加，手动执行更新脚本是一个耗时耗力的工作，而且还会出现遗漏或者其他状况，SpringBoot内部集成了一个自动执行数据库脚本的第三方依赖Flyway来解决这个繁琐的问题。 什么是Flyway官网给出的定义是Version control for your database. Robust schema evolution across all your environments. With ease, pleasure and plain SQL.（数据库的版本控制，在所有环境中进行稳健的架构演变，轻松，愉快和简单的SQL。） Flyway 是一款开源的数据库版本管理工具，它更倾向于规约优于配置的方式。 Flyway 可以独立于应用实现管理并跟踪数据库变更，支持数据库版本自动升级，并且有一套默认的规约，不需要复杂的配置，Migrations 可以写成 SQL 脚本，也可以写在 Java 代码中，不仅支持 Command Line 和 Java API，还支持 Build 构建工具和 Spring Boot 等，同时在分布式环境下能够安全可靠地升级数据库，同时也支持失败恢复等。 Flyway运行原理当我们运行配置使用Flyway的应用程序时，会自动在配置数据源的数据库内创建一个名为flyway_schema_history的表，该表内存放了数据库的历史记录信息。然后通过扫码应用程序的/reosurces/db/migration目录下的历史版本脚本SQL文件，文件格式为：V?__desc.sql，如：V1__init-db.sql，根据版本号进行排序后，获取最大的版本号与flyway_schema_history表内执行成功的最大版本号进行比对，如果项目内版本较高，则自动执行脚本文件。 创建项目通过idea工具创建SpringBoot项目，在pom.xml添加相关依赖如下所示： 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加数据库配置在application.yml配置文件内添加数据源信息，如下所示： 1234567spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/flyway username: root password: 123456 type: com.zaxxer.hikari.HikariDataSource 添加Flyway版本脚本 脚本比较简单，大家可以任意添加一些SQL来查看结构或者数据变动。 db.migration目录是SpringBoot在整合Flyway时默认读取版本脚本的目录，我们可以在application.yml配置spring.flyway.locations参数进行修改。 测试当我们启动项目时，会自动比对脚本的版本，在db.migration目录内找到V1.1__add_logging.sql为最高版本，拿着1.1再去flyway_schema_history表内执行成功最大的版本比对，如果低于1.1则自动执行V1.1_add_logging.sql脚本内容，否则跳过。 flyway_schema_history表每次启动项目如果存在可更新的脚本信息，执行完成后会自动在flyway_schema_history表内添加一条记录。 installed_rank version description type script checksum installed_by installed_on execute_time success 1 1 init SQL V1__init.sql 2034194600 root 2019-10-23 21:44:36 17 1 2 1.1 add logging SQL V1.1_add_logging.sql 1859098444 root 2019-10-23 21:46:50 54 1 敲黑板，划重点本章简单的介绍了Flyway的基本使用方法，它很强大，功能远远不止于此，使用脚本统一自动执行可大大减少手动执行出现的遗漏、错误等。存在既有道理，为什么不尝试使用呢？ 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为springboot-integration-using-flyway： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/springboot-integration-using-flyway.html"},{"title":"SpringBoot1.x配置WebMvcConfiguration","text":"WebMvcConfigurerAdapter配置类其实是Spring内部的一种配置方式，采用JavaBean的形式来代替传统的xml配置文件形式进行针对框架个性化定制，下面我们来看一下该类内的常用方法。 本章目标继承WebMvcConfigurerAdapter采用JavaBean形式实现个性化配置定制。 构建项目本章内容同样不涉及到业务逻辑，我们创建一个web项目即可，pom.xml配置文件如下所示： 12345678910111213141516171819...//省略&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...//省略 WebMvcConfigurerAdapter实现类我们创建一个配置实体类型，并继承WebMvcConfigurerAdapter，代码如下所示： 12345678910111213141516171819202122package com.yuqiyu.chapter34;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.*;import java.util.List;/** * 自定义配置类实现JavaBean注解形式配置 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/3 * Time：21:48 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configurationpublic class WebConfiguration extends WebMvcConfigurerAdapter{} 我们在配置类上添加了注解@Configuration，标明了该类是一个配置类并且会将该类作为一个SpringBean添加到IOC容器内，我们打开该注解的源码查看如下所示： 123456789101112131415161718192021//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.context.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.stereotype.Component;@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Configuration { String value() default &quot;&quot;;} 可以看到在@Configuration 上声明式添加了Spring注入注解@Component，也就是解释了为什么我们配置了@Configuration会被自动添加到IOC容器内。 WebMvcConfigurerAdapter该抽象类其实里面没有任何的方法实现，只是空实现了接口WebMvcConfigurer内的全部方法，并没有给出任何的业务逻辑处理，这一点设计恰到好处的让我们不必去实现那些我们不用的方法，都交由WebMvcConfigurerAdapter抽象类空实现，如果我们需要针对具体的某一个方法做出逻辑处理，仅仅需要在WebMvcConfigurerAdapter子类中@Override对应方法就可以了。 配置拦截器在之前Xml配置形式天下的时候，我们都是在spring-mvc.xml配置文件内添加&lt;mvc:interceptor&gt;标签配置拦截器。拦截器的相关创建请访问第六章：如何在SpringBoot项目中使用拦截器，拦截器配置如下所示： 123456789/** * 拦截器配置 * @param registry */@Overridepublic void addInterceptors(InterceptorRegistry registry) { super.addInterceptors(registry); registry.addInterceptor(new TestInterceptor()).addPathPatterns(&quot;/**&quot;);} InterceptorRegistry 内的addInterceptor需要一个实现HandlerInterceptor接口的拦截器实例，addPathPatterns方法用于设置拦截器的过滤路径规则。 配置CORS跨域我们之前章节也有讲到，请访问第二十五章：SpringBoot添加支持CORS跨域访问，Spring既然为了集成了CROS，那就证明了一点，以后前后端分离是一个开发趋势，配置代码如下所示： 123456789101112/** * 跨域CORS配置 * @param registry */@Overridepublic void addCorsMappings(CorsRegistry registry) { super.addCorsMappings(registry); registry.addMapping(&quot;/cors/**&quot;) .allowedHeaders(&quot;*&quot;) .allowedMethods(&quot;POST&quot;,&quot;GET&quot;) .allowedOrigins(&quot;*&quot;);} 配置ViewController这一个配置在之前是经常被使用到的，最经常用到的就是”/“、”/index”路径请求时不通过@RequestMapping配置，而是直接通过配置文件映射指定请求路径到指定View页面，当然也是在请求目标页面时不需要做什么数据处理才可以这样使用，配置内容如下所示： 123456789/** * 视图控制器配置 * @param registry */@Overridepublic void addViewControllers(ViewControllerRegistry registry) { super.addViewControllers(registry); registry.addViewController(&quot;/&quot;).setViewName(&quot;/index&quot;);} 配置ViewResolver这个对我们来说很熟悉，只要我们配置html、Jsp页面视图时就会用到InternalResourceViewResolver配置类，然后设置preffix、suffix参数进行配置视图文件路径前缀与后缀。配置代码如下所示： 12345678910111213141516171819202122232425/** * 配置请求视图映射 * @return */@Beanpublic InternalResourceViewResolver resourceViewResolver(){ InternalResourceViewResolver internalResourceViewResolver = new InternalResourceViewResolver(); //请求视图文件的前缀地址 internalResourceViewResolver.setPrefix(&quot;/WEB-INF/jsp/&quot;); //请求视图文件的后缀 internalResourceViewResolver.setSuffix(&quot;.jsp&quot;); return internalResourceViewResolver;}/** * 视图配置 * @param registry */@Overridepublic void configureViewResolvers(ViewResolverRegistry registry) { super.configureViewResolvers(registry); registry.viewResolver(resourceViewResolver()); /*registry.jsp(&quot;/WEB-INF/jsp/&quot;,&quot;.jsp&quot;);*/} 上述代码中方法resourceViewResolver上配置了@Bean注解，该注解会将方法返回值加入到SpringIoc容器内。而在configureViewResolvers方法内配置视图映射为resourceViewResolver方法返回的InternalResourceViewResolver 实例，这样完成了视图的配置。在下面还有注释掉的一部分代码，这块代码很神奇，我们先来看看org.springframework.web.servlet.config.annotation.ViewResolverRegistry源码： 1234567891011121314151617package org.springframework.web.servlet.config.annotation;public class ViewResolverRegistry { ...//省略代码 public UrlBasedViewResolverRegistration jsp() { return this.jsp(&quot;/WEB-INF/&quot;, &quot;.jsp&quot;); } public UrlBasedViewResolverRegistration jsp(String prefix, String suffix) { InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(prefix); resolver.setSuffix(suffix); this.viewResolvers.add(resolver); return new UrlBasedViewResolverRegistration(resolver); }}...//省略代码 可以看到上述源码中有两个jsp方法，而没有参数的方法恰恰跟我们配置的内容一样，这一点看来是Spring早就根据用户使用习惯添加的默认配置，同样也提供了自定义配置Jsp相关的前缀、后缀内容的方法，方法内部同样是实例化了一个InternalResourceViewResolver 视图映射类，并将实例添加到了viewResolvers集合内。 配置MessageConverter这个配置一般针对于Api接口服务程序，配置在请求返回时内容采用什么转换器进行转换，我们最常用到的就是fastJson的转换，配置如下所示： 1234567891011121314151617181920212223/** * 消息内容转换配置 * 配置fastJson返回json转换 * @param converters */ @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { //调用父类的配置 super.configureMessageConverters(converters); //创建fastJson消息转换器 FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); //创建配置类 FastJsonConfig fastJsonConfig = new FastJsonConfig(); //修改配置返回内容的过滤 fastJsonConfig.setSerializerFeatures( SerializerFeature.DisableCircularReferenceDetect, SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullStringAsEmpty ); fastConverter.setFastJsonConfig(fastJsonConfig); //将fastjson添加到视图消息转换器列表内 converters.add(fastConverter); } 内容转换都是针对面向接口进行编写的实现类，都必须implements HttpMessageConverter接口完成方法的实现。 总结以上内容就是本章的全部讲解内容，本章主要讲解了采用JavaBean配置的形式代替传统的Xml配置文件的形式进行多种配置声明，根据源码我们可见到Spring在多年被使用的过程中不断的提供一些默认配置，从而达到用于预计的效果并提高了开发效率。","link":"/springboot-mvc-configuration.html"},{"title":"SpringBoot2.x内配置WebMvc","text":"初升级SpringBoot2.0版本，在已经使用SpringBoot1.x的系统内还是存在一些兼容性的问题，有很多变化！！！也存在一些过时的方法、配置文件信息以及类，我们在之前版本的SpringBoot1.x中可以使用WebMvcConfigurerAdapter抽象类来处理SpringMVC相关的配置，由于SpringBoot2.0版本最低支持 JDK1.8环境，在JDK1.8引入了特殊的关键字default，该关键字配置在interface接口的方法时子类可以不去实现该方法，相当于抽象类内已经实现的接口方法。 本章目标代替WebMvcConfigurerAdapter抽象类扩展SpringMVC相关配置。 构建项目我们本章仅仅使用了web相关的依赖，pom.xml配置文件如下所示： 123456789//......&lt;dependencies&gt; &lt;!--添加web依赖配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;//...... 新版本我们可以采用两种方式来配置WebMvcConfigurer JavaBean方式配置WebMvcConfigurer WebMvcConfigurer实现类方式 方式一：JavaBean配置WebMvcConfigurer采用JavaBean方式我们只需要添加一个web相关配置的类型，并且配置@Configuration注解，将该配置类托管给Spring IOC完成配置，代码配置如下所示： 1234567891011121314151617181920212223242526272829303132333435363738/** * web配置类 * * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/15 * Time：下午10:29 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Configurationpublic class WebJavaBeanConfiguration { /** * 日志拦截器 */ @Autowired private LogInterceptor logInterceptor; /** * 实例化WebMvcConfigurer接口 * * @return */ @Bean public WebMvcConfigurer webMvcConfigurer() { return new WebMvcConfigurer() { /** * 添加拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(logInterceptor).addPathPatterns(&quot;/**&quot;); } }; }} 我们通过@Bean注解的返回值来完成WebMvcConfigurer 的配置实例化，在WebMvcConfigurer接口实例内调用addInterceptors 方法完成添加拦截器配置，跟之前WebMvcConfigurerAdapter方式感觉没事区别，只不过是编码形式有一点变化。 测试拦截器在上面配置内添加了一个LogInterceptor拦截器，该拦截器目的很简单，仅仅是测试拦截器配置是否生效，代码也很简单，输出访问地址的URI，实现代码如下所示： 12345678910111213@Componentpublic class LogInterceptor implements HandlerInterceptor { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(LogInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { logger.info(&quot;请求路径：{}&quot;, request.getRequestURI()); return true; }} 测试控制器为了测试访问地址被拦截需要添加一个测试控制器请求地址，测试控制器代码如下所示： 123456789101112131415161718192021/** * 测试控制器 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/15 * Time：下午10:34 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@RestControllerpublic class TestController { /** * 测试拦截地址 * @return */ @RequestMapping(value = &quot;/index&quot;) public String index() { return &quot;Success&quot;; }} 运行测试配置我们来启动项目，访问地址http://127.0.0.1:8080/index，查看控制台输出内容，如下所示： 12018-03-17 16:51:26.633 INFO 2152 --- [nio-8080-exec-1] c.h.c.interceptors.LogInterceptor : 请求路径：/index 根据日志的输出我们判定JavaBean配置WebMvcConfigurer 的方式是可以生效的，回想文章开头说到的关键字deault，既然default修饰的方法可以不被子类实现，那么我们完全可以实现WebMvcConfigurer接口，来添加对应的配置，下面我们来尝试添加一个新的配置类使用实现接口的方式来添加拦截器的配置。 方式二：实现类配置WebMvcConfigurer我们创建一个名为WebConfiguration的配置类并且实现WebMvcConfigurer接口，代码如下所示： 12345678910111213141516171819202122232425262728/** * web相关配置类 * @author：于起宇 &lt;br/&gt; * =============================== * Created with IDEA. * Date：2018/3/17 * Time：下午4:45 * 简书：http://www.jianshu.com/u/092df3f77bca * ================================ */@Configurationpublic class WebConfiguration implements WebMvcConfigurer { /** * 日志拦截器 */ @Autowired private LogInterceptor logInterceptor; /** * 重写添加拦截器方法并添加配置拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(logInterceptor).addPathPatterns(&quot;/**&quot;); }} 第二种方式有点我们之前使用的感觉，只不过之前是使用的WebMvcConfigurerAdapter 抽象类，而现在我们直接使用WebMvcConfigurer接口。 正因为SpringBoot2.0是基于JDK1.8及以上版本，所以可以完全使用JDK1.8新特性提供更好的实现方式。 重启尝试再次测试我们重启项目，再次访问地址http://127.0.0.1:8080/index在控制台查看，输出内容跟方式一一样，也就表明了这种配置也是可以生效的。 总结本章介绍了SpringBoot2.0版本的WebMvcConfigurer两种的配置方式，可以根据自己的喜好在项目中进行配置，不过第二种可能更吻合项目中的开发模式。","link":"/springboot-mvc-configurer.html"},{"title":"SpringBoot2.2版本配置绑定是不是有点坑了？","text":"SpringBoot版本升级兼容性一直做的不是多么的美丽，各个大分支之间由于底层使用的Srping版本不同，才导致的这种问题出现，而升级到2.2.1.RELEASE版本之后又遇到一个配置绑定的坑。 问题描述SpringBoot在升级到2.2.1.RELEASE版本后遇到了属性配置绑定的问题，我去找到SpringBoot版本发布的页面（Spring-Boot-2.2-Release-Notes）才了解到从2.2.1.RELEASE版本开始@SpringBootApplication注解已经不再添加@ConfigurationPropertiesScan支持，需要手动进行配置，这一点我们从源码上可以更清楚的看到。 2.2.0.RELEASESpringBoot 2.2.0.RELEASE版本中@SpringBootApplication注解部分源码如下所示： 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })@ConfigurationPropertiesScanpublic @interface SpringBootApplication { //...} 通过源码我们可以看到2.2.0.RELEASE版本的@SpringBootApplication注解默认添加了ConfigurationPropertiesScan注解，也就是默认开启了扫描@ConfigurationProperties注解的配置类，然后根据prefix进行属性绑定。 2.2.1.RELEASESpringBoot 2.2.1.RELEASE版本中@SpringBootApplication注解部分源码如下所示： 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication { //...} 我们发现在SpringBoot2.2.1.RELEASE版本的@SpringBootApplication注解中已经不再默认添加@ConfigurationPropertiesScan注解的支持了，也就是我们无法通过默认的配置实现扫描@ConfigurationProperties注解的类，也无法将application.yml/application.properties文件的配置内容与实体类内的属性进行绑定。 解决问题SpringBoot官方给出的解决方法是手动在@SpringBootApplication注解的类上手动添加@ConfigurationPropertiesScan即可，如下所示： 1234567891011121314/** * 2.2.1.RELEASE版本属性绑定问题解决 * * @author 恒宇少年 */@SpringBootApplication@ConfigurationPropertiesScanpublic class SpringbootConfigurationBindingBitPittedApplication { public static void main(String[] args) { SpringApplication.run(SpringbootConfigurationBindingBitPittedApplication.class, args); }} 敲黑板，划重点SpringBoot的每次中大版本升级往往会删除或者新增一些功能，建议大家关注SpringBoot的动态，以免出现类似今天这篇文章的问题，根据官方的文档及时做出调整。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，源码分支为2.x，目录为springboot2-2-configuration-binding-bit-pitted： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/springboot2.2-configuration-binding-bit-pitted.html"},{"title":"SpringCloud Gateway整合Eureka转发服务请求","text":"在上一篇文章/springcloud-gateway-route.html中我们讲解了SpringCloud Gateway内部提供的断言、谓语，让我们可以组合更精确的业务场景进行请求，既然SpringCloud GateWay担任了网关的角色，在之前Zuul可以通过服务名进行自动转发，SpringCloud Gateway是否可以实现自动转发呢？ 初始化Gateway服务Spring Cloud Gateway可以根据配置的断言、谓语进行满足条件转发，也可以自动同步服务注册中心的服务列表进行指定serviceId前缀进行转发，这里的serviceId是业务服务的spring.application.name配置参数。 SpringCloud 版本控制依赖把SpringCloud的版本依赖添加到pom.xml内，如下所示： 123456789101112131415161718//...&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;!--Spring Cloud 版本控制--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;//... 我们本章使用Eureka作为服务注册中心来完成服务请求转发讲解，需要把Spring Cloud Gateway网关项目作为一个Client注册到Eureka Server，先来看下添加的依赖，pom.xml如下所示： 1234567891011121314//...&lt;dependencies&gt; &lt;!--Spring Cloud Gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;//.... 接下来我们需要开启Gateway服务注册中心的发现配置，开启后才能自动同步服务注册中心的服务列表，application.yml配置文件如下所示： 12345678910111213141516171819# 服务名称spring: application: name: spring-cloud-gateway # 开启 Gateway 服务注册中心服务发现 cloud: gateway: discovery: locator: enabled: true# Eureka Server 配置eureka: client: service-url: defaultZone: http://localhost:10000/eureka/# 配置Gateway日志等级，输出转发细节信息logging: level: org.springframework.cloud.gateway: debug 配置参数解释如下所示： spring.application.name：服务名 spring.cloud.gateway.discovery.locator.enabled：开启SpringCloud Gateway的注册中心发现配置，开启后可自动从服务注册中心拉取服务列表，通过各个服务的spring.application.name作为前缀进行转发，该配置默认为false。 eureka.client.service-url.defaultZone：配置Eureka Server默认的空间地址 logging.level.org.springframework.cloud.gateway：设置SpringCloud Gateway日志等级为debug，用于输出转发的细节日志，方便查看细节流程。 注册网关到Eureka在入口类添加对应的注解，开启服务自动注册，如下所示： 1234567@SpringBootApplication@EnableDiscoveryClientpublic class SpringCloudGatewayApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudGatewayApplication.class, args); }} 服务注册中心对应上面网关配置的Eureka Server的地址，我们需要添加对应的配置，pom.xml如下所示： 123456789//...&lt;dependencies&gt; &lt;!--Eureka Server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;//... 添加依赖后对Eureka Server进行配置，配置文件application.yml如下所示： 123456789101112131415# 服务名spring: application: name: sample-eureka-server# 端口号 server: port: 10000# Eureka 配置信息eureka: client: service-url: defaultZone: http://localhost:${server.port}/eureka/ fetch-registry: false register-with-eureka: false 这里我们修改默认的端口号为10000，为了匹配在网关项目的配置信息，至于fetch-registry、register-with-eureka可以去我之前的文章查看，/eureka-register-service.html 开启Eureka Server我们通过@EnableEurekaServer注解来开启服务，如下所示： 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 网关、服务注册中心我们都已经准备好了，下面我们可以编写业务逻辑服务，来验证SpringCloud Gateway具体是否可以根据serviceId进行转发请求。 单服务我们简单编写一个GET请求地址，输出字符串信息，pom.xml添加依赖如下所示： 123456789101112&lt;dependencies&gt; &lt;!--Web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka Client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置文件application.yml如下所示： 12345678910111213# 服务名spring: application: name: user-service# 注册到Eurekaeureka: client: service-url: defaultZone: http://localhost:10000/eureka/# 服务端口号server: port: 9090 配置该服务的服务名称为user-service，这里对应SpringCloud Gateway的serviceId。 注册服务到Eureka12345678910111213141516171819@SpringBootApplication@EnableDiscoveryClient@RestControllerpublic class UserServiceApplication { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(UserServiceApplication.class); public static void main(String[] args) { SpringApplication.run(UserServiceApplication.class, args); logger.info(&quot;「「「「「用户服务启动完成.」」」」」&quot;); } @GetMapping(value = &quot;/index&quot;) public String index() { return &quot;this is user index&quot;; }} user-service提供了/index的请求地址，当访问时，会对应输出this is user index。 测试服务请求转发接下来我们进行验证，测试顺序如下所示： 第一步：启动Eureka Server 第二步：启动SpringCloud Gateway 启动成功后控制台会打印响应的注册到Eureka的日志信息，如下所示： 12DiscoveryClient_SPRING-CLOUD-GATEWAY/192.168.1.56:spring-cloud-gateway: registering service...Netty started on port(s): 8080 SpringCloud Gateway内部通过Netty完成WebServer的请求转发。 第三步：启动user-service服务 启动成功后控制台打印相应注册日志，如下所示： 12DiscoveryClient_USER-SERVICE/192.168.1.56:user-service:9090: registering service...Tomcat started on port(s): 9090 (http) with context path '' 第四步：测试访问 SpringCloud Gateway会每间隔30秒进行重新拉取服务列表后路由重定义操作，日志信息如下所示： 12345678# Spring Cloud GatewayRouteDefinition CompositeDiscoveryClient_SPRING-CLOUD-GATEWAY applying {pattern=/SPRING-CLOUD-GATEWAY/**} to PathRouteDefinition CompositeDiscoveryClient_SPRING-CLOUD-GATEWAY applying filter {regexp=/SPRING-CLOUD-GATEWAY/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePathRouteDefinition matched: CompositeDiscoveryClient_SPRING-CLOUD-GATEWAY# User ServiceRouteDefinition CompositeDiscoveryClient_USER-SERVICE applying {pattern=/USER-SERVICE/**} to PathRouteDefinition CompositeDiscoveryClient_USER-SERVICE applying filter {regexp=/USER-SERVICE/(?&lt;remaining&gt;.*), replacement=/${remaining}} to RewritePathRouteDefinition matched: CompositeDiscoveryClient_USER-SERVICE 通过上面的日志信息我们已经可以推断出SpringCloud Gateway映射spring.application.name的值作为服务路径前缀，不过是大写的，预计我们可以通过http://localhost:8080/USER-SERVICE/index访问到对应的信息。 访问测试如下： 12~ curl http://localhost:8080/USER-SERVICE/indexthis is user index 通过网关访问具体服务的格式：http://网关IP:网关端口号/serviceId/** 多服务的负载均衡如果Eureka Server上有两个相同serviceId的服务时，SpringCloud Gateway会自动完成负载均衡。 复制一个user-service服务实例，修改服务端口号，如下所示： 123456789101112# 服务名称spring: application: name: user-service# Eureka Servereureka: client: service-url: defaultZone: http://localhost:10000/eureka/# 服务端口号server: port: 9091 在复制的项目内使用相同的spring.application.name保持serviceId一致，只做端口号的修改，为了区分GateWay完成了负载均衡，我们修改/index请求的返回内容如下所示： 1234@GetMapping(value = &quot;/index&quot;)public String index() { return &quot;this is user lb index&quot;;} 访问http://localhost:8080/USER-SERVICE/index，输出内容如下所示： 12345this is user lb indexthis is user indexthis is user lb indexthis is user index... 总结通过本章的讲解，我们已经对SpringCloud Gateway的转发有一个简单的理解，通过从服务注册中心拉取服务列表后，自动根据serviceId映射路径前缀，同名服务多实例时会自动实现负载均衡。","link":"/springcloud-gateway-eureka.html"},{"title":"SpringCloud Gateway路由转发规则","text":"Spring在因Netflix开源流产事件后，在不断的更换Netflix相关的组件，比如：Eureka、Zuul、Feign、Ribbon等，Zuul的替代产品就是SpringCloud Gateway，这是Spring团队研发的网关组件，可以实现限流、安全认证、支持长连接等新特性。 Spring Cloud GatewaySpring Cloud Gateway是SpringCloud的全新子项目，该项目基于Spring5.x、SpringBoot2.x技术版本进行编写，意在提供简单方便、可扩展的统一API路由管理方式。概念解释： Route（路由）：路由是网关的基本单元，由ID、URI、一组Predicate、一组Filter组成，根据Predicate进行匹配转发。 Predicate（谓语、断言）：路由转发的判断条件，目前SpringCloud Gateway支持多种方式，常见如：Path、Query、Method、Header等。 Filter（过滤器）：过滤器是路由转发请求时所经过的过滤逻辑，可用于修改请求、响应内容。 Spring Cloud GateWay 工作流程如下所示： 客户端向Spring Cloud Gateway发出请求。如果网关处理程序映射确定请求与路由匹配，则将其发送到网关Web处理程序。此处理程序运行时通过特定于请求的筛选链发送请求。过滤器被虚线分隔的原因是过滤器可以在发送代理请求之前或之后执行逻辑。执行所有“预”过滤逻辑，然后发出代理请求。在发出代理请求后，将执行“post”过滤器逻辑。 开始使用Spring Cloud Gateway目前有两种方式进行配置： application.yml配置文件方式 通过@Bean注解RouteLocator方法返回值 在本章会侧重针对配置文件方式进行讲解，当然RouteLocator方式也会简单的告诉大家的使用方式。 添加依赖添加Spring Cloud Gateway相关依赖，pom.xml如下所示： 1234567891011121314151617181920212223242526272829303132//...省略部分内容&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--Spring Cloud Gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;//...省略部分内容 Spring Cloud Gateway Predicates在我们开始本章内容之前我们要来先了解下Spring Cloud Gateway内部提供的所有谓语、断言，这样我们才能目标性的进行学习，我整理出来了一个脑图，如下所示： 每一个Predicate的使用，你可以理解为：当满足这种条件后才会被转发，如果是多个，那就是都满足的情况下被转发。 Path 方式匹配转发通过Path转发示例，我们讲解下上面的两种配置，分别是application.yml以及RouteLocator。 配置文件匹配地址转发我们在application.yml配置文件内添加对应的路由配置，如下所示： 123456789101112131415spring: application: name: spring-cloud-gateway-sample cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: # 匹配路径转发 - Path=/api-boot-datasource-switch.html# 端口号server: port: 9090 先来解释下route的组成部分： id：路由的ID uri：匹配路由的转发地址 predicates：配置该路由的断言，通过PredicateDefinition类进行接收配置。 在上面的配置中，当访问http://localhost:9090/api-boot-datasource-switch.html时就会被自动转发到https://blog.minbox.org/api-boot-datasource-switch.html，这里要注意完全匹配Path的值时才会进行路由转发。 访问效果如下所示： RouteLocator 匹配路径转发在上面的配置中，如果使用RouteLocator方式该怎么进行配置呢？ 如下所示： 1234567@Beanpublic RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(&quot;blog&quot;, r -&gt; r.path(&quot;/api-boot-datasource-switch.html&quot;).uri(&quot;https://blog.minbox.org&quot;)) .build();} Before 方式匹配转发当部署有访问时间限制的接口时，我们可以通过Before Predicate来完成某一个时间点之前允许访问，过时后则不允许转发请求到具体的服务，配置如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Before=2019-05-01T00:00:00+08:00[Asia/Shanghai] 在上面配置中，我们允许2019-05-01日凌晨之前通过路由转发到https://blog.minbox.org，通过查看org.springframework.cloud.gateway.handler.predicate.BeforeRoutePredicateFactory源码我们发现，Spring Cloud Gateway的Before断言采用的ZonedDateTime进行匹配时间，这里要注意存在时区的问题，需要配置[Asia/Shanghai]作为中国时区。 After 方式匹配转发After Predicate与Before配置使用一致，匹配某一个时间点之后允许路由转发，如下所示配置： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - After=2019-04-29T00:00:00+08:00[Asia/Shanghai] 在上面配置中允许2019-04-29凌晨之后进行转发到https://blog.minbox.org。 Between 方式匹配转发那如果是一个时间段内允许请求转发，通过Before、After组合配置也可以完成，不过Spring Cloud Gateway还是提供了Between方式，如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Between=2019-04-29T00:00:00+08:00[Asia/Shanghai], 2019-05-01T00:00:00+08:00[Asia/Shanghai] 在上面配置中，允许在2019-04-29日凌晨后 &amp; 2019-05-01凌晨之前请求转发到https://blog.minbox.org。 Cookie 方式匹配转发Spring Cloud Gateway 还提供了根据Cookie值的方式匹配转发请求，如果请求中所携带的Cookie值与配置的Predicate匹配，那么就可以被允许转发到指定地址，如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Cookie=hengboy, yuqiyu 在上面配置中，如果客户端发送请求时携带了&quot;hengboy=yuqiyu&quot;的Cookie信息，则允许请求转发。 测试Cookie方式转发： 1curl http://localhost:9090 --cookie &quot;hengboy=yuqiyu&quot; 通过上面方式我们是可以成功转发请求的，如果我们修改Cookie的值，就会导致无法转发，出现404。 Header 方式匹配转发Spring Cloud Gateway可以根据发送请求的Header信息进行匹配转发，加入我们可以根据X-Request-Id的值进行匹配，如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Header=X-Request-Id, \\d+ 在上面配置中，如果X-Request-Id的值为数字，那么就可以转发到https://blog.minbox.org，我们通过如下方式进行测试： 1curl http://localhost:9090 -H &quot;X-Request-Id:123456&quot; 如果头信息为X-Request-Id:abc时，就会转发失败，出现404。 Host 方式匹配转发Spring Cloud Gateway可以根据Host主机名进行匹配转发，如果我们的接口只允许**.yuqiyu.com域名进行访问，那么配置如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Host=**.yuqiyu.com 测试如下所示： 12341. curl http://localhost:9090 -H &quot;Host: yuqiyu.com&quot; // 匹配2. curl http://localhost:9090 -H &quot;Host: api.yuqiyu.com&quot; // 匹配3. curl http://localhost:9090 -H &quot;Host: admin.yuqiyu.com&quot; // 匹配4. curl http://localhost:9090 -H &quot;Host: hengboy.com&quot; // 不匹配 请求方式 方式匹配转发Rest请求风格的接口内往往会存在多种请求方式的接口，如果我们的接口只允许POST请求访问，那么配置如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Method=POST 发送GET请求测试： 12~ curl http://localhost:9090{&quot;timestamp&quot;:&quot;2019-04-29T06:27:41.121+0000&quot;,&quot;path&quot;:&quot;/&quot;,&quot;status&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:null} 我们的请求并未被Spring Cloud Gateway进行转发，那么我们再来通过POST请求进行测试： 1curl -X POST http://localhost:9090 是可以被转发到目标地址uri的，不过我的这个博客是OSS部署的，阿里云限制了POST访问，尽管如此我们也证明了可以转发。 请求参数 方式匹配转发Spring Cloud GateWay还支持根据指定的参数进行匹配，Query方式的Predicate也有两种方式匹配情况，如下所示： 请求中存在xxx参数 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Query=xxx 我们通过curl http://localhost:9090\\?xxx\\=123是可以被成功转发的，只要参数存在xxx就会被成功转发，否则出现404转发失败。 请求中存在xxx参数且值为zzz 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Query=xxx, zzz 根据上面配置，我们限定了参数xxx必须为zzz时才会被成功转发，否则同样会出现404抓发失败。 请求路径 方式匹配转发Spring Cloud Gateway提供了请求路径变量方式匹配转发，如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Path=/article/{articleId} 在上面配置中{articleId}是一个路径变量，可以是任意值，匹配/article/1、/article/abc等，测试如下所示： 123~ curl http://localhost:9090/article/1 // 匹配~ curl http://localhost:9090/article/abc // 匹配~ curl http://localhost:9090/article/1/1 // 不匹配 请求IP 方式匹配转发Spring Cloud Gateway可以限制允许访问接口的客户端IP地址，配置后只对指定IP地址的客户端进行请求转发，配置如下所示： 12345678spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - RemoteAddr=192.168.1.56/24 在上面我们配置了192.168.1.56/24，其中192.168.1.56是客户端的IP地址，而24则是子网掩码。 组合示例相同的Predicate也可以配置多个，请求的转发是必须满足所有的Predicate后才可以进行路由转发，组合使用示例如下所示： 12345678910111213spring: cloud: gateway: routes: - id: blog uri: https://blog.minbox.org predicates: - Query=author, hengboy - Query=yuqiyu - Method=GET - Cookie=hengboy, yuqiyu - Header=X-Request-Id, \\d+ - RemoteAddr=192.168.1.56/24 总结本章节讲解了Spring Cloud Gateway的相关谓词、断言基本使用方式，GateWay内部提供了很多种灵活的路由转发规则，在同一个路由内存在多个Predicate时，同时满足规则后请求才会被路由转发。","link":"/springcloud-gateway-route.html"},{"title":"Nacos Config 使用自定义的NameSpace &amp; Group","text":"在之前的章节中，我们并没有对SpringCloud Alibaba Nacos Config的NameSpace、Group做过修改，都是使用的默认值，默认值分别是：Public、DEFAULT_GROUP，我们本章来看下如何自定义这两项参数。 回顾通过本系列的前篇文章： /nacos-config-properties.html /nacos-config-yaml.html 在之前文章中我们学习到了SpringCloud Alibaba读取Nacos Config内定义的properties、Yaml类型的配置文件信息、配置信息实时更新、Profile环境下的配置信息读取优先级等。 开始本章本章同样需要在Nacos Console控制台添加我们需要的配置信息。 Nacos Server需要在本地安装Nacos Server才能完成本章的内容讲解，具体的安装步骤访问Nacos 官方文档 添加配置我们通过访问本地的Nacos Console控制台添加本章所需要的配置信息。 添加自定义的NameSpace不过在添加配置之前我们需要先来自定义一个namespace，如下图所示： 添加完成后在命名空间列表内有一个我们需要用到的参数命名空间ID，这个参数需要配置到我们的应用程序内，下面进行讲解。回到配置列表后在顶部我们点击测试命名空间就可以查看该NameSpace下所有的配置列表。添加本章使用的配置信息如下图所示： 在上图中我们定义的Group为hengboy，该参数也需要接下来配置在应用程序内。 创建应用第一步：创建应用程序通过Idea开发工具创建一个SpringBoot项目并添加本章使用的依赖信息，pom.xml如下所示： 123456789101112131415161718192021222324252627282930313233343536373839//...&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--spring cloud alibaba config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;!--SpringCloud--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringCloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 第二步：bootstrap.yml配置创建bootstrap.yml配置文件，添加如下配置信息： 123456789101112spring: application: name: hengboy-sca-nacos-config-namespace cloud: nacos: config: server-addr: 127.0.0.1:8848 file-extension: yaml # 自定义namespace namespace: 52cfe0c1-746c-4f82-b161-a8799af1b1e9 # 自定义分组 group: hengboy spring.cloud.nacos.config.namespace配置自定义的namespace的ID，该值可以在Nacos Console控制台命名空间列表中获得。 spring.cloud.nacos.config.group配置自定义的group，该值是在添加配置信息时输入的值，也就是hengboy。 第三步：读取配置信息我们通过一个单元测试来读取配置信息，如下所示： 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTestpublic class ConfigNameSpaceTest { /** * logger instance */ static Logger logger = LoggerFactory.getLogger(ConfigNameSpaceTest.class); /** * 配置信息 */ @Value(value = &quot;${hengboy.name:}&quot;) private String name; @Test public void getConfig() { logger.info(&quot;获取配置信息：{}&quot;, name); }} 第四步：运行测试执行ConfigNameSpaceTest#getConfig单元测试方法，查看控制台输出内容如下所示： 12019-03-05 15:55:17.388 INFO 81736 --- [ main] c.y.c.s.a.n.c.n.ConfigNameSpaceTest : 获取配置信息：yuqiyu 总结自定义配置NameSpace、Group对于SpringCloud Alibaba Nacos Config来说是比较简单的，只需要简单的配置就可以，如果你的系统模块较多，建议使用namespace、group来进行划分，这样就可以更好的管理配置信息。","link":"/springcloud-nacos-config-namespace.html"},{"title":"Nacos Config的多环境（Profile）配置信息读取","text":"本章目标读取Profile多环境下Nacos Config的配置信息，了解多环境下相同的配置优先级加载问题。 在之前文章中我们学习到了SpringCloud Alibaba读取Nacos Config内定义的properties、Yaml类型的配置文件信息，并且使用Nacos Console进行修改配置信息后可以在应用程序内实时更新。 在我之前的SpringBoot系列教程中有提到Profile（多环境）相关的概念，有兴趣的同学可以去查看/springboot-active-profiles.html文章，既然应用程序存在Profile分离的概念， Nacos Config同样为我们提供了这一概念，接下来我们来看看是如何进行Profile的配置信息切换使用、优先级替换。 快速入门我们还是先来通过Nacos Console来添加本章所使用的配置信息，要注意配置的后缀名改为yaml。 Nacos Server需要在本地安装Nacos Server才能完成本章的内容讲解，具体的安装步骤访问Nacos 官方文档 添加配置通过Nacos控制台添加本项目所使用的配置信息，之前又讲到过SpringCloud Alibaba默认使用spring.application.name作为DATA-ID，本章的spring.application.name = hengboy-spring-cloud-config-profile，所以我们添加如下两个配置信息： hengboy-spring-cloud-config-profile.yaml这个配置是不参与任何profile环境的基础配置，其定位其实跟application.yml差不多。 hengboy-spring-cloud-config-profile-dev.yaml这个配置则是profile=dev环境的配置信息，其定位跟application-dev.yml差不多。 创建应用通过idea开发工具来创建一个SpringCloud项目，并添加SpringCloud 版本依赖、SpringCloud Alibaba 版本依赖，pom.xml配置内容如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940//...&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.RELEASE&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--spring cloud alibaba config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;!--SpringCloud--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringCloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;//... 配置bootstrap.yml之前有说过，SpringCloud Alibaba所需要的配置信息，需要在引导配置bootstrap.yml文件内添加，如下所示： 123456789101112131415# application namespring: application: name: hengboy-spring-cloud-config-profile # profile profiles: active: dev # nacos config cloud: nacos: config: server-addr: 127.0.0.1:8848 # nacos配置扩展类型为yaml file-extension: yaml 我们本章用到的配置文件的格式为yaml所以需要通过spring.cloud.nacos.config.file-extension进行配置，该参数默认为properties。 读取配置我们创建一个SpringMvc Controller来读取配置信息，ConfigController如下所示： 12345678910111213141516//...@RestController@RequestMapping(value = &quot;/config&quot;)@RefreshScopepublic class ConfigController { /** * 读取data-id对应的配置信息 */ @Value(value = &quot;${hengboy.name:}&quot;) private String name; @RequestMapping(value = &quot;/get&quot;) public String getConfig() { return this.name; }} 运行测试 通过Application方式启动应用程序后，打开终端访问通过如下命令行： 12curl -X GET http://localhost:8080/config/get输出内容：xxx-xxx-dev 看到输出内容你应该会感觉到不可思议，按照我们之前说的这里应该去找spring.application.name所对应的配置信息，也就是hengboy-spring-cloud-config-profile.yaml的配置信息，在上面步骤中我们在hengboy-spring-cloud-config-profile.yaml内添加的配置信息不是xxx-xxx-dev而是xxx-xxx-xx。 多环境配置的优先级上面出现的情况，其实一点也不奇怪，Nacos Config所被应用到SpringBoot、SpringCloud项目时，如果项目内存在Profile多环境的配置，就会自动去找spring.profile.actives所激活的profile配置文件，如下所示： 12# 激活dev profile时spring.profile.actives=dev -&gt; hengboy-spring-cloud-config-profile-dev.yaml 我们激活spring.profile.actives=dev时，Nacos Config会自动去找两个配置文件，分别是：hengboy-spring-cloud-config-profile.yaml、hengboy-spring-cloud-config-profile-dev.yaml。 这也就对应上面说的application配置文件与Nacos Config配置文件的对应关系： 1234# 默认的配置application.yml -&gt; hengboy-spring-cloud-config-profile.yaml# 激活profile=dev的配置application-dev.yml -&gt; hengboy-spring-cloud-config-profile-dev.yaml 我们之前在学习SpringBoot时讲到过，profile多环境下的配置如果与默认配置（application.yml）相同时会自动被覆盖掉，如下所示： 123456789# application.ymlserver: port: 8000spring: profile: actives: dev# application-dev.ymlserver: port: 9000 根据上面的额配置的项目，在启动时会使用9000作为启动端口。 Nacos Config也是同样的概念设计，这一点可能是不想改变太多相关SpringBoot、SpringCloud的习惯，让开发者更方面的集成使用。 结论 根据上面的解释，我们在访问/config/get时你就明白为什么返回的是xxx-xxx-dev了。","link":"/springcloud-nacos-config-profile.html"},{"title":"重写SpringMvc参数装载方式","text":"在国内企业开发项目中大多数都已经偏向Spring家族式的开发风格，在前几年国内项目都是以Structs2作为Web开发的主导，不过由于近几年发生的事情确实让开发者对它失去了以往的信心。与此同时Spring家族发布了SpringMVC，而且完美的整合Spring来开发企业级大型Web项目。它有着比Structs2更强大的技术支持以及更灵活的自定义配置，接下来我们就看看本章的内容，我们自定义实现SpringMVC参数绑定规则，根据业务定制参数装载实现方式。 本章目标根据项目定制SpringMVC参数状态并了解SpringMVC的装载过程以及实现方式。 构建项目我们先来创建一个SpringBoot项目，添加本章所需的依赖，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930313233343536373839...//省略部分配置&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring boot tomcat jsp 支持开启 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--servlet支持开启--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- jstl 支持开启 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--fastjson支持--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...//省略部分配置 本章需要JSP相关的依赖支持，所以需要添加对应的依赖，修改application.properties配置文件让JSP生效，配置内容如下所示： 12spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jsp 相关JSP配置可以访问第二章：SpringBoot与JSP间不可描述的秘密查看讲解。 SpringMVC的参数装载在讲解我们自定义参数装载之前，我们先来看看SpringMVC内部为我们提供的参数装载方式。 添加测试JSP我们首先来添加一个测试的jsp页面，页面上添加一些输入元素，代码如下所示： 123456789101112131415161718192021&lt;%-- Created by IntelliJ IDEA. User: hengyu Date: 2017/9/17 Time: 10:33 To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form method=&quot;post&quot; action=&quot;/submit&quot;&gt; 教师姓名：&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生姓名：&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生年龄：&lt;input type=&quot;text&quot; name=&quot;age&quot;/&gt;&lt;br/&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 在index.jsp内添加了三个name的文本输入框，如果我们现在提交到后台SpringMVC为默认为我们解析成一个数组，如果根据描述而言的来处理则是不合理的，当然也可以使用各种手段完成字段参数的装载，比如：为教师的name添加一个数组或者List集合进行接受，这种方式也是可以实现但不优雅。 如果你们项目组有严格的开发规范要求，这种方式是不允许出现在Controller方法内的。 那这个问题就让人头疼了，在之前我们使用Struct2的时候是可以根据指定的前缀，如：xxx.xxx来进行映射的，而SpringMVC并没有提供这个支持，不过它提供了自定义参数装载的实现方法，那就没有问题了，我们可以手写。 自定义的参数装载既然上面的代码实现满足不了我们的需求，那么我接下来就来重写参数装载。 创建ParameterModel注解对于一直使用SpringMVC的朋友来说，应该对@RequestParam很熟悉，而本章我们自定义的注解跟@RequestParam类似，主要目的也是标识指定参数完成数据的绑定。下面我们先来看看该注解的源码，如下所示： 1234567891011121314151617181920212223package com.yuqiyu.chapter36.annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 参数实体映射注解 * 配置该注解的参数会使用 com.yuqiyu.chapter36.resovler.CustomerArgumentResolver类完成参数装载 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/16 * Time：22:19 * 码云：http://git.oschina.net/jnyqy * ======================== */@Target(value = ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)public @interface ParameterModel{} 该注解目前没有添加任何一个属性，这个也是可以根据项目的需求已经业务逻辑进行相应添加的，比如@RequestParam内常用的属性required、defaultValue等属性，由于我们本章内容不需要自定义注解内的属性所以这里就不添加了。 该注解的作用域是在参数上@Target(value = ElementType.PARAMETER)，我们仅可以在方法参数上使用。 创建参数接受实体我们可以回到上面看看index.jsp的内容，我们需要教师的基本信息以及学生的基本信息，那我们就为教师、以及学生创建实体（注意：这个实体可以是对应数据库内的实体） 教师实体123456789101112131415161718package com.yuqiyu.chapter36.bean;import lombok.Data;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/17 * Time：10:40 * 码云：http://git.oschina.net/jnyqy * ======================== */@Datapublic class TeacherEntity { //教师姓名 private String name;} 教师实体内目前为了测试就添加一个跟页面参数有关的字段。 学生实体1234567891011121314151617181920package com.yuqiyu.chapter36.bean;import lombok.Data;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/17 * Time：10:41 * 码云：http://git.oschina.net/jnyqy * ======================== */@Datapublic class StudentEntity { //学生姓名 private String name; //年龄 private String age;} 学生实体添加与页面参数对应的字段，名称、年龄。 编写CustomerArgumentResolver参数装载在写参数装载之前，我们需要先了解下它的接口HandlerMethodArgumentResolver，该接口内定义了两个方法： supportsParameter1boolean supportsParameter(MethodParameter var1); supportsParameter方法顾名思义，是允许装载的参数，也就是说方法返回true时才会指定装载方法完成参数装载。 resolveArgument1Object resolveArgument(MethodParameter var1, ModelAndViewContainer var2, NativeWebRequest var3, WebDataBinderFactory var4) throws Exception; resolveArgument方法是参数状态的实现逻辑方法，该方法返回的值会直接装载到指定的参数上，有木有很神奇啊？下面我们就创建实现类来揭开这位神奇的姑娘的面纱吧！ 创建CustomerArgumentResolver实现接口HandlerMethodArgumentResolver内的两个方法，具体实现代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346package com.yuqiyu.chapter36.resovler;import com.yuqiyu.chapter36.annotation.ParameterModel;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.BeanUtils;import org.springframework.core.MethodParameter;import org.springframework.core.convert.ConversionService;import org.springframework.core.convert.TypeDescriptor;import org.springframework.util.StringUtils;import org.springframework.validation.DataBinder;import org.springframework.web.bind.support.WebDataBinderFactory;import org.springframework.web.context.request.NativeWebRequest;import org.springframework.web.context.request.RequestAttributes;import org.springframework.web.method.support.HandlerMethodArgumentResolver;import org.springframework.web.method.support.ModelAndViewContainer;import org.springframework.web.servlet.HandlerMapping;import java.lang.reflect.Field;import java.util.*;/** * 自定义参数装载 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/16 * Time：22:11 * 码云：http://git.oschina.net/jnyqy * ======================== */public class CustomerArgumentResolver implements HandlerMethodArgumentResolver{ /** * 日志对象 */ private Logger logger = LoggerFactory.getLogger(CustomerArgumentResolver.class); /** * 该方法返回true时调用resolveArgument方法执行逻辑 * spring家族的架构设计万变不离其宗啊，在之前event &amp; listener也是用到了同样的方式 * @param methodParameter * @return */ @Override public boolean supportsParameter(MethodParameter methodParameter) { return methodParameter.hasParameterAnnotation(ParameterModel.class); } /** * 装载参数 * @param methodParameter 方法参数 * @param modelAndViewContainer 返回视图容器 * @param nativeWebRequest 本次请求对象 * @param webDataBinderFactory 数据绑定工厂 * @return * @throws Exception */ @Override public Object resolveArgument ( MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory ) throws Exception { String parameterName = methodParameter.getParameterName(); logger.info(&quot;参数名称：{}&quot;,parameterName); /** * 目标返回对象 * 如果Model存在该Attribute时从module内获取并设置为返回值 * 如果Model不存在该Attribute则从request parameterMap内获取并设置为返回值 */ Object target = modelAndViewContainer.containsAttribute(parameterName) ? modelAndViewContainer.getModel().get(parameterName) : createAttribute(parameterName, methodParameter, webDataBinderFactory, nativeWebRequest);; /** * 返回内容，这里返回的内容才是最终装载到参数的值 */ return target; } /** * 根据参数attributeName获取请求的值 * @param attributeName 请求参数 * @param parameter method 参数对象 * @param binderFactory 数据绑定工厂 * @param request 请求对象 * @return * @throws Exception */ protected Object createAttribute(String attributeName, MethodParameter parameter, WebDataBinderFactory binderFactory, NativeWebRequest request) throws Exception { /** * 获取attributeName的值 */ String value = getRequestValueForAttribute(attributeName, request); /** * 如果存在值 */ if (value != null) { /** * 进行类型转换 * 检查请求的类型与目标参数类型是否可以进行转换 */ Object attribute = convertAttributeToParameterValue(value, attributeName, parameter, binderFactory, request); /** * 如果存在转换后的值，则返回 */ if (attribute != null) { return attribute; } } /** * 检查request parameterMap 内是否存在以attributeName作为前缀的数据 * 如果存在则根据字段的类型来进行设置值、集合、数组等 */ else { Object attribute = putParameters(parameter,request); if(attribute!=null) { return attribute; } } /** * 如果以上两种条件不符合，直接返回初始化参数类型的空对象 */ return BeanUtils.instantiateClass(parameter.getParameterType()); } /** * 将attribute的值转换为parameter参数值类型 * @param sourceValue 源请求值 * @param attributeName 参数名 * @param parameter 目标参数对象 * @param binderFactory 数据绑定工厂 * @param request 请求对象 * @return * @throws Exception */ protected Object convertAttributeToParameterValue(String sourceValue, String attributeName, MethodParameter parameter, WebDataBinderFactory binderFactory, NativeWebRequest request) throws Exception { /** * 获取类型转换业务逻辑实现类 */ DataBinder binder = binderFactory.createBinder(request, null, attributeName); ConversionService conversionService = binder.getConversionService(); if (conversionService != null) { /** * 源类型描述 */ TypeDescriptor source = TypeDescriptor.valueOf(String.class); /** * 根据目标参数对象获取目标参数类型描述 */ TypeDescriptor target = new TypeDescriptor(parameter); /** * 验证是否可以进行转换 */ if (conversionService.canConvert(source, target)) { /** * 返回转换后的值 */ return binder.convertIfNecessary(sourceValue, parameter.getParameterType(), parameter); } } return null; } /** * 从request parameterMap集合内获取attributeName的值 * @param attributeName 参数名称 * @param request 请求对象 * @return */ protected String getRequestValueForAttribute(String attributeName, NativeWebRequest request) { /** * 获取PathVariables参数集合 */ Map&lt;String, String&gt; variables = getUriTemplateVariables(request); /** * 如果PathVariables参数集合内存在该attributeName * 直接返回相对应的值 */ if (StringUtils.hasText(variables.get(attributeName))) { return variables.get(attributeName); } /** * 如果request parameterMap内存在该attributeName * 直接返回相对应的值 */ else if (StringUtils.hasText(request.getParameter(attributeName))) { return request.getParameter(attributeName); } //不存在时返回null else { return null; } } /** * 获取指定前缀的参数：包括uri varaibles 和 parameters * * @param namePrefix * @param request * @return * @subPrefix 是否截取掉namePrefix的前缀 */ protected Map&lt;String, String[]&gt; getPrefixParameterMap(String namePrefix, NativeWebRequest request, boolean subPrefix) { Map&lt;String, String[]&gt; result = new HashMap(); /** * 从PathVariables内获取该前缀的参数列表 */ Map&lt;String, String&gt; variables = getUriTemplateVariables(request); int namePrefixLength = namePrefix.length(); for (String name : variables.keySet()) { if (name.startsWith(namePrefix)) { //page.pn 则截取 pn if (subPrefix) { char ch = name.charAt(namePrefix.length()); //如果下一个字符不是 数字 . _ 则不可能是查询 只是前缀类似 if (illegalChar(ch)) { continue; } result.put(name.substring(namePrefixLength + 1), new String[]{variables.get(name)}); } else { result.put(name, new String[]{variables.get(name)}); } } } /** * 从request parameterMap集合内获取该前缀的参数列表 */ Iterator&lt;String&gt; parameterNames = request.getParameterNames(); while (parameterNames.hasNext()) { String name = parameterNames.next(); if (name.startsWith(namePrefix)) { //page.pn 则截取 pn if (subPrefix) { char ch = name.charAt(namePrefix.length()); //如果下一个字符不是 数字 . _ 则不可能是查询 只是前缀类似 if (illegalChar(ch)) { continue; } result.put(name.substring(namePrefixLength + 1), request.getParameterValues(name)); } else { result.put(name, request.getParameterValues(name)); } } } return result; } /** * 验证参数前缀是否合法 * @param ch * @return */ private boolean illegalChar(char ch) { return ch != '.' &amp;&amp; ch != '_' &amp;&amp; !(ch &gt;= '0' &amp;&amp; ch &lt;= '9'); } /** * 获取PathVariables集合 * @param request 请求对象 * @return */ protected final Map&lt;String, String&gt; getUriTemplateVariables(NativeWebRequest request) { Map&lt;String, String&gt; variables = (Map&lt;String, String&gt;) request.getAttribute( HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE, RequestAttributes.SCOPE_REQUEST); return (variables != null) ? variables : Collections.emptyMap(); } /** * 从request内获取parameter前缀的所有参数 * 并根据parameter的类型将对应字段的值设置到parmaeter对象内并返回 * @param parameter * @param request * @return */ protected Object putParameters(MethodParameter parameter,NativeWebRequest request) { /** * 根据请求参数类型初始化空对象 */ Object object = BeanUtils.instantiateClass(parameter.getParameterType()); /** * 获取指定前缀的请求参数集合 */ Map&lt;String, String[]&gt; parameters = getPrefixParameterMap(parameter.getParameterName(),request,true); Iterator&lt;String&gt; iterator = parameters.keySet().iterator(); while(iterator.hasNext()) { //字段名称 String fieldName = iterator.next(); //请求参数值 String[] parameterValue = parameters.get(fieldName); try { Field field = object.getClass().getDeclaredField(fieldName); field.setAccessible(true); //字段的类型 Class&lt;?&gt; fieldTargetType = field.getType(); /** * List（ArrayList、LinkedList）类型 * 将数组类型的值转换为List集合对象 */ if(List.class.isAssignableFrom(fieldTargetType)) { field.set(object, Arrays.asList(parameterValue)); } /** *Object数组类型，直接将数组值设置为目标字段的值 */ else if(Object[].class.isAssignableFrom(fieldTargetType)) { field.set(object, parameterValue); } /** * 单值时获取数组索引为0的值 */ else { field.set(object, parameterValue[0]); } } catch (Exception e) { logger.error(&quot;Set Field：{} Value Error，In {}&quot;,fieldName,object.getClass().getName()); continue; } } return object; }} 上面我直接贴出了参数装载的全部实现方法，下面我们就开始按照装载的流程进行讲解。 supportsParameter方法实现12345678910/** * 该方法返回true时调用resolveArgument方法执行逻辑 * spring家族的架构设计万变不离其宗啊，在之前event &amp; listener也是用到了同样的方式 * @param methodParameter * @return */ @Override public boolean supportsParameter(MethodParameter methodParameter) { return methodParameter.hasParameterAnnotation(ParameterModel.class); } 我们只对配置了ParameterModel注解的参数进行装载。 resolveArgument方法实现123456789101112131415161718192021222324252627282930313233/** * 装载参数 * @param methodParameter 方法参数 * @param modelAndViewContainer 返回视图容器 * @param nativeWebRequest 本次请求对象 * @param webDataBinderFactory 数据绑定工厂 * @return * @throws Exception */ @Override public Object resolveArgument ( MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory ) throws Exception { String parameterName = methodParameter.getParameterName(); logger.info(&quot;参数名称：{}&quot;,parameterName); /** * 目标返回对象 * 如果Model存在该Attribute时从module内获取并设置为返回值 * 如果Model不存在该Attribute则从request parameterMap内获取并设置为返回值 */ Object target = modelAndViewContainer.containsAttribute(parameterName) ? modelAndViewContainer.getModel().get(parameterName) : createAttribute(parameterName, methodParameter, webDataBinderFactory, nativeWebRequest);; /** * 返回内容，这里返回的内容才是最终装载到参数的值 */ return target; } 该方法作为装载参数逻辑的入口，我们从MethodParameter 对象内获取了参数的名称，根据该名称检查Model内是否存在该名称的值，如果存在则直接使用并返回，反则需要从ParameterMap内获取对应该参数名称的值返回。我们下面主要看看从parameterMap获取的方法实现 createAttribute方法实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 根据参数attributeName获取请求的值 * @param attributeName 请求参数 * @param parameter method 参数对象 * @param binderFactory 数据绑定工厂 * @param request 请求对象 * @return * @throws Exception */ protected Object createAttribute(String attributeName, MethodParameter parameter, WebDataBinderFactory binderFactory, NativeWebRequest request) throws Exception { /** * 获取attributeName的值 */ String value = getRequestValueForAttribute(attributeName, request); /** * 如果存在值 */ if (value != null) { /** * 进行类型转换 * 检查请求的类型与目标参数类型是否可以进行转换 */ Object attribute = convertAttributeToParameterValue(value, attributeName, parameter, binderFactory, request); /** * 如果存在转换后的值，则返回 */ if (attribute != null) { return attribute; } } /** * 检查request parameterMap 内是否存在以attributeName作为前缀的数据 * 如果存在则根据字段的类型来进行设置值、集合、数组等 */ else { Object attribute = putParameters(parameter,request); if(attribute!=null) { return attribute; } } /** * 如果以上两种条件不符合，直接返回初始化参数类型的空对象 */ return BeanUtils.instantiateClass(parameter.getParameterType()); } 该方法的逻辑存在两个分支，首先通过调用getRequestValueForAttribute方法从parameterMap内获取指定属性名的请求值，如果存在值则需要验证是否可以完成类型转换，验证通过后则直接返回值。 上面的部分其实是SpringMVC原有的参数装载的流程，下面我们就来根据需求个性化定制装载逻辑。 putParameters方法实现该方法实现了自定义规则xxx.xxx方式进行参数装载的逻辑，我们在前台传递参数的时候只需要将Controller内方法参数名称作为传递的前缀即可，如：teacher.name、student.name。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 从request内获取parameter前缀的所有参数 * 并根据parameter的类型将对应字段的值设置到parmaeter对象内并返回 * @param parameter * @param request * @return */ protected Object putParameters(MethodParameter parameter,NativeWebRequest request) { /** * 根据请求参数类型初始化空对象 */ Object object = BeanUtils.instantiateClass(parameter.getParameterType()); /** * 获取指定前缀的请求参数集合 */ Map&lt;String, String[]&gt; parameters = getPrefixParameterMap(parameter.getParameterName(),request,true); Iterator&lt;String&gt; iterator = parameters.keySet().iterator(); while(iterator.hasNext()) { //字段名称 String fieldName = iterator.next(); //请求参数值 String[] parameterValue = parameters.get(fieldName); try { Field field = object.getClass().getDeclaredField(fieldName); field.setAccessible(true); //字段的类型 Class&lt;?&gt; fieldTargetType = field.getType(); /** * List（ArrayList、LinkedList）类型 * 将数组类型的值转换为List集合对象 */ if(List.class.isAssignableFrom(fieldTargetType)) { field.set(object, Arrays.asList(parameterValue)); } /** *Object数组类型，直接将数组值设置为目标字段的值 */ else if(Object[].class.isAssignableFrom(fieldTargetType)) { field.set(object, parameterValue); } /** * 单值时获取数组索引为0的值 */ else { field.set(object, parameterValue[0]); } } catch (Exception e) { logger.error(&quot;Set Field：{} Value Error，In {}&quot;,fieldName,object.getClass().getName()); continue; } } return object; } 该方法首先实例化了一个MethodParameter类型的空对象，然后通过getPrefixParameterMap获取PathVariables、ParameterMap内前缀为MethodParameter名称的请求参数列表，遍历列表对应设置object 内的字段，用于完成参数的装载，在装载过程中，我这里分别根据Collection、List、Array、Single类型进行了处理（注意：这里需要根据项目需求进行调整装载类型）。 配置Spring托管CustomerArgumentResolver我们将CustomerArgumentResolver托管交付给Spring框架，我们来创建一个名叫WebMvcConfiguration的配置类，该类继承抽象类WebMvcConfigurerAdapter，代码如下所示： 1234567891011121314151617181920212223242526272829303132333435/** * springmvc 注解式配置类 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/16 * Time：22:15 * 码云：http://git.oschina.net/jnyqy * ======================== */@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter{ /** * 添加参数装载 * @param argumentResolvers */ @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) { /** * 将自定义的参数装载添加到spring内托管 */ argumentResolvers.add(new CustomerArgumentResolver()); } /** * 配置静态请求视图映射 * @param registry */ @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(&quot;/index&quot;).setViewName(&quot;index&quot;); }} 我们重写了WebMvcConfigurerAdapter抽象类内的两个方法addArgumentResolvers、addViewControllers，其中addArgumentResolvers方法完成了参数装载的托管。 addViewControllers配置了视图控制器映射，这样我们访问/index地址就可以请求到index.jsp页面。 创建测试控制器创建名为IndexController的控制器并添加数据提交的方法，具体代码如下所示： 1234567891011121314151617181920212223/** * 表单提交控制器 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/9/16 * Time：22:26 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestControllerpublic class IndexController{ /** * 装载参数测试 * @return */ @RequestMapping(value = &quot;/submit&quot;) public String resolver(@ParameterModel TeacherEntity teacher, @ParameterModel StudentEntity student) { return &quot;教师名称：&quot;+ JSON.toJSON(teacher.getName()) +&quot;，学生名称：&quot;+student.getName()+&quot;，学生年龄：&quot;+student.getAge(); }} 可以看到我们为TeacherEntity 、StudentEntity 分别添加了注解@ParameterModel，也就证明了这两个实体需要使用我们的CustomerArgumentResolver完成参数装载。 运行测试在运行测试之前，我们需要修改下index.jsp内的参数映射前缀，修改后代码如下所示： 123456&lt;form method=&quot;post&quot; action=&quot;/submit&quot;&gt; 教师姓名：&lt;input type=&quot;text&quot; name=&quot;teacher.name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生姓名：&lt;input type=&quot;text&quot; name=&quot;student.name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生年龄：&lt;input type=&quot;text&quot; name=&quot;student.age&quot;/&gt;&lt;br/&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form&gt; 测试单值装载我们为教师名称、学生名称、学生年龄都分别添加了前缀，下面我们来启动项目，访问项目根下路径/index，如下图1所示： 在上图1中输入了部分请求参数，点击“提交”按钮查看界面输出的效果，图下所示： 1教师名称：王老师，学生名称：张小跑，学生年龄：23 可以看到参数已经被正确的装载到了不同的实体类内。 上面的例子只是针对实体内的单个值的装载，下面我们来测试下List类型的值是否可以装载？ 测试List装载我们先来修改下教师实体内的名称为List，字段名称不需要变动，如下所示： 12//教师姓名private List&lt;String&gt; name; 再来修改下index.jsp输入框，如下所示： 1234567&lt;form method=&quot;post&quot; action=&quot;/submit&quot;&gt; 语文老师姓名：&lt;input type=&quot;text&quot; name=&quot;teacher.name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 数学教师姓名：&lt;input type=&quot;text&quot; name=&quot;teacher.name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生姓名：&lt;input type=&quot;text&quot; name=&quot;student.name&quot;/&gt;&lt;br/&gt;&lt;br/&gt; 学生年龄：&lt;input type=&quot;text&quot; name=&quot;student.age&quot;/&gt;&lt;br/&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot;/&gt;&lt;/form&gt; 在上代码中我们添加了两位老师的名称，接下来重启项目，再次提交测试，查看是不是我们想要的效果？修改后的界面如下图2所示： 界面输出内容如下所示： 1教师名称：[&quot;王老师&quot;,&quot;李老师&quot;]，学生名称：张小跑，学生年龄：24 可以看到我们已经拿到了两位老师的名称，这也证明了我们的CustomerArgumentResolver是可以完成List的映射装载的。 总结以上内容就是本章的全部讲解内容，本章简单实现了参数的状态，其中还有很多细节性质的逻辑，如：@Valid注解的生效、文件的上传等。在下一章我们会降到如果通过参数装载实现接口服务的安全认证。","link":"/springmvc-rewrite-parameter-loader.html"},{"title":"技术杂谈专题","text":"关于专题本专题涵盖了Java基础、数据结构与算法、Linux服务器基础使用、代码编写规范、脱坑经验… 作者推荐我整理了极客时间学习热度比较高的课程，相关SpringCloud、SpringBoot、K8s、数据结构与算法、Jvm调优、架构师修炼等更多内容，有兴趣访问 我的推荐课程 了解详情，还能领取恒宇少年粉丝专属的 ¥199 优惠券。 请给我支持 请将该页面分享给更多需要它的技术学习爱好者 如果你想要成为接口服务架构师，来看看这个 助力成为服务架构师 阅读指南文章已分类，请按需点击查看，希望对你有所帮助。 架构杂谈 初识BFF架构设计 RESTful规范Api最佳设计实践 在阿里Java大牛们都是这样对Java项目代码分层的 微服务杂谈 你的微服务敢独立交付么？ 脱坑杂谈 记一次操蛋的方案降级（云上冷热分离的坎坷之路） 数据算法杂谈 聊聊缓存淘汰算法-LRU 实现原理 Linux杂谈 在Ubuntu下部署Gitolite服务端 在Ubuntu下为Gitolite添加管理端 在Ubuntu下为Gitolite添加客户端 Mac/Linux下配置远程Linux服务器免密登录 Linux上，最常用的一批命令解析（10年精选） 作为高级Java，你应该了解的Linux知识 Spring杂谈 业务解耦利器Event/Listener 非注入方式获取ApplicationContext上下文 重写SpringMvc参数装载方式 Spring声明式事务为何不回滚？ 消息队列杂谈 深入理解RocketMq普通消息和顺序消息使用，原理，优化 不知道怎么分类的杂谈 GitHub Actions使用入门 使用GitHub Actions发布Jar到Maven Central 秒懂 QPS、TPS、PV、UV、GMV、IP、RPS！ 使用Gitbook创建文档并导出PDF GitHub标星超1万的Chrome插件，助你轻松查看文件Git历史 无意间发现一个视频转换gif图片的开源框架 作者公众号关注恒宇少年的微信公众号，定期会有「抽奖活动」、「签到福利」、「免费电子小册」…","link":"/technical-talk.html"},{"title":"Spring Boot 使用 AOP 防止重复提交","text":"在传统的web项目中，防止重复提交，通常做法是：后端生成一个唯一的提交令牌（uuid），并存储在服务端。页面提交请求携带这个提交令牌，后端验证并在第一次验证后删除该令牌，保证提交请求的唯一性。 上述的思路其实没有问题的，但是需要前后端都稍加改动，如果在业务开发完在加这个的话，改动量未免有些大了，本节的实现方案无需前端配合，纯后端处理。 思路 自定义注解 @NoRepeatSubmit 标记所有Controller中的提交请求 通过AOP 对所有标记了 @NoRepeatSubmit 的方法拦截 在业务方法执行前，获取当前用户的 token（或者JSessionId）+ 当前请求地址，作为一个唯一 KEY，去获取 Redis 分布式锁（如果此时并发获取，只有一个线程会成功获取锁） 业务方法执行后，释放锁 关于Redis分布式锁 不了解的同学戳这里 ==&gt; Redis分布式锁的正确实现方式 使用Redis 是为了在负载均衡部署，如果是单机的部署的项目可以使用一个线程安全的本地Cache 替代 Redis Code这里只贴出 AOP 类和测试类，完整代码码云 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Aspect@Componentpublic class RepeatSubmitAspect { private final static Logger LOGGER = LoggerFactory.getLogger(RepeatSubmitAspect.class); @Autowired private RedisLock redisLock; @Pointcut(&quot;@annotation(noRepeatSubmit)&quot;) public void pointCut(NoRepeatSubmit noRepeatSubmit) { } @Around(&quot;pointCut(noRepeatSubmit)&quot;) public Object around(ProceedingJoinPoint pjp, NoRepeatSubmit noRepeatSubmit) throws Throwable { int lockSeconds = noRepeatSubmit.lockTime(); HttpServletRequest request = RequestUtils.getRequest(); Assert.notNull(request, &quot;request can not null&quot;); // 此处可以用token或者JSessionId String token = request.getHeader(&quot;Authorization&quot;); String path = request.getServletPath(); String key = getKey(token, path); String clientId = getClientId(); boolean isSuccess = redisLock.tryLock(key, clientId, lockSeconds); if (isSuccess) { LOGGER.info(&quot;tryLock success, key = [{}], clientId = [{}]&quot;, key, clientId); // 获取锁成功, 执行进程 Object result; try { result = pjp.proceed(); } finally { // 解锁 redisLock.releaseLock(key, clientId); LOGGER.info(&quot;releaseLock success, key = [{}], clientId = [{}]&quot;, key, clientId); } return result; } else { // 获取锁失败，认为是重复提交的请求 LOGGER.info(&quot;tryLock fail, key = [{}]&quot;, key); return new ResultBean(ResultBean.FAIL, &quot;重复请求，请稍后再试&quot;, null); } } private String getKey(String token, String path) { return token + path; } private String getClientId() { return UUID.randomUUID().toString(); }} 多线程测试测试代码如下，模拟十个请求并发同时提交 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class RunTest implements ApplicationRunner { private static final Logger LOGGER = LoggerFactory.getLogger(RunTest.class); @Autowired private RestTemplate restTemplate; @Override public void run(ApplicationArguments args) throws Exception { System.out.println(&quot;执行多线程测试&quot;); String url=&quot;http://localhost:8000/submit&quot;; CountDownLatch countDownLatch = new CountDownLatch(1); ExecutorService executorService = Executors.newFixedThreadPool(10); for(int i=0; i&lt;10; i++){ String userId = &quot;userId&quot; + i; HttpEntity request = buildRequest(userId); executorService.submit(() -&gt; { try { countDownLatch.await(); System.out.println(&quot;Thread:&quot;+Thread.currentThread().getName()+&quot;, time:&quot;+System.currentTimeMillis()); ResponseEntity&lt;String&gt; response = restTemplate.postForEntity(url, request, String.class); System.out.println(&quot;Thread:&quot;+Thread.currentThread().getName() + &quot;,&quot; + response.getBody()); } catch (InterruptedException e) { e.printStackTrace(); } }); } countDownLatch.countDown(); } private HttpEntity buildRequest(String userId) { HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); headers.set(&quot;Authorization&quot;, &quot;yourToken&quot;); Map&lt;String, Object&gt; body = new HashMap&lt;&gt;(); body.put(&quot;userId&quot;, userId); return new HttpEntity&lt;&gt;(body, headers); }} 成功防止重复提交，控制台日志如下，可以看到十个线程的启动时间几乎同时发起，只有一个请求提交成功了","link":"/use_aop_to_prevent_duplicate_submissions.html"},{"title":"自定义项目的启动Banner","text":"Banner是SpringBoot框架一个特色的部分，其设计的目的无非就是一个框架的标识，其中包含了版本号、框架名称等内容，既然SpringBoot为我们提供了这个模块，它肯定也是可以更换的这也是Spring开源框架的设计理念。 本章目标修改SpringBoot启动Banner内容. 构建项目本章不涉及业务逻辑相关内容，简单创建一个SpringBoot框架即可。 Banner的隐藏隐藏的方式SpringBoot提供了两种，不过其中application.properties方式已经被抛弃掉了，我们下面介绍下修改SpringBootApplication配置的方式。具体代码如下所示： 1234567891011121314151617181920212223package com.yuqiyu.chapter33;import org.springframework.boot.Banner;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Chapter33Application { public static void main(String[] args) { /** * 隐藏banner启动方式 */ SpringApplication springApplication = new SpringApplication(Chapter33Application.class); //设置banner的模式为隐藏 springApplication.setBannerMode(Banner.Mode.OFF); //启动springboot应用程序 springApplication.run(args); //原启动方式 /*SpringApplication.run(Chapter33Application.class, args);*/ }} 配置完成后，我们启动项目在控制台你就会发现Banner已经隐藏不见了，当然我们也是可以更换Banner内容的。 Banner的更换更换Banner相对于隐藏要简单一些，我们只需要在src/main/resource下添加一个名叫banner.txt的文件，将需要修改的内容写入到该文件内就可以了，具体Banner内容如下所示： 123456789101112${AnsiColor.BRIGHT_RED} ! 天地山青 ${AnsiColor.BRIGHT_YELLOW} !${AnsiColor.BRIGHT_RED} /^\\ ${AnsiColor.BRIGHT_YELLOW}道法无常 /^\\${AnsiColor.BRIGHT_RED} / \\ 天地无极 ${AnsiColor.BRIGHT_YELLOW} / \\${AnsiColor.BRIGHT_RED} | | ( ) | | ${AnsiColor.BRIGHT_YELLOW}乾坤戒法 | | ( ) | |${AnsiColor.BRIGHT_RED} /^\\ | /^\\ \\ / /^\\ | /^\\ 元阳入体 ${AnsiColor.BRIGHT_YELLOW} /^\\ | /^\\ \\ / /^\\ | /^\\${AnsiColor.BRIGHT_RED} |O| /^\\ ( )|-----|( ) /^\\ |O| ${AnsiColor.BRIGHT_YELLOW}五毒不侵 |O| /^\\ ( )|-----|( ) /^\\ |O|${AnsiColor.BRIGHT_RED} |_| |-| |^-^|---||-----||---|^-^| |-| |_| 九阳之体 ${AnsiColor.BRIGHT_YELLOW} |_| |-| |^-^|---||-----||---|^-^| |-| |_|${AnsiColor.BRIGHT_RED} |O| |O| |/^\\|/^\\|| | ||/^\\|/^\\| |O| |O| ${AnsiColor.BRIGHT_YELLOW}化缘神功 |O| |O| |/^\\|/^\\|| | ||/^\\|/^\\| |O| |O|${AnsiColor.BRIGHT_RED} |-| |-| ||_|||_||| /^\\ |||_|||_|| |-| |-| 邪魔退散 ${AnsiColor.BRIGHT_YELLOW} |-| |-| ||_|||_||| /^\\ |||_|||_|| |-| |-|${AnsiColor.BRIGHT_RED} |O| |O| |/^\\|/^\\||( )||/^\\|/^\\| |O| |O| ${AnsiColor.BRIGHT_YELLOW}永不宕机 |O| |O| |/^\\|/^\\||( )||/^\\|/^\\| |O| |O|${AnsiColor.BRIGHT_RED} |-| |-| ||_|||_|||| ||||_|||_|| |-| |-| 永无八哥 ${AnsiColor.BRIGHT_YELLOW} |-| |-| ||_|||_|||| ||||_|||_|| |-| |-|${AnsiColor.BRIGHT_CYAN} 在上面有一些属性配置，如${AnsiColor.BRIGHT_RED}，这些配置都位于``org.springframework.boot.ansi.AnsiColor`枚举内，用于配置的是输出的颜色。可配置内容如下所示： 1234567891011121314151617DEFAULT(&quot;39&quot;),BLACK(&quot;30&quot;),RED(&quot;31&quot;),GREEN(&quot;32&quot;),YELLOW(&quot;33&quot;),BLUE(&quot;34&quot;),MAGENTA(&quot;35&quot;),CYAN(&quot;36&quot;),WHITE(&quot;37&quot;),BRIGHT_BLACK(&quot;90&quot;),BRIGHT_RED(&quot;91&quot;),BRIGHT_GREEN(&quot;92&quot;),BRIGHT_YELLOW(&quot;93&quot;),BRIGHT_BLUE(&quot;94&quot;),BRIGHT_MAGENTA(&quot;95&quot;),BRIGHT_CYAN(&quot;96&quot;),BRIGHT_WHITE(&quot;97&quot;); 这个配置是针对文字的颜色，当然还有背景颜色的配置，位于org.springframework.boot.ansi.AnsiBackground枚举内，可配置的内容如下所示： 1234567891011121314151617DEFAULT(&quot;49&quot;),BLACK(&quot;40&quot;),RED(&quot;41&quot;),GREEN(&quot;42&quot;),YELLOW(&quot;43&quot;),BLUE(&quot;44&quot;),MAGENTA(&quot;45&quot;),CYAN(&quot;46&quot;),WHITE(&quot;47&quot;),BRIGHT_BLACK(&quot;100&quot;),BRIGHT_RED(&quot;101&quot;),BRIGHT_GREEN(&quot;102&quot;),BRIGHT_YELLOW(&quot;103&quot;),BRIGHT_BLUE(&quot;104&quot;),BRIGHT_MAGENTA(&quot;105&quot;),BRIGHT_CYAN(&quot;106&quot;),BRIGHT_WHITE(&quot;107&quot;); 具体的banner.txt的内容可根据自己的爱好进行配置，上述banner.txt的效果如下图1所示： 总结本章主要讲解了如何隐藏与修改SpringBoot内的Banner内容，SpringBoot为我们提供了最大的遍历，让我们根据其中的一些属性自由组合配置内容。","link":"/use-consumer-banner.html"},{"title":"使用Gitbook创建文档并导出PDF","text":"导出PDF的方式有很多种，之前使用过马克飞象的导出功能，不过只是简单的导出并不能添加目录，因为源文件是markdown编写的，经过筛选后采用了gitbook的方式进行编写文档并且使用gitbook pdf .的方式导出为PDF文件。 注意：本机需要有NodeJs环境。 环境准备想要使用gitbook，那么我们本机需要进行安装，通过npm命令可以很方便的安装。 安装GitBook通过npm的方式进行安装gitbook环境，命令如下所示： 1npm install gitbook -g 安装calibre &amp; ebook-convert使用gitbook的导出功能，需要第三方插件ebook的支持，下面针对两种不同的操作系统进行配置环境。 Linux系统下载地址：https://calibre-ebook.com/download_linux 下载并安装 1sudo -v &amp;&amp; wget -nv -O- https://download.calibre-ebook.com/linux-installer.sh | sudo sh /dev/stdin 配置软链接 1sudo ln -s /usr/bin/nodejs /usr/bin/node Mac系统下载地址：https://calibre-ebook.com/download_osx 下载并安装 下载的为dmg文件直接双击安装即可。 配置软链接 1sudo ln -s ~/Applications/calibre.app/Contents/MacOS/ebook-convert /usr/bin 测试安装安装完成后通过如下命令进行测试是否已经生效。 1ebook-convert --version 生成文档一个新的gitbook文档有两个文件组成，分别是README.md、SUMMARY.md（可自行创建文件夹，在文件夹内创建这两个文件）。 README.md：关于当前文档的详细描述 SUMMARY.md：当前文档的目录层级关系配置，通过初始化命令可直接生成markdown文件以及文件夹。 编写Summary下面是一个示例文档的层级关系： 123456# Summary- 第一级目录 - [第一级目录的子目录](one/first.md)- 第二级目录 - [第二级目录的子目录](two/first.md) GitBook初始化gitbook内部提供了一个初始化的命令，自动根据SUMMARY.md文件的层级内容生成对应的md文件以及文件夹，执行如下命令： 12345➜ gitbook-example gitbook initinfo: create one/first.md info: create two/first.md info: create SUMMARY.md info: initialization is finished 控制台的输出信息已经告诉我们成功创建了one/first.md、two/first.md这两个文件。 配置语言gitbook默认使用的并不是中文汉子，我们需要通过配置book.json文件来修改默认语言方式（book.json文件创建在SUMMARY.md同级目录下）如下所示： 123{ &quot;language&quot;: &quot;zh-hans&quot;} 导出文档gitbook导出文档的方式有多种，下面简单介绍几种导出的方式。 导出为PDF在SUMMARY.md文件的同级目录执行gitbook pdf .命令进行导出PDF文件，执行日志如下所示： 12345678910111213➜ gitbook-example gitbook pdf .info: 7 plugins are installed info: 6 explicitly listed info: loading plugin &quot;highlight&quot;... OK info: loading plugin &quot;search&quot;... OK info: loading plugin &quot;lunr&quot;... OK info: loading plugin &quot;sharing&quot;... OK info: loading plugin &quot;fontsettings&quot;... OK info: loading plugin &quot;theme-default&quot;... OK info: found 3 pages info: found 0 asset files info: &gt;&gt; generation finished with success in 5.7s ! info: &gt;&gt; 1 file(s) generated 如果想要自定义生成的pdf文件名称，可以使用gitbook pdf . ./xxxx.pdf命令。 导出为epub在SUMMARY.md文件的同级目录执行gitbook epub .命令进行导出epub文件，执行日志如下所示： 12345678910111213➜ gitbook-example gitbook epub .info: 7 plugins are installed info: 6 explicitly listed info: loading plugin &quot;highlight&quot;... OK info: loading plugin &quot;search&quot;... OK info: loading plugin &quot;lunr&quot;... OK info: loading plugin &quot;sharing&quot;... OK info: loading plugin &quot;fontsettings&quot;... OK info: loading plugin &quot;theme-default&quot;... OK info: found 3 pages info: found 2 asset files info: &gt;&gt; generation finished with success in 2.4s ! info: &gt;&gt; 1 file(s) generated 导出为mobi在SUMMARY.md文件的同级目录执行gitbook mobi .命令进行导出mobi文件，执行日志如下所示： 12345678910111213➜ gitbook-example gitbook mobi .info: 7 plugins are installed info: 6 explicitly listed info: loading plugin &quot;highlight&quot;... OK info: loading plugin &quot;search&quot;... OK info: loading plugin &quot;lunr&quot;... OK info: loading plugin &quot;sharing&quot;... OK info: loading plugin &quot;fontsettings&quot;... OK info: loading plugin &quot;theme-default&quot;... OK info: found 3 pages info: found 3 asset files info: &gt;&gt; generation finished with success in 1.9s ! info: &gt;&gt; 1 file(s) generated 导出日志查看如果你在导出过程中遇到了问题，你可以在执行导出命令时添加--log=debug命令参数，这样导出时就可以看到完整的日志信息在控制台输出，如下所示： 12345➜ gitbook-example gitbook pdf . ./example.pdf --log=debugdebug: readme found at README.md debug: summary file found at SUMMARY.md debug: cleanup folder &quot;/var/folders/c1/5mrhntb13_zfrnjg4grnf8zr0000gn/T/tmp-2291a4Jd8P8oNX4l&quot; ...... 总结使用gitbook可以用来编写公司的接口使用文档、项目设计文档等等，功能远不止如此，它还可以通过gitbook build命令来生成静态html文件，可以部署到Nginx、阿里云OSS等静态页面托管的地方。","link":"/use-gitbook-export-pdf.html"},{"title":"使用Lombok优雅编码","text":"Lombok对于Java偷懒开发者来说应该是比较中意的，恰恰笔者就是一个喜欢在小细节上偷懒来提高开发效率的人。所以在技术框架的海洋里寻找了很久才在GitHub开源平台上找到，而在这之前国外很多程序猿一直使用该框架了，Lombok框架提供了很多编码遍历，但是也降低了代码的阅读力。下面我们看看在Idea开发工具中该怎么使用Lombok？ 本章目标使用Lombok提高开发效率。 构建项目本章的项目不涉及数据访问，所以添加的依赖也比较少，pom.xml配置文件如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yuqiyu&lt;/groupId&gt; &lt;artifactId&gt;chapter29&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;chapter29&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--web依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; lombok的依赖仅仅只有一个，lombok基于配置在编译class文件时会自动将指定模板的内容写入。 创建实体为了方便演示lombok的神奇之处，我们简单创建一个用户实体，基于该实体进行配置lombok注解，实体代码如下所示： 123456789101112131415161718192021package com.yuqiyu.chapter29.bean;/** * 用户实体&gt;&gt;&gt;测试lombok * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/4 * Time：23:07 * 码云：http://git.oschina.net/jnyqy * ======================== */public class UserBean{ //名称 private String name; //年龄 private int age; //家庭住址 private String address;} 下面我们先来看看我们最常用的getter/setter基于lombok如何使用。 Getter/SetterGetter/Setter注解作用域可以是实体类也可以是具体的属性字段，下面我们仅仅对name属性添加注解，代码如下所示： 12345//...省略//名称@Getter@Setterprivate String name; 如果想让lombok生效我们还需要针对idea工具进行插件的安装，下面我们按照顺序打开Idea配置File &gt; Settings &gt; Plugins &gt; Browse repositories... &gt; 输入lombok，插件就会被自动检索出来，界面如下图1所示：我的工具已经安装了该插件，所有在右侧是没有任何按钮的，如果你的工具没有安装该插件，右侧会有一个绿色的按钮，按钮的内容则是Install，点击安装后重启Idea就可以了。为了方便我们直接使用SpringBoot项目为我们创建的测试类（位置：com.yuqiyu.chapter29.Chapter29ApplicationTests）来验证我们的lombok注解是否已经生效，测试类代码如下所示： 123456789101112131415161718192021package com.yuqiyu.chapter29;import com.yuqiyu.chapter29.bean.UserBean;import org.junit.Test;import org.junit.runner.RunWith;import org.junit.runners.JUnit4;@RunWith(JUnit4.class)//@RunWith(SpringRunner.class)//@SpringBootTestpublic class Chapter29ApplicationTests { @Test public void testLombok() { //测试Getter/Setter UserBean user = new UserBean(); user.setName(&quot;测试lombok&quot;); System.out.println(user.getName()); }} 可以看到我们可以正常使用name属性的getter/setter方法，但是其他属性的却是无法调用，下面我们修改注解Getter/Setter位置，配置到实体类上。修改后的代码如下所示： 123456789101112//省略...@Getter@Setterpublic class UserBean{ //名称 private String name; //年龄 private int age; //家庭住址 private String address;} 我们再来测试下其他属性是否可以访问到了，测试类修改代码如下所示： 123456789101112//省略...@Test public void testLombok() { //测试Getter/Setter UserBean user = new UserBean(); user.setName(&quot;测试lombok&quot;); user.setAge(10); user.setAddress(&quot;测试地址&quot;); System.out.println(user.getName()+&quot; &quot; + user.getAge() +&quot; &quot;+user.getAddress()); } 可以看到我们修改配置位置后UserBean实体内的所有属性都具备了Getter/Setter方法，这样我们在开发中就不需要再去做多余的生成操作了。 注意：如果你的属性Getter/Setter需要做特殊处理，那么直接使用原始方法实现即可，Lombok检查到存在自定义的方法后不会再做生成处理。 ToString除了上述的Getter/SetterLombok还为我们提供了自动生成toString方法的注解@ToString，该注解的作用域仅仅是在实体类上，我们修改实体类添加该注解，在测试类中调用toString方法查看输出内容如下： 123System.out.println(user.toString());//输出：UserBean(name=测试lombok, age=10, address=sss测试地址) Lombok自动创建的toString方法会将所有的属性都包含并且调用后可以输出。 AllArgsConstructorLombok还提供了全部参数的构造函数的自动生成，该注解的作用域也是只有在实体类上，因为只有实体类才会存在构造函数。修改添加该注解并且测试调用，如下所示： 123UserBean u = new UserBean(&quot;构造lombok&quot;,1,&quot;测试地址&quot;);//输出：UserBean(name=构造lombok, age=1, address=sss测试地址) 注意：该注解配置后会自动生成一个具体全部参数的构造函数，参数的顺序与属性定义的顺序一致。 NoArgsConstructor当然除了全部参数的构造函数，Lombok还提供了没有参数的构造函数，使用方式与@AllArgsConstructor一致。 到这里也许你就有疑问了，我为了一个类添加这么多注解麻烦吗？还不如工具生成getter/setter来的快呢，那好Lombok针对这个问题也做出了解决方案。 Data我们使用@Data注解就可以涵盖@ToString、@Getter、@Setter方法，当然我们使用构造函数时还是需要单独添加注解，下面我们修改实体类添加@Data注解代码如下所示： 12345678910111213141516171819/*@Getter@Setter@ToString*/@Data@AllArgsConstructor@NoArgsConstructorpublic class UserBean{ //名称 private String name; //年龄 private int age; //家庭住址 private String address; public String getAddress() { return &quot;sss&quot;+address; }} 我们将@ToString、@Getter、@Setter三个注解注释掉后添加@Data，按照官方所说这时我们的测试类应该不会出现任何的异常，我们打开测试类查看是否正常。查看后果然，没有出现任何的异常，这也说明了@Data注解确实涵盖了上面三个注解。 Slf4j还有一个利器，Lombok为我们内置了各种日志组件的支持，我们在SpringBoot项目开发中几乎都是使用logback作为日志组件，而logback是基于slf4j完成的。所以我们在实体类上直接添加@Slf4j就可以自动创建一个日志对象作为类内全局字段，自动创建的代码如下所示： 1private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(Chapter29ApplicationTests.class); 为了测试我在Chapter29ApplicationTests测试类上添加了@Slf4j，调用效果如下所示： 1234//调用：log.info(u.toString());//输出：23:55:46.100 [main] INFO com.yuqiyu.chapter29.Chapter29ApplicationTests - UserBean(name=构造lombok, age=1, address=sss测试地址) 总结以上内容就是本章的全部讲述，本章主要讲解Lombok用于便于开发的注解组件。Lombok虽然提供的组件不多，但是每一个都是我们需要的，正是因为如此从而大大减少了我们的工作量，尤其是这种不起眼却又不得不写的代码。Lombok官方文档地址","link":"/use-lombok.html"},{"title":"使用MapStruct自动化转换实体","text":"MapStruct是一种类型安全的bean映射类生成java注释处理器。我们要做的就是定义一个映射器接口，声明任何必需的映射方法。在编译的过程中，MapStruct会生成此接口的实现。该实现使用纯java方法调用的源和目标对象之间的映射，MapStruct节省了时间，通过生成代码完成繁琐和容易出错的代码逻辑。下面我们来揭开它的神秘面纱 本章目标基于SpringBoot平台完成MapStruct映射框架的集成。 构建项目我们使用idea开发工具创建一个SpringBoot项目，添加相应的依赖，pom.xml配置文件如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970...省略部分代码&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;org.mapstruct.version&gt;1.2.0.CR1&lt;/org.mapstruct.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mapStruct依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.inject&lt;/groupId&gt; &lt;artifactId&gt;javax.inject&lt;/artifactId&gt; &lt;version&gt;1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.31&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;....省略部分代码 集成MapStruct官方提供了两种方式，上面配置文件内我们采用的是直接添加Maven依赖，而官方文档还提供了另外一种方式，采用Maven插件形式配置，配置如下所示： 1234567891011121314151617181920212223242526272829303132333435...引用官方文档...&lt;properties&gt; &lt;org.mapstruct.version&gt;1.2.0.CR1&lt;/org.mapstruct.version&gt;&lt;/properties&gt;...&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;...&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;${org.mapstruct.version}&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;... 我个人比较喜欢采用第一种方式，不需要配置过多的插件，依赖方式比较方便。接下来我们开始配置下数据库连接信息以及简单的两张表的SpringDataJPA相关接口。 数据库连接信息在resource下新创建一个application.yml文件，并添加如下数据库连接配置： 1234567891011121314151617181920212223242526272829303132spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8 username: root password: 123456 #最大活跃数 maxActive: 20 #初始化数量 initialSize: 1 #最大连接等待超时时间 maxWait: 60000 #打开PSCache，并且指定每个连接PSCache的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 #通过connectionProperties属性来打开mergeSql功能；慢SQL记录 #connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 minIdle: 1 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: select 1 from dual testWhileIdle: true testOnBorrow: false testOnReturn: false #配置监控统计拦截的filters，去掉后监控界面sql将无法统计,'wall'用于防火墙 filters: stat, wall, log4j jpa: properties: hibernate: show_sql: true format_sql: true 有关SpringDataJPA相关的学习请访问第三章：SpringBoot使用SpringDataJPA完成CRUD，我们在数据库内创建两张表信息分别是商品基本信息表、商品类型表。两张表有相应的关联，我们在不采用连接查询的方式模拟使用MapStruct，表信息如下所示： 123456789101112131415161718192021--商品类型信息表CREATE TABLE `good_types` ( `tgt_id` int(11) NOT NULL AUTO_INCREMENT, `tgt_name` varchar(30) DEFAULT NULL, `tgt_is_show` int(1) DEFAULT NULL, `tgt_order` int(255) DEFAULT NULL, PRIMARY KEY (`tgt_id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;--商品基本信息表CREATE TABLE `good_infos` ( `tg_id` int(11) NOT NULL AUTO_INCREMENT, `tg_type_id` int(11) DEFAULT NULL, `tg_title` varchar(30) DEFAULT NULL, `tg_price` decimal(8,2) DEFAULT NULL, `tg_order` int(2) DEFAULT NULL, PRIMARY KEY (`tg_id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;INSERT INTO `good_types` VALUES ('1', '青菜', '1', '1');INSERT INTO `good_infos` VALUES ('1', '1', '芹菜', '12.40', '1'); 下面我们根据这两张表创建对应的实体类。 商品类型实体123456789101112131415161718192021222324252627282930313233343536package com.yuqiyu.chapter30.bean;import lombok.Data;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.Table;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:17 * 码云：http://git.oschina.net/jnyqy * ======================== */@Entity@Table(name = &quot;good_types&quot;)@Datapublic class GoodTypeBean{ @Id @Column(name = &quot;tgt_id&quot;) private Long id; @Column(name = &quot;tgt_name&quot;) private String name; @Column(name = &quot;tgt_is_show&quot;) private int show; @Column(name = &quot;tgt_order&quot;) private int order;} 商品基本信息实体1234567891011121314151617181920212223242526272829303132333435package com.yuqiyu.chapter30.bean;import lombok.Data;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.Id;import javax.persistence.Table;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:16 * 码云：http://git.oschina.net/jnyqy * ======================== */@Entity@Table(name = &quot;good_infos&quot;)@Datapublic class GoodInfoBean{ @Id @Column(name = &quot;tg_id&quot;) private Long id; @Column(name = &quot;tg_title&quot;) private String title; @Column(name = &quot;tg_price&quot;) private double price; @Column(name = &quot;tg_order&quot;) private int order; @Column(name = &quot;tg_type_id&quot;) private Long typeId;} 接下来我们继续创建相关的JPA。 商品类型JPA12345678910111213141516171819package com.yuqiyu.chapter30.jpa;import com.yuqiyu.chapter30.bean.GoodTypeBean;import org.springframework.data.jpa.repository.JpaRepository;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:24 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface GoodTypeJPA extends JpaRepository&lt;GoodTypeBean,Long&gt;{} 商品信息JPA12345678910111213141516171819package com.yuqiyu.chapter30.jpa;import com.yuqiyu.chapter30.bean.GoodInfoBean;import org.springframework.data.jpa.repository.JpaRepository;/** * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:23 * 码云：http://git.oschina.net/jnyqy * ======================== */public interface GoodInfoJPA extends JpaRepository&lt;GoodInfoBean,Long&gt;{ } 配置MapStruct到目前为止我们的准备工作差不多完成了，下面我们开始配置使用MapStruct。我们的最终目的是为了返回一个自定义的DTO实体，那么我们就先来创建这个DTO，DTO的代码如下所示： 1234567891011121314151617181920212223242526package com.yuqiyu.chapter30.dto;import lombok.Data;/** * 转换Dto * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:25 * 码云：http://git.oschina.net/jnyqy * ======================== */@Datapublic class GoodInfoDTO{ //商品编号 private String goodId; //商品名称 private String goodName; //商品价格 private double goodPrice; //类型名称 private String typeName;} 可以看到GoodInfoDTO实体内集成了商品信息、商品类型两张表内的数据，对应查询出信息后，我们需要使用MapStruct自动映射到GoodInfoDTO。 创建MapperMapper这个定义一般是被广泛应用到MyBatis半自动化ORM框架上，而这里的Mapper跟Mybatis没有关系。下面我们先来看下代码，如下所示： 123456789101112131415161718192021222324252627282930313233package com.yuqiyu.chapter30.mapper;import com.yuqiyu.chapter30.bean.GoodInfoBean;import com.yuqiyu.chapter30.bean.GoodTypeBean;import com.yuqiyu.chapter30.dto.GoodInfoDTO;import org.mapstruct.Mapper;import org.mapstruct.Mapping;import org.mapstruct.Mappings;/** * 配置映射 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：11:26 * 码云：http://git.oschina.net/jnyqy * ======================== */@Mapper(componentModel = &quot;spring&quot;)//@Mapperpublic interface GoodInfoMapper{ //public static GoodInfoMapper MAPPER = Mappers.getMapper(GoodInfoMapper.class); @Mappings({ @Mapping(source = &quot;type.name&quot;,target = &quot;typeName&quot;), @Mapping(source = &quot;good.id&quot;,target = &quot;goodId&quot;), @Mapping(source = &quot;good.title&quot;,target = &quot;goodName&quot;), @Mapping(source = &quot;good.price&quot;,target = &quot;goodPrice&quot;) }) public GoodInfoDTO from(GoodInfoBean good, GoodTypeBean type);} 可以看到GoodInfoMapper是一个接口的形式存在的，当然也可以是一个抽象类，如果你需要在转换的时候才用个性化的定制的时候可以采用抽象类的方式，相应的代码配置官方文档已经声明。@Mapper注解是用于标注接口、抽象类是被MapStruct自动映射的标识，只有存在该注解才会将内部的接口方法自动实现。MapStruct为我们提供了多种的获取Mapper的方式，比较常用的两种分别是 默认配置默认配置，我们不需要做过多的配置内容，获取Mapper的方式就是采用Mappers通过动态工厂内部反射机制完成Mapper实现类的获取。默认方式获取Mapper如下所示： 12345//Mapper接口内部定义public static GoodInfoMapper MAPPER = Mappers.getMapper(GoodInfoMapper.class);//外部调用GoodInfoMapper.MAPPER.from(goodBean,goodTypeBean); Spring方式配置Spring方式我们需要在@Mapper注解内添加componentModel属性值，配置后在外部可以采用@Autowired方式注入Mapper实现类完成映射方法调用。Spring方式获取Mapper如下所示： 123456789//注解配置@Mapper(componentModel = &quot;spring&quot;)//注入Mapper实现类@Autowiredprivate GoodInfoMapper goodInfoMapper;//调用goodInfoMapper.from(goodBean,goodTypeBean); @Mappings &amp; @Mapping在Mapper接口定义方法上面声明了一系列的注解映射@Mapping以及@Mappings，那么这两个注解是用来干什么工作的呢？@Mapping注解我们用到了两个属性，分别是source、target source代表的是映射接口方法内的参数名称，如果是基本类型的参数，参数名可以直接作为source的内容，如果是实体类型，则可以采用实体参数名.字段名的方式作为source的内容，配置如上面GoodInfoMapper内容所示。 target代表的是映射到方法方法值内的字段名称，配置如上面GoodInfoMapper所示。 查看Mapper实现下面我们执行maven compile命令，到target/generated-sources/annotations目录下查看对应Mapper实现类，实现类代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839package com.yuqiyu.chapter30.mapper;import com.yuqiyu.chapter30.bean.GoodInfoBean;import com.yuqiyu.chapter30.bean.GoodTypeBean;import com.yuqiyu.chapter30.dto.GoodInfoDTO;import javax.annotation.Generated;import org.springframework.stereotype.Component;@Generated( value = &quot;org.mapstruct.ap.MappingProcessor&quot;, date = &quot;2017-08-20T12:52:52+0800&quot;, comments = &quot;version: 1.2.0.CR1, compiler: javac, environment: Java 1.8.0_111 (Oracle Corporation)&quot;)@Componentpublic class GoodInfoMapperImpl implements GoodInfoMapper { @Override public GoodInfoDTO from(GoodInfoBean good, GoodTypeBean type) { if ( good == null &amp;&amp; type == null ) { return null; } GoodInfoDTO goodInfoDTO = new GoodInfoDTO(); if ( good != null ) { if ( good.getId() != null ) { goodInfoDTO.setGoodId( String.valueOf( good.getId() ) ); } goodInfoDTO.setGoodName( good.getTitle() ); goodInfoDTO.setGoodPrice( good.getPrice() ); } if ( type != null ) { goodInfoDTO.setTypeName( type.getName() ); } return goodInfoDTO; }} MapStruct根据我们配置的@Mapping注解自动将source实体内的字段进行了调用target实体内字段的setXxx方法赋值，并且做出了一切参数验证。我们采用了Spring方式获取Mapper，在自动生成的实现类上MapStruct为我们自动添加了@ComponentSpring声明式注入注解配置。 运行测试下面我们来创建一个测试的Controller，用于访问具体请求地址时查询出商品的基本信息以及商品的类型后调用GoodInfoMapper.from(xxx,xxx)方法完成返回GoodInfoDTO实例。Controller代码实现如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.yuqiyu.chapter30.controller;import com.yuqiyu.chapter30.bean.GoodInfoBean;import com.yuqiyu.chapter30.bean.GoodTypeBean;import com.yuqiyu.chapter30.dto.GoodInfoDTO;import com.yuqiyu.chapter30.jpa.GoodInfoJPA;import com.yuqiyu.chapter30.jpa.GoodTypeJPA;import com.yuqiyu.chapter30.mapper.GoodInfoMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * 测试控制器 * ======================== * Created with IntelliJ IDEA. * User：恒宇少年 * Date：2017/8/20 * Time：12:24 * 码云：http://git.oschina.net/jnyqy * ======================== */@RestControllerpublic class GoodInfoController{ /** * 注入商品基本信息jpa */ @Autowired private GoodInfoJPA goodInfoJPA; /** * 注入商品类型jpa */ @Autowired private GoodTypeJPA goodTypeJPA; /** * 注入mapStruct转换Mapper */ @Autowired private GoodInfoMapper goodInfoMapper; /** * 查询商品详情 * @param id * @return */ @RequestMapping(value = &quot;/detail/{id}&quot;) public GoodInfoDTO detail(@PathVariable(&quot;id&quot;) Long id) { //查询商品基本信息 GoodInfoBean goodInfoBean = goodInfoJPA.findOne(id); //查询商品类型基本信息 GoodTypeBean typeBean = goodTypeJPA.findOne(goodInfoBean.getTypeId()); //返回转换dto return goodInfoMapper.from(goodInfoBean,typeBean); }} 在Controller内我们注入了GoodInfoJPA、GoodTypeJPA以及GoodInfoMapper，在查询商品详情方法时做出了映射处理。接下来我们启动项目访问地址http://127.0.0.1:8080/detail/1查看界面输出效果，如下所示： 123456{&quot;goodId&quot;: &quot;1&quot;,&quot;goodName&quot;: &quot;芹菜&quot;,&quot;goodPrice&quot;: 12.4,&quot;typeName&quot;: &quot;青菜&quot;} 可以看到界面输出了GoodInfoDTO内的所有字段内容，并且通过from方法将对应配置的target字段赋值。 总结本章主要讲述了基于SpringBoot开发框架上集成MapStruct自动映射框架，完成模拟多表获取数据后将某一些字段通过@Mapping配置自动映射到DTO实体实例指定的字段内。MapStruct官方文档地址：http://mapstruct.org/documentation/dev/reference/html/","link":"/use-mapstruct.html"},{"title":"使用nginx的负载均衡机制实现用户无感更新服务","text":"前言用户请求的转发是接口服务在部署时必须要做的一步。 请求转发的步骤大约分为如下几步： 域名解析到转发服务器 转发服务器会根据权重(weight)、备用(backup)配置转发到统一网关 如果统一网关存在灰度的配置，需要根据身份或者头信息过滤请求 转发到具体的业务服务 目前市面上优秀的请求转发有很多种，比如：Nginx、F5、Kong、Tengine等，其中Tengine是阿里巴巴基于Nginx进行封装，我们本章的内容基于Nginx进行讲解，我们先来准备下nginx的测试环境。 准备环境如果你的测试环境没有安装Nginx，下面我通过两种方式来说下具体的安装过程。 使用Brew安装Nginx如果你是OSX系统，可以直接使用brew管理工具进行安装，这种方式比较简单，自动从远程服务器下载最新稳定的版本进行解压、配置环境等。 12# 安装nginx➜ ~ brew install nginx 静静等待~ 安装完成后，我们先来修改下端口号（brew安装包把默认的监听端口号改为了8080，一般在使用解压的方式安装时监听端口都是80）。 我们需要先找到nginx.conf这个文件的位置： 12➜ ~ sudo find / -name nginx.conf /usr/local/etc/nginx/nginx.conf 找到文件后，我们通过sudo vi /usr/local/etc/nginx/nginx.conf命令来修改默认的端口号，位置如下： 12345server { listen 80; server_name localhost; #...} 修改后保存退出。 最后不要忘记重启Nginx服务。 1➜ ~ brew services restart nginx 解压包方式首先去nginx官方提供 http://nginx.org/download 的下载地址去挑选自己中意的版本，下面以1.17.7版本示例： http://nginx.org/download/nginx-1.17.7.tar.gz 点击下载完成后解压安装即可（注意编译环境，可能会缺少一些依赖库，本机安装对应的依赖就可以了） 1234567891011121314# 解压nginxtar -xvf nginx-1.17.7.tar.gz# 进入目录cd nginx-1.17.7# 配置./configure --prefix=/usr/local/nginx# 编译sudo make# 安装sudo make install# 进入nginx执行目录cd /usr/local/nginx/sbin# 启动nginx./nginx 安装完成如果访问 http://127.0.0.1 可以看到Welcome to nginx!字样，说明我们已经安装成功了。 示例项目为了演示更新服务用户无痛感知，我们先来创建一个简单的SpringBoot示例项目，在项目内添加一个测试接口，项目pom.xml依赖如下所示： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 示例接口创建一个名为TestController的测试控制器，如下所示： 12345678910111213141516/** * 测试控制器 * * @author 恒宇少年 */@RestController@RequestMapping(value = &quot;/test&quot;)public class TestController { @Autowired private ServerProperties serverProperties; @GetMapping public String hello() { return &quot;请求分发到了，端口号：&quot; + serverProperties.getPort() + &quot;的服务，接口访问成功.&quot;; }} 配置转发我们测试所需要的请求接口已经准备好了，接下来需要在访问nginx时将请求转发到我们测试的接口，配置转发时需要用到nginx的两个关键字，分别是upstream、location。 upstream：服务器组，配置请求分发到组内多台服务器。 location：转发的路径前缀，如：”/user/“，当我们访问http://127.0.0.1/user/1时，就会执行该location的转发业务。 upstream转发流程如下图所示： 配置UpStream在nginx.conf文件http内添加转发的服务器组(upstream)，如下所示： 123456# 负载配置upstream test { server 127.0.0.1:8080 weight=1; server 127.0.0.1:9090 weight=2; server 127.0.0.1:9000 backup;} 配置Location在上面已经配置好了服务器组，我们需要把名为test的服务器组作为代理的方式配置在location，在location的server下新增一个location，如下所示： 12345678910# 配置&quot;/lb/&quot;路径的请求全部转发到本地8080端口location /lb/ { proxy_pass http://test/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 50; proxy_read_timeout 50; proxy_send_timeout 50;} 重启Nginx我这里是使用brew的方式安装的nginx，所以重启的命令如下所示： 1brew services restart nginx 如果你是安装包的方式安装： 1234# 进入安装包目录cd /usr/local/nginx/sbin# 重载./nginx -s reload 权重配置在nginx中有一个权重的概念，根据权重值的大小来控制请求流量，当权重的配值越大时，流量分发就会越多，我们在test服务器组内配置权重解释： server 127.0.0.1:8080 weight 1; 权重占比为1/3，每3次请求会转发1次到这台服务器上。 server 127.0.0.1:9090 weight 2; 权重占比为2/3，每3次请求会转发2次到这台服务器上。 备用配置当我们在upstream内的server尾部添加backup时，表示这台服务器是备用服务器，只有其他服务器都停机时才会启用，我们更新时其实就利用的这一点。 运行测试为了演示方便我们直接将本章测试项目package打包后，通过--server.port来指定运行的端口号来模拟多台服务器的场景。 123456# 启动127.0.0.1:8080服务器java -jar target/use-nginx-loadbalance-upgrade-service-0.0.1-SNAPSHOT.jar --server.port=8080# 启动127.0.0.1:9090服务器java -jar target/use-nginx-loadbalance-upgrade-service-0.0.1-SNAPSHOT.jar --server.port=9090# 启动127.0.0.1:9000备用服务器java -jar target/use-nginx-loadbalance-upgrade-service-0.0.1-SNAPSHOT.jar --server.port=9000 注意：使用多个终端窗口运行服务。 在nginx.conf&gt;server中配置location的转发条件为/lb/路径前缀，所以我们访问 http://127.0.0.1/lb/test （由于nginx监听的端口号是80，所以通过nginx访问转发时不需要携带端口号）就会被转发到test服务器组内的服务器上。 测试点：权重转发1234567891011curl http://localhost/lb/test端口号：8080，接口访问成功. curl http://localhost/lb/test端口号：9090，接口访问成功.curl http://localhost/lb/test 端口号：9090，接口访问成功.curl http://localhost/lb/test 端口号：8080，接口访问成功. 根据访问的结果来看，8080端口号的服务是每3次中请求了1次，而9090则是每3次中请求了2次，这一点正是符合我们配置的权重（weight），测试通过。 测试点：备用生效我们把8080、9090这两个服务都停掉，再次访问 http://127.0.0.1/lb/test 。 12345678curl http://localhost/lb/test端口号：9000，接口访问成功.curl http://localhost/lb/test 端口号：9000，接口访问成功. curl http://localhost/lb/test 端口号：9000，接口访问成功. 可以看到我们的备用服务器启用了，已经把全部的请求流量转发到9000这台服务上，测试通过。 敲黑板，划重点当我们把8080、9090都停掉时，备用服务器会启用，这时我们就可以来更新8080、9090这两个服务的运行代码，更新完成后重启，只要8080、9090这两台服务器有一台处于运行状态，nginx就不会把流量分发到备用的9000，以此类推把全部的服务都更新完成。 代码示例如果您喜欢本篇文章请为源码仓库点个Star，谢谢！！！本篇文章示例源码可以通过以下途径获取，目录为use-nginx-loadbalance-upgrade-service： Gitee：https://gitee.com/hengboy/spring-boot-chapter","link":"/use-nginx-loadbalance-upgrade-service.html"},{"title":"Spring Boot中使用Swagger2构建强大的RESTful API文档","text":"由于Spring Boot能够快速开发、便捷部署等特性，相信有很大一部分Spring Boot的用户会用来构建RESTful API。而我们构建RESTful API的目的通常都是由于多终端的原因，这些终端会共用很多底层业务逻辑，因此我们会抽象出这样一层来同时服务于多个移动端或者Web前端。 这样一来，我们的RESTful API就有可能要面对多个开发人员或多个开发团队：IOS开发、Android开发或是Web开发等。为了减少与其他团队平时开发期间的频繁沟通成本，传统做法我们会创建一份RESTful API文档来记录所有接口细节，然而这样的做法有以下几个问题： 由于接口众多，并且细节复杂（需要考虑不同的HTTP请求类型、HTTP头部信息、HTTP请求内容等），高质量地创建这份文档本身就是件非常吃力的事，下游的抱怨声不绝于耳。 随着时间推移，不断修改接口实现的时候都必须同步修改接口文档，而文档与代码又处于两个不同的媒介，除非有严格的管理机制，不然很容易导致不一致现象。 为了解决上面这样的问题，本文将介绍RESTful API的重磅好伙伴Swagger2，它可以轻松的整合到Spring Boot中，并与Spring MVC程序配合组织出强大RESTful API文档。它既可以减少我们创建文档的工作量，同时说明内容又整合入实现代码中，让维护文档和修改代码整合为一体，可以让我们在修改代码逻辑的同时方便的修改文档说明。另外Swagger2也提供了强大的页面测试功能来调试每个RESTful API。具体效果如下图所示：下面来具体介绍，如果在Spring Boot中使用Swagger2。首先，我们需要一个Spring Boot实现的RESTful API工程，若您没有做过这类内容，建议先阅读Spring Boot构建一个较为完成的RESTful APIs和单元测试。下面的内容我们会以教程样例中的Chapter3-1-1进行下面的实验（Chpater3-1-5是我们的结果工程，亦可参考）。 添加Swagger2依赖在pom.xml中加入Swagger2的依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt; 创建Swagger2配置类在Application.java同级创建Swagger2的配置类Swagger2。 1234567891011121314151617181920212223242526@Configuration@EnableSwagger2public class Swagger2 { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.didispace.web&quot;)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;Spring Boot中使用Swagger2构建RESTful APIs&quot;) .description(&quot;更多Spring Boot相关文章请关注：https://blog.didispace.com/&quot;) .termsOfServiceUrl(&quot;https://blog.didispace.com/&quot;) .contact(&quot;程序猿DD&quot;) .version(&quot;1.0&quot;) .build(); }} 如上代码所示，通过@Configuration注解，让Spring来加载该类配置。再通过@EnableSwagger2注解来启用Swagger2。 再通过createRestApi函数创建Docket的Bean之后，apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中）。select()函数返回一个ApiSelectorBuilder实例用来控制哪些接口暴露给Swagger来展现，本例采用指定扫描的包路径来定义，Swagger会扫描该包下所有Controller定义的API，并产生文档内容（除了被@ApiIgnore指定的请求）。 添加文档内容在完成了上述配置后，其实已经可以生产文档内容，但是这样的文档主要针对请求本身，而描述主要来源于函数等命名产生，对用户并不友好，我们通常需要自己增加一些说明来丰富文档内容。如下所示，我们通过@ApiOperation注解来给API增加说明、通过@ApiImplicitParams、@ApiImplicitParam注解来给参数增加说明。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@RestController@RequestMapping(value=&quot;/users&quot;) // 通过这里配置使下面的映射都在/users下，可去除public class UserController { static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;()); @ApiOperation(value=&quot;获取用户列表&quot;, notes=&quot;&quot;) @RequestMapping(value={&quot;&quot;}, method=RequestMethod.GET) public List&lt;User&gt; getUserList() { List&lt;User&gt; r = new ArrayList&lt;User&gt;(users.values()); return r; } @ApiOperation(value=&quot;创建用户&quot;, notes=&quot;根据User对象创建用户&quot;) @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;) @RequestMapping(value=&quot;&quot;, method=RequestMethod.POST) public String postUser(@RequestBody User user) { users.put(user.getId(), user); return &quot;success&quot;; } @ApiOperation(value=&quot;获取用户详细信息&quot;, notes=&quot;根据url的id来获取用户详细信息&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;) @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.GET) public User getUser(@PathVariable Long id) { return users.get(id); } @ApiOperation(value=&quot;更新用户详细信息&quot;, notes=&quot;根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;) }) @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.PUT) public String putUser(@PathVariable Long id, @RequestBody User user) { User u = users.get(id); u.setName(user.getName()); u.setAge(user.getAge()); users.put(id, u); return &quot;success&quot;; } @ApiOperation(value=&quot;删除用户&quot;, notes=&quot;根据url的id来指定删除对象&quot;) @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;) @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.DELETE) public String deleteUser(@PathVariable Long id) { users.remove(id); return &quot;success&quot;; }} 完成上述代码添加上，启动Spring Boot程序，访问：http://localhost:8080/swagger-ui.html。就能看到前文所展示的RESTful API的页面。我们可以再点开具体的API请求，以POST类型的/users请求为例，可找到上述代码中我们配置的Notes信息以及参数user的描述信息，如下图所示。 API文档访问与调试在上图请求的页面中，我们看到user的Value是个输入框？是的，Swagger除了查看接口功能外，还提供了调试测试功能，我们可以点击上图中右侧的Model Schema（黄色区域：它指明了User的数据结构），此时Value中就有了user对象的模板，我们只需要稍适修改，点击下方“Try it out！”按钮，即可完成了一次请求调用！ 此时，你也可以通过几个GET请求来验证之前的POST请求是否正确。 相比为这些接口编写文档的工作，我们增加的配置内容是非常少而且精简的，对于原有代码的侵入也在忍受范围之内。因此，在构建RESTful API的同时，加入swagger来对API文档进行管理，是个不错的选择。 完整结果示例可查看Chapter3-1-5。 参考信息 Swagger官方网站","link":"/use-swagger2-build-restful-api.html"},{"title":"Spring声明式事务为何不回滚","text":"疑问，确实像往常一样在service上添加了注解 @Transactional，为什么查询数据库时还是发现有数据不一致的情况，想想肯定是事务没起作用，出现异常的时候数据没有回滚。于是就对相关代码进行了一番测试，结果发现一下踩进了两个坑，确实是事务未回滚导致的数据不一致。 下面总结一下经验教训： Spring事务的管理操作方法下面先总结一下Spring的事务管理方式，spring支持两种事务管理的操作方式，编程式的和声明式的（xml或者注解）。 编程式的事务管理 实际应用中很少使用 通过使用TransactionTemplate手动管理事务 声明式的事务管理 开发中推荐使用（代码侵入最少） Spring的声明式事务是通过AOP实现的 主要掌握声明式的事务管理。 spring事务不回滚的两个原因总结一下导致事务不回滚的两个原因，一是Service类内部方法调用，二是try…catch异常。 1. Service类内部方法调用大概就是 Service 中有一个方法 A，会内部调用方法 B， 方法 A 没有事务管理，方法 B 采用了声明式事务，通过在方法上声明 Transactional 的注解来做事务管理。示例代码如下： 123456789101112131415161718192021@Servicepublic class RabbitServiceImpl implements RabbitService { @Autowired private RabbitDao rabbitDao; @Autowired private TortoiseDao tortoiseDao; @Override public Rabbit methodA(String name){ return methodB(name); } @Transactional(propagation = Propagation.REQUIRED, isolation = Isolation.READ_COMMITTED) public boolean methodB(String name){ rabbitDao.insertRabbit(name); tortoiseDao.insertTortoise(name); return true; } } 单元测试代码如下： 1234567891011121314151617public class RabbitServiceImplTest { @Autowired private RabbitService rabbitService; // 事务未开启 @Test public void testA(){ rabbitService.methodA(&quot;rabbit&quot;); } // 事务开启 @Test public void testB(){ rabbitService.methodB(&quot;rabbit&quot;); }} 从上一节中可以看到，声明式事务是通通过AOP动态代理实现的，这样会产生一个代理类来做事务管理，而目标类（service）本身是不能感知代理类的存在的。 对于加了@Transactional注解的方法来说，在调用代理类的方法时，会先通过拦截器TransactionInterceptor开启事务，然后在调用目标类的方法，最后在调用结束后，TransactionInterceptor 会提交或回滚事务，大致流程如下图： 总结，在方法 A 中调用方法 B，实际上是通过“this”的引用，也就是直接调用了目标类的方法，而非通过 Spring 上下文获得的代理类，所以事务是不会开启的。 2. try…catch异常在一段业务逻辑中对数据库异常进行了处理，使用了try…catch子句捕获异常并throw了一个自定义异常，这种情况导致了事务未回滚，示例代码如下： 12345678910@Transactional(propagation = Propagation.REQUIRED, isolation = Isolation.READ_COMMITTED)public boolean methodB(String name) throws BizException { try { rabbitDao.insertRabbit(name); tortoiseDao.insertTortoise(name); } catch (Exception e) { throw new BizException(ReturnCode.EXCEPTION.code, ReturnCode.EXCEPTION.msg); } return true;} BizException的定义如下： 123public class BizException extends Exception { // 自定义异常} 上面代码中的声明式事务在出现异常的时候，事务是不会回滚的。在代码中我虽然捕获了异常，但是同时我也抛出了异常，为什么事务未回滚呢？猜测是异常类型不对，于是开始查询原因，翻看了Spring的官方文档，找到了答案。下面是翻译自Spring官网。 17.5.3 声明式事务的回滚上一节中介绍了如何设置开启Spring事务，一般在你的应用的Service层代码中设置，这一节将介绍在简单流行的声明式事务中如何控制事务回滚。 在Spring FrameWork 的事务框架中推荐的事务回滚方法是，在当前执行的事务上下文中抛出一个异常。如果异常未被处理，当抛出异常调用堆栈的时候，Spring FrameWork 的事务框架代码将捕获任何未处理的异常，然后并决定是否将此事务标记为回滚。 在默认配置中，Spring FrameWork 的事务框架代码只会将出现runtime, unchecked 异常的事务标记为回滚；也就是说事务中抛出的异常时RuntimeException或者是其子类，这样事务才会回滚（默认情况下Error也会导致事务回滚）。在默认配置的情况下，所有的 checked 异常都不会引起事务回滚。 注：Unchecked Exception包括Error与RuntimeException. RuntimeException的所有子类也都属于此类。另一类就是checked Exception。 你可以精确的配置异常类型，指定此异常类事务回滚，包括 checked 异常。下面的xml代码片段展示了如何配置checked异常引起事务回滚，应用自定义异常类型：123456&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;txManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;get*&quot; read-only=&quot;true&quot; rollback-for=&quot;NoProductInStockException&quot;/&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 与其有同等作用的注解形式如下：123@Transactional(rollbackForClassName={&quot;NoProductInStockException&quot;})或者@Transactional(rollbackFor={NoProductInStockException.class}) 在你遇到异常不想回滚事务的时候，同样的你也可指定不回滚的规则，下面的一个例子告诉你，即使遇到未处理的 InstrumentNotFoundException 异常时，Spring FrameWork 的事务框架同样会提交事务，而不回滚。 123456&lt;tx:advice id=&quot;txAdvice&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;updateStock&quot; no-rollback-for=&quot;InstrumentNotFoundException&quot;/&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 与其有同样作用的注解形式如下： 123@Transactional(noRollbackForClassName={&quot;InstrumentNotFoundException&quot;})或者@Transactional(noRollbackFor={InstrumentNotFoundException.class}) 还有更灵活的回滚规则配置方法，同时指定什么异常回滚，什么异常不回滚。当Spring FrameWork 的事务框架捕获到一个异常的时候，会去匹配配置的回滚规则来决定是否标记回滚事务，使用匹配度最强的规则结果。因此，下面的配置例子表达的意思是，除了异常 InstrumentNotFoundException 之外的任何异常都会导致事务回滚。12345&lt;tx:advice id=&quot;txAdvice&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; rollback-for=&quot;Throwable&quot; no-rollback-for=&quot;InstrumentNotFoundException&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 你也可以通过编程式的方式回滚一个事务，尽管方法非常简单，但是也有非常强的代码侵入性，使你的业务代码和Spring FrameWork 的事务框架代码紧密的绑定在一起，示例代码如下：12345678public void resolvePosition() { try { // some business logic... } catch (NoProductInStockException ex) { // trigger rollback programmatically TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); }} 如果可能的话，强烈推荐您使用声明式事务方式回滚事务，对于编程式事务，如果你强烈需要它，也是可以使用的，but its usage flies in the face of achieving a clean POJO-based architecture.(没懂…) 看完官方文档这节内容找到了问题的答案，原来是因为我们自定义的异常不是 RuntimeException。我的解决办法是，在注解@Transactional中添加 rollbackFor={BizException.class}。可能你会问我为什么不将自定义异常修改为继承RuntimeException，因为我需要BizException是一个checked 异常。 结束语：终于将spring事务中的异常回滚机制搞明白啦，欢迎读者在评论区添加其他导致spring事务不回滚的原因。","link":"/why_doesnot_spring_declarative_transactions_roll_back.html"},{"title":"你的微服务敢独立交付么？","text":"最近经常在项目或是社区里听到大家谈论微服务架构，但谈论的焦点更多集中在微服务拆分，分布式架构，微服务门槛，DevOps配套设施等话题上。 但是在我眼里，真正能称之为微服务架构的少之又少。原因也很简单，我所见到的很多所谓的微服务架构项目，大多都没有做到微服务架构的一个基本要求：服务的独立部署（交付）。 这里的独立部署和自动化部署还不是一个概念，服务的自动化部署相对简单，已有大量的工具可以帮助我们做到。但是这里所谈的独立部署，我认为关键和难点并不在于“部署”，而在于“独立”。 如果失去了服务独立部署（交付）的能力，一个微服务架构的威力将大打折扣，我们的系统虽然在物理上被拆分成了多个小的服务，但是如果从最终交付的角度来看，仍然是以一个整体存在的，就像单体应用一样，存在诸多的问题。 为什么服务的独立交付并不简单？那为什么不能让每一个服务都独立部署到产品环境呢？问题的答案是：不是不能，而是不敢！ 为了表达清楚，让我们来看个例子吧。 像下图一样，我现在就是那个程序员帅哥（本色出演），突然有一天心血来潮，动手开发了一个网上商城。代码Push到Github并通过CI构建持续交付流水线，最终自动化部署到云端产品环境，供用户访问使用。 随着用户和访问量的增加，需求和功能也越来越多，系统也变得越发复杂。 从网上了解到最近有个叫微服务的架构非常火爆，我也赶了回时髦，当然也觉得这种架构确实可以帮助我解决现在的一些问题。 经过对系统的分析，我将商城的后台部分拆分出了3个服务，为了简单我们就称之为ABC三个服务。我们假设一个比较极端的情况，三个服务相互调用（先不考虑这样是否合理），每个服务通过自己的持续交付流水线独立部署到产品环境。当前产品环境的各个服务的版本是：A：1.0、B：2.0、C：3.0 一切都非常完美是不是？看！我们已经做到了服务的独立部署！So easy~ 当然，事情肯定不会那么简单。 问题出现在当我对A服务做了一次新的提交之后，A服务的最新版本升级到了1.1。不幸的是，这个新的版本意外的破坏了A与B之间的契约，错误的调用了B的接口，导致出现了错误。 虽然我的A服务和B服务都有比较完备的UT（单元测试），但因为UT无法发现服务之间的集成是否被破坏，所以只有UT作为质量保障的A服务持续交付流水线也自然没有能力发现AB服务集成被破坏的这个问题。最终导致存在问题的A1.1版本被部署到了产品环境，产品环境出现了严重的Bug。 请问在座的同学，碰到这样的情况，你会如何处理？ “加集成测试啊！” 这位同学说的极是，我这么聪明自然也想到了这一点，不就是要测集成吗？UT干不了就加集成测试不就成了。 为了统一语言，毕竟对于各种测试的叫法太容易引起混淆，参考Martin Fowler在《微服务测试策略》中的定义，我们在本文中将这种测试多服务集成的测试统一称作端到端测试（End-to-End tests，简称E2E测试）。 添加了E2E测试之后，我的交付流水线就变成了下面这个样子。因为有了E2E测试的存在，问题迎刃而解，当A服务的新版本破坏了与B服务的集成时，E2E测试就会及时诊断出来，并阻止A服务的最新版本向产品环境流动，保证产品环境不被破坏。 这样看似没有什么问题，通过添加E2E测试，解决了服务间集成的验证问题，但在不知不觉中，我们也失去了微服务架构的那个重要的特性：“服务的独立交付”。 怎么讲？别急，我们再往下看。 假设A服务的修复过程中，B和C服务也提交了新的代码，我们假设这两个提交是没有问题的，但因为A服务的1.1版本导致E2E测试挂掉的问题还没有被修复，所以B和C的新版本也被E2E测试拦了下来，此时的E2E测试就像是一个亮起红灯的路口，阻塞了所有服务通往产品环境的通道。 所以说，随着集中E2E测试的添加，质量被保障的同时，我们的“微服务架构”也已悄然失去了服务独立交付的能力，杀敌一千自损八百，损失惨重！ 这并不是我假想的场景，在我自己经历的几个真实项目中，这个问题都在一直困扰着我们。带来了各种各样的衍生问题，例如E2E测试长时间失败，无人修复，修复难度大，服务交付堵塞，为了保持交付通路畅通还不得不引入同样存在很大副作用的CodeFrezze机制和提交Token机制等。 可以看到，虽然我们能够在代码库，在部署结构上，甚至在组织上进行服务化拆分，但就因为这最后一个交付的十里路口，最后这一个红绿灯，让所有的服务又纠缠在了一起，所有的服务化拆分形同虚设，最终我们得到的也只是一个看起来像微服务架构的单体应用而已。 拆除红绿灯，各行其道，收复失地！那，如何才能将这个“红绿灯”拆除，让服务可以在有质量保障的前提下还可以做到独立交付呢？这就是本文要解决的问题，让我们继续往下看。 我的解决方法其实也很简单：Inline E2E tests。 即并不添加新的集中的Pipeline做E2E测试，而是为每一个服务的Pipeline都添加一个相同的E2E测试的Stage，就相当于将E2E测试Inline到每个服务各自的部署流水线中，如下图所示。 其实Inline E2E测试还不是最关键的，最关键的变化点就是假设A服务有了新的提交，运行到A服务自己Pipeline的E2E测试的时候，此时的E2E测试并不是像之前一样获取B和C服务的最新代码库版本做集成验证，而获取当前产品环境上的B和C服务的已部署当前版本做集成验证。 例如，如图所示A服务的版本从1.0升级到了1.1，当前产品环境的B和C的版本是2.0和3.0。在执行A服务Pipeline上的E2E测试时，验证出A1.1和B2.0集成存在问题，测试变红，Pipeline挂掉，从而阻断了A服务的1.1版本部署到产品环境，保证了产品环境不会被A的1.1版本破坏。 同样，假设A还没有被修复之前，B也有了新的提交，产生了一个新的版本B2.1，这时在B服务Pipeline上的E2E测试并不获取当前A服务的代码库最新版本1.1做集成测试，而是获取产品环境上的当前版本A1.0版本做集成测试。我们假设B2.1和A1.0之间的集成没有问题，测试通过，所以B的2.1版本就被成功的交付到了产品环境，而此时产品环境的A服务的版本仍是1.0。 看！服务之间的阻塞被神奇的解决了，服务再也不会被堵在一个统一的十字路口，而是各行其道，A的车道出了事故，是A的问题，应该由A来承担后果和解决问题，不应该影响到其他服务，其他服务依然可以持续的交付到产品环境。 向前看是持续集成，向后看是持续交付！看到这里可能有些小伙伴会感到有些失望。咋呼半天，不就是将E2E测试整到每个服务的Pipeline里，再把获取版本从最新代码改成产品环境么？有啥厉害的。 但是，在我看来，这个看似简单的变化，意义却是重大的：它揭示了“持续集成”和“持续交付”的一个主要区别。 “持续集成”和”持续交付”，这两个概念相信大家一定都不陌生，在软件领域也被提了不少年头了，不算什么新概念新技术。但对于这两个概念，我们经常一起提及，也经常混淆，搞不清楚两者的区别到底是什么，可能认为持续交付只不过是持续集成的演进版，新瓶装旧酒而已。 但其实它们却有着本质的区别。 “持续集成”关注的是各个集成单元之前最新版本的集成问题，即是不是某个集成单元的最新版本破坏了系统整体的集成，我管这种视角叫：向“前”看。 而“持续交付”关注的应该不是集成单元最新版本之间的集成问题，而是某个集成单元的最新版本是否可以（能和敢）部署到产品环境。换句话说就是维持产品环境的其他服务不变，只将当前集成单元的最新版本部署到产品环境，产品是否依然可用，不被破坏。所以在“持续交付”的视角下，应该关注的是当前集成单元与产品环境上的其他服务的版本是否兼容，我管这种视角叫：向“后”看。 向前看是持续集成，向后看才是持续交付，如果前后都不看那就是在裸奔。 但是肯定早有同学在心里疑惑，将E2E测试下放到每一个服务自己的Pipeline中，靠谱么？是不是太重了？根据测试金字塔，E2E测试应该是属于靠近金字塔顶端的测试种类，无论从数量和覆盖范围应该也都不会太多，怎么能靠它来保障服务之间的所有集成点和契约呢？ 主角登场-契约测试细心的同学肯定已经发现上面最后一张图中，我已经悄悄的把E2E测试变为了CT，即Contract Test，契约测试。 契约测试也是这两年伴随微服务架构的兴起，经常被提及的一种比较新的测试类型。在测试金字塔中，他的位置介于E2E和Component Tests（可以理解成单个服务的API测试）之间。 简单的理解，契约测试就是一种可以用类似于单元测试的技术验证两两服务之间集成的测试技术。它相比于更低层次的单元测试的优势是可以测集成（两两服务之间），相比于更高层次的E2E测试的优势是实现方式上又类似于单元测试，更轻量，跑的更快，覆盖的范围也自然可以更广更细。 使用契约测试替换掉E2E测试之后，整个架构也会变得更复杂一些，目前契约测试的框架也有很多，如大家常常提到的Pact或是SpringContracts等等。这里我先以Pact为例予以说明，其他框架实现上可能有些差别，但是思路是一致的。 A服务调用B服务的一个API，我们就称为A和B之间存在了一个契约，即B应该按照这个契约提供一个满足契约要求的API，而A也应该按照这个契约约定的方式来调用B的这个API。在这个过程中A作为调用方，我们称之为Consumer端。B作为被调用方，我们称之为Provider端。 如果A和B都履行契约，按照契约定义的约定调用和被调用，我们就可以认为集成不会有问题。但无论是B擅自修改了API破坏了契约，还是A擅自修改了调用API的方式破坏了契约，都会导致契约被破坏，反应到测试上就是契约测试会失败，反应到产品上就是功能被破坏，出现Bug。 每个契约，例如A-&gt;B，都会有Consumer端和Provider端生成的两个产出物：分别是a-b.consumer.json.1.1(由Consumer端生成的契约文件，所以版本也是Consumer端A的版本号)和a-b.provider.jar.2.0（由Provider端生成的契约验证测试包，他由Provider端生成，所以版本是B的版本）。这个jar包其实就是一组测试，他的输入是a-b.consumer.json，产出则是测试的结果，也就是契约的验证结果：成功或是失败。 可以把A服务产出的契约文件a-b.consumer.json.1.1想象成一把钥匙，把B服务产出的Provider端的测试a-b.provider.jar.2.0想象成一把锁。那契约测试的执行过程就像是用这把钥匙试着去打开这把锁：如果可以打开，我们认为这A1.1-&gt;B2.0的契约是满足的，反之契约就是被破坏了。 值得注意的一点就是，契约测试不像E2E测试，它是有方向的，所以我们看到a-b和b-a是两个不同的契约。 所以，只有当A1.1-&gt;B2.0和B2.0-&gt;A1.1双向的契约都被验证通过后，我们才能认为A1.1版本和B2.0版本的集成是没有问题的。 用契约测试替换E2E测试回到前面的例子上，假设我们已经构建了ABC三个服务两两之间的契约测试。此时，A服务有了新的提交升级到了1.1版本，那我们如何才能通过契约测试来验证A1.1版本能否交付到产品环境呢？ 答案就是只要通过A的1.1版本的最新代码，生成所有A作为Consumer端的契约文件（a-b.consumer.json.1.1和a-c.consumer.json.1.1），用这两把“钥匙”去试着开（作为输入执行Provider端测试）产品环境对应的两把“锁”（a-b.provider.jar.2.0和a-c.provider.jar.3.0）。 如果都可以打开（测试通过）的话，就证明A的新版本1.1作为Consumer端与产品环境的B和C服务是兼容的。 等等，别着急，还没完…… 因为我们还需要考虑A作为Provider的情况，做法还是通过A的1.1版本的最新代码生成A版本作为Provider端的契约测试（b-a.provider.jar.1.1和c-a.provider.jar.1.1），拿着这两把“新锁”，然后试着用产品环境上的两把“钥匙”（b-a.consumer.json.2.0和c-a.consumer.json3.0）去开。 如果也都可以打开（测试通过）的话，就证明A的新版本1.1作为Provider端与产品环境的B和C服务也是兼容的。 至此，当验证了A的新版本1.1无论是作为调用端还是被调用端都与产品环境上的其他服务契约满足后，我们就认为A1.1与B2.0和C3.0集成是没有问题的，也就代表A1.1可以被放心地部署到产品环境中，替代现在的1.0版本。 最后，敲黑板划重点 微服务架构下的独立部署（交付）很重要，但往往容易被忽视，没有被引起足够重视。 为了实现微服务的独立持续交付，我们要向“后”看，不要向“前”看，即关注当前变更服务与部署环境中其他服务的兼容性而不是关注当前变更服务与其他服务最新版本的兼容性。 用契约测试来替代E2E测试，降低测试成本，提高测试覆盖，尽早测试。并通过不断地完善契约管理，保障微服务架构质量和避免微服务架构腐化僵化。","link":"/your-microservice-can-deploy-single.html"}],"tags":[{"name":"技术杂谈","slug":"技术杂谈","link":"/tags/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"ApiBoot","slug":"ApiBoot","link":"/tags/ApiBoot/"},{"name":"日志组件","slug":"日志组件","link":"/tags/%E6%97%A5%E5%BF%97%E7%BB%84%E4%BB%B6/"},{"name":"OAuth2","slug":"OAuth2","link":"/tags/OAuth2/"},{"name":"Spring Security","slug":"Spring-Security","link":"/tags/Spring-Security/"},{"name":"Quartz","slug":"Quartz","link":"/tags/Quartz/"},{"name":"Swagger2","slug":"Swagger2","link":"/tags/Swagger2/"},{"name":"BFF","slug":"BFF","link":"/tags/BFF/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Eureka","slug":"Eureka","link":"/tags/Eureka/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"分支管理","slug":"分支管理","link":"/tags/%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"GitHub Action","slug":"GitHub-Action","link":"/tags/GitHub-Action/"},{"name":"Map","slug":"Map","link":"/tags/Map/"},{"name":"OpenStreet","slug":"OpenStreet","link":"/tags/OpenStreet/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"Jvm","slug":"Jvm","link":"/tags/Jvm/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"配置中心","slug":"配置中心","link":"/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"Nacos","slug":"Nacos","link":"/tags/Nacos/"},{"name":"注册中心","slug":"注册中心","link":"/tags/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Geo","slug":"Geo","link":"/tags/Geo/"},{"name":"RocketMQ","slug":"RocketMQ","link":"/tags/RocketMQ/"},{"name":"分布式事务","slug":"分布式事务","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"SpringBoot1.x","slug":"SpringBoot1-x","link":"/tags/SpringBoot1-x/"},{"name":"文章目录","slug":"文章目录","link":"/tags/%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95/"},{"name":"SpringBoot2.x","slug":"SpringBoot2-x","link":"/tags/SpringBoot2-x/"},{"name":"文章列表","slug":"文章列表","link":"/tags/%E6%96%87%E7%AB%A0%E5%88%97%E8%A1%A8/"},{"name":"网关","slug":"网关","link":"/tags/%E7%BD%91%E5%85%B3/"}],"categories":[{"name":"技术杂谈","slug":"技术杂谈","link":"/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/categories/SpringBoot/"},{"name":"ApiBoot","slug":"ApiBoot","link":"/categories/ApiBoot/"},{"name":"微服务","slug":"微服务","link":"/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"地图服务","slug":"地图服务","link":"/categories/%E5%9C%B0%E5%9B%BE%E6%9C%8D%E5%8A%A1/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"MongoDB","slug":"MongoDB","link":"/categories/MongoDB/"},{"name":"Quartz","slug":"Quartz","link":"/categories/Quartz/"},{"name":"消息队列","slug":"消息队列","link":"/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"}],"pages":[{"title":"关于我","text":"","link":"/about/index.html"},{"title":"友链","text":"","link":"/friends-link/index.html"},{"title":"全网最优惠的极客时间购买通道","text":"恒宇少年为爱学习的你准备了专属的极客时间优惠券199元大礼包，点击领取：http://gk.link/a/10f7u 如果您身边的朋友也需要，那么请把这个页面分享给他吧~ 推荐一下极客时间出品的内容中，个人觉得非常不错的的专栏！ 微服务 玩转Spring全家桶 这门课程是极客时间订阅最多的视频课，同时也是市面上性价比最高的付费教程，20000+订阅，课程由丁雪丰（市面上畅销书《SpringBoot实战》和《Spring攻略》的译者）主讲，详述 Spring、Spring Boot 和 Spring Cloud 技术应用，目前已经开始讲 Cloud 和 Cloud Native 部分了。最后课程还会带你用相关技术搭建一个线上咖啡馆项目，通过实战把所有知识点串联起来。 微服务架构实战160讲 资深架构师杨波老师在《微服务架构实践160讲》视频课程中，通过原理讲解和实战操作的方式，帮助你从0到1深入理解主流微服务技术栈组建及架构，帮你踏上从程序员到架构师的进阶之路。随着课程难度的提升，还会带有字幕。学习起来更轻松。 Spring Boot 与 Kubernetes 云原生微服务实践 \"平时虽然学习了很多微服务理论，但是在真正落地实施微服务架构的时候，仍然会感到手足无措。我们都知道微服务、云原生、SpringBoot 和 Kubernetes，是当前互联网行业，尤其是主流互联网公司的主流技术，该课程将这些技术做了很好的融合。讲师杨波，资深架构师，有15年以上的研发经验，一直在一线互联网公司(携程和拍拍贷)的基础框架部担任架构师和研发总监等职位，主导这些公司的微服务基础平台建设，有非常丰富的落地微服务经验，是妥妥的前辈了。\" 从0开始学微服务 服务化问题，是每个后端程序员迟早会面临的难题。专栏作者是新浪微博技术专家胡忠想，如果你刷微博，一定对他不陌生。胡大大几乎亲历了微博后端架构的每一次重大升级，积累了大量实战干货经验。他会由浅入深，带你从0开始构建微服务体系，给你提供一套可以快速落地的方法论。现在这个专栏已经有1.5W+人上车，你还不来吗？ 深入剖析Kubernetes 最近几年Kubernetes一跃成为容器王者，推荐Kubernetes项目维护者张磊的这个专栏，张磊从开发者和使用者的真实逻辑出发，帮你理解 Kubernetes 的核心特性，甚至从Docker诞生背景讲起，把设计原则和容器编排理念讲的明明白白。化繁为简，深入浅出。如果你觉得Kubernetes学习来晦涩难懂，那你一定要好好学学这个专栏。 Nginx核心知识100讲 Nginx，是应对高并发场景的万能药。掌握好 Nginx，便掌握了应对高并发以及海量数据处理的利器。陶辉的《Nginx 核心知识100讲》 就是出于能带你学好 Nginx 目的而设计的一个课程，从概念、代码再到实战，从 HTTP 到 OpenResty 等5大核心内容全覆盖。跟着他学，让你少走弯路，进阶 Nginx 高手！ 基础知识 左耳听风 左耳朵耗子，陈皓的专栏，他可是骨灰级程序员，圈内的大神。这个专栏集合了他20年技术经验和学习过程的总结，内容涉及分布式、编程范式、容器技术、AI、区块链、程序员练级、高效管理等等，算是极客时间价格最贵的专栏，但绝对超值，已有近3.5w人加入学习，而且耗子目前坚决不出书，说实话，未来的你如果想成为一名骨灰级程序员，这就是你的必修课程。 数据结构与算法之美 订阅量Top1，50000+程序员的算法课堂，整个专栏会涵盖100 多个算法真实项目场景案例，更难得的是它跟市面上晦涩的算法书籍不同的是，还手绘了一些清晰易懂的详解图（总共有 300 多张），市面上的大多数的算法教程都看过，走心的说，这个专栏是市面上唯一一门真正适用于工程师的专栏，作者是前Google工程师王争，相信会开启你的趣味学习算法之旅。 Java核心技术36讲 如果你想认真进阶Java或者准备面试，我推荐你好好看下《Java核心技术36讲》专栏。作者从核心知识点和能力出发，精选出36道Java面试题。每期针对1道题目，不仅会给出典型回答和考点分析，还会剖析Java核心知识点，将其讲清讲透，让你彻底领悟题目背后所考察的能力，帮你梳理复习Java知识体系。不管你是在准备面试、还是想进阶Java，你都可以通过这个专栏，提升Java技能。作者杨晓峰是前 Oracle 首席工程师，大家都知道，Java就是Oracle公司的，内部人的专栏，给你与众不同的视角。 MySQL实战45讲 这个专栏是数据库大神、前阿里资深技术专家丁奇写的，冲着作者买都不会亏。在这个专栏里，丁奇会帮你梳理出学习 MySQL 的主线知识，比如事务、索引、锁等，还会就开发过程中经常遇到的具体问题和你分析讨论，并且帮你理解问题背后的本质。你会收获 MySQL 核心技术详解与原理说明和36 个 MySQL 常见痛点问题解析。 深入拆解Java虚拟机 作为 Java 程序员，如果你不去深入理解 Java 虚拟机，那基本是与进阶加薪无缘了。这个专栏，我记得当时上线不到3天，已经有1W人订阅，异常火爆。1、Java虚拟机确实是面试大题；2、作者是郑雨迪，Oracle Labs高级研究员，专攻Graal编译器，也在研究HotSpot虚拟机项目。既然你要学JVM，那跟着Oracle内部专家学，是我想到最高效的方式。想认真进阶Java的同学，实力推荐这个专栏。 代码精进之路 普通的工程师堆砌代码，优秀的工程师优雅代码，卓越的工程师简化代码。如何写出优雅整洁易懂的代码是一门学问，也是软件工程实践里重要的一环。范学雷老师，现在是 Oracle 的主任工程师，也是 OpenJDK 和 Java 安全的评审成员。他是1998年参加工作的，20多年了一直在一线从事编程工作，04年的时候，就加入了 Java SE 团队，这15年来完整经历了JDK从1.5.0到12.0的整个迭代过程。希望这门专栏能够培养你的良好的编程习惯，这意味着你可以用更少的努力：时间和精力的投入，产生更干净、简洁、智能的代码。 程序员的数学基础课 数学基础的好坏，会直接决定一个程序员的发展潜力。很多大公司在招人时，都会优先考虑数学专业的毕业生。LinkedIn 资深数据科学家黄申，为你精讲程序员真正用得上的数学知识。超过 2.1 万人已加入学习，是极客时间最火爆的基础课程，专栏图文并茂，老师不仅会回答问题，还会在每一章节末尾总结「学习笔记」，可以保存下来随时复习。算法学不好？或许你该补补数学了。 Java并发编程实战 这应该是完结之后用户最舍不得呼声最高要求作者再写的一门课，真真带开了大家的并发编程世界。京东资深架构师宝令老师带你搭建一张「处理并发问题」全景图，找到并发根源，系统提升你的并发编程能力。如果你正在苦恼并发，那么这个专栏值得你花时间多次看、反复看、来回看。 玩转Git三剑客 作为程序员，怎么能不掌握Git、GitHub 和 GitLab 三剑客？就说B站代码泄漏的锅，Git背不背？[奸笑]《玩转Git三剑客》正在限时优惠中，62节视频课手把手带你从入门到精通，推荐～ 架构师修炼 从0开始学架构 每个程序员都有成为架构师的梦想，李运华，资深技术专家，14年技术老兵，超过十年架构经验，有自己一套独门的架构设计方法论，经受了超过3万学员锤炼，用户留言超过20万字。照着做，你也能成为架构师。 许式伟的架构课 印象中这个专栏上线不到 1 个月，就有 1.5W+ 订阅了。用四个字概括这个专栏，我觉得是：高屋建瓴——既有架构观，也有方法论，结合老许 20 年的经验沉淀，可以说是始于架构，又高于架构。老许是个传奇人物啊，毕业 2 年就成为 WPS 的首席架构师，创建七牛云后，他亲自架构设计，编写了大量核心代码。所谓「带你重新理解架构设计」，这话可不止说说而已。 技术管理 朱赟的技术管理课 技术人必须开拓自己的视野，去了解外面的技术实战、公司文化。而这个专栏可以带你走进硅谷，了解硅谷的开发流程、Core Review、热点技术等等。朱赟--前Airbnb技术经理、计算机博士，将自己近几年在硅谷的技术经历总结成文，囊括了技术管理、技术实践、硅谷文化、个人成长等5个维度的内容。无论你是初入职场的程序员，还是正面临技术转管理选择的职场中人，相信都能在这个专栏中有所收获，找到成长跃迁的最佳路径。 技术管理实战36讲 你能不能想像，一个教技术人怎样管理的专栏，竟然3个月订阅量过万？很多技术人觉得管理跟自己无关，但其实，超过80%的技术管理者，都是在没有明确表达管理意愿的情况下，被公司推到管理岗位的。你是管理者，可以对照自己，你是下属，也可以对照上司，很多事情就通透了。这个专栏的最大特点就是几十张管理卡片，张张经典，是作者带团队十几年总结的精华。 技术领导力实战笔记 《技术领导力300讲》用一句话总结：“都TM是人生经验啊！” ——100 位 CTO 的真知灼见都凝聚在这了，用二爷的话说：和作者中任何一位聊上一杯咖啡的时间，我都愿意付出比这 100 多块钱多得多的代价。由阿里、腾讯、京东、AWS 等上百家知名互联网公司的优秀技术领导者与 CEO 共同贡献内容，涵盖前沿技术、趋势分析、团队管理、软性技能等技术管理者关注的重点问题，手把手带你做管理。 必备技能 面试现场 很多人简历或面试被Pass，并不是因为专业技能不够。被录用的，也往往并不是专业技能最强的人。《面试现场》专栏，作者将立足应聘者的素质模型，带你全方位梳理经验、总结技能、找出潜能、调整动机，让你能够充分理解面试这个场景下的各个关键因素。系统告诉你怎样“知己知彼”准备面试，从而在“面试现场”高水准发挥。 程序员的法律课 批量爬虫企业数据，违法吗？搬运其他网站的用户评论到自家平台，侵权吗？开源代码的版权，到底怎么看？转正申请不被批，劳动合同你看懂了吗？无故被裁员，工资社保跟谁要？租房碰上黑中介，维权从哪儿入手？资深律师老周为程序员量身定制，选取了职场、技术、生活三个领域中与程序员联系最密切的 40 个法律问题，给到你最实用有效的处理办法。每天通勤路上 8 分钟，就能掌握一生必知的法律常识。","link":"/geektime/index.html"},{"title":"免费开源书籍","text":"书籍名称 贡献者 上架时间 SpringBoot1.5.9中文文档 DocsHome 2019-10-15 微服务：从设计到部署 DocsHome 2019-10-15 Nginx中文文档 DocsHome 2019-10-15","link":"/openbooks/index.html"},{"title":"拥抱开源的我","text":"拖延症晚期的我，原本打算从2018年开始编写开源框架，直到2019年年初我才着手开始准备。 愿景热爱编码的我，对开源这件事情一直向往。 我从2013年开始参加工作以来，大大小小的遇到了太多的三方框架集成的问题，爬过很多坑，走过很多的弯路，浪费了太多的宝贵时间！！！ 把浪费的时间做点别的事情不香吗？ 希望新进程序员在集成第三方框架时不再那么困难，不再翻阅一篇一篇的文章跟大量的官方文档，把集成的门槛降到最低，有相关框架的基础就可以快速上手，让大家更专注具体的业务实现。 开源组织在编写开源框架之前我建立了名为minbox-projects的开源组织，欢迎大家加入进来成为代码贡献者，成为开源组织内的一员。 minbox-projects内包含了 GroupId为&quot;org.minbox.framework&quot;的全部开源框架，放在一起方便进行维护升级。 组织地址 Gitee：https://gitee.com/minbox-projects GitHub：https://github.com/minbox-projects 官方文档：https://www.minbox.io 组织架构图 核心基础：提供了minbox-projects组织内开源框架的基础支持，公共使用的工具类、统一版本依赖等 开源框架：提供指定业务场景的解决方案，如：minbox-logging（分布式链路日志框架） 集成实践：基于SpringBoot进行封装minbox-projects开源组织内框架的Starter，统一命名为：api-boot-starter-xxx Apache Maven：统一使用oss-parent发布到Apache Maven中央仓库，可直接在项目内添加依赖使用，无需使用源码方式构建到本地 I. 分布式链路日志minbox-logging是一款分布式零侵入式、链路式请求日志分析框架。提供Admin端点进行采集日志、分析日志、日志告警通知、服务性能分析等。通过Admin Ui可查看实时链路日志信息、在线业务服务列表。 链路日志架构图 链路日志地址 Gitee：https://gitee.com/minbox-projects/minbox-logging GitHub：https://github.com/minbox-projects/minbox-logging 官方文档：https://www.minbox.io/logging II. ApiBootApiBoot为接口服务而生，基于SpringBoot完成扩展、自动化配置，通过封装一系列Starter来让调用者快速集成组件，降低学习、使用门槛，提高开发效率。 架构层级图 **公共模块(common)**：提供各个组件之间共用的工具类、枚举、常量、实体等。 **插件(plugins)**：封装第三方框架的中间件，会陆续从api-boot-plugins迁移到minbox-projects开源组织内 **统一版本(dependencies)**：提供使用的第三方依赖的指定版本，为api-boot-starter-xxx提供固定版本，使用依赖时类似SpringBoot可不用添加版本号 **自动化配置(autoconfigure)**：内部通过SpringBoot提供的自动化配置注解来条件式的实例化各个组件所需要的类，也是所有组件的统一自动化集成入口。 Starters：提供使用的具体依赖，每一个Starter内仅引用封装的第三方依赖以及api-boot-autoconfigure。 ApiBoot相关地址 Gitee：https://gitee.com/minbox-projects/api-boot GitHub：https://github.com/minbox-projects/api-boot 官方文档：https://apiboot.minbox.org 系列使用文章：https://blog.minbox.org/apiboot-all-articles.html","link":"/opensource/index.html"},{"title":"自律改变人生 - 每日签到福利","text":"焦虑的时代，我们都不能很好的静下心来阅读一篇文章，一本书，不能从文章中汲取我们需要的更多的知识点。希望通过恒宇少年的“自律改变人生”的签到计划来改变焦虑的你，希望大家不再焦虑、浮躁，走向人生巅峰，迎娶白富美。 什么是每日签到计划？每日签到计划是在一个规定的时间段内连续阅读文章，根据文章底部的小程序码进行签到，在签到结束的最后一天进行抽奖，签到次数越多中奖的概率就会越高，一般签到计划的周期为7天，也就是一周。 注意事项： 1. 每天的签到小程序码不是固定的，所以保存下来的签到不会计算在内; 2. 必须通过阅读文章，根据文章内的小程序码签到才会计算在内; 3. 签到计划是在微信公众号的文章中进行的，关注右侧公众号参与; 怎么参与？该签到计划会在恒宇少年的微信公众号“程序员恒宇少年”中进行，微信扫码下方二维码即可关注，关注后请根据下面的签到日程留意公众号发文内容。 签到日程 签到计划名称 开始时间 结束时间 奖品 参与人数 中奖名单 自律改变人生第二期 2019-12-19 2019-12-26 《极客时间：程序员的数学基础课》 - - 自律改变人生第一期 2019-12-9 2019-12-15 《实体书：码农翻身 - 用故事给技术加点料》 61 中奖名单公布","link":"/welfare/index.html"},{"title":"我的2019年余额已经不足了~","text":"我的2019年余额已经不足了~ 最近看到大家都在纷纷总结自己的2019，我想我也应该把这一年的心酸履历总结下。 虽然一年只有365天，但是我感觉这一年我过成了500天，每一天的事情都是那么的饱和，感觉每一天有忙不完的事情，虽然提前做了规划，但是还是显得那么的举足无措，每到晚上睡觉时脑子里完全是一团浆糊在左右摇晃，我知道这是我的身体在向我宣告他的不满！！！ 工作变迁由于业界内被传的沸沸扬扬的互联网寒冬来临，在今年年初时，我曾受着公司拖欠工资的事情而无法自拔，一度想离开，但是每一次我都放弃了，想着陪着公司度过难关。 直到2019年5月份由于公司的运营不得当，我还是拍拍屁股走人了，经我朋友介绍我来到了一家相对来说比较稳定的公司，我也如愿的负责着自己喜欢的方向，从公司微服务的选型、落地、测试、实施、上线运营每一步都在用心的做着，偶尔也看看前端的一些编程语言，弥补下自己纯Java后台的知识漏洞。 拥抱开源在2018年也曾想过写开源框架，毕竟这是对自己技术的总结以及提升的平台，也可以为咱国人的开源做一点微乎其微的贡献，但是我并没有敲出一行代码，我放弃了！！！ 直到今年3月份，我想我不能再拖了，我要开始敲出属于我开源框架的第一行代码，不能被拖延症害了我这个有着一腔开源热血的好少年，终于，我默默的在Gitee、GitHub创建了一个名为ApiBoot的公开仓库。 命名我为什么选择使用ApiBoot作为这一开源项目的名字呢？ 在最近几年的后端技术发展中，开发者往往把一大堆复杂、不易整合的框架融入到自己的项目中，但是这不是一件容易的事情，为此失去的不仅仅是时间。 那我的想法是这个框架提供给后端开发者使用，一般用于快速构建前后端分离的服务、管理后台所需的接口，既然都跟接口有关，那我是不是可以在名称中加入Service、Interface、Api等关键词进行组合，由于是基于SpringBoot封装的第三方框架的Starter，所以我想着把Boot关键词也加入名称。 经过组合我得到了ServiceBoot、InterfaceBoot、ApiBoot这些名称，想着让大家容易记忆、简短一些因此选择了ApiBoot。 定位该框架定位于组件化快速构建接口服务，可用于构建微服务架构中的单体服务。 我整理了目前主流使用的第三方框架，把每一个框架进行了封装，为每一个框架提供了一个SpringBoot Starter，顺带着为每一个Starter提供了一系列的配置参数，这样只需要简单配置就可以实现整合，从而告别了繁琐的整合步骤，极高的提高开发效率，让你跟你的白富美有更多的时间一起玩耍。 官网 &amp; 文档我想着既然写了框架是不是就得有官网跟文档，咱也不是那种耍流氓的人啊，肯定要有，这个一定要有！！！ 所以我又不分日夜的把每一个组件的详细配置参数、使用细节、功能特性都整了一遍，我都崩溃了，真是太多了，多到离谱，我感觉我写文章都没有这么累，我是真想知道Spring那群人是不是天天活在码文档的生活里？上了班就开始码一直到下班关灯走人，脑子里全是这个。 有兴趣的大哥就看看吧，好歹是我吐血编写的。 ApiBoot官网，独此一家，绝无分店：https://apiboot.minbox.org 折腾博客我今年终于想起来了我还有一个博客，它可能想我想的都得相思病了，而我却不知红豆已在南国长的遍地都是。 当我准备再次拥抱它时，我发现我的博客源码没有了，把我自己雷的外焦里嫩，可以直接把我装盘往外卖了。 但是我并没有放弃它，由于我的博客采用的Hexo进行构建部署的，所以我果断重新生成了一个新的，经过我一段时间的折腾总算是能看得过去了，我把我毕生所学的前端样式功底都拿出来了，美观度只能这样了，怎奈何我才疏学浅。 当我想着把近两年编写的文章重新发布到博客时，又一个问题把我难住了，由于我博客是用Markdown编写的文章，也用顺手了，习惯了这种行云流水的编写文章方式，可是我发现我的简书有接近30篇文章都是富文本编辑器写的，这….. 实在是没招了，索性旧的不去新的不来，我再写就是了。 欢迎大家访问一探究竟：https://blog.minbox.org 折腾公众号我的公众号毫不客气的说已经落灰了，我让它吃土太久了，我放弃它比我的博客还要早，感觉每次发版文章都要费劲巴拉的去排版，咱又不是那种美观度在线的人，这不是难为人嘛~ 折腾的心，颤抖的手，既然折腾了索性折腾到底，眼见博客恢复了以往的活力访问量日渐增长，我找到了尘封已久的公众号账号跟密码，登录了我的账号，我好激动，我发现我的粉丝们竟然没有放弃我，粉丝数竟然不是一个大鸭蛋。 我其实不懂什么公众号的运营，我只是把我写的一些技术文章通过公众号这个平台发表了出来，偶尔给粉丝们送个书、送个学习课程啥的，自律改变人生。 日更挑战我今年给自己定了一个小目标，每天更新一篇文章，如我所愿，我确实没有坚持下来，我自己也找过借口，一天天的多累啊、多忙啊，不得写ApiBoot吗？不得PS博客的图片吗？ 借口是有的，努力也是不可少的，临近2019年的年末时，我感觉我重生了，我竟然差不多保持住了原创日更，想想都有点小兴奋。 希望我在2020年可以保持住~ 自律改变人生想了想粉丝跟着我也是受了罪了，尤其是公众号上面的那群人，日盼夜盼着更新，我却无动于衷。 那我怎么才可以让他们变的人前显贵？让他们更爱学习呢？ 左思右想，绞尽脑汁…. 终于还是逃不过我自掏腰包的命运来给他们这群家伙谋福利，就这么办吧，咱也不是那种斤斤计较的人，于是乎我在博客专门添加了一篇文章来记录每一期的相关信息，取名为：《自律改变人生》，每一期的周期时间以及奖品内容都会在列出来，奖品肯定不能太过于寒酸，不过都是我推荐的，必免费赠送精品。 焦虑的时代，我们都不能很好的静下心来阅读一篇文章，一本书，不能从文章中汲取我们需要的更多的知识点。希望通过《自律改变人生》的签到计划来改变焦虑的你，希望大家不再焦虑、浮躁，走向人生巅峰，迎娶白富美。 来撸羊毛吧：https://blog.minbox.org/welfare 收获爱情都说程序员与单身狗更配，可是我感觉爱情跟我更配，来咬我呀~ 在2018年夏天我遇到了我一生中最爱的女人，当时一见钟情，看上一眼天仙一般的容颜感觉已经走不动道了，这辈子就她了，于是乎我发动了猛烈的追求进攻，终于功夫不负有心人，被我骗到手了。 我老婆对我平时做的事情特别支持，这一点我很欣慰，要知道一天的时间除了工作之外在家里的时间没有多少，我这是拿着赔她的时间来做这些事情。 遇到喜欢的就去追求，程序员也是需要春天的。 落幕你的2019过的怎么样呢？ 2019年虽然累，但是我也收获到了很多，这点让我很满足！！！ 我希望我的2020会更幸福、收获更多，我相信只要不断的努力就会有收获，其实并不在乎收获的多少，至少我努力过等老了坐着摇椅慢慢摇的时候不会后悔。","link":"/years/2019.html"}]}